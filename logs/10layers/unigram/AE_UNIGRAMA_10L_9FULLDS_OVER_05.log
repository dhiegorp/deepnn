[2017-11-18 20:36:34,473 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_9FULLDS_OVER_05
[2017-11-18 20:36:34,473 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 20:36:34,473 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_9FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42,25,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc14caf6eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc14cafb400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:36:34,473 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 20:36:36,645 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:36:36,645 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:36:36,646 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 20:36:36,646 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc14caf6eb8>, 'discard_decoder_function': True}
[2017-11-18 20:36:36,876 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 20:40:02,108 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 20:40:02,109 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0093140832994931411, 0.0084929277713779189, 0.0078776291816624391, 0.0074141915416627716, 0.0070583888518499765, 0.0067834488177129183, 0.0065695785425154331, 0.0063950722769809112, 0.0062524088973625099, 0.0061392495222115876, 0.0060488649038820414, 0.0059761924293331697, 0.0059175509166243551, 0.0058691096482699195, 0.00582650594977345, 0.0057887313251706362, 0.0057577546965741563, 0.0057325267011504406, 0.0057118236464959969, 0.005694830080888582, 0.0056807552743258173, 0.0056690478170148889, 0.0056592253921057198, 0.0056510378655562372, 0.0056441119853722034, 0.0056382685384443743, 0.0056333389707034246, 0.0056291379546044955, 0.0056255866350891541, 0.0056225516497424828, 0.0056199661795924751, 0.0056177442617001113, 0.005615843182466637, 0.0056142098739611797, 0.0056128073970587678, 0.0056116059649248297, 0.0056105817695350571, 0.005609693501034436, 0.0056089196769669187, 0.0056082605618233243, 0.0056076859992862747, 0.0056071818160363437, 0.00560675347807452, 0.005606379920260098, 0.0056060462086593259, 0.0056057754803574868, 0.0056055181305335261, 0.0056053039230897789, 0.0056051154664927428, 0.0056049479253779044, 0.0056048017857717441, 0.0056046750915888111, 0.0056045547771879914, 0.0056044446713969147, 0.0056043541461410044, 0.0056042713744621289, 0.0056041924359748543, 0.0056041250219626797, 0.0056040606255075244, 0.0056040032383585705, 0.0056039529230660573, 0.005603910838991393, 0.0056038676419331995, 0.0056038220932940622, 0.0056037915342079065, 0.0056037498060107311, 0.0056037192645515916, 0.005603680615092586, 0.005603655792744704, 0.0056036281498174365, 0.0056035933606750996, 0.0056035546730527465, 0.005603522203916746, 0.0056035027957156173, 0.005603469583849008, 0.0056034445385963758, 0.0056034163470068199, 0.0056033863633657499, 0.0056033600569257392, 0.0056033438942348947, 0.0056033208847315608, 0.0056032954349987917, 0.0056032708396629256, 0.0056032448920952851, 0.005603222340038707, 0.0056031996827334363, 0.0056031785214142532, 0.0056031581127515715, 0.00560313251139223, 0.0056031113297934209, 0.0056030943781652243, 0.0056030727557198597, 0.0056030514151356276, 0.0056030279575124556, 0.0056030028500518555, 0.0056029826259594417, 0.0056029573841570156, 0.0056029358524993444, 0.0056029198823365949, 0.0056028898745653375, 0.0056028666929846703], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098449828410005595, 0.0088901411107753531, 0.0081802180299369188, 0.0076473838597905554, 0.0072430371539695827, 0.0069311406517455522, 0.0066896550497606011, 0.0064993160543020219, 0.006340806512327846, 0.0062143008890664072, 0.0061136822421865048, 0.0060330939001222101, 0.0059681705848375708, 0.0059156193833135601, 0.0058700840095885949, 0.005830360660360326, 0.0057959050640630271, 0.0057679528907321857, 0.0057450832564846033, 0.00572629417283057, 0.005710796098054147, 0.0056978950728628587, 0.0056871623407838551, 0.0056781409524026324, 0.0056705926885622379, 0.0056642055215627941, 0.0056588095634543777, 0.0056542431938182919, 0.0056503518286539619, 0.0056470500333187798, 0.0056442298419541294, 0.0056418273738562891, 0.005639758733516952, 0.0056379880197483384, 0.0056364675030972826, 0.0056351576592259698, 0.0056340427426441846, 0.0056330830970948475, 0.0056322455800917924, 0.0056315332134321151, 0.0056309220689731033, 0.0056303820215102517, 0.0056299184186893239, 0.0056295164954980395, 0.0056291649730678779, 0.0056288648353062173, 0.0056286000825439119, 0.005628367024585303, 0.0056281709520330757, 0.0056279955513096778, 0.0056278419627051159, 0.0056277066702966243, 0.0056275831266475868, 0.0056274773337416113, 0.0056273795013745001, 0.0056273033850446456, 0.005627218757978854, 0.0056271423406010065, 0.0056270836047486164, 0.0056270360172744165, 0.0056269754771917334, 0.0056269260922318124, 0.0056268877215588349, 0.0056268446363725438, 0.0056267941994307905, 0.005626772044424749, 0.0056267300223088257, 0.0056266990159087801, 0.0056266720728278602, 0.0056266369419502773, 0.005626608145369391, 0.0056265821060040248, 0.005626558280973251, 0.0056265288276539102, 0.0056264938990563439, 0.0056264751422288369, 0.005626452662854586, 0.0056264254121525716, 0.0056263996848665756, 0.0056263833097876673, 0.0056263543543663835, 0.0056263365816177253, 0.0056263100126891048, 0.0056262909667594996, 0.0056262663214629678, 0.0056262461056358262, 0.0056262220914140796, 0.0056262048477714148, 0.0056261800174563998, 0.0056261636223724036, 0.005626142645094462, 0.0056261210106208059, 0.0056260917007093661, 0.0056260765965251095, 0.0056260542308369139, 0.0056260351027721343, 0.0056260053082803092, 0.0056259955553427327, 0.0056259726331701516, 0.005625942718762115, 0.0056259239200382371], 'acc': [0.59138333128027443, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822264767316, 0.59383822264767316, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427]}
[2017-11-18 20:40:02,109 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:95]: done!
[2017-11-18 20:40:02,109 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 20:40:02,109 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 20:40:02,110 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc14cafb400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:40:02,179 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 20:44:39,596 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:125]: trained!
[2017-11-18 20:44:39,598 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0093140832994931411, 0.0084929277713779189, 0.0078776291816624391, 0.0074141915416627716, 0.0070583888518499765, 0.0067834488177129183, 0.0065695785425154331, 0.0063950722769809112, 0.0062524088973625099, 0.0061392495222115876, 0.0060488649038820414, 0.0059761924293331697, 0.0059175509166243551, 0.0058691096482699195, 0.00582650594977345, 0.0057887313251706362, 0.0057577546965741563, 0.0057325267011504406, 0.0057118236464959969, 0.005694830080888582, 0.0056807552743258173, 0.0056690478170148889, 0.0056592253921057198, 0.0056510378655562372, 0.0056441119853722034, 0.0056382685384443743, 0.0056333389707034246, 0.0056291379546044955, 0.0056255866350891541, 0.0056225516497424828, 0.0056199661795924751, 0.0056177442617001113, 0.005615843182466637, 0.0056142098739611797, 0.0056128073970587678, 0.0056116059649248297, 0.0056105817695350571, 0.005609693501034436, 0.0056089196769669187, 0.0056082605618233243, 0.0056076859992862747, 0.0056071818160363437, 0.00560675347807452, 0.005606379920260098, 0.0056060462086593259, 0.0056057754803574868, 0.0056055181305335261, 0.0056053039230897789, 0.0056051154664927428, 0.0056049479253779044, 0.0056048017857717441, 0.0056046750915888111, 0.0056045547771879914, 0.0056044446713969147, 0.0056043541461410044, 0.0056042713744621289, 0.0056041924359748543, 0.0056041250219626797, 0.0056040606255075244, 0.0056040032383585705, 0.0056039529230660573, 0.005603910838991393, 0.0056038676419331995, 0.0056038220932940622, 0.0056037915342079065, 0.0056037498060107311, 0.0056037192645515916, 0.005603680615092586, 0.005603655792744704, 0.0056036281498174365, 0.0056035933606750996, 0.0056035546730527465, 0.005603522203916746, 0.0056035027957156173, 0.005603469583849008, 0.0056034445385963758, 0.0056034163470068199, 0.0056033863633657499, 0.0056033600569257392, 0.0056033438942348947, 0.0056033208847315608, 0.0056032954349987917, 0.0056032708396629256, 0.0056032448920952851, 0.005603222340038707, 0.0056031996827334363, 0.0056031785214142532, 0.0056031581127515715, 0.00560313251139223, 0.0056031113297934209, 0.0056030943781652243, 0.0056030727557198597, 0.0056030514151356276, 0.0056030279575124556, 0.0056030028500518555, 0.0056029826259594417, 0.0056029573841570156, 0.0056029358524993444, 0.0056029198823365949, 0.0056028898745653375, 0.0056028666929846703], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098449828410005595, 0.0088901411107753531, 0.0081802180299369188, 0.0076473838597905554, 0.0072430371539695827, 0.0069311406517455522, 0.0066896550497606011, 0.0064993160543020219, 0.006340806512327846, 0.0062143008890664072, 0.0061136822421865048, 0.0060330939001222101, 0.0059681705848375708, 0.0059156193833135601, 0.0058700840095885949, 0.005830360660360326, 0.0057959050640630271, 0.0057679528907321857, 0.0057450832564846033, 0.00572629417283057, 0.005710796098054147, 0.0056978950728628587, 0.0056871623407838551, 0.0056781409524026324, 0.0056705926885622379, 0.0056642055215627941, 0.0056588095634543777, 0.0056542431938182919, 0.0056503518286539619, 0.0056470500333187798, 0.0056442298419541294, 0.0056418273738562891, 0.005639758733516952, 0.0056379880197483384, 0.0056364675030972826, 0.0056351576592259698, 0.0056340427426441846, 0.0056330830970948475, 0.0056322455800917924, 0.0056315332134321151, 0.0056309220689731033, 0.0056303820215102517, 0.0056299184186893239, 0.0056295164954980395, 0.0056291649730678779, 0.0056288648353062173, 0.0056286000825439119, 0.005628367024585303, 0.0056281709520330757, 0.0056279955513096778, 0.0056278419627051159, 0.0056277066702966243, 0.0056275831266475868, 0.0056274773337416113, 0.0056273795013745001, 0.0056273033850446456, 0.005627218757978854, 0.0056271423406010065, 0.0056270836047486164, 0.0056270360172744165, 0.0056269754771917334, 0.0056269260922318124, 0.0056268877215588349, 0.0056268446363725438, 0.0056267941994307905, 0.005626772044424749, 0.0056267300223088257, 0.0056266990159087801, 0.0056266720728278602, 0.0056266369419502773, 0.005626608145369391, 0.0056265821060040248, 0.005626558280973251, 0.0056265288276539102, 0.0056264938990563439, 0.0056264751422288369, 0.005626452662854586, 0.0056264254121525716, 0.0056263996848665756, 0.0056263833097876673, 0.0056263543543663835, 0.0056263365816177253, 0.0056263100126891048, 0.0056262909667594996, 0.0056262663214629678, 0.0056262461056358262, 0.0056262220914140796, 0.0056262048477714148, 0.0056261800174563998, 0.0056261636223724036, 0.005626142645094462, 0.0056261210106208059, 0.0056260917007093661, 0.0056260765965251095, 0.0056260542308369139, 0.0056260351027721343, 0.0056260053082803092, 0.0056259955553427327, 0.0056259726331701516, 0.005625942718762115, 0.0056259239200382371], 'acc': [0.59138333128027443, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822264767316, 0.59383822264767316, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427]}
[2017-11-18 20:44:39,598 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 20:44:39,838 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 20:44:39,838 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 20:44:40,680 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:141]: done!
[2017-11-18 20:44:40,680 AE_UNIGRAMA_10L_9FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_10L_9FULLDS_OVER_05 finished!
