[2018-07-21 00:52:16,527 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_01
[2018-07-21 00:52:16,527 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-07-21 00:52:16,527 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_01
	layers = 96,144,130,117,103,90,76,63,49,36,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2737903668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2737903e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,527 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,501 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,501 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,502 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:57]: =======================================
[2018-07-21 00:52:18,502 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2737903668>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,893 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-07-21 01:16:32,138 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_01
[2018-07-21 01:16:32,138 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-07-21 01:16:32,138 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_01
	layers = 96,144,130,117,103,90,76,63,49,36,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f61f1079668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f61f1079e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 01:16:32,139 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-07-21 01:16:34,003 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 01:16:34,003 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-07-21 01:16:34,004 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:57]: =======================================
[2018-07-21 01:16:34,004 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f61f1079668>, 'discard_decoder_function': True}
[2018-07-21 01:16:34,442 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-07-21 01:18:50,120 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_01
[2018-07-21 01:18:50,120 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-07-21 01:18:50,120 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_01
	layers = 96,144,130,117,103,90,76,63,49,36,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9a475ac668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9a475ace48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 01:18:50,120 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-07-21 01:18:52,149 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 01:18:52,150 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-07-21 01:18:52,150 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:57]: =======================================
[2018-07-21 01:18:52,150 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9a475ac668>, 'discard_decoder_function': True}
[2018-07-21 01:18:52,529 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-07-21 01:21:48,965 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:85]: trained and evaluated!
[2018-07-21 01:21:48,966 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:88]: Training history: 
{'val_loss': [0.009861209907270187, 0.009471808639257456, 0.009195400086374941, 0.008996170063087911, 0.008850077626824883, 0.00874111727489318, 0.008658497610725997, 0.008594990550488705, 0.008545408504222715, 0.00850600858610185, 0.008474402826173982, 0.008448925396055804, 0.008428006866267063, 0.008410658483016649, 0.008396128815137061, 0.008383918162373685, 0.008373586562945097, 0.008364782187073207, 0.008357240335494882, 0.008350779475950223, 0.008345219961072167, 0.008340429007741446, 0.008336277683058432, 0.008332680889947127, 0.00832954603591328, 0.008326829240295607, 0.008324456175269668, 0.008322388300989117, 0.008320579499359496, 0.008318999630920329, 0.008317612226229627, 0.008316395011241385, 0.008315328852941296, 0.008314385624429247, 0.008313552775611579, 0.008312818742138482, 0.00831217074356713, 0.00831158987894375, 0.008311077716901696, 0.008310616470925382, 0.008310211388389445, 0.00830983917835726, 0.008309507055583901, 0.008309220200016388, 0.008308951589266898, 0.008308705193350328, 0.008308477841799573, 0.008308265450965368, 0.008308065060535717, 0.00830785163775092, 0.008307675445279142, 0.008307495317019683, 0.008307335813738917, 0.008307175883987028, 0.008307002261294704, 0.008306821894471543, 0.008306624390080829, 0.008306396774295958, 0.008306156761413087, 0.008305917351613781, 0.008305673675049604, 0.008305407100477252, 0.008305133717769168, 0.008304867223288505, 0.008304614070577027, 0.008304356224971828, 0.008304087178509865, 0.008303818621497105, 0.008303567361208455, 0.008303297721588821, 0.008303040746039478, 0.008302809798577305, 0.008302591746561408, 0.008302376168831027, 0.00830215824277129, 0.008301920238683785, 0.008301681184505263, 0.008301442236773388, 0.008301167703003995, 0.008300888383242848, 0.008300609869532662, 0.008300316928708237, 0.008300013531811291, 0.008299677331549571, 0.008299302468223526, 0.00829892920262397, 0.008298560388958529, 0.008298175908811323, 0.008297799986495182, 0.008297409652467051, 0.00829701937183338, 0.008296564874095169, 0.008296012871230253, 0.00829544236410501, 0.008294855751705077, 0.00829428886684621, 0.00829368263985503, 0.0082930798054656, 0.008292524656092625, 0.008292022293987343, 0.008291606870040063], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.01012418040454962, 0.009656268515482012, 0.009327425243753889, 0.009092395390610585, 0.008921695053732892, 0.008795525846774005, 0.008700751365250798, 0.008628416447396679, 0.00857240631154425, 0.00852834505701308, 0.008493160733609489, 0.00846489254436446, 0.008441893844091924, 0.00842293615407105, 0.008407129763338746, 0.008393868437370442, 0.008382694662779631, 0.008373208583472177, 0.008365115299990086, 0.008358172856740415, 0.008352219147523777, 0.008347081346157264, 0.008342650159187474, 0.008338807259892172, 0.008335470986245373, 0.008332573722879244, 0.008330051199390951, 0.008327844995322608, 0.008325921471947554, 0.008324241857919478, 0.008322766327452474, 0.00832147556672023, 0.008320344253854143, 0.008319348963124995, 0.008318468789558945, 0.008317695063636818, 0.008317010843678458, 0.00831640065249046, 0.008315856026434578, 0.008315371483545171, 0.008314941484927839, 0.008314555778032221, 0.008314210077539878, 0.008313897933238917, 0.008313616877530336, 0.008313364037569203, 0.008313124296025065, 0.008312903076905962, 0.008312695526977587, 0.008312482398258948, 0.008312289422894418, 0.008312110412910231, 0.008311936754458512, 0.008311772703021542, 0.008311604478180306, 0.00831142680727954, 0.008311239888198145, 0.008311024816585374, 0.008310783979562626, 0.008310542603317025, 0.008310293786893472, 0.008310031352835161, 0.008309754131015926, 0.00830948566067957, 0.008309221770022236, 0.00830896844479483, 0.008308704432163617, 0.008308439960444216, 0.00830817424932389, 0.008307916596138625, 0.008307656668146245, 0.00830741019843381, 0.008307189737564693, 0.008306974515285033, 0.008306754373468488, 0.008306526007846125, 0.00830628924928921, 0.008306047922370441, 0.00830579226112035, 0.008305516630448644, 0.008305235178410692, 0.008304946177024168, 0.00830464378663246, 0.008304314573533304, 0.008303966204190771, 0.008303581082358237, 0.00830320456688596, 0.00830282702006567, 0.008302447487883306, 0.008302060572394597, 0.008301671966475965, 0.008301260673873217, 0.008300746073282187, 0.008300175879923854, 0.008299598362988653, 0.008299019244388962, 0.008298446062384822, 0.00829782901619627, 0.008297272973122447, 0.008296725618544058, 0.00829627423368763], 'acc': [0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373]}
[2018-07-21 01:21:48,966 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:92]: done!
[2018-07-21 01:21:48,967 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:152]: >> Executing classifier part ... 
[2018-07-21 01:21:48,967 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:97]: =======================================
[2018-07-21 01:21:48,967 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9a475ace48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 01:21:49,009 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:110]: training ... 
[2018-07-21 01:29:14,036 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:122]: trained!
[2018-07-21 01:29:14,037 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:125]: Training history: 
{'val_loss': [0.009861209907270187, 0.009471808639257456, 0.009195400086374941, 0.008996170063087911, 0.008850077626824883, 0.00874111727489318, 0.008658497610725997, 0.008594990550488705, 0.008545408504222715, 0.00850600858610185, 0.008474402826173982, 0.008448925396055804, 0.008428006866267063, 0.008410658483016649, 0.008396128815137061, 0.008383918162373685, 0.008373586562945097, 0.008364782187073207, 0.008357240335494882, 0.008350779475950223, 0.008345219961072167, 0.008340429007741446, 0.008336277683058432, 0.008332680889947127, 0.00832954603591328, 0.008326829240295607, 0.008324456175269668, 0.008322388300989117, 0.008320579499359496, 0.008318999630920329, 0.008317612226229627, 0.008316395011241385, 0.008315328852941296, 0.008314385624429247, 0.008313552775611579, 0.008312818742138482, 0.00831217074356713, 0.00831158987894375, 0.008311077716901696, 0.008310616470925382, 0.008310211388389445, 0.00830983917835726, 0.008309507055583901, 0.008309220200016388, 0.008308951589266898, 0.008308705193350328, 0.008308477841799573, 0.008308265450965368, 0.008308065060535717, 0.00830785163775092, 0.008307675445279142, 0.008307495317019683, 0.008307335813738917, 0.008307175883987028, 0.008307002261294704, 0.008306821894471543, 0.008306624390080829, 0.008306396774295958, 0.008306156761413087, 0.008305917351613781, 0.008305673675049604, 0.008305407100477252, 0.008305133717769168, 0.008304867223288505, 0.008304614070577027, 0.008304356224971828, 0.008304087178509865, 0.008303818621497105, 0.008303567361208455, 0.008303297721588821, 0.008303040746039478, 0.008302809798577305, 0.008302591746561408, 0.008302376168831027, 0.00830215824277129, 0.008301920238683785, 0.008301681184505263, 0.008301442236773388, 0.008301167703003995, 0.008300888383242848, 0.008300609869532662, 0.008300316928708237, 0.008300013531811291, 0.008299677331549571, 0.008299302468223526, 0.00829892920262397, 0.008298560388958529, 0.008298175908811323, 0.008297799986495182, 0.008297409652467051, 0.00829701937183338, 0.008296564874095169, 0.008296012871230253, 0.00829544236410501, 0.008294855751705077, 0.00829428886684621, 0.00829368263985503, 0.0082930798054656, 0.008292524656092625, 0.008292022293987343, 0.008291606870040063], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.01012418040454962, 0.009656268515482012, 0.009327425243753889, 0.009092395390610585, 0.008921695053732892, 0.008795525846774005, 0.008700751365250798, 0.008628416447396679, 0.00857240631154425, 0.00852834505701308, 0.008493160733609489, 0.00846489254436446, 0.008441893844091924, 0.00842293615407105, 0.008407129763338746, 0.008393868437370442, 0.008382694662779631, 0.008373208583472177, 0.008365115299990086, 0.008358172856740415, 0.008352219147523777, 0.008347081346157264, 0.008342650159187474, 0.008338807259892172, 0.008335470986245373, 0.008332573722879244, 0.008330051199390951, 0.008327844995322608, 0.008325921471947554, 0.008324241857919478, 0.008322766327452474, 0.00832147556672023, 0.008320344253854143, 0.008319348963124995, 0.008318468789558945, 0.008317695063636818, 0.008317010843678458, 0.00831640065249046, 0.008315856026434578, 0.008315371483545171, 0.008314941484927839, 0.008314555778032221, 0.008314210077539878, 0.008313897933238917, 0.008313616877530336, 0.008313364037569203, 0.008313124296025065, 0.008312903076905962, 0.008312695526977587, 0.008312482398258948, 0.008312289422894418, 0.008312110412910231, 0.008311936754458512, 0.008311772703021542, 0.008311604478180306, 0.00831142680727954, 0.008311239888198145, 0.008311024816585374, 0.008310783979562626, 0.008310542603317025, 0.008310293786893472, 0.008310031352835161, 0.008309754131015926, 0.00830948566067957, 0.008309221770022236, 0.00830896844479483, 0.008308704432163617, 0.008308439960444216, 0.00830817424932389, 0.008307916596138625, 0.008307656668146245, 0.00830741019843381, 0.008307189737564693, 0.008306974515285033, 0.008306754373468488, 0.008306526007846125, 0.00830628924928921, 0.008306047922370441, 0.00830579226112035, 0.008305516630448644, 0.008305235178410692, 0.008304946177024168, 0.00830464378663246, 0.008304314573533304, 0.008303966204190771, 0.008303581082358237, 0.00830320456688596, 0.00830282702006567, 0.008302447487883306, 0.008302060572394597, 0.008301671966475965, 0.008301260673873217, 0.008300746073282187, 0.008300175879923854, 0.008299598362988653, 0.008299019244388962, 0.008298446062384822, 0.00829782901619627, 0.008297272973122447, 0.008296725618544058, 0.00829627423368763], 'acc': [0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373]}
[2018-07-21 01:29:14,037 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:129]: evaluating model ... 
[2018-07-21 01:29:14,203 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:133]: evaluated! 
[2018-07-21 01:29:14,203 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:135]: generating reports ... 
[2018-07-21 01:29:15,206 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:138]: done!
[2018-07-21 01:29:15,206 AE_UNIGRAMA_10L_FULLDS_OVER_01.py:154]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_01 finished!
