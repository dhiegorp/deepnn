[2017-11-13 01:21:22,952 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_MINIDS_UNDER_01
[2017-11-13 01:21:22,952 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:149]: >> Printing header log
[2017-11-13 01:21:22,952 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_MINIDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17,15,13,11
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f33bcc5deb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f33bcc62400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 01:21:22,952 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-13 01:21:23,587 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-13 01:21:23,587 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-13 01:21:23,587 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:60]: =======================================
[2017-11-13 01:21:23,587 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f33bcc5deb8>, 'discard_decoder_function': True}
[2017-11-13 01:21:23,820 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-13 01:22:36,583 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-13 01:22:36,583 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010242486919612246, 0.010074978098827224, 0.0099155511568580854, 0.0097636622947997326, 0.0096189657565497119, 0.0094809880286288971, 0.0093493663453147312, 0.009223727014289692, 0.0091038369833315175, 0.0089892696062982298, 0.008879784612352077, 0.0087751072786443739, 0.0086749664899031034, 0.008579094181024231, 0.0084873745598757575, 0.008399571191699531, 0.0083154339315612072, 0.008234785869717598, 0.0081574290741553545, 0.0080832614282970085, 0.0080121223551660892, 0.007943797383983672, 0.0078781748720233545, 0.0078151487125616981, 0.0077546362585100767, 0.007696435270921005, 0.0076405042315033514, 0.0075866917120535138, 0.0075349547419018463, 0.007485135018714742, 0.0074371495838086625, 0.0073909492813549298, 0.007346451486768997, 0.0073036087562631273, 0.0072622869032189308, 0.0072224271591046487, 0.0071839991711135469, 0.0071469500875550578, 0.0071111881039122669, 0.0070766840531701937, 0.0070433407540685848, 0.0070111727702074781, 0.0069798216687646944, 0.0069490773343657691, 0.0069193926477133117, 0.0068906985212906805, 0.0068629434276856896, 0.00683610748021853, 0.0068101345485277118, 0.0067850084348709833, 0.0067606861824273624, 0.0067371616458527222, 0.0067143768788796594, 0.0066923096284381076, 0.0066709537301420279, 0.0066502561003357503, 0.0066301963278213617, 0.0066107520106556692, 0.0065919006430305068, 0.0065736315078119365, 0.0065559022073187348, 0.0065387331146649933, 0.0065220641058810801, 0.0065058859491021435, 0.0064902002784703967, 0.0064749735542555722, 0.0064601919918449175, 0.0064458499756056579, 0.0064319433838295227, 0.006418434395818351, 0.006405294154420994, 0.006392571794693133, 0.0063801962695323403, 0.0063681712124815217, 0.0063564849248827614, 0.0063451240583561833, 0.006334092727685728, 0.0063233823674734421, 0.0063129485062008456, 0.0063028169629686824, 0.0062929631165855437, 0.0062833799146198872, 0.0062740606041175057, 0.0062650003293909995, 0.0062561786723181216, 0.0062476037482152866, 0.0062392630396223862, 0.0062311648003424633, 0.0062232730619360081, 0.0062155820287376311, 0.0062081110750266165, 0.0062006110979804987, 0.0061930921101824941, 0.0061857730105214625, 0.0061786329117517044, 0.0061716945620329854, 0.0061649437353264221, 0.0061583939704310054, 0.0061520016077061127, 0.0061457803902185094, 0.0061397317634223781], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010324903178820415, 0.010152736034750316, 0.0099886774108931195, 0.0098324654195698115, 0.0096835625617230827, 0.0095416579662278966, 0.0094062895694382361, 0.0092770914611828501, 0.0091537273052184585, 0.0090359300472295651, 0.0089233422367968069, 0.0088156939603814179, 0.0087127313578813891, 0.0086141772512128983, 0.0085197968617970032, 0.008429455555421338, 0.0083429387987539235, 0.0082599998416851908, 0.0081804659917089715, 0.0081041391009319466, 0.0080309247892274404, 0.0079606658113363631, 0.0078931685234291202, 0.0078282991390430309, 0.007765972772733375, 0.0077060909521638361, 0.0076485013107860204, 0.0075930959339578167, 0.007539793824949877, 0.0074885046033998101, 0.0074390939639488573, 0.0073914867968910411, 0.0073456211040196021, 0.0073014271323075123, 0.0072588542262784859, 0.007217765047908122, 0.0071781220778332913, 0.0071398796612132378, 0.0071029894288054587, 0.0070673567039712341, 0.0070329670348967706, 0.0069997179514849264, 0.0069675796814652113, 0.0069359907540982131, 0.0069052916004127274, 0.0068756424848816847, 0.0068469606405759447, 0.0068192023256726077, 0.0067923504955947544, 0.0067663451573126291, 0.0067411748264225337, 0.0067167968286594038, 0.0066932036816734954, 0.0066703429738129471, 0.0066481925742889591, 0.0066267347424654559, 0.0066059356336106937, 0.0065857583771962913, 0.0065661913554453744, 0.006547218336040851, 0.00652880877852852, 0.0065109447585264268, 0.0064936203171728612, 0.0064768080946490782, 0.006460470779665552, 0.006444631412009392, 0.006429231142912566, 0.0064142863609620267, 0.0063997697235115411, 0.006385684721446616, 0.0063720053163733156, 0.0063586791859368422, 0.0063457687387669937, 0.0063331953367789648, 0.0063209931724478698, 0.0063091138210067477, 0.0062975551184328623, 0.006286340207262188, 0.0062754257592431556, 0.0062647959278677784, 0.0062544641028299749, 0.0062444175409809097, 0.0062346319417848715, 0.0062251093453363033, 0.0062158447375478708, 0.0062068301721257928, 0.0061980496920855882, 0.0061895080387578578, 0.0061812086546588658, 0.0061731172714682356, 0.0061652249500347778, 0.0061574984386508352, 0.0061496300187783882, 0.0061419173364184645, 0.006134393333601087, 0.0061270765434737655, 0.006119943476615779, 0.006112996381195176, 0.0061062580883530435, 0.0060996775510798185, 0.0060932727106437594], 'acc': [0.55623847616180444, 0.5888137674873859, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376772551131, 0.58881376737748181, 0.5888137681468103, 0.5888137674873859, 0.58881376785373274, 0.58881376785373274, 0.58881376811017561, 0.58881376726757773, 0.58881376774382865, 0.58881376785373274, 0.58881376737748181, 0.5888137681468103, 0.58881376800027152, 0.58881376811017561, 0.58881376800027152, 0.58881376774382865, 0.58881376737748181, 0.58881376772551131, 0.58881376811017561, 0.58881376737748181, 0.58881376800027152, 0.58881376737748181, 0.5888137674873859, 0.5888137674873859, 0.58881376737748181, 0.58881376811017561, 0.58881376737748181, 0.5888137674873859, 0.58881376811017561, 0.58881376737748181, 0.58881376811017561, 0.58881376726757773, 0.58881376763392457, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.58881376737748181, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376774382865, 0.58881376772551131, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.58881376737748181, 0.58881376800027152, 0.58881376737748181, 0.58881376737748181, 0.58881376763392457, 0.58881376774382865, 0.58881376772551131, 0.58881376772551131, 0.58881376789036743, 0.58881376746906855, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376811017561, 0.58881376772551131, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376726757773, 0.58881376737748181, 0.58881376800027152, 0.58881376772551131, 0.58881376800027152, 0.58881376789036743, 0.58881376737748181, 0.58881376811017561, 0.58881376759728987, 0.58881376811017561, 0.58881376800027152, 0.5888137674873859, 0.58881376785373274, 0.58881376772551131, 0.58881376774382865, 0.58881376737748181, 0.58881376737748181]}
[2017-11-13 01:22:36,583 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:95]: done!
[2017-11-13 01:22:36,583 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-13 01:22:36,583 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:100]: =======================================
[2017-11-13 01:22:36,584 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f33bcc62400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 01:22:36,617 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:113]: training ... 
[2017-11-13 01:24:53,606 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:125]: trained!
[2017-11-13 01:24:53,608 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010242486919612246, 0.010074978098827224, 0.0099155511568580854, 0.0097636622947997326, 0.0096189657565497119, 0.0094809880286288971, 0.0093493663453147312, 0.009223727014289692, 0.0091038369833315175, 0.0089892696062982298, 0.008879784612352077, 0.0087751072786443739, 0.0086749664899031034, 0.008579094181024231, 0.0084873745598757575, 0.008399571191699531, 0.0083154339315612072, 0.008234785869717598, 0.0081574290741553545, 0.0080832614282970085, 0.0080121223551660892, 0.007943797383983672, 0.0078781748720233545, 0.0078151487125616981, 0.0077546362585100767, 0.007696435270921005, 0.0076405042315033514, 0.0075866917120535138, 0.0075349547419018463, 0.007485135018714742, 0.0074371495838086625, 0.0073909492813549298, 0.007346451486768997, 0.0073036087562631273, 0.0072622869032189308, 0.0072224271591046487, 0.0071839991711135469, 0.0071469500875550578, 0.0071111881039122669, 0.0070766840531701937, 0.0070433407540685848, 0.0070111727702074781, 0.0069798216687646944, 0.0069490773343657691, 0.0069193926477133117, 0.0068906985212906805, 0.0068629434276856896, 0.00683610748021853, 0.0068101345485277118, 0.0067850084348709833, 0.0067606861824273624, 0.0067371616458527222, 0.0067143768788796594, 0.0066923096284381076, 0.0066709537301420279, 0.0066502561003357503, 0.0066301963278213617, 0.0066107520106556692, 0.0065919006430305068, 0.0065736315078119365, 0.0065559022073187348, 0.0065387331146649933, 0.0065220641058810801, 0.0065058859491021435, 0.0064902002784703967, 0.0064749735542555722, 0.0064601919918449175, 0.0064458499756056579, 0.0064319433838295227, 0.006418434395818351, 0.006405294154420994, 0.006392571794693133, 0.0063801962695323403, 0.0063681712124815217, 0.0063564849248827614, 0.0063451240583561833, 0.006334092727685728, 0.0063233823674734421, 0.0063129485062008456, 0.0063028169629686824, 0.0062929631165855437, 0.0062833799146198872, 0.0062740606041175057, 0.0062650003293909995, 0.0062561786723181216, 0.0062476037482152866, 0.0062392630396223862, 0.0062311648003424633, 0.0062232730619360081, 0.0062155820287376311, 0.0062081110750266165, 0.0062006110979804987, 0.0061930921101824941, 0.0061857730105214625, 0.0061786329117517044, 0.0061716945620329854, 0.0061649437353264221, 0.0061583939704310054, 0.0061520016077061127, 0.0061457803902185094, 0.0061397317634223781], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010324903178820415, 0.010152736034750316, 0.0099886774108931195, 0.0098324654195698115, 0.0096835625617230827, 0.0095416579662278966, 0.0094062895694382361, 0.0092770914611828501, 0.0091537273052184585, 0.0090359300472295651, 0.0089233422367968069, 0.0088156939603814179, 0.0087127313578813891, 0.0086141772512128983, 0.0085197968617970032, 0.008429455555421338, 0.0083429387987539235, 0.0082599998416851908, 0.0081804659917089715, 0.0081041391009319466, 0.0080309247892274404, 0.0079606658113363631, 0.0078931685234291202, 0.0078282991390430309, 0.007765972772733375, 0.0077060909521638361, 0.0076485013107860204, 0.0075930959339578167, 0.007539793824949877, 0.0074885046033998101, 0.0074390939639488573, 0.0073914867968910411, 0.0073456211040196021, 0.0073014271323075123, 0.0072588542262784859, 0.007217765047908122, 0.0071781220778332913, 0.0071398796612132378, 0.0071029894288054587, 0.0070673567039712341, 0.0070329670348967706, 0.0069997179514849264, 0.0069675796814652113, 0.0069359907540982131, 0.0069052916004127274, 0.0068756424848816847, 0.0068469606405759447, 0.0068192023256726077, 0.0067923504955947544, 0.0067663451573126291, 0.0067411748264225337, 0.0067167968286594038, 0.0066932036816734954, 0.0066703429738129471, 0.0066481925742889591, 0.0066267347424654559, 0.0066059356336106937, 0.0065857583771962913, 0.0065661913554453744, 0.006547218336040851, 0.00652880877852852, 0.0065109447585264268, 0.0064936203171728612, 0.0064768080946490782, 0.006460470779665552, 0.006444631412009392, 0.006429231142912566, 0.0064142863609620267, 0.0063997697235115411, 0.006385684721446616, 0.0063720053163733156, 0.0063586791859368422, 0.0063457687387669937, 0.0063331953367789648, 0.0063209931724478698, 0.0063091138210067477, 0.0062975551184328623, 0.006286340207262188, 0.0062754257592431556, 0.0062647959278677784, 0.0062544641028299749, 0.0062444175409809097, 0.0062346319417848715, 0.0062251093453363033, 0.0062158447375478708, 0.0062068301721257928, 0.0061980496920855882, 0.0061895080387578578, 0.0061812086546588658, 0.0061731172714682356, 0.0061652249500347778, 0.0061574984386508352, 0.0061496300187783882, 0.0061419173364184645, 0.006134393333601087, 0.0061270765434737655, 0.006119943476615779, 0.006112996381195176, 0.0061062580883530435, 0.0060996775510798185, 0.0060932727106437594], 'acc': [0.55623847616180444, 0.5888137674873859, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376772551131, 0.58881376737748181, 0.5888137681468103, 0.5888137674873859, 0.58881376785373274, 0.58881376785373274, 0.58881376811017561, 0.58881376726757773, 0.58881376774382865, 0.58881376785373274, 0.58881376737748181, 0.5888137681468103, 0.58881376800027152, 0.58881376811017561, 0.58881376800027152, 0.58881376774382865, 0.58881376737748181, 0.58881376772551131, 0.58881376811017561, 0.58881376737748181, 0.58881376800027152, 0.58881376737748181, 0.5888137674873859, 0.5888137674873859, 0.58881376737748181, 0.58881376811017561, 0.58881376737748181, 0.5888137674873859, 0.58881376811017561, 0.58881376737748181, 0.58881376811017561, 0.58881376726757773, 0.58881376763392457, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.58881376737748181, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376774382865, 0.58881376772551131, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.58881376737748181, 0.58881376800027152, 0.58881376737748181, 0.58881376737748181, 0.58881376763392457, 0.58881376774382865, 0.58881376772551131, 0.58881376772551131, 0.58881376789036743, 0.58881376746906855, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376811017561, 0.58881376772551131, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376726757773, 0.58881376737748181, 0.58881376800027152, 0.58881376772551131, 0.58881376800027152, 0.58881376789036743, 0.58881376737748181, 0.58881376811017561, 0.58881376759728987, 0.58881376811017561, 0.58881376800027152, 0.5888137674873859, 0.58881376785373274, 0.58881376772551131, 0.58881376774382865, 0.58881376737748181, 0.58881376737748181]}
[2017-11-13 01:24:53,608 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-13 01:24:53,682 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:136]: evaluated! 
[2017-11-13 01:24:53,682 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:138]: generating reports ... 
[2017-11-13 01:24:54,370 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:141]: done!
[2017-11-13 01:24:54,370 AE_UNIGRAMA_10L_MINIDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_10L_MINIDS_UNDER_01 finished!
