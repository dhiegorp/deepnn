[2017-10-20 01:40:16,803 AE_UNIGRAMA_10L_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_OVER_04
[2017-10-20 01:40:16,803 AE_UNIGRAMA_10L_OVER_04.py:149]: >> Printing header log
[2017-10-20 01:40:16,804 AE_UNIGRAMA_10L_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,34,22,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6e53f9bb70>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6e53f9bcf8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:40:16,804 AE_UNIGRAMA_10L_OVER_04.py:151]: >> Loading dataset... 
[2017-10-20 01:40:17,433 AE_UNIGRAMA_10L_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:40:17,433 AE_UNIGRAMA_10L_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:40:17,433 AE_UNIGRAMA_10L_OVER_04.py:60]: =======================================
[2017-10-20 01:40:17,433 AE_UNIGRAMA_10L_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6e53f9bb70>, 'discard_decoder_function': True}
[2017-10-20 01:40:17,667 AE_UNIGRAMA_10L_OVER_04.py:76]: training and evaluate autoencoder
[2017-10-21 21:18:47,558 AE_UNIGRAMA_10L_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_OVER_04
[2017-10-21 21:18:47,558 AE_UNIGRAMA_10L_OVER_04.py:149]: >> Printing header log
[2017-10-21 21:18:47,558 AE_UNIGRAMA_10L_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,34,22,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc875b6f710>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc875b6f7f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 21:18:47,558 AE_UNIGRAMA_10L_OVER_04.py:151]: >> Loading dataset... 
[2017-10-21 21:18:48,099 AE_UNIGRAMA_10L_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 21:18:48,099 AE_UNIGRAMA_10L_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-10-21 21:18:48,099 AE_UNIGRAMA_10L_OVER_04.py:60]: =======================================
[2017-10-21 21:18:48,099 AE_UNIGRAMA_10L_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc875b6f710>, 'discard_decoder_function': True}
[2017-10-21 21:18:48,306 AE_UNIGRAMA_10L_OVER_04.py:76]: training and evaluate autoencoder
[2017-10-21 21:23:08,130 AE_UNIGRAMA_10L_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_OVER_04
[2017-10-21 21:23:08,131 AE_UNIGRAMA_10L_OVER_04.py:149]: >> Printing header log
[2017-10-21 21:23:08,131 AE_UNIGRAMA_10L_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,34,22,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f011bf21710>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f011bf217f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 21:23:08,131 AE_UNIGRAMA_10L_OVER_04.py:151]: >> Loading dataset... 
[2017-10-21 21:23:08,657 AE_UNIGRAMA_10L_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 21:23:08,657 AE_UNIGRAMA_10L_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-10-21 21:23:08,657 AE_UNIGRAMA_10L_OVER_04.py:60]: =======================================
[2017-10-21 21:23:08,657 AE_UNIGRAMA_10L_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f011bf21710>, 'discard_decoder_function': True}
[2017-10-21 21:23:08,865 AE_UNIGRAMA_10L_OVER_04.py:76]: training and evaluate autoencoder
[2017-10-21 21:24:12,848 AE_UNIGRAMA_10L_OVER_04.py:88]: trained and evaluated!
[2017-10-21 21:24:12,849 AE_UNIGRAMA_10L_OVER_04.py:91]: Training history: 
{'val_loss': [0.010331874692528664, 0.010251432193311616, 0.010175608001566288, 0.010104367402157154, 0.010037693201969325, 0.0099751473539491566, 0.0099166500932609727, 0.0098616783282127526, 0.0098101507117590945, 0.0097617762869563248, 0.0097163512187985676, 0.0096736264840931695, 0.0096334889496513896, 0.0095957159255129262, 0.0095601605327599107, 0.0095266113230840863, 0.0094949859454119961, 0.0094651641656530398, 0.0094370172604863085, 0.0094104063555210497, 0.0093852607083254151, 0.0093614839668278351, 0.0093389671351275915, 0.0093176550263033477, 0.009297452264614264, 0.0092783017485613718, 0.0092601413218837691, 0.0092429010384477202, 0.009226525095066395, 0.0092109799018081241, 0.0091962113207877793, 0.0091821760783962151, 0.0091688216397310274, 0.0091561054028432166, 0.0091439999958507195, 0.0091324479398785033, 0.0091214215929955791, 0.0091108993928339394, 0.0091008479052593714, 0.0090912467935105237, 0.0090820694646926176, 0.0090733185846732459, 0.0090649540304140533, 0.0090569530381755317, 0.0090493069179217612, 0.0090419855730462691, 0.0090349850601423188, 0.0090282590311976177, 0.0090218044914388302, 0.0090156429859231391, 0.0090097247460185371, 0.0090040595731161344, 0.0089986056234812213, 0.0089933661238522332, 0.0089883522604865661, 0.008983520448180158, 0.0089788823198097781, 0.0089744168046349479, 0.0089701385199192733, 0.0089660265888035513, 0.0089620517040550924, 0.0089582281609560926, 0.0089545530685981849, 0.0089510176746264714, 0.0089476063958331114, 0.008944314838729827, 0.0089411530470593272, 0.0089380849589036308, 0.0089351267079549202, 0.0089322844499438222, 0.0089295344621109253, 0.0089268812972041305, 0.0089243210222031983, 0.0089218492713171761, 0.0089194655771536891, 0.0089171592866288691, 0.0089149326882342426, 0.0089127860035484157, 0.0089107066822207114, 0.0089086965522746173, 0.0089067525358448238, 0.0089048670161667818, 0.0089030492579959142, 0.0089012954979581019, 0.0088995916208037661, 0.0088979470817074462, 0.0088963551848406687, 0.0088948099822027532, 0.008893320510046189, 0.008891873196681414, 0.0088904774280396531, 0.0088891255769698585, 0.0088878185817189374, 0.0088865475479831934, 0.0088853195351184973, 0.0088841272102578861, 0.0088829713420021487, 0.0088818524704491336, 0.0088807705679015154, 0.008879722224126075, 0.0088787043681818317, 0.0088777182256754451], 'loss': [0.010368404814947142, 0.010286754733907458, 0.010209108597513681, 0.01013619637033217, 0.010067731448287201, 0.010003691471050727, 0.0099436614711636701, 0.0098874344425785368, 0.0098346620019623739, 0.0097851779863705433, 0.0097387355581136596, 0.0096951093766254447, 0.0096540792737002737, 0.0096155247000202348, 0.0095792496788699565, 0.0095450954784232194, 0.0095128695375773162, 0.0094825002818741018, 0.009453857001020232, 0.0094268181256505698, 0.0094012562523251974, 0.0093771049966915442, 0.0093542632670327794, 0.0093326412700002158, 0.0093121673441283088, 0.0092927630299263816, 0.0092743689047782869, 0.0092569291414194999, 0.0092403640158900315, 0.0092246351270182554, 0.0092097062963280279, 0.0091955239759196009, 0.0091820407021142771, 0.009169213033608117, 0.0091569972079712045, 0.0091453672483444368, 0.0091342690109418954, 0.0091236795990807407, 0.0091135587930203064, 0.0091039005674985046, 0.0090946790830363292, 0.0090858620037934344, 0.0090774577374317638, 0.009069410238023469, 0.0090617243619549835, 0.0090543770305148361, 0.0090473424626105609, 0.0090406053495200121, 0.0090341374252882189, 0.0090279388238607775, 0.0090220092876500055, 0.0090163219182053146, 0.009010861159520385, 0.0090056198340575603, 0.0090005747297321938, 0.0089957509504673527, 0.0089910974275016244, 0.0089866340139762857, 0.0089823379860784498, 0.0089782167050916507, 0.0089742528262062166, 0.0089704200365542264, 0.0089667417079246914, 0.0089631976574641031, 0.0089597839183221586, 0.0089564951738891011, 0.0089533242145719231, 0.008950270731837821, 0.0089473088793387869, 0.0089444572755124716, 0.0089417163376509234, 0.0089390603653724827, 0.0089364992775201584, 0.0089340246921907774, 0.0089316366397224466, 0.008929338561486597, 0.0089271015418348823, 0.0089249451912037422, 0.0089228663326784297, 0.0089208524915737174, 0.0089189095855372845, 0.0089170286539523025, 0.0089152006537738804, 0.0089134464272799929, 0.0089117313884587903, 0.0089100860087882178, 0.0089084886966963525, 0.0089069408746396163, 0.0089054439421777497, 0.0089039897761400959, 0.0089025965021132109, 0.008901233684109007, 0.0088999238593324096, 0.0088986412289460224, 0.008897416382918126, 0.0088962054523492266, 0.0088950504784111092, 0.0088939291923624576, 0.0088928357984804276, 0.0088917819048108023, 0.0088907524155705849, 0.008889765921148993]}
[2017-10-21 21:24:12,849 AE_UNIGRAMA_10L_OVER_04.py:95]: done!
[2017-10-21 21:24:12,849 AE_UNIGRAMA_10L_OVER_04.py:155]: >> Executing classifier part ... 
[2017-10-21 21:24:12,849 AE_UNIGRAMA_10L_OVER_04.py:100]: =======================================
[2017-10-21 21:24:12,849 AE_UNIGRAMA_10L_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f011bf217f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-21 21:24:12,880 AE_UNIGRAMA_10L_OVER_04.py:113]: training ... 
[2017-10-21 21:25:52,891 AE_UNIGRAMA_10L_OVER_04.py:125]: trained!
[2017-10-21 21:25:52,891 AE_UNIGRAMA_10L_OVER_04.py:128]: Training history: 
{'val_loss': [0.010331874692528664, 0.010251432193311616, 0.010175608001566288, 0.010104367402157154, 0.010037693201969325, 0.0099751473539491566, 0.0099166500932609727, 0.0098616783282127526, 0.0098101507117590945, 0.0097617762869563248, 0.0097163512187985676, 0.0096736264840931695, 0.0096334889496513896, 0.0095957159255129262, 0.0095601605327599107, 0.0095266113230840863, 0.0094949859454119961, 0.0094651641656530398, 0.0094370172604863085, 0.0094104063555210497, 0.0093852607083254151, 0.0093614839668278351, 0.0093389671351275915, 0.0093176550263033477, 0.009297452264614264, 0.0092783017485613718, 0.0092601413218837691, 0.0092429010384477202, 0.009226525095066395, 0.0092109799018081241, 0.0091962113207877793, 0.0091821760783962151, 0.0091688216397310274, 0.0091561054028432166, 0.0091439999958507195, 0.0091324479398785033, 0.0091214215929955791, 0.0091108993928339394, 0.0091008479052593714, 0.0090912467935105237, 0.0090820694646926176, 0.0090733185846732459, 0.0090649540304140533, 0.0090569530381755317, 0.0090493069179217612, 0.0090419855730462691, 0.0090349850601423188, 0.0090282590311976177, 0.0090218044914388302, 0.0090156429859231391, 0.0090097247460185371, 0.0090040595731161344, 0.0089986056234812213, 0.0089933661238522332, 0.0089883522604865661, 0.008983520448180158, 0.0089788823198097781, 0.0089744168046349479, 0.0089701385199192733, 0.0089660265888035513, 0.0089620517040550924, 0.0089582281609560926, 0.0089545530685981849, 0.0089510176746264714, 0.0089476063958331114, 0.008944314838729827, 0.0089411530470593272, 0.0089380849589036308, 0.0089351267079549202, 0.0089322844499438222, 0.0089295344621109253, 0.0089268812972041305, 0.0089243210222031983, 0.0089218492713171761, 0.0089194655771536891, 0.0089171592866288691, 0.0089149326882342426, 0.0089127860035484157, 0.0089107066822207114, 0.0089086965522746173, 0.0089067525358448238, 0.0089048670161667818, 0.0089030492579959142, 0.0089012954979581019, 0.0088995916208037661, 0.0088979470817074462, 0.0088963551848406687, 0.0088948099822027532, 0.008893320510046189, 0.008891873196681414, 0.0088904774280396531, 0.0088891255769698585, 0.0088878185817189374, 0.0088865475479831934, 0.0088853195351184973, 0.0088841272102578861, 0.0088829713420021487, 0.0088818524704491336, 0.0088807705679015154, 0.008879722224126075, 0.0088787043681818317, 0.0088777182256754451], 'loss': [0.010368404814947142, 0.010286754733907458, 0.010209108597513681, 0.01013619637033217, 0.010067731448287201, 0.010003691471050727, 0.0099436614711636701, 0.0098874344425785368, 0.0098346620019623739, 0.0097851779863705433, 0.0097387355581136596, 0.0096951093766254447, 0.0096540792737002737, 0.0096155247000202348, 0.0095792496788699565, 0.0095450954784232194, 0.0095128695375773162, 0.0094825002818741018, 0.009453857001020232, 0.0094268181256505698, 0.0094012562523251974, 0.0093771049966915442, 0.0093542632670327794, 0.0093326412700002158, 0.0093121673441283088, 0.0092927630299263816, 0.0092743689047782869, 0.0092569291414194999, 0.0092403640158900315, 0.0092246351270182554, 0.0092097062963280279, 0.0091955239759196009, 0.0091820407021142771, 0.009169213033608117, 0.0091569972079712045, 0.0091453672483444368, 0.0091342690109418954, 0.0091236795990807407, 0.0091135587930203064, 0.0091039005674985046, 0.0090946790830363292, 0.0090858620037934344, 0.0090774577374317638, 0.009069410238023469, 0.0090617243619549835, 0.0090543770305148361, 0.0090473424626105609, 0.0090406053495200121, 0.0090341374252882189, 0.0090279388238607775, 0.0090220092876500055, 0.0090163219182053146, 0.009010861159520385, 0.0090056198340575603, 0.0090005747297321938, 0.0089957509504673527, 0.0089910974275016244, 0.0089866340139762857, 0.0089823379860784498, 0.0089782167050916507, 0.0089742528262062166, 0.0089704200365542264, 0.0089667417079246914, 0.0089631976574641031, 0.0089597839183221586, 0.0089564951738891011, 0.0089533242145719231, 0.008950270731837821, 0.0089473088793387869, 0.0089444572755124716, 0.0089417163376509234, 0.0089390603653724827, 0.0089364992775201584, 0.0089340246921907774, 0.0089316366397224466, 0.008929338561486597, 0.0089271015418348823, 0.0089249451912037422, 0.0089228663326784297, 0.0089208524915737174, 0.0089189095855372845, 0.0089170286539523025, 0.0089152006537738804, 0.0089134464272799929, 0.0089117313884587903, 0.0089100860087882178, 0.0089084886966963525, 0.0089069408746396163, 0.0089054439421777497, 0.0089039897761400959, 0.0089025965021132109, 0.008901233684109007, 0.0088999238593324096, 0.0088986412289460224, 0.008897416382918126, 0.0088962054523492266, 0.0088950504784111092, 0.0088939291923624576, 0.0088928357984804276, 0.0088917819048108023, 0.0088907524155705849, 0.008889765921148993]}
[2017-10-21 21:25:52,892 AE_UNIGRAMA_10L_OVER_04.py:132]: evaluating model ... 
[2017-10-21 21:25:52,970 AE_UNIGRAMA_10L_OVER_04.py:136]: evaluated! 
[2017-10-21 21:25:52,970 AE_UNIGRAMA_10L_OVER_04.py:138]: generating reports ... 
[2017-10-21 21:25:53,542 AE_UNIGRAMA_10L_OVER_04.py:141]: done!
[2017-10-21 21:25:53,542 AE_UNIGRAMA_10L_OVER_04.py:157]: >> experiment AE_UNIGRAMA_10L_OVER_04 finished!
