[2018-07-21 00:52:16,517 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_02
[2018-07-21 00:52:16,518 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:146]: >> Printing header log
[2018-07-21 00:52:16,518 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_02
	layers = 96,134,121,109,96,84,71,59,46,34,21
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4901c6f5f8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4901c6fdd8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,518 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,530 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,530 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,530 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:57]: =======================================
[2018-07-21 00:52:18,530 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4901c6f5f8>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,979 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-07-21 01:16:32,131 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_02
[2018-07-21 01:16:32,131 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:146]: >> Printing header log
[2018-07-21 01:16:32,131 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_02
	layers = 96,134,121,109,96,84,71,59,46,34,21
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb80d30a5f8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fb80d30add8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 01:16:32,131 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:148]: >> Loading dataset... 
[2018-07-21 01:16:34,041 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 01:16:34,041 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-07-21 01:16:34,041 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:57]: =======================================
[2018-07-21 01:16:34,041 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb80d30a5f8>, 'discard_decoder_function': True}
[2018-07-21 01:16:34,428 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-07-21 01:18:50,128 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_02
[2018-07-21 01:18:50,128 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:146]: >> Printing header log
[2018-07-21 01:18:50,128 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_02
	layers = 96,134,121,109,96,84,71,59,46,34,21
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc35638f668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc35638fe48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 01:18:50,129 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:148]: >> Loading dataset... 
[2018-07-21 01:18:52,000 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 01:18:52,001 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-07-21 01:18:52,001 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:57]: =======================================
[2018-07-21 01:18:52,001 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc35638f668>, 'discard_decoder_function': True}
[2018-07-21 01:18:52,371 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-07-21 01:21:43,004 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:85]: trained and evaluated!
[2018-07-21 01:21:43,005 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:88]: Training history: 
{'val_loss': [0.009841818416211172, 0.00943840260335745, 0.009147048622879067, 0.008937664188989511, 0.008785502906054949, 0.008673096546278264, 0.008589295586533447, 0.008525838593869186, 0.008476839794440881, 0.008438640271027007, 0.008408385148913336, 0.008384159247252991, 0.008364531329296631, 0.008348471413885724, 0.008335202817696612, 0.008324021996176559, 0.008311237381734926, 0.008299678286146653, 0.008290285850748097, 0.008282615732674059, 0.008276273932161467, 0.00827099980997967, 0.008266569494459065, 0.00826283197956778, 0.008259650496084849, 0.008256946115363328, 0.00825463040214674, 0.008252608823257634, 0.00825087416120276, 0.008249377537120335, 0.008248060360860295, 0.00824692002362416, 0.008245918316885046, 0.008245042980453825, 0.008244272663734802, 0.00824358536102335, 0.008242975194821766, 0.008242446596185563, 0.008241962810217765, 0.008241551805004198, 0.008241175913492554, 0.008240827883277822, 0.008240514173035847, 0.008240231525704664, 0.00823997342065716, 0.008239735149597364, 0.008239501287345389, 0.008239288040146215, 0.008239102151788406, 0.008238929499095413, 0.00823877313342363, 0.008238638803576424, 0.008238524270751533, 0.00823839548400212, 0.008238294422667568, 0.008238208662952648, 0.008238116797102216, 0.008238018204919099, 0.008237941165956799, 0.008237868669288467, 0.008237796753113737, 0.008237715067806729, 0.008237641735994304, 0.008237581659356206, 0.008237525013996612, 0.00823746739897996, 0.008237415003271631, 0.008237373245382344, 0.008237326192884859, 0.0082372821458793, 0.008237238668414632, 0.008237199301638725, 0.008237163832316019, 0.008237114780264516, 0.008237069395659317, 0.00823702592777827, 0.00823697927676604, 0.008236929804746586, 0.008236885776908268, 0.008236840869430473, 0.008236800503904374, 0.008236750819333902, 0.008236702083884159, 0.00823665200570069, 0.008236615976420714, 0.008236568808577508, 0.008236524844059541, 0.008236485956122402, 0.008236440100892967, 0.00823639285227353, 0.008236349274180843, 0.008236306065399828, 0.008236262056728751, 0.008236212095602366, 0.008236166086008185, 0.008236121491367153, 0.008236078542370715, 0.008236036928920285, 0.008235998568082286, 0.008235955818630522, 0.008235912806656006], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010112036969405245, 0.009630453163316437, 0.009287398018613247, 0.009039666432449718, 0.008861212035620725, 0.00873048803425536, 0.008633665364965883, 0.008560994750992373, 0.00850556568046331, 0.008462483035104435, 0.008428726073460109, 0.00840188539767007, 0.00838027362327287, 0.008362709080481019, 0.008348286824399882, 0.008336243941342887, 0.008324776788252336, 0.008312258729316789, 0.008301905535821778, 0.00829344048476064, 0.008286515029374296, 0.008280790458147886, 0.00827601746664803, 0.008271998798992973, 0.008268615787402317, 0.008265755873878112, 0.00826331921222679, 0.008261214888469344, 0.008259410934589737, 0.008257860502787597, 0.008256512139519768, 0.008255346449339179, 0.008254327200802632, 0.00825343963398485, 0.008252670359594866, 0.008251986078478097, 0.008251386466780747, 0.008250857097976622, 0.008250392867224567, 0.00824998180439454, 0.008249619193087037, 0.008249296813611568, 0.008249001416998566, 0.008248734797361466, 0.008248491158997688, 0.008248270665548858, 0.00824805757055308, 0.008247860095415567, 0.008247686301729453, 0.008247523731812131, 0.008247376944651644, 0.008247250138458569, 0.008247136843930443, 0.008247031563783447, 0.008246940892266104, 0.00824685422782501, 0.008246771826068032, 0.008246693809997879, 0.00824661635990024, 0.008246548354204566, 0.008246484097233723, 0.008246416642478167, 0.008246354931640588, 0.008246293548657819, 0.008246237771272133, 0.008246191201828273, 0.008246141131722673, 0.008246093178841254, 0.008246052439108618, 0.008246012176983163, 0.00824597288093198, 0.008245934774440477, 0.008245893395688177, 0.008245854172284042, 0.008245812700079404, 0.00824577309240611, 0.008245732754832896, 0.008245688851095568, 0.00824564582506718, 0.008245602537600873, 0.008245562305425894, 0.00824551765024031, 0.008245471755482327, 0.008245429212834018, 0.00824538435182466, 0.008245342995249429, 0.00824530269860091, 0.008245256861800524, 0.008245222150915471, 0.008245184049796763, 0.00824513686213853, 0.008245100268717557, 0.008245052348987425, 0.008245002855485614, 0.008244953374901373, 0.008244911120612116, 0.008244863773827701, 0.008244820191314927, 0.008244779500108919, 0.008244738160623748, 0.00824470040404981], 'acc': [0.010310543758438689, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2018-07-21 01:21:43,005 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:92]: done!
[2018-07-21 01:21:43,005 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:152]: >> Executing classifier part ... 
[2018-07-21 01:21:43,006 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:97]: =======================================
[2018-07-21 01:21:43,006 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc35638fe48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 01:21:43,049 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:110]: training ... 
[2018-07-21 01:28:00,063 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:122]: trained!
[2018-07-21 01:28:00,064 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:125]: Training history: 
{'val_loss': [0.009841818416211172, 0.00943840260335745, 0.009147048622879067, 0.008937664188989511, 0.008785502906054949, 0.008673096546278264, 0.008589295586533447, 0.008525838593869186, 0.008476839794440881, 0.008438640271027007, 0.008408385148913336, 0.008384159247252991, 0.008364531329296631, 0.008348471413885724, 0.008335202817696612, 0.008324021996176559, 0.008311237381734926, 0.008299678286146653, 0.008290285850748097, 0.008282615732674059, 0.008276273932161467, 0.00827099980997967, 0.008266569494459065, 0.00826283197956778, 0.008259650496084849, 0.008256946115363328, 0.00825463040214674, 0.008252608823257634, 0.00825087416120276, 0.008249377537120335, 0.008248060360860295, 0.00824692002362416, 0.008245918316885046, 0.008245042980453825, 0.008244272663734802, 0.00824358536102335, 0.008242975194821766, 0.008242446596185563, 0.008241962810217765, 0.008241551805004198, 0.008241175913492554, 0.008240827883277822, 0.008240514173035847, 0.008240231525704664, 0.00823997342065716, 0.008239735149597364, 0.008239501287345389, 0.008239288040146215, 0.008239102151788406, 0.008238929499095413, 0.00823877313342363, 0.008238638803576424, 0.008238524270751533, 0.00823839548400212, 0.008238294422667568, 0.008238208662952648, 0.008238116797102216, 0.008238018204919099, 0.008237941165956799, 0.008237868669288467, 0.008237796753113737, 0.008237715067806729, 0.008237641735994304, 0.008237581659356206, 0.008237525013996612, 0.00823746739897996, 0.008237415003271631, 0.008237373245382344, 0.008237326192884859, 0.0082372821458793, 0.008237238668414632, 0.008237199301638725, 0.008237163832316019, 0.008237114780264516, 0.008237069395659317, 0.00823702592777827, 0.00823697927676604, 0.008236929804746586, 0.008236885776908268, 0.008236840869430473, 0.008236800503904374, 0.008236750819333902, 0.008236702083884159, 0.00823665200570069, 0.008236615976420714, 0.008236568808577508, 0.008236524844059541, 0.008236485956122402, 0.008236440100892967, 0.00823639285227353, 0.008236349274180843, 0.008236306065399828, 0.008236262056728751, 0.008236212095602366, 0.008236166086008185, 0.008236121491367153, 0.008236078542370715, 0.008236036928920285, 0.008235998568082286, 0.008235955818630522, 0.008235912806656006], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010112036969405245, 0.009630453163316437, 0.009287398018613247, 0.009039666432449718, 0.008861212035620725, 0.00873048803425536, 0.008633665364965883, 0.008560994750992373, 0.00850556568046331, 0.008462483035104435, 0.008428726073460109, 0.00840188539767007, 0.00838027362327287, 0.008362709080481019, 0.008348286824399882, 0.008336243941342887, 0.008324776788252336, 0.008312258729316789, 0.008301905535821778, 0.00829344048476064, 0.008286515029374296, 0.008280790458147886, 0.00827601746664803, 0.008271998798992973, 0.008268615787402317, 0.008265755873878112, 0.00826331921222679, 0.008261214888469344, 0.008259410934589737, 0.008257860502787597, 0.008256512139519768, 0.008255346449339179, 0.008254327200802632, 0.00825343963398485, 0.008252670359594866, 0.008251986078478097, 0.008251386466780747, 0.008250857097976622, 0.008250392867224567, 0.00824998180439454, 0.008249619193087037, 0.008249296813611568, 0.008249001416998566, 0.008248734797361466, 0.008248491158997688, 0.008248270665548858, 0.00824805757055308, 0.008247860095415567, 0.008247686301729453, 0.008247523731812131, 0.008247376944651644, 0.008247250138458569, 0.008247136843930443, 0.008247031563783447, 0.008246940892266104, 0.00824685422782501, 0.008246771826068032, 0.008246693809997879, 0.00824661635990024, 0.008246548354204566, 0.008246484097233723, 0.008246416642478167, 0.008246354931640588, 0.008246293548657819, 0.008246237771272133, 0.008246191201828273, 0.008246141131722673, 0.008246093178841254, 0.008246052439108618, 0.008246012176983163, 0.00824597288093198, 0.008245934774440477, 0.008245893395688177, 0.008245854172284042, 0.008245812700079404, 0.00824577309240611, 0.008245732754832896, 0.008245688851095568, 0.00824564582506718, 0.008245602537600873, 0.008245562305425894, 0.00824551765024031, 0.008245471755482327, 0.008245429212834018, 0.00824538435182466, 0.008245342995249429, 0.00824530269860091, 0.008245256861800524, 0.008245222150915471, 0.008245184049796763, 0.00824513686213853, 0.008245100268717557, 0.008245052348987425, 0.008245002855485614, 0.008244953374901373, 0.008244911120612116, 0.008244863773827701, 0.008244820191314927, 0.008244779500108919, 0.008244738160623748, 0.00824470040404981], 'acc': [0.010310543758438689, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2018-07-21 01:28:00,064 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:129]: evaluating model ... 
[2018-07-21 01:28:00,231 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:133]: evaluated! 
[2018-07-21 01:28:00,231 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:135]: generating reports ... 
[2018-07-21 01:28:01,254 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:138]: done!
[2018-07-21 01:28:01,254 AE_UNIGRAMA_10L_FULLDS_OVER_02.py:154]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_02 finished!
