[2017-11-29 00:32:08,127 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02
[2017-11-29 00:32:08,127 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:150]: >> Printing header log
[2017-11-29 00:32:08,127 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:39]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22,16
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6fa31bddd8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6fa31bf320>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-29 00:32:08,127 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:152]: >> Loading dataset... 
[2017-11-29 00:32:10,285 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:56]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-29 00:32:10,286 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:154]: >> Executing autoencoder part ... 
[2017-11-29 00:32:10,286 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:61]: =======================================
[2017-11-29 00:32:10,286 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:66]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6fa31bddd8>, 'discard_decoder_function': True}
[2017-11-29 00:32:10,488 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:77]: training and evaluate autoencoder
[2017-11-29 00:34:11,032 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:89]: trained and evaluated!
[2017-11-29 00:34:11,033 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:92]: Training history: 
{'val_loss': [0.0093824878603340472, 0.0086410695451453121, 0.0080949442426221235, 0.0076820778406167982, 0.0073628250099800714, 0.0070995818999846144, 0.0068869182572332821, 0.0067135298414821905, 0.0065705879476401939, 0.0064514604044920033, 0.0063515893677889602, 0.0062673743829632211, 0.0061959082357248632, 0.0061350787912099426, 0.0060831194398503711, 0.0060385415721232894, 0.0060002867482227464, 0.0059674059340161451, 0.0059390152769128336, 0.005914528096657423, 0.0058933638614006491, 0.0058749769726177377, 0.0058590675957804874, 0.0058452922478455125, 0.0058332987051650208, 0.0058229027109926385, 0.0058138608806367819, 0.0058059988475621339, 0.005799118796081441, 0.0057931528011701781, 0.0057879189401214689, 0.0057833635734099156, 0.0057794019167107151, 0.0057759284086659609, 0.005772894741922825, 0.0057702438678395298, 0.0057679200962525391, 0.0057658880560712607, 0.0057641020863912849, 0.0057625494879738554, 0.0057611765276821374, 0.0057599707953262221, 0.0057589045385373168, 0.0057579714814984797, 0.0057571458536823505, 0.0057564229533816963, 0.0057557801307356674, 0.0057552112630085495, 0.0057547128900854094, 0.0057542722791848171, 0.0057538826076244717, 0.0057535275289133736, 0.0057532271701953444, 0.0057529534807258262, 0.0057527138058367251, 0.0057524945547558484, 0.0057522974411543847, 0.0057521243686645745, 0.005751970432868494, 0.0057518324013477694, 0.0057517062904821822, 0.0057515924456243523, 0.0057514873584845359, 0.0057513894588035862, 0.0057513023823676295, 0.0057512175291605525, 0.0057511460840378951, 0.0057510704521564864, 0.0057510010625493472, 0.0057509393787722749, 0.0057508833388065818, 0.0057508277865787319, 0.0057507718389409566, 0.0057507257082679945, 0.0057506783427626103, 0.0057506378441782051, 0.0057505963506086022, 0.0057505585186666741, 0.0057505244942459332, 0.0057504946206453659, 0.00575044877645421, 0.0057504047128484502, 0.0057503716425969511, 0.0057503343617132168, 0.0057502970372753483, 0.0057502348268269748, 0.0057501980563566136, 0.0057501662881940174, 0.0057501258944304646, 0.0057500955736513072, 0.0057500617968644814, 0.0057500278579262149, 0.0057499945917238986, 0.0057499569161147844, 0.0057499269668720675, 0.0057498975254756833, 0.0057498649811253731, 0.0057498392525263536, 0.0057498106629598322, 0.0057497878863727106, 0.005749761187432088], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098738361902674879, 0.0089991040333714072, 0.0083646425356391357, 0.0078917243652826732, 0.007530559419513817, 0.0072434426921945535, 0.0070081179153585237, 0.0068176381375809362, 0.0066614997750613436, 0.0065322975887343922, 0.0064243170182625656, 0.0063336139390062409, 0.0062569685360800639, 0.006191882443110976, 0.0061364133097071344, 0.0060890157309448712, 0.006048335408732685, 0.0060134462978381296, 0.005983483649017976, 0.0059576185366541886, 0.0059353074613774318, 0.0059160290268683406, 0.0058993246685587787, 0.0058848889682012583, 0.0058723849183714609, 0.0058615248846590915, 0.0058521240150799002, 0.0058439699507681847, 0.005836884326189372, 0.0058307026360767877, 0.0058253520699127603, 0.0058206635474956584, 0.0058166054134603856, 0.0058130728239994909, 0.0058099913841351911, 0.0058073088774445916, 0.0058049715468272466, 0.0058029331843026562, 0.0058011528472294354, 0.0057995974032382771, 0.0057982526227102057, 0.0057970634933684094, 0.0057960260721529183, 0.0057951201977647455, 0.0057943242452183621, 0.0057936302052196461, 0.0057930262392720368, 0.0057924908846598453, 0.0057920223893374806, 0.0057916138336022195, 0.0057912515091676758, 0.0057909337134865605, 0.0057906507902172931, 0.0057904094346055111, 0.0057901957172228728, 0.005790004127182097, 0.0057898368232036325, 0.0057896850738096885, 0.0057895514406231816, 0.0057894392085366926, 0.005789339406297161, 0.0057892415709007083, 0.0057891595457537975, 0.0057890799328203773, 0.005789012732358067, 0.0057889499180970002, 0.0057888877758354119, 0.0057888327826491684, 0.0057887810105678528, 0.0057887311961844325, 0.0057886857296496437, 0.0057886424208636279, 0.0057886022600210762, 0.005788568954236236, 0.0057885318747487842, 0.0057884998361433636, 0.0057884683939753477, 0.0057884364152708759, 0.0057884101981460151, 0.0057883800485353026, 0.0057883537325281497, 0.0057883140740419324, 0.0057882851375397459, 0.0057882542013861374, 0.0057882257163702046, 0.0057881794063065978, 0.0057881328756154513, 0.0057881000536679486, 0.0057880750936628068, 0.0057880437087664991, 0.0057880163182575011, 0.0057879883394274479, 0.0057879575025562317, 0.0057879271658693695, 0.0057879012451055954, 0.0057878718710635589, 0.0057878451702728312, 0.0057878232645301843, 0.0057878000358796578, 0.0057877758460132397, 0.0057877496707275907], 'acc': [0.59027863016329885, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822272449271, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822262938279, 0.59383822264767316, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822267327968, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124]}
[2017-11-29 00:34:11,033 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:96]: done!
[2017-11-29 00:34:11,033 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:156]: >> Executing classifier part ... 
[2017-11-29 00:34:11,033 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:101]: =======================================
[2017-11-29 00:34:11,033 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:105]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6fa31bf320>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-29 00:34:11,065 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:114]: training ... 
[2017-11-29 00:38:13,903 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:126]: trained!
[2017-11-29 00:38:13,904 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:129]: Training history: 
{'val_loss': [0.0093824878603340472, 0.0086410695451453121, 0.0080949442426221235, 0.0076820778406167982, 0.0073628250099800714, 0.0070995818999846144, 0.0068869182572332821, 0.0067135298414821905, 0.0065705879476401939, 0.0064514604044920033, 0.0063515893677889602, 0.0062673743829632211, 0.0061959082357248632, 0.0061350787912099426, 0.0060831194398503711, 0.0060385415721232894, 0.0060002867482227464, 0.0059674059340161451, 0.0059390152769128336, 0.005914528096657423, 0.0058933638614006491, 0.0058749769726177377, 0.0058590675957804874, 0.0058452922478455125, 0.0058332987051650208, 0.0058229027109926385, 0.0058138608806367819, 0.0058059988475621339, 0.005799118796081441, 0.0057931528011701781, 0.0057879189401214689, 0.0057833635734099156, 0.0057794019167107151, 0.0057759284086659609, 0.005772894741922825, 0.0057702438678395298, 0.0057679200962525391, 0.0057658880560712607, 0.0057641020863912849, 0.0057625494879738554, 0.0057611765276821374, 0.0057599707953262221, 0.0057589045385373168, 0.0057579714814984797, 0.0057571458536823505, 0.0057564229533816963, 0.0057557801307356674, 0.0057552112630085495, 0.0057547128900854094, 0.0057542722791848171, 0.0057538826076244717, 0.0057535275289133736, 0.0057532271701953444, 0.0057529534807258262, 0.0057527138058367251, 0.0057524945547558484, 0.0057522974411543847, 0.0057521243686645745, 0.005751970432868494, 0.0057518324013477694, 0.0057517062904821822, 0.0057515924456243523, 0.0057514873584845359, 0.0057513894588035862, 0.0057513023823676295, 0.0057512175291605525, 0.0057511460840378951, 0.0057510704521564864, 0.0057510010625493472, 0.0057509393787722749, 0.0057508833388065818, 0.0057508277865787319, 0.0057507718389409566, 0.0057507257082679945, 0.0057506783427626103, 0.0057506378441782051, 0.0057505963506086022, 0.0057505585186666741, 0.0057505244942459332, 0.0057504946206453659, 0.00575044877645421, 0.0057504047128484502, 0.0057503716425969511, 0.0057503343617132168, 0.0057502970372753483, 0.0057502348268269748, 0.0057501980563566136, 0.0057501662881940174, 0.0057501258944304646, 0.0057500955736513072, 0.0057500617968644814, 0.0057500278579262149, 0.0057499945917238986, 0.0057499569161147844, 0.0057499269668720675, 0.0057498975254756833, 0.0057498649811253731, 0.0057498392525263536, 0.0057498106629598322, 0.0057497878863727106, 0.005749761187432088], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098738361902674879, 0.0089991040333714072, 0.0083646425356391357, 0.0078917243652826732, 0.007530559419513817, 0.0072434426921945535, 0.0070081179153585237, 0.0068176381375809362, 0.0066614997750613436, 0.0065322975887343922, 0.0064243170182625656, 0.0063336139390062409, 0.0062569685360800639, 0.006191882443110976, 0.0061364133097071344, 0.0060890157309448712, 0.006048335408732685, 0.0060134462978381296, 0.005983483649017976, 0.0059576185366541886, 0.0059353074613774318, 0.0059160290268683406, 0.0058993246685587787, 0.0058848889682012583, 0.0058723849183714609, 0.0058615248846590915, 0.0058521240150799002, 0.0058439699507681847, 0.005836884326189372, 0.0058307026360767877, 0.0058253520699127603, 0.0058206635474956584, 0.0058166054134603856, 0.0058130728239994909, 0.0058099913841351911, 0.0058073088774445916, 0.0058049715468272466, 0.0058029331843026562, 0.0058011528472294354, 0.0057995974032382771, 0.0057982526227102057, 0.0057970634933684094, 0.0057960260721529183, 0.0057951201977647455, 0.0057943242452183621, 0.0057936302052196461, 0.0057930262392720368, 0.0057924908846598453, 0.0057920223893374806, 0.0057916138336022195, 0.0057912515091676758, 0.0057909337134865605, 0.0057906507902172931, 0.0057904094346055111, 0.0057901957172228728, 0.005790004127182097, 0.0057898368232036325, 0.0057896850738096885, 0.0057895514406231816, 0.0057894392085366926, 0.005789339406297161, 0.0057892415709007083, 0.0057891595457537975, 0.0057890799328203773, 0.005789012732358067, 0.0057889499180970002, 0.0057888877758354119, 0.0057888327826491684, 0.0057887810105678528, 0.0057887311961844325, 0.0057886857296496437, 0.0057886424208636279, 0.0057886022600210762, 0.005788568954236236, 0.0057885318747487842, 0.0057884998361433636, 0.0057884683939753477, 0.0057884364152708759, 0.0057884101981460151, 0.0057883800485353026, 0.0057883537325281497, 0.0057883140740419324, 0.0057882851375397459, 0.0057882542013861374, 0.0057882257163702046, 0.0057881794063065978, 0.0057881328756154513, 0.0057881000536679486, 0.0057880750936628068, 0.0057880437087664991, 0.0057880163182575011, 0.0057879883394274479, 0.0057879575025562317, 0.0057879271658693695, 0.0057879012451055954, 0.0057878718710635589, 0.0057878451702728312, 0.0057878232645301843, 0.0057878000358796578, 0.0057877758460132397, 0.0057877496707275907], 'acc': [0.59027863016329885, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822272449271, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822262938279, 0.59383822264767316, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822267327968, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124]}
[2017-11-29 00:38:13,904 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:133]: evaluating model ... 
[2017-11-29 00:38:14,047 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:137]: evaluated! 
[2017-11-29 00:38:14,047 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:139]: generating reports ... 
[2017-11-29 00:38:14,872 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:142]: done!
[2017-11-29 00:38:14,872 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:158]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02 finished!
