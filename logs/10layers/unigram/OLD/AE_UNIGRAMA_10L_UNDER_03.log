[2017-10-20 01:41:28,845 AE_UNIGRAMA_10L_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_UNDER_03
[2017-10-20 01:41:28,845 AE_UNIGRAMA_10L_UNDER_03.py:149]: >> Printing header log
[2017-10-20 01:41:28,846 AE_UNIGRAMA_10L_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_UNDER_03
	layers = 96,86,78,71,63,55,48,40,32,24,17,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5b3117b7b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5b3117b898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:41:28,846 AE_UNIGRAMA_10L_UNDER_03.py:151]: >> Loading dataset... 
[2017-10-20 01:41:29,447 AE_UNIGRAMA_10L_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:41:29,447 AE_UNIGRAMA_10L_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:41:29,447 AE_UNIGRAMA_10L_UNDER_03.py:60]: =======================================
[2017-10-20 01:41:29,447 AE_UNIGRAMA_10L_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5b3117b7b8>, 'discard_decoder_function': True}
[2017-10-20 01:41:29,694 AE_UNIGRAMA_10L_UNDER_03.py:76]: training and evaluate autoencoder
[2017-10-21 21:32:10,447 AE_UNIGRAMA_10L_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_UNDER_03
[2017-10-21 21:32:10,447 AE_UNIGRAMA_10L_UNDER_03.py:149]: >> Printing header log
[2017-10-21 21:32:10,447 AE_UNIGRAMA_10L_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_UNDER_03
	layers = 96,86,78,71,63,55,48,40,32,24,17,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f52a4bff710>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f52a4bff7f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 21:32:10,447 AE_UNIGRAMA_10L_UNDER_03.py:151]: >> Loading dataset... 
[2017-10-21 21:32:10,995 AE_UNIGRAMA_10L_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 21:32:10,995 AE_UNIGRAMA_10L_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-10-21 21:32:10,995 AE_UNIGRAMA_10L_UNDER_03.py:60]: =======================================
[2017-10-21 21:32:10,995 AE_UNIGRAMA_10L_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f52a4bff710>, 'discard_decoder_function': True}
[2017-10-21 21:32:11,204 AE_UNIGRAMA_10L_UNDER_03.py:76]: training and evaluate autoencoder
[2017-10-21 21:33:05,092 AE_UNIGRAMA_10L_UNDER_03.py:88]: trained and evaluated!
[2017-10-21 21:33:05,093 AE_UNIGRAMA_10L_UNDER_03.py:91]: Training history: 
{'val_loss': [0.010184821946248689, 0.0099580000054271256, 0.0097387712275727092, 0.0095320532036093537, 0.00933771016470894, 0.0091552015006209839, 0.0089839957966071082, 0.0088232587572865777, 0.008672045765368468, 0.0085296304584878968, 0.0083953953316940697, 0.0082689123505165583, 0.0081491257327169064, 0.0080356854550734328, 0.0079284648230943319, 0.0078269785986763169, 0.0077308898559705699, 0.0076398718201981155, 0.0075534966022994879, 0.0074715437177139367, 0.0073936700277362835, 0.007319716149837222, 0.0072493535400711025, 0.0071824235395012512, 0.0071186237868101623, 0.0070578229187755782, 0.0069998761355101399, 0.0069446223337881847, 0.0068918208878999748, 0.0068406688835347231, 0.0067909084239690717, 0.0067433167705970186, 0.006697343198450968, 0.0066531485961023092, 0.0066108634906602839, 0.0065704035195331594, 0.0065317912266129232, 0.0064947384419992956, 0.006459213402053016, 0.0064251813795209818, 0.0063925159707333076, 0.0063612126333285881, 0.0063311671768921012, 0.0063023183193597872, 0.0062746027117546602, 0.0062479919245030354, 0.0062223868842711015, 0.0061977943665171426, 0.0061741161963393479, 0.0061513232482687252, 0.0061294024058905008, 0.006108279414405721, 0.006087938773698523, 0.0060683603547374999, 0.006049474767066511, 0.0060312789207026636, 0.0060137619738740546, 0.0059968557461514572, 0.005980557732657983, 0.0059648480519070724, 0.0059496923609460156, 0.0059350262392575412, 0.0059208888889439263, 0.0059072421327039434, 0.0058940589171747734, 0.0058813131272405055, 0.0058690009943337691, 0.0058571591273947274, 0.0058457551153591357, 0.0058347157420777481, 0.0058240241433414166, 0.0058137044781424296, 0.0058037241900055821, 0.0057940453284014998, 0.0057846644259712289, 0.0057755970745780212, 0.005766806718945282, 0.0057582869800326996, 0.0057500358324733365, 0.0057420356226842639, 0.005734294301529024, 0.0057267880925846362, 0.0057195125850519951, 0.0057124482921314286, 0.0057056130924466372, 0.0056989738911556488, 0.005692540600438876, 0.0056863113489957545, 0.005680261029200594, 0.0056743953051564865, 0.0056686940876469289, 0.0056631669962993346, 0.0056578046140229833, 0.0056525929225089378, 0.0056475369263177247, 0.0056426235644292215, 0.0056378541316934013, 0.0056332341641132273, 0.0056287376279336816, 0.0056243741185470139, 0.005620133431219811, 0.0056160278981863127], 'loss': [0.010296629104115293, 0.010066577921991855, 0.0098431471852012103, 0.0096293842659252293, 0.0094285386276202979, 0.0092398294184148563, 0.0090626431131058845, 0.0088963369485712089, 0.0087400697487662309, 0.0085928567010307138, 0.0084542292608125631, 0.0083234721076913456, 0.0082000833629792495, 0.0080829955363839624, 0.0079722634065019331, 0.0078675330398442853, 0.0077683288637221265, 0.0076743557773869351, 0.0075852658313978975, 0.0075006712060341563, 0.0074203584847494404, 0.0073440038617963652, 0.0072714333627407323, 0.0072023572858718361, 0.0071366043628571805, 0.0070738645402695149, 0.0070140627258615806, 0.0069570293576761708, 0.0069026038006003015, 0.0068503898155166283, 0.0067993910037571839, 0.0067503827277138216, 0.0067032962732964966, 0.0066577980364086109, 0.0066142021915941204, 0.0065724600190050627, 0.0065326171960926674, 0.0064944858077773853, 0.0064578968470603614, 0.0064227871846387046, 0.0063891392435876226, 0.0063568602313791855, 0.0063258736470477228, 0.0062961331995109067, 0.0062675431016409001, 0.0062400667963076681, 0.0062136748011699652, 0.0061882495188647132, 0.0061638271018230779, 0.0061403104967306605, 0.0061176551706841661, 0.0060958459137033924, 0.0060748242167498372, 0.0060545673554381965, 0.0060350520887767602, 0.0060162203911332422, 0.0059980819503803635, 0.005980578020212745, 0.005963680542462815, 0.0059473930263334281, 0.0059316769699075504, 0.0059164942124287226, 0.0059018166173082339, 0.0058876404936008099, 0.0058739594531319371, 0.0058607343969535779, 0.0058479312027117083, 0.0058355759128071848, 0.0058237159625840612, 0.0058122265322068647, 0.0058011115750740954, 0.0057903404273756754, 0.0057799355710782775, 0.0057698701558143509, 0.0057600936717877521, 0.0057506229291706089, 0.0057414607622860471, 0.0057325611542395159, 0.0057239476328036793, 0.0057155891838492102, 0.0057074938197840593, 0.0056996446228216929, 0.0056920286251395738, 0.0056846370301183629, 0.0056774424770806896, 0.0056705016951341712, 0.0056637478019233925, 0.0056571946104446947, 0.0056508557319174023, 0.0056446728436247698, 0.0056386956591307933, 0.0056328767940365398, 0.0056272356106356457, 0.0056217460067096705, 0.0056164151214443256, 0.0056112405326567728, 0.0056062018969305176, 0.0056013129662994821, 0.0055965742754012105, 0.0055919619567335096, 0.0055874750117147964, 0.0055831151306926837]}
[2017-10-21 21:33:05,093 AE_UNIGRAMA_10L_UNDER_03.py:95]: done!
[2017-10-21 21:33:05,093 AE_UNIGRAMA_10L_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-10-21 21:33:05,093 AE_UNIGRAMA_10L_UNDER_03.py:100]: =======================================
[2017-10-21 21:33:05,093 AE_UNIGRAMA_10L_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f52a4bff7f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-21 21:33:05,124 AE_UNIGRAMA_10L_UNDER_03.py:113]: training ... 
[2017-10-21 21:34:37,046 AE_UNIGRAMA_10L_UNDER_03.py:125]: trained!
[2017-10-21 21:34:37,046 AE_UNIGRAMA_10L_UNDER_03.py:128]: Training history: 
{'val_loss': [0.010184821946248689, 0.0099580000054271256, 0.0097387712275727092, 0.0095320532036093537, 0.00933771016470894, 0.0091552015006209839, 0.0089839957966071082, 0.0088232587572865777, 0.008672045765368468, 0.0085296304584878968, 0.0083953953316940697, 0.0082689123505165583, 0.0081491257327169064, 0.0080356854550734328, 0.0079284648230943319, 0.0078269785986763169, 0.0077308898559705699, 0.0076398718201981155, 0.0075534966022994879, 0.0074715437177139367, 0.0073936700277362835, 0.007319716149837222, 0.0072493535400711025, 0.0071824235395012512, 0.0071186237868101623, 0.0070578229187755782, 0.0069998761355101399, 0.0069446223337881847, 0.0068918208878999748, 0.0068406688835347231, 0.0067909084239690717, 0.0067433167705970186, 0.006697343198450968, 0.0066531485961023092, 0.0066108634906602839, 0.0065704035195331594, 0.0065317912266129232, 0.0064947384419992956, 0.006459213402053016, 0.0064251813795209818, 0.0063925159707333076, 0.0063612126333285881, 0.0063311671768921012, 0.0063023183193597872, 0.0062746027117546602, 0.0062479919245030354, 0.0062223868842711015, 0.0061977943665171426, 0.0061741161963393479, 0.0061513232482687252, 0.0061294024058905008, 0.006108279414405721, 0.006087938773698523, 0.0060683603547374999, 0.006049474767066511, 0.0060312789207026636, 0.0060137619738740546, 0.0059968557461514572, 0.005980557732657983, 0.0059648480519070724, 0.0059496923609460156, 0.0059350262392575412, 0.0059208888889439263, 0.0059072421327039434, 0.0058940589171747734, 0.0058813131272405055, 0.0058690009943337691, 0.0058571591273947274, 0.0058457551153591357, 0.0058347157420777481, 0.0058240241433414166, 0.0058137044781424296, 0.0058037241900055821, 0.0057940453284014998, 0.0057846644259712289, 0.0057755970745780212, 0.005766806718945282, 0.0057582869800326996, 0.0057500358324733365, 0.0057420356226842639, 0.005734294301529024, 0.0057267880925846362, 0.0057195125850519951, 0.0057124482921314286, 0.0057056130924466372, 0.0056989738911556488, 0.005692540600438876, 0.0056863113489957545, 0.005680261029200594, 0.0056743953051564865, 0.0056686940876469289, 0.0056631669962993346, 0.0056578046140229833, 0.0056525929225089378, 0.0056475369263177247, 0.0056426235644292215, 0.0056378541316934013, 0.0056332341641132273, 0.0056287376279336816, 0.0056243741185470139, 0.005620133431219811, 0.0056160278981863127], 'loss': [0.010296629104115293, 0.010066577921991855, 0.0098431471852012103, 0.0096293842659252293, 0.0094285386276202979, 0.0092398294184148563, 0.0090626431131058845, 0.0088963369485712089, 0.0087400697487662309, 0.0085928567010307138, 0.0084542292608125631, 0.0083234721076913456, 0.0082000833629792495, 0.0080829955363839624, 0.0079722634065019331, 0.0078675330398442853, 0.0077683288637221265, 0.0076743557773869351, 0.0075852658313978975, 0.0075006712060341563, 0.0074203584847494404, 0.0073440038617963652, 0.0072714333627407323, 0.0072023572858718361, 0.0071366043628571805, 0.0070738645402695149, 0.0070140627258615806, 0.0069570293576761708, 0.0069026038006003015, 0.0068503898155166283, 0.0067993910037571839, 0.0067503827277138216, 0.0067032962732964966, 0.0066577980364086109, 0.0066142021915941204, 0.0065724600190050627, 0.0065326171960926674, 0.0064944858077773853, 0.0064578968470603614, 0.0064227871846387046, 0.0063891392435876226, 0.0063568602313791855, 0.0063258736470477228, 0.0062961331995109067, 0.0062675431016409001, 0.0062400667963076681, 0.0062136748011699652, 0.0061882495188647132, 0.0061638271018230779, 0.0061403104967306605, 0.0061176551706841661, 0.0060958459137033924, 0.0060748242167498372, 0.0060545673554381965, 0.0060350520887767602, 0.0060162203911332422, 0.0059980819503803635, 0.005980578020212745, 0.005963680542462815, 0.0059473930263334281, 0.0059316769699075504, 0.0059164942124287226, 0.0059018166173082339, 0.0058876404936008099, 0.0058739594531319371, 0.0058607343969535779, 0.0058479312027117083, 0.0058355759128071848, 0.0058237159625840612, 0.0058122265322068647, 0.0058011115750740954, 0.0057903404273756754, 0.0057799355710782775, 0.0057698701558143509, 0.0057600936717877521, 0.0057506229291706089, 0.0057414607622860471, 0.0057325611542395159, 0.0057239476328036793, 0.0057155891838492102, 0.0057074938197840593, 0.0056996446228216929, 0.0056920286251395738, 0.0056846370301183629, 0.0056774424770806896, 0.0056705016951341712, 0.0056637478019233925, 0.0056571946104446947, 0.0056508557319174023, 0.0056446728436247698, 0.0056386956591307933, 0.0056328767940365398, 0.0056272356106356457, 0.0056217460067096705, 0.0056164151214443256, 0.0056112405326567728, 0.0056062018969305176, 0.0056013129662994821, 0.0055965742754012105, 0.0055919619567335096, 0.0055874750117147964, 0.0055831151306926837]}
[2017-10-21 21:34:37,046 AE_UNIGRAMA_10L_UNDER_03.py:132]: evaluating model ... 
[2017-10-21 21:34:37,124 AE_UNIGRAMA_10L_UNDER_03.py:136]: evaluated! 
[2017-10-21 21:34:37,124 AE_UNIGRAMA_10L_UNDER_03.py:138]: generating reports ... 
[2017-10-21 21:34:37,675 AE_UNIGRAMA_10L_UNDER_03.py:141]: done!
[2017-10-21 21:34:37,675 AE_UNIGRAMA_10L_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_10L_UNDER_03 finished!
