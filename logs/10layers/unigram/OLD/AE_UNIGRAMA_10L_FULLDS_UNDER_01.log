[2017-11-29 00:26:11,294 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01
[2017-11-29 00:26:11,294 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-29 00:26:11,294 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17,15,13,11
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f65d4b78e10>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f65d4b7b358>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-29 00:26:11,294 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-29 00:26:13,423 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-29 00:26:13,423 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-29 00:26:13,423 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-29 00:26:13,423 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f65d4b78e10>, 'discard_decoder_function': True}
[2017-11-29 00:26:13,626 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-29 00:27:51,297 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-29 00:27:51,299 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0097251793031485935, 0.0091746485778751823, 0.0087256527059834388, 0.0083604934887165794, 0.0080524248020358603, 0.0077540128712926728, 0.0075051844125501987, 0.0072951173414611417, 0.0071142504122813305, 0.0069579556360169943, 0.0068248698889363099, 0.0067105851767982399, 0.0066090226899017876, 0.0065162800109025551, 0.0064316689490639452, 0.0063584016814680058, 0.0062950013019897532, 0.0062374185528763625, 0.0061856419166693112, 0.0061397002470836683, 0.006100047231357146, 0.0060652509680478531, 0.0060350437856011314, 0.0060087099857217621, 0.0059857367476648989, 0.005965587693290187, 0.0059478051015968243, 0.0059321304782027108, 0.0059183024394352263, 0.0059060741968771932, 0.0058952322957413639, 0.0058856276049628134, 0.0058771046146357522, 0.0058695646500039004, 0.0058628746777470335, 0.0058569305428180221, 0.0058516285463329713, 0.0058469227126682127, 0.0058427335967736584, 0.0058390193447526795, 0.0058357173334622333, 0.0058327526677617557, 0.0058301114818633685, 0.0058277534982904885, 0.0058256627832467848, 0.0058237822752552721, 0.0058221141859931469, 0.0058206181616571318, 0.0058192870863232431, 0.0058180861554468976, 0.0058170206293235065, 0.0058160411712166928, 0.0058151493356410839, 0.005814337278060815, 0.0058136091474135631, 0.0058129520597191677, 0.0058123514673835879, 0.0058118026428580424, 0.0058113115603321231, 0.005810850041907162, 0.0058103922539065808, 0.0058099733576081345, 0.0058095907185429308, 0.0058092329024245848, 0.0058089082153429828, 0.0058086072123831618, 0.0058083317891339673, 0.0058080711644498831, 0.005807836182454504, 0.0058076096684437483, 0.0058074028137763255, 0.0058072125416821314, 0.0058070348937835203, 0.0058068578140567121, 0.0058066976299965996, 0.0058065459000590869, 0.0058063954269449826, 0.0058062620819003784, 0.00580613623381425, 0.005805995155557804, 0.0058058479519986035, 0.0058056994392483531, 0.0058055481590564718, 0.005805398258392571, 0.0058052569931699525, 0.0058051257166472081, 0.0058049893643137493, 0.0058048498483586237, 0.0058047190613706497, 0.0058045964441626706, 0.0058044786108928112, 0.0058043625301420305, 0.0058042535568439959, 0.0058041555971798491, 0.0058040663900996332, 0.0058039808864042966, 0.0058038973541966596, 0.0058038163459895728, 0.0058037377167452029, 0.0058036653258389725, 0.0058035904308695457], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010057348894817054, 0.0094453337803168409, 0.0089497262202966905, 0.0085458980362925901, 0.008216118362869524, 0.0079111773748194517, 0.0076403839300348084, 0.007413551113960918, 0.0072201134853510382, 0.0070525102085388517, 0.0069095877717553515, 0.0067872279337926836, 0.0066809880342487693, 0.0065848798371258834, 0.0064970366943138784, 0.0064186874487404955, 0.0063513618103091677, 0.0062914190088457396, 0.0062378979859844157, 0.0061891407050133828, 0.0061469784635664994, 0.0061102768004341144, 0.0060782746233071661, 0.0060504674074714779, 0.0060263007581009918, 0.0060051549196895341, 0.0059865910161619931, 0.0059702106452797022, 0.0059557709314443036, 0.005943034944226603, 0.0059317731035810877, 0.0059217925992709397, 0.0059129546642325411, 0.0059051296386899311, 0.0058982012332390206, 0.0058920513207511961, 0.0058866059591638625, 0.0058817498008553104, 0.0058774466631375958, 0.0058736209355238003, 0.0058702279485961482, 0.005867211358710653, 0.0058645164827027755, 0.0058621106367744346, 0.0058599675410991071, 0.005858070267314313, 0.0058563715788350927, 0.0058548636370393025, 0.005853514386174305, 0.0058523133316853377, 0.0058512359339598901, 0.0058502770300277382, 0.0058493905380547478, 0.0058485912412292529, 0.0058478629982460862, 0.0058472158221089653, 0.005846629722076566, 0.0058460899860643531, 0.0058456034156307169, 0.0058451593566946096, 0.0058447277277197751, 0.0058443146510632933, 0.0058439329194072583, 0.0058435909222567745, 0.0058432765668791917, 0.0058429885012163613, 0.005842723242382491, 0.0058424765215204675, 0.0058422498523867088, 0.0058420425722412322, 0.0058418439761900682, 0.0058416582000279183, 0.0058414898917940449, 0.0058413259919956407, 0.0058411779527452858, 0.0058410283824198231, 0.0058408916029474177, 0.0058407605446443439, 0.0058406349374990757, 0.0058405175215799129, 0.0058403777366574259, 0.0058402320031363374, 0.0058400936194273594, 0.0058399508164801656, 0.0058398178190553502, 0.0058396887277096703, 0.00583955959075239, 0.0058394287841704792, 0.0058393011338770118, 0.0058391757509601988, 0.0058390627494208742, 0.0058389523655187139, 0.0058388448026768817, 0.0058387484909822327, 0.0058386549146689781, 0.0058385694086367851, 0.005838492253128354, 0.0058384149324350546, 0.0058383416702596598, 0.0058382662947467859, 0.0058381984027943258], 'acc': [0.56462501532112264, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822267327968, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822266596353]}
[2017-11-29 00:27:51,299 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:95]: done!
[2017-11-29 00:27:51,299 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-29 00:27:51,299 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-29 00:27:51,299 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f65d4b7b358>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-29 00:27:51,346 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-29 00:32:03,376 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-29 00:32:03,377 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0097251793031485935, 0.0091746485778751823, 0.0087256527059834388, 0.0083604934887165794, 0.0080524248020358603, 0.0077540128712926728, 0.0075051844125501987, 0.0072951173414611417, 0.0071142504122813305, 0.0069579556360169943, 0.0068248698889363099, 0.0067105851767982399, 0.0066090226899017876, 0.0065162800109025551, 0.0064316689490639452, 0.0063584016814680058, 0.0062950013019897532, 0.0062374185528763625, 0.0061856419166693112, 0.0061397002470836683, 0.006100047231357146, 0.0060652509680478531, 0.0060350437856011314, 0.0060087099857217621, 0.0059857367476648989, 0.005965587693290187, 0.0059478051015968243, 0.0059321304782027108, 0.0059183024394352263, 0.0059060741968771932, 0.0058952322957413639, 0.0058856276049628134, 0.0058771046146357522, 0.0058695646500039004, 0.0058628746777470335, 0.0058569305428180221, 0.0058516285463329713, 0.0058469227126682127, 0.0058427335967736584, 0.0058390193447526795, 0.0058357173334622333, 0.0058327526677617557, 0.0058301114818633685, 0.0058277534982904885, 0.0058256627832467848, 0.0058237822752552721, 0.0058221141859931469, 0.0058206181616571318, 0.0058192870863232431, 0.0058180861554468976, 0.0058170206293235065, 0.0058160411712166928, 0.0058151493356410839, 0.005814337278060815, 0.0058136091474135631, 0.0058129520597191677, 0.0058123514673835879, 0.0058118026428580424, 0.0058113115603321231, 0.005810850041907162, 0.0058103922539065808, 0.0058099733576081345, 0.0058095907185429308, 0.0058092329024245848, 0.0058089082153429828, 0.0058086072123831618, 0.0058083317891339673, 0.0058080711644498831, 0.005807836182454504, 0.0058076096684437483, 0.0058074028137763255, 0.0058072125416821314, 0.0058070348937835203, 0.0058068578140567121, 0.0058066976299965996, 0.0058065459000590869, 0.0058063954269449826, 0.0058062620819003784, 0.00580613623381425, 0.005805995155557804, 0.0058058479519986035, 0.0058056994392483531, 0.0058055481590564718, 0.005805398258392571, 0.0058052569931699525, 0.0058051257166472081, 0.0058049893643137493, 0.0058048498483586237, 0.0058047190613706497, 0.0058045964441626706, 0.0058044786108928112, 0.0058043625301420305, 0.0058042535568439959, 0.0058041555971798491, 0.0058040663900996332, 0.0058039808864042966, 0.0058038973541966596, 0.0058038163459895728, 0.0058037377167452029, 0.0058036653258389725, 0.0058035904308695457], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010057348894817054, 0.0094453337803168409, 0.0089497262202966905, 0.0085458980362925901, 0.008216118362869524, 0.0079111773748194517, 0.0076403839300348084, 0.007413551113960918, 0.0072201134853510382, 0.0070525102085388517, 0.0069095877717553515, 0.0067872279337926836, 0.0066809880342487693, 0.0065848798371258834, 0.0064970366943138784, 0.0064186874487404955, 0.0063513618103091677, 0.0062914190088457396, 0.0062378979859844157, 0.0061891407050133828, 0.0061469784635664994, 0.0061102768004341144, 0.0060782746233071661, 0.0060504674074714779, 0.0060263007581009918, 0.0060051549196895341, 0.0059865910161619931, 0.0059702106452797022, 0.0059557709314443036, 0.005943034944226603, 0.0059317731035810877, 0.0059217925992709397, 0.0059129546642325411, 0.0059051296386899311, 0.0058982012332390206, 0.0058920513207511961, 0.0058866059591638625, 0.0058817498008553104, 0.0058774466631375958, 0.0058736209355238003, 0.0058702279485961482, 0.005867211358710653, 0.0058645164827027755, 0.0058621106367744346, 0.0058599675410991071, 0.005858070267314313, 0.0058563715788350927, 0.0058548636370393025, 0.005853514386174305, 0.0058523133316853377, 0.0058512359339598901, 0.0058502770300277382, 0.0058493905380547478, 0.0058485912412292529, 0.0058478629982460862, 0.0058472158221089653, 0.005846629722076566, 0.0058460899860643531, 0.0058456034156307169, 0.0058451593566946096, 0.0058447277277197751, 0.0058443146510632933, 0.0058439329194072583, 0.0058435909222567745, 0.0058432765668791917, 0.0058429885012163613, 0.005842723242382491, 0.0058424765215204675, 0.0058422498523867088, 0.0058420425722412322, 0.0058418439761900682, 0.0058416582000279183, 0.0058414898917940449, 0.0058413259919956407, 0.0058411779527452858, 0.0058410283824198231, 0.0058408916029474177, 0.0058407605446443439, 0.0058406349374990757, 0.0058405175215799129, 0.0058403777366574259, 0.0058402320031363374, 0.0058400936194273594, 0.0058399508164801656, 0.0058398178190553502, 0.0058396887277096703, 0.00583955959075239, 0.0058394287841704792, 0.0058393011338770118, 0.0058391757509601988, 0.0058390627494208742, 0.0058389523655187139, 0.0058388448026768817, 0.0058387484909822327, 0.0058386549146689781, 0.0058385694086367851, 0.005838492253128354, 0.0058384149324350546, 0.0058383416702596598, 0.0058382662947467859, 0.0058381984027943258], 'acc': [0.56462501532112264, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822267327968, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822266596353]}
[2017-11-29 00:32:03,377 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-29 00:32:03,485 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-29 00:32:03,485 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-29 00:32:04,332 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:141]: done!
[2017-11-29 00:32:04,332 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01 finished!
