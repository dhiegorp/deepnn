[2017-11-29 00:06:39,945 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_05
[2017-11-29 00:06:39,945 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-29 00:06:39,945 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42,25
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f87f1a21e10>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f87f1a24358>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-29 00:06:39,945 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-29 00:06:42,184 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-29 00:06:42,185 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-29 00:06:42,185 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-29 00:06:42,185 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f87f1a21e10>, 'discard_decoder_function': True}
[2017-11-29 00:06:42,390 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-29 00:11:06,530 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-29 00:11:06,531 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0099132456462481186, 0.0095438382638640944, 0.0092760578457790448, 0.0090796234618731389, 0.008934936979741067, 0.0088285002299543034, 0.0087494853728590141, 0.008690472651863089, 0.0086456889578253194, 0.0086114392422470959, 0.0085849387068760077, 0.008564152931455675, 0.0085476828028490017, 0.0085344994067598108, 0.0085238089661077293, 0.0085151222415024725, 0.0085079742955623729, 0.0085020422951230367, 0.0084970990916011045, 0.008492941565630914, 0.0084894203859183209, 0.008486437640717279, 0.0084839085947334743, 0.0084817347013059884, 0.0084798795306964079, 0.0084782781247809413, 0.0084768877029610615, 0.0084756787730129665, 0.008474630524788718, 0.0084737176366509077, 0.0084729306129427227, 0.0084722365472754638, 0.0084716305537139037, 0.0084711017124067325, 0.0084706270606563355, 0.0084702131454447802, 0.0084698499330634006, 0.008469509138482342, 0.0084692099631703405, 0.0084689460870717784, 0.0084687034161032362, 0.0084684845556404747, 0.0084682814225839238, 0.0084680911473237128, 0.0084679136993976167, 0.0084677381507397929, 0.0084675831681898482, 0.0084674393464508231, 0.0084673095428107938, 0.0084671902308395917, 0.0084670816538927312, 0.0084669691363663761, 0.0084668728377490701, 0.0084667824104685679, 0.0084666467498671662, 0.0084665417024309218, 0.0084664607297345717, 0.0084663769918213606, 0.0084662958349825835, 0.0084662194809068964, 0.0084661493157965877, 0.0084660783415548679, 0.0084660041516661112, 0.0084659290290856927, 0.0084658657912218323, 0.0084657947707733709, 0.0084657202820810091, 0.0084656583896890493, 0.0084655840858236606, 0.0084655218073486933, 0.0084654591927624551, 0.0084653964275764621, 0.0084653235585160098, 0.0084652572213776492, 0.0084651866017298981, 0.0084651159341640435, 0.0084650433050363835, 0.008464974236223834, 0.0084649001438826463, 0.0084648294263450548, 0.008464757040572906, 0.0084646827500561329, 0.0084646185822387868, 0.0084645483712640062, 0.0084644766953643393, 0.0084644113432852854, 0.0084643429911906605, 0.0084642818538511067, 0.0084642086154789846, 0.0084641382634880694, 0.0084640655686441524, 0.0084639898477719792, 0.0084639070843076369, 0.0084638228446234243, 0.008463742788189673, 0.0084636306694103967, 0.0084634762745417688, 0.0084633352505354611, 0.0084631895196022721, 0.0084630704366111531, 0.008462980729471296], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010153278707200484, 0.0097195055236077629, 0.0094031265868088701, 0.00917349486438368, 0.009003884389144198, 0.0088794526875081263, 0.0087874826779802823, 0.0087190060272156217, 0.0086674805648503262, 0.0086282500490771196, 0.0085980631225885638, 0.0085745500606429041, 0.0085560303221191378, 0.0085412594294846534, 0.0085293701807009781, 0.0085196937153732485, 0.0085117969395826238, 0.0085052622933038113, 0.0084998230929405859, 0.008495256272046876, 0.0084914183044058275, 0.008488157262578214, 0.0084853947840057599, 0.0084830375968526512, 0.0084810146983752693, 0.0084792735005705007, 0.0084777683756625498, 0.0084764628982160212, 0.0084753304651793305, 0.0084743417899612559, 0.0084734766835414723, 0.0084727275644489505, 0.0084720701861742947, 0.0084714948366474661, 0.0084709873560386683, 0.0084705323289987929, 0.0084701265991822382, 0.0084697691464438399, 0.0084694459998018324, 0.0084691573349580419, 0.0084688936057131878, 0.0084686536666330955, 0.0084684365198639863, 0.0084682343208965054, 0.0084680448118992797, 0.0084678641203445679, 0.0084676972018927245, 0.0084675403050753668, 0.0084673992570887917, 0.0084672708079635891, 0.0084671502711364099, 0.0084670415451987713, 0.0084669352430775738, 0.0084668377542835571, 0.0084667289813625396, 0.0084665976544768731, 0.00846650259384326, 0.0084664246956316531, 0.00846633902687236, 0.0084662608775111659, 0.0084661856069392673, 0.0084661083431747317, 0.0084660408990504515, 0.008465966073277393, 0.0084658931601050442, 0.0084658237922915179, 0.008465754438081452, 0.0084656872531087973, 0.0084656217735984574, 0.008465553092359546, 0.0084654861029794908, 0.0084654188196961171, 0.0084653519649788827, 0.0084652850032630057, 0.00846521802005595, 0.0084651452279429617, 0.0084650764362759652, 0.0084650010876270668, 0.0084649290296436447, 0.0084648604539172834, 0.0084647932053856043, 0.00846472086367288, 0.0084646484792064245, 0.0084645800136795169, 0.0084645116091967062, 0.008464445026548667, 0.0084643740051717382, 0.0084643082071803998, 0.0084642409827691417, 0.0084641719833921762, 0.008464104880954797, 0.0084640335687610497, 0.0084639556047041258, 0.008463872952483447, 0.0084637903006057127, 0.0084636912631321105, 0.0084635507116718155, 0.0084634025034642044, 0.0084632593129898813, 0.0084631236742647407, 0.0084630168760173648], 'acc': [0.010924266601202897, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-29 00:11:06,531 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:95]: done!
[2017-11-29 00:11:06,531 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-29 00:11:06,531 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-29 00:11:06,531 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f87f1a24358>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-29 00:11:06,577 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-29 00:26:05,901 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:125]: trained!
[2017-11-29 00:26:05,903 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0099132456462481186, 0.0095438382638640944, 0.0092760578457790448, 0.0090796234618731389, 0.008934936979741067, 0.0088285002299543034, 0.0087494853728590141, 0.008690472651863089, 0.0086456889578253194, 0.0086114392422470959, 0.0085849387068760077, 0.008564152931455675, 0.0085476828028490017, 0.0085344994067598108, 0.0085238089661077293, 0.0085151222415024725, 0.0085079742955623729, 0.0085020422951230367, 0.0084970990916011045, 0.008492941565630914, 0.0084894203859183209, 0.008486437640717279, 0.0084839085947334743, 0.0084817347013059884, 0.0084798795306964079, 0.0084782781247809413, 0.0084768877029610615, 0.0084756787730129665, 0.008474630524788718, 0.0084737176366509077, 0.0084729306129427227, 0.0084722365472754638, 0.0084716305537139037, 0.0084711017124067325, 0.0084706270606563355, 0.0084702131454447802, 0.0084698499330634006, 0.008469509138482342, 0.0084692099631703405, 0.0084689460870717784, 0.0084687034161032362, 0.0084684845556404747, 0.0084682814225839238, 0.0084680911473237128, 0.0084679136993976167, 0.0084677381507397929, 0.0084675831681898482, 0.0084674393464508231, 0.0084673095428107938, 0.0084671902308395917, 0.0084670816538927312, 0.0084669691363663761, 0.0084668728377490701, 0.0084667824104685679, 0.0084666467498671662, 0.0084665417024309218, 0.0084664607297345717, 0.0084663769918213606, 0.0084662958349825835, 0.0084662194809068964, 0.0084661493157965877, 0.0084660783415548679, 0.0084660041516661112, 0.0084659290290856927, 0.0084658657912218323, 0.0084657947707733709, 0.0084657202820810091, 0.0084656583896890493, 0.0084655840858236606, 0.0084655218073486933, 0.0084654591927624551, 0.0084653964275764621, 0.0084653235585160098, 0.0084652572213776492, 0.0084651866017298981, 0.0084651159341640435, 0.0084650433050363835, 0.008464974236223834, 0.0084649001438826463, 0.0084648294263450548, 0.008464757040572906, 0.0084646827500561329, 0.0084646185822387868, 0.0084645483712640062, 0.0084644766953643393, 0.0084644113432852854, 0.0084643429911906605, 0.0084642818538511067, 0.0084642086154789846, 0.0084641382634880694, 0.0084640655686441524, 0.0084639898477719792, 0.0084639070843076369, 0.0084638228446234243, 0.008463742788189673, 0.0084636306694103967, 0.0084634762745417688, 0.0084633352505354611, 0.0084631895196022721, 0.0084630704366111531, 0.008462980729471296], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010153278707200484, 0.0097195055236077629, 0.0094031265868088701, 0.00917349486438368, 0.009003884389144198, 0.0088794526875081263, 0.0087874826779802823, 0.0087190060272156217, 0.0086674805648503262, 0.0086282500490771196, 0.0085980631225885638, 0.0085745500606429041, 0.0085560303221191378, 0.0085412594294846534, 0.0085293701807009781, 0.0085196937153732485, 0.0085117969395826238, 0.0085052622933038113, 0.0084998230929405859, 0.008495256272046876, 0.0084914183044058275, 0.008488157262578214, 0.0084853947840057599, 0.0084830375968526512, 0.0084810146983752693, 0.0084792735005705007, 0.0084777683756625498, 0.0084764628982160212, 0.0084753304651793305, 0.0084743417899612559, 0.0084734766835414723, 0.0084727275644489505, 0.0084720701861742947, 0.0084714948366474661, 0.0084709873560386683, 0.0084705323289987929, 0.0084701265991822382, 0.0084697691464438399, 0.0084694459998018324, 0.0084691573349580419, 0.0084688936057131878, 0.0084686536666330955, 0.0084684365198639863, 0.0084682343208965054, 0.0084680448118992797, 0.0084678641203445679, 0.0084676972018927245, 0.0084675403050753668, 0.0084673992570887917, 0.0084672708079635891, 0.0084671502711364099, 0.0084670415451987713, 0.0084669352430775738, 0.0084668377542835571, 0.0084667289813625396, 0.0084665976544768731, 0.00846650259384326, 0.0084664246956316531, 0.00846633902687236, 0.0084662608775111659, 0.0084661856069392673, 0.0084661083431747317, 0.0084660408990504515, 0.008465966073277393, 0.0084658931601050442, 0.0084658237922915179, 0.008465754438081452, 0.0084656872531087973, 0.0084656217735984574, 0.008465553092359546, 0.0084654861029794908, 0.0084654188196961171, 0.0084653519649788827, 0.0084652850032630057, 0.00846521802005595, 0.0084651452279429617, 0.0084650764362759652, 0.0084650010876270668, 0.0084649290296436447, 0.0084648604539172834, 0.0084647932053856043, 0.00846472086367288, 0.0084646484792064245, 0.0084645800136795169, 0.0084645116091967062, 0.008464445026548667, 0.0084643740051717382, 0.0084643082071803998, 0.0084642409827691417, 0.0084641719833921762, 0.008464104880954797, 0.0084640335687610497, 0.0084639556047041258, 0.008463872952483447, 0.0084637903006057127, 0.0084636912631321105, 0.0084635507116718155, 0.0084634025034642044, 0.0084632593129898813, 0.0084631236742647407, 0.0084630168760173648], 'acc': [0.010924266601202897, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-29 00:26:05,903 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-29 00:26:06,158 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-29 00:26:06,159 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-29 00:26:07,055 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:141]: done!
[2017-11-29 00:26:07,055 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_05 finished!
