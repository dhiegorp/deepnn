[2017-10-25 00:05:13,762 AE_UNIGRAMA_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_05
[2017-10-25 00:05:13,762 AE_UNIGRAMA_05.py:149]: >> Printing header log
[2017-10-25 00:05:13,762 AE_UNIGRAMA_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_05
	layers = 96,172,156,139,123,107,91,74,58,42,25,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f41fe62d710>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f41fe62d7f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-25 00:05:13,762 AE_UNIGRAMA_05.py:151]: >> Loading dataset... 
[2017-10-25 00:05:15,907 AE_UNIGRAMA_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-10-25 00:05:15,908 AE_UNIGRAMA_05.py:153]: >> Executing autoencoder part ... 
[2017-10-25 00:05:15,908 AE_UNIGRAMA_05.py:60]: =======================================
[2017-10-25 00:05:15,908 AE_UNIGRAMA_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f41fe62d710>, 'discard_decoder_function': True}
[2017-10-25 00:05:16,112 AE_UNIGRAMA_05.py:76]: training and evaluate autoencoder
[2017-10-25 00:08:55,405 AE_UNIGRAMA_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_05
[2017-10-25 00:08:55,405 AE_UNIGRAMA_05.py:149]: >> Printing header log
[2017-10-25 00:08:55,406 AE_UNIGRAMA_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_05
	layers = 96,172,156,139,123,107,91,74,58,42,25,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc61644e710>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc61644e7f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-25 00:08:55,406 AE_UNIGRAMA_05.py:151]: >> Loading dataset... 
[2017-10-25 00:08:57,588 AE_UNIGRAMA_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-10-25 00:08:57,588 AE_UNIGRAMA_05.py:153]: >> Executing autoencoder part ... 
[2017-10-25 00:08:57,588 AE_UNIGRAMA_05.py:60]: =======================================
[2017-10-25 00:08:57,588 AE_UNIGRAMA_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc61644e710>, 'discard_decoder_function': True}
[2017-10-25 00:08:57,792 AE_UNIGRAMA_05.py:76]: training and evaluate autoencoder
[2017-10-25 00:13:25,095 AE_UNIGRAMA_05.py:88]: trained and evaluated!
[2017-10-25 00:13:25,096 AE_UNIGRAMA_05.py:91]: Training history: 
{'val_loss': [0.0092877634321447237, 0.0084495037460055513, 0.0078196903989841641, 0.0073379611384940908, 0.0069667965788784399, 0.0066732246844931065, 0.0064420300066602536, 0.0062578351403566376, 0.0061071228428659242, 0.0059858327719510612, 0.0058879036004889519, 0.0058079427921065001, 0.0057423197861469237, 0.0056864010955274477, 0.005640304646530394, 0.0056021188976888665, 0.0055652425235266723, 0.0055299412628730914, 0.0055005761563883347, 0.0054760606661171966, 0.0054554805610170102, 0.0054382296128986417, 0.0054236835202332951, 0.0054114021984494071, 0.0054009838938645985, 0.0053921499437091548, 0.00538463596001648, 0.0053781868327061281, 0.0053726956812176789, 0.0053679936701340825, 0.0053639524472204473, 0.0053604997470132936, 0.0053575188896144051, 0.0053549577041027002, 0.0053527395829499501, 0.0053508441251945964, 0.0053491998413041676, 0.0053477916738702254, 0.0053465722081001924, 0.0053455083350658151, 0.0053445893155499189, 0.0053437842571788232, 0.0053430878567875244, 0.0053424859739147268, 0.0053419715477422683, 0.0053415068650110951, 0.0053411008226584254, 0.0053407359938967246, 0.0053404161176216084, 0.0053401296616568533, 0.0053398812245146312, 0.0053396631515345641, 0.0053394697894072187, 0.0053392924383441473, 0.0053391474922410446, 0.0053390238925408008, 0.0053389022909399175, 0.0053387980583681424, 0.0053387057585165985, 0.0053386181214388267, 0.0053385504733124874, 0.0053384760580375071, 0.0053383900069634031, 0.0053382800062498825, 0.0053382269526944413, 0.0053381691307742632, 0.0053381326404536734, 0.0053380804815976847, 0.0053380394431645, 0.0053379944306947164, 0.0053379576979598626, 0.005337919417213551, 0.0053378789316354891, 0.0053378501488563273, 0.0053378173267521522, 0.0053377835555272488, 0.0053377438817332054, 0.0053377112812502603, 0.0053376555096259484, 0.0053375953012130654, 0.0053375390389415979, 0.0053374687645608987, 0.0053374188254255005, 0.0053373860075997268, 0.0053373497043308783, 0.0053373185430168396, 0.0053372846006558509, 0.0053372533603625091, 0.0053372255988379351, 0.0053371957379014382, 0.0053371723809918521, 0.005337142003994491, 0.0053371150047956083, 0.005337096446370709, 0.0053370705385066405, 0.0053370468573797408, 0.0053370139284866485, 0.0053369827512569539, 0.0053369514073407119, 0.0053369203888397367, 0.0053368774154564065, 0.0053368388307724083], 'loss': [0.009829593577040505, 0.0088547338594752133, 0.0081292032209301941, 0.0075798032215916552, 0.0071583209193857031, 0.0068301129057922036, 0.0065707491829783745, 0.0063659811381680904, 0.0062004475154387772, 0.0060663054668865487, 0.0059582774291996781, 0.0058706575310504975, 0.0057990061763019685, 0.0057392325538653081, 0.0056889939930221851, 0.0056475842122033805, 0.0056119579124504822, 0.0055749269848916006, 0.0055430159635194371, 0.0055164522293630891, 0.005494243146768666, 0.0054756345561045592, 0.0054600130409625091, 0.0054468488978818511, 0.0054357358016374584, 0.0054262983846489936, 0.0054183054334841045, 0.0054114897957987778, 0.0054056631957094033, 0.0054006948555557106, 0.0053964543811463863, 0.0053928166052194639, 0.005389695517042963, 0.0053870240553328267, 0.0053847217287608081, 0.0053827370385722472, 0.0053810506617956522, 0.0053795836868188243, 0.0053783304920406103, 0.0053772417385127922, 0.0053763032832098469, 0.0053754933128697903, 0.0053747859712595459, 0.0053741774189455006, 0.0053736488999575069, 0.0053731950527605536, 0.0053727946773914929, 0.0053724406112858353, 0.0053721265450103507, 0.005371852811506859, 0.0053716108423104546, 0.0053713935771112255, 0.0053712038497155988, 0.0053710503251844753, 0.0053709129639641154, 0.0053707863967461028, 0.0053706777556871942, 0.0053705868795463811, 0.0053704986476209192, 0.005370427615212614, 0.0053703579867042158, 0.0053703015548092125, 0.0053702381868073147, 0.0053701274565313472, 0.0053700597630293584, 0.0053700191712772148, 0.0053699702298015128, 0.0053699360014391783, 0.0053698983309442743, 0.0053698682019673811, 0.0053698344298925222, 0.0053698116583868307, 0.0053697758445927076, 0.0053697454262279292, 0.0053697180724139775, 0.0053696968388994388, 0.0053696669854211843, 0.0053696244297981467, 0.0053695930950288734, 0.0053695378662970104, 0.0053694899918926928, 0.0053694265792508704, 0.0053693651233352674, 0.0053693282777930278, 0.0053692926966294975, 0.0053692548386011845, 0.0053692403905266518, 0.0053692099942817843, 0.0053691846441202727, 0.0053691602820386273, 0.0053691279236947461, 0.005369106175992293, 0.0053690830049564191, 0.005369061521092496, 0.0053690329030141506, 0.0053690083714036749, 0.0053689794243273704, 0.0053689545065043849, 0.0053689231269237149, 0.0053688944283106022, 0.0053688553500862461, 0.0053688199090726448]}
[2017-10-25 00:13:25,096 AE_UNIGRAMA_05.py:95]: done!
[2017-10-25 00:13:25,096 AE_UNIGRAMA_05.py:155]: >> Executing classifier part ... 
[2017-10-25 00:13:25,096 AE_UNIGRAMA_05.py:100]: =======================================
[2017-10-25 00:13:25,097 AE_UNIGRAMA_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc61644e7f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-25 00:13:25,146 AE_UNIGRAMA_05.py:113]: training ... 
[2017-10-25 00:25:03,378 AE_UNIGRAMA_05.py:125]: trained!
[2017-10-25 00:25:03,378 AE_UNIGRAMA_05.py:128]: Training history: 
{'val_loss': [0.0092877634321447237, 0.0084495037460055513, 0.0078196903989841641, 0.0073379611384940908, 0.0069667965788784399, 0.0066732246844931065, 0.0064420300066602536, 0.0062578351403566376, 0.0061071228428659242, 0.0059858327719510612, 0.0058879036004889519, 0.0058079427921065001, 0.0057423197861469237, 0.0056864010955274477, 0.005640304646530394, 0.0056021188976888665, 0.0055652425235266723, 0.0055299412628730914, 0.0055005761563883347, 0.0054760606661171966, 0.0054554805610170102, 0.0054382296128986417, 0.0054236835202332951, 0.0054114021984494071, 0.0054009838938645985, 0.0053921499437091548, 0.00538463596001648, 0.0053781868327061281, 0.0053726956812176789, 0.0053679936701340825, 0.0053639524472204473, 0.0053604997470132936, 0.0053575188896144051, 0.0053549577041027002, 0.0053527395829499501, 0.0053508441251945964, 0.0053491998413041676, 0.0053477916738702254, 0.0053465722081001924, 0.0053455083350658151, 0.0053445893155499189, 0.0053437842571788232, 0.0053430878567875244, 0.0053424859739147268, 0.0053419715477422683, 0.0053415068650110951, 0.0053411008226584254, 0.0053407359938967246, 0.0053404161176216084, 0.0053401296616568533, 0.0053398812245146312, 0.0053396631515345641, 0.0053394697894072187, 0.0053392924383441473, 0.0053391474922410446, 0.0053390238925408008, 0.0053389022909399175, 0.0053387980583681424, 0.0053387057585165985, 0.0053386181214388267, 0.0053385504733124874, 0.0053384760580375071, 0.0053383900069634031, 0.0053382800062498825, 0.0053382269526944413, 0.0053381691307742632, 0.0053381326404536734, 0.0053380804815976847, 0.0053380394431645, 0.0053379944306947164, 0.0053379576979598626, 0.005337919417213551, 0.0053378789316354891, 0.0053378501488563273, 0.0053378173267521522, 0.0053377835555272488, 0.0053377438817332054, 0.0053377112812502603, 0.0053376555096259484, 0.0053375953012130654, 0.0053375390389415979, 0.0053374687645608987, 0.0053374188254255005, 0.0053373860075997268, 0.0053373497043308783, 0.0053373185430168396, 0.0053372846006558509, 0.0053372533603625091, 0.0053372255988379351, 0.0053371957379014382, 0.0053371723809918521, 0.005337142003994491, 0.0053371150047956083, 0.005337096446370709, 0.0053370705385066405, 0.0053370468573797408, 0.0053370139284866485, 0.0053369827512569539, 0.0053369514073407119, 0.0053369203888397367, 0.0053368774154564065, 0.0053368388307724083], 'loss': [0.009829593577040505, 0.0088547338594752133, 0.0081292032209301941, 0.0075798032215916552, 0.0071583209193857031, 0.0068301129057922036, 0.0065707491829783745, 0.0063659811381680904, 0.0062004475154387772, 0.0060663054668865487, 0.0059582774291996781, 0.0058706575310504975, 0.0057990061763019685, 0.0057392325538653081, 0.0056889939930221851, 0.0056475842122033805, 0.0056119579124504822, 0.0055749269848916006, 0.0055430159635194371, 0.0055164522293630891, 0.005494243146768666, 0.0054756345561045592, 0.0054600130409625091, 0.0054468488978818511, 0.0054357358016374584, 0.0054262983846489936, 0.0054183054334841045, 0.0054114897957987778, 0.0054056631957094033, 0.0054006948555557106, 0.0053964543811463863, 0.0053928166052194639, 0.005389695517042963, 0.0053870240553328267, 0.0053847217287608081, 0.0053827370385722472, 0.0053810506617956522, 0.0053795836868188243, 0.0053783304920406103, 0.0053772417385127922, 0.0053763032832098469, 0.0053754933128697903, 0.0053747859712595459, 0.0053741774189455006, 0.0053736488999575069, 0.0053731950527605536, 0.0053727946773914929, 0.0053724406112858353, 0.0053721265450103507, 0.005371852811506859, 0.0053716108423104546, 0.0053713935771112255, 0.0053712038497155988, 0.0053710503251844753, 0.0053709129639641154, 0.0053707863967461028, 0.0053706777556871942, 0.0053705868795463811, 0.0053704986476209192, 0.005370427615212614, 0.0053703579867042158, 0.0053703015548092125, 0.0053702381868073147, 0.0053701274565313472, 0.0053700597630293584, 0.0053700191712772148, 0.0053699702298015128, 0.0053699360014391783, 0.0053698983309442743, 0.0053698682019673811, 0.0053698344298925222, 0.0053698116583868307, 0.0053697758445927076, 0.0053697454262279292, 0.0053697180724139775, 0.0053696968388994388, 0.0053696669854211843, 0.0053696244297981467, 0.0053695930950288734, 0.0053695378662970104, 0.0053694899918926928, 0.0053694265792508704, 0.0053693651233352674, 0.0053693282777930278, 0.0053692926966294975, 0.0053692548386011845, 0.0053692403905266518, 0.0053692099942817843, 0.0053691846441202727, 0.0053691602820386273, 0.0053691279236947461, 0.005369106175992293, 0.0053690830049564191, 0.005369061521092496, 0.0053690329030141506, 0.0053690083714036749, 0.0053689794243273704, 0.0053689545065043849, 0.0053689231269237149, 0.0053688944283106022, 0.0053688553500862461, 0.0053688199090726448]}
[2017-10-25 00:25:03,378 AE_UNIGRAMA_05.py:132]: evaluating model ... 
[2017-10-25 00:25:03,556 AE_UNIGRAMA_05.py:136]: evaluated! 
[2017-10-25 00:25:03,557 AE_UNIGRAMA_05.py:138]: generating reports ... 
[2017-10-25 00:25:04,364 AE_UNIGRAMA_05.py:141]: done!
[2017-10-25 00:25:04,364 AE_UNIGRAMA_05.py:157]: >> experiment AE_UNIGRAMA_05 finished!
