[2017-11-29 00:38:18,729 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_04
[2017-11-29 00:38:18,730 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-29 00:38:18,730 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,34,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efceeafee10>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efceeb01358>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-29 00:38:18,730 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-29 00:38:20,932 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-29 00:38:20,932 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-29 00:38:20,932 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-29 00:38:20,932 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efceeafee10>, 'discard_decoder_function': True}
[2017-11-29 00:38:21,131 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-29 00:41:12,727 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-29 00:41:12,729 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0092110378518481546, 0.0083694404659560729, 0.0077684721091432919, 0.0073290650410394878, 0.0070011197494870706, 0.0067514229720908132, 0.0065575335997963531, 0.0064045874919100246, 0.0062818612592915697, 0.0061821269661390755, 0.0061000080134696339, 0.0060319129113369412, 0.0059749200078975358, 0.0059270517001608278, 0.005886606018027124, 0.0058522265421063011, 0.0058230386738203676, 0.0057981643701353492, 0.0057768730866150824, 0.0057586176589251832, 0.0057429359409135305, 0.005724423867539092, 0.0057046863575421821, 0.0056886028544446783, 0.0056753651252155384, 0.0056643761303043078, 0.0056551651159271969, 0.0056474064026700143, 0.0056408597627885361, 0.0056352913622682429, 0.0056305550712577312, 0.0056265152703993942, 0.0056230475224529897, 0.0056200580092476259, 0.0056175076446705764, 0.0056153134118049558, 0.005613434695009278, 0.005611806484562225, 0.0056104012931848012, 0.0056091869585880054, 0.0056081326446163603, 0.0056072197917325832, 0.0056064366498186453, 0.0056057421751361438, 0.0056051398192432074, 0.0056046185456592838, 0.0056041662062038091, 0.0056037688664633345, 0.0056034244353260374, 0.0056031324775928535, 0.0056028680743951485, 0.005602639233104772, 0.0056024363302262566, 0.0056022559521081133, 0.0056020991394288757, 0.0056019618451624061, 0.0056018361145611997, 0.0056017278677358466, 0.0056016323749983644, 0.0056015463653391927, 0.0056014700964892757, 0.0056014010787608483, 0.0056013473653046637, 0.0056012873679881408, 0.0056012405420748333, 0.0056011924238273791, 0.0056011480751944698, 0.0056011112730639332, 0.0056010796868189959, 0.0056010449931705938, 0.0056010209192863796, 0.0056009922102668716, 0.0056009654528832763, 0.0056009484361377992, 0.0056009280312401119, 0.0056009122256247086, 0.0056008923717852143, 0.0056008722158049622, 0.0056008584208674219, 0.0056008440536508136, 0.005600827703309252, 0.0056008130748534096, 0.0056008026720042103, 0.005600794254675869, 0.0056007806358373598, 0.0056007713222693415, 0.0056007648863545933, 0.005600754398793031, 0.0056007460898794001, 0.0056007370099977055, 0.005600729768031997, 0.0056007257952789191, 0.0056007194107049957, 0.005600714311962047, 0.0056007074450410681, 0.0056007016205099833, 0.005600694264139801, 0.0056006822132501025, 0.0056006758854933595, 0.0056006700692623748, 0.0056006612165638327], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097804985006733208, 0.0087726635489637061, 0.0080621396090821158, 0.0075494670873841431, 0.0071713863043209427, 0.0068867747343590111, 0.0066683003581750316, 0.0064975063195236039, 0.0063618885467979632, 0.0062524910407613888, 0.0061631183181361793, 0.0060893249424999549, 0.0060279374605297815, 0.0059765381686530282, 0.005933282437159417, 0.005896675114820428, 0.0058655738793414102, 0.0058391803417849122, 0.0058166830963029322, 0.0057974201913434213, 0.0057809371418900708, 0.0057655434090220243, 0.0057458056163715411, 0.0057286766510444452, 0.0057146890582527076, 0.0057031637650612815, 0.0056935836948208375, 0.0056855540575256802, 0.0056787896185758521, 0.0056730901908298185, 0.0056682523144851458, 0.0056641424292310063, 0.0056606375004049532, 0.0056576331923287662, 0.0056550650418077247, 0.0056528752226493607, 0.0056509891218204352, 0.0056493676268593133, 0.0056479701461281655, 0.0056467774441634694, 0.0056457478760309427, 0.0056448623120082409, 0.005644103628826171, 0.0056434444094547046, 0.0056428727409211944, 0.00564238091920916, 0.0056419572273386578, 0.0056415936147479308, 0.0056412745988707724, 0.0056410024313655561, 0.0056407654941346298, 0.0056405614231481854, 0.0056403859402324556, 0.0056402281579327525, 0.0056400909664698524, 0.0056399751566734557, 0.0056398743965903192, 0.0056397809807178694, 0.0056397038233804014, 0.0056396352335933205, 0.0056395703505775427, 0.0056395203309990783, 0.0056394687116994762, 0.0056394278814295281, 0.0056393931580270059, 0.0056393631816603548, 0.005639327192164402, 0.0056393012863758651, 0.0056392722246418284, 0.0056392539087836147, 0.0056392346691476018, 0.0056392134674125736, 0.0056392002455356097, 0.0056391824660423787, 0.0056391729137272549, 0.0056391559525564312, 0.0056391540958556502, 0.0056391363966685577, 0.0056391292494794073, 0.0056391191027273871, 0.0056391076783361433, 0.0056390937449067842, 0.005639082244038948, 0.0056390795762175918, 0.005639071034788134, 0.0056390633967312856, 0.0056390605859021311, 0.0056390529294977586, 0.0056390439012587784, 0.0056390394294929163, 0.0056390345056692272, 0.0056390243500006538, 0.0056390226325924424, 0.0056390163122421507, 0.005639012028524115, 0.0056390029266092535, 0.0056389934999832381, 0.0056389913428060382, 0.0056389888997275548, 0.0056389815268238566, 0.0056389795285442116], 'acc': [0.59150607579761416, 0.59383822272449271, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.59383822266596353, 0.59383822270254427, 0.59383822262938279, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822264767316, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822262938279, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822267327968, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353]}
[2017-11-29 00:41:12,729 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:95]: done!
[2017-11-29 00:41:12,729 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-29 00:41:12,730 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-29 00:41:12,730 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efceeb01358>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-29 00:41:12,801 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-29 00:47:02,938 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:125]: trained!
[2017-11-29 00:47:02,940 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0092110378518481546, 0.0083694404659560729, 0.0077684721091432919, 0.0073290650410394878, 0.0070011197494870706, 0.0067514229720908132, 0.0065575335997963531, 0.0064045874919100246, 0.0062818612592915697, 0.0061821269661390755, 0.0061000080134696339, 0.0060319129113369412, 0.0059749200078975358, 0.0059270517001608278, 0.005886606018027124, 0.0058522265421063011, 0.0058230386738203676, 0.0057981643701353492, 0.0057768730866150824, 0.0057586176589251832, 0.0057429359409135305, 0.005724423867539092, 0.0057046863575421821, 0.0056886028544446783, 0.0056753651252155384, 0.0056643761303043078, 0.0056551651159271969, 0.0056474064026700143, 0.0056408597627885361, 0.0056352913622682429, 0.0056305550712577312, 0.0056265152703993942, 0.0056230475224529897, 0.0056200580092476259, 0.0056175076446705764, 0.0056153134118049558, 0.005613434695009278, 0.005611806484562225, 0.0056104012931848012, 0.0056091869585880054, 0.0056081326446163603, 0.0056072197917325832, 0.0056064366498186453, 0.0056057421751361438, 0.0056051398192432074, 0.0056046185456592838, 0.0056041662062038091, 0.0056037688664633345, 0.0056034244353260374, 0.0056031324775928535, 0.0056028680743951485, 0.005602639233104772, 0.0056024363302262566, 0.0056022559521081133, 0.0056020991394288757, 0.0056019618451624061, 0.0056018361145611997, 0.0056017278677358466, 0.0056016323749983644, 0.0056015463653391927, 0.0056014700964892757, 0.0056014010787608483, 0.0056013473653046637, 0.0056012873679881408, 0.0056012405420748333, 0.0056011924238273791, 0.0056011480751944698, 0.0056011112730639332, 0.0056010796868189959, 0.0056010449931705938, 0.0056010209192863796, 0.0056009922102668716, 0.0056009654528832763, 0.0056009484361377992, 0.0056009280312401119, 0.0056009122256247086, 0.0056008923717852143, 0.0056008722158049622, 0.0056008584208674219, 0.0056008440536508136, 0.005600827703309252, 0.0056008130748534096, 0.0056008026720042103, 0.005600794254675869, 0.0056007806358373598, 0.0056007713222693415, 0.0056007648863545933, 0.005600754398793031, 0.0056007460898794001, 0.0056007370099977055, 0.005600729768031997, 0.0056007257952789191, 0.0056007194107049957, 0.005600714311962047, 0.0056007074450410681, 0.0056007016205099833, 0.005600694264139801, 0.0056006822132501025, 0.0056006758854933595, 0.0056006700692623748, 0.0056006612165638327], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097804985006733208, 0.0087726635489637061, 0.0080621396090821158, 0.0075494670873841431, 0.0071713863043209427, 0.0068867747343590111, 0.0066683003581750316, 0.0064975063195236039, 0.0063618885467979632, 0.0062524910407613888, 0.0061631183181361793, 0.0060893249424999549, 0.0060279374605297815, 0.0059765381686530282, 0.005933282437159417, 0.005896675114820428, 0.0058655738793414102, 0.0058391803417849122, 0.0058166830963029322, 0.0057974201913434213, 0.0057809371418900708, 0.0057655434090220243, 0.0057458056163715411, 0.0057286766510444452, 0.0057146890582527076, 0.0057031637650612815, 0.0056935836948208375, 0.0056855540575256802, 0.0056787896185758521, 0.0056730901908298185, 0.0056682523144851458, 0.0056641424292310063, 0.0056606375004049532, 0.0056576331923287662, 0.0056550650418077247, 0.0056528752226493607, 0.0056509891218204352, 0.0056493676268593133, 0.0056479701461281655, 0.0056467774441634694, 0.0056457478760309427, 0.0056448623120082409, 0.005644103628826171, 0.0056434444094547046, 0.0056428727409211944, 0.00564238091920916, 0.0056419572273386578, 0.0056415936147479308, 0.0056412745988707724, 0.0056410024313655561, 0.0056407654941346298, 0.0056405614231481854, 0.0056403859402324556, 0.0056402281579327525, 0.0056400909664698524, 0.0056399751566734557, 0.0056398743965903192, 0.0056397809807178694, 0.0056397038233804014, 0.0056396352335933205, 0.0056395703505775427, 0.0056395203309990783, 0.0056394687116994762, 0.0056394278814295281, 0.0056393931580270059, 0.0056393631816603548, 0.005639327192164402, 0.0056393012863758651, 0.0056392722246418284, 0.0056392539087836147, 0.0056392346691476018, 0.0056392134674125736, 0.0056392002455356097, 0.0056391824660423787, 0.0056391729137272549, 0.0056391559525564312, 0.0056391540958556502, 0.0056391363966685577, 0.0056391292494794073, 0.0056391191027273871, 0.0056391076783361433, 0.0056390937449067842, 0.005639082244038948, 0.0056390795762175918, 0.005639071034788134, 0.0056390633967312856, 0.0056390605859021311, 0.0056390529294977586, 0.0056390439012587784, 0.0056390394294929163, 0.0056390345056692272, 0.0056390243500006538, 0.0056390226325924424, 0.0056390163122421507, 0.005639012028524115, 0.0056390029266092535, 0.0056389934999832381, 0.0056389913428060382, 0.0056389888997275548, 0.0056389815268238566, 0.0056389795285442116], 'acc': [0.59150607579761416, 0.59383822272449271, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.59383822266596353, 0.59383822270254427, 0.59383822262938279, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822264767316, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822262938279, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822267327968, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353]}
[2017-11-29 00:47:02,940 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-29 00:47:03,182 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-29 00:47:03,182 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-29 00:47:04,062 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:141]: done!
[2017-11-29 00:47:04,062 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_04 finished!
