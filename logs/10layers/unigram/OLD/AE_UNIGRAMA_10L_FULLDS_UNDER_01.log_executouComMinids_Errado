[2017-11-13 17:34:14,571 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01
[2017-11-13 17:34:14,571 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-13 17:34:14,571 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17,15,13,11
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f17001d0eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f17001d5400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 17:34:14,571 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-13 17:34:15,216 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-13 17:34:15,216 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-13 17:34:15,218 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-13 17:34:15,218 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f17001d0eb8>, 'discard_decoder_function': True}
[2017-11-13 17:34:15,608 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-13 17:35:25,631 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-13 17:35:25,632 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010233055031598721, 0.010054847793342012, 0.0098860865064159201, 0.0097258559300055294, 0.0095740010179440772, 0.0094299987443206921, 0.0092934494090290767, 0.0091637258649869477, 0.0090405153920770139, 0.0089233758267306049, 0.0088119687630230613, 0.0087059837624042895, 0.0086050277652018128, 0.0085088774444168382, 0.0084172218975690667, 0.0083297358715013498, 0.0082461801132526543, 0.0081664096532895001, 0.0080901900199016902, 0.0080173546379106644, 0.0079477268901262371, 0.0078811237924354891, 0.0078173896841372478, 0.0077562863076431161, 0.0076978114246629651, 0.0076417802195982197, 0.0075880021660079747, 0.0075364478891473052, 0.0074869599678037777, 0.0074394024254193312, 0.0073937126123744534, 0.0073497721347196175, 0.0073075410511801676, 0.0072669403603279675, 0.0072278755242662805, 0.007190282228073888, 0.0071540107659746281, 0.0071191255065532867, 0.0070854622531391432, 0.0070530228493354353, 0.0070217294604638693, 0.0069915478387812917, 0.0069624210351240234, 0.0069342879249565444, 0.0069071260942180808, 0.0068808719913949533, 0.0068555057280762707, 0.006831002324736473, 0.0068072655539419573, 0.0067843307557491567, 0.0067621318235661018, 0.0067406518741417332, 0.0067198444330947103, 0.0066996906368151921, 0.0066801830451090763, 0.0066612783549388106, 0.0066429774041484946, 0.0066252047209879282, 0.0066080033955714735, 0.0065913175035365009, 0.0065751303832105546, 0.006559415902166894, 0.0065442005078893391, 0.0065294210470132671, 0.0065150711006834606, 0.0065011522649583101, 0.0064876188548302566, 0.0064744783606948018, 0.0064617247774255322, 0.0064493351145110834, 0.0064372898816896194, 0.0064255917759882255, 0.006414214318763589, 0.0064031536566252828, 0.0063924096320447646, 0.0063819725630756422, 0.0063718210137189545, 0.0063619450371726295, 0.0063523385123277019, 0.0063429802576543898, 0.0063338756845176883, 0.0063250252326126433, 0.006316427901373366, 0.006308073271412167, 0.0062999300845659797, 0.0062920042178610889, 0.0062842917988651529, 0.0062767817815384897, 0.0062694677816475409, 0.0062623260625842333, 0.0062553775496780872, 0.0062486151368339928, 0.006242034648680111, 0.0062356249405050362, 0.0062293832962397747, 0.0062233074325860433, 0.006217383750156953, 0.0062116150481134761, 0.0062059917726093507, 0.0062005197591248722, 0.0061951839697433004], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010321532788250844, 0.010138683761203846, 0.0099650756063852201, 0.0098003656211290251, 0.009644183508831991, 0.0094960773605269454, 0.0093555789745396172, 0.0092222877402034879, 0.0090956049624970146, 0.0089752344344756901, 0.0088607392599548609, 0.0087518093898004013, 0.0086481188405041834, 0.0085493150712680661, 0.0084551752979404073, 0.0083653821862350233, 0.0082796057806417255, 0.0081976632980862198, 0.0081194343958931534, 0.0080446306559971009, 0.0079731289188583049, 0.0079047361700197421, 0.0078392829030486579, 0.0077766166234614484, 0.007716523735545296, 0.0076589814399282627, 0.0076038068032765688, 0.007550844271537363, 0.0075000286704477682, 0.0074512263763977585, 0.0074043071619277912, 0.0073592099844814081, 0.0073158267090359238, 0.0072741020312298088, 0.0072339691293838567, 0.0071953311347881747, 0.0071581379174453464, 0.0071222351846235363, 0.0070876795761333003, 0.0070543123060550035, 0.007022160162648945, 0.0069911156714617404, 0.0069611629444851636, 0.0069322416108941916, 0.006904292058316417, 0.006877294741284741, 0.0068511939908079593, 0.0068259540768987065, 0.0068015609243936197, 0.0067779224273790484, 0.0067550702525397792, 0.0067329447548756327, 0.0067115253723067925, 0.0066907561124264093, 0.0066706407540457775, 0.0066511463625762973, 0.0066322579933530759, 0.0066139574855859102, 0.0065961782723211885, 0.0065789649800523957, 0.0065622468271190285, 0.0065460402358806452, 0.0065303005326193542, 0.0065150486557791955, 0.0065002298751329632, 0.006485825220492715, 0.0064718520681510579, 0.0064582630694851274, 0.0064450595662405357, 0.0064322356135797926, 0.0064197748535402581, 0.0064076642075366931, 0.0063958863988770581, 0.0063844216124858124, 0.0063732815150814911, 0.0063624487681510113, 0.006351927833113025, 0.006341682816841299, 0.0063317129417072432, 0.0063220138687894584, 0.0063125588410243745, 0.0063033534663820383, 0.0062944014956253071, 0.0062857087413633276, 0.0062772511048374106, 0.0062690007599951044, 0.0062609666731774111, 0.0062531517010317233, 0.0062455333275325507, 0.006238105102970546, 0.0062308622920254882, 0.0062238079356630666, 0.0062169380555846384, 0.0062102525504723824, 0.0062037285422470098, 0.0061973770900063344, 0.0061911943868906243, 0.0061851581650171896, 0.0061792767662200085, 0.0061735482228153973, 0.0061679699806783854], 'acc': [0.56238475740505423, 0.58881376763392457, 0.58881376737748181, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376785373274, 0.58881376772551131, 0.58881376785373274, 0.58881376763392457, 0.58881376800027152, 0.58881376737748181, 0.58881376737748181, 0.5888137674873859, 0.58881376785373274, 0.58881376726757773, 0.58881376737748181, 0.58881376772551131, 0.58881376800027152, 0.58881376800027152, 0.58881376763392457, 0.58881376785373274, 0.5888137674873859, 0.58881376800027152, 0.58881376774382865, 0.58881376772551131, 0.58881376774382865, 0.58881376811017561, 0.5888137674873859, 0.58881376774382865, 0.5888137674873859, 0.58881376726757773, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.5888137674873859, 0.5888137674873859, 0.58881376737748181, 0.58881376811017561, 0.58881376785373274, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.58881376763392457, 0.58881376737748181, 0.58881376774382865, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376774382865, 0.58881376811017561, 0.58881376726757773, 0.58881376811017561, 0.58881376811017561, 0.58881376785373274, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.5888137674873859, 0.58881376811017561, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376759728987, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376763392457, 0.58881376811017561, 0.58881376811017561, 0.58881376759728987, 0.5888137674873859, 0.58881376785373274, 0.5888137674873859, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376763392457, 0.58881376737748181, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865]}
[2017-11-13 17:35:25,632 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:95]: done!
[2017-11-13 17:35:25,632 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-13 17:35:25,633 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-13 17:35:25,633 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f17001d5400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 17:35:25,671 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-13 17:37:07,855 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-13 17:37:07,856 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010233055031598721, 0.010054847793342012, 0.0098860865064159201, 0.0097258559300055294, 0.0095740010179440772, 0.0094299987443206921, 0.0092934494090290767, 0.0091637258649869477, 0.0090405153920770139, 0.0089233758267306049, 0.0088119687630230613, 0.0087059837624042895, 0.0086050277652018128, 0.0085088774444168382, 0.0084172218975690667, 0.0083297358715013498, 0.0082461801132526543, 0.0081664096532895001, 0.0080901900199016902, 0.0080173546379106644, 0.0079477268901262371, 0.0078811237924354891, 0.0078173896841372478, 0.0077562863076431161, 0.0076978114246629651, 0.0076417802195982197, 0.0075880021660079747, 0.0075364478891473052, 0.0074869599678037777, 0.0074394024254193312, 0.0073937126123744534, 0.0073497721347196175, 0.0073075410511801676, 0.0072669403603279675, 0.0072278755242662805, 0.007190282228073888, 0.0071540107659746281, 0.0071191255065532867, 0.0070854622531391432, 0.0070530228493354353, 0.0070217294604638693, 0.0069915478387812917, 0.0069624210351240234, 0.0069342879249565444, 0.0069071260942180808, 0.0068808719913949533, 0.0068555057280762707, 0.006831002324736473, 0.0068072655539419573, 0.0067843307557491567, 0.0067621318235661018, 0.0067406518741417332, 0.0067198444330947103, 0.0066996906368151921, 0.0066801830451090763, 0.0066612783549388106, 0.0066429774041484946, 0.0066252047209879282, 0.0066080033955714735, 0.0065913175035365009, 0.0065751303832105546, 0.006559415902166894, 0.0065442005078893391, 0.0065294210470132671, 0.0065150711006834606, 0.0065011522649583101, 0.0064876188548302566, 0.0064744783606948018, 0.0064617247774255322, 0.0064493351145110834, 0.0064372898816896194, 0.0064255917759882255, 0.006414214318763589, 0.0064031536566252828, 0.0063924096320447646, 0.0063819725630756422, 0.0063718210137189545, 0.0063619450371726295, 0.0063523385123277019, 0.0063429802576543898, 0.0063338756845176883, 0.0063250252326126433, 0.006316427901373366, 0.006308073271412167, 0.0062999300845659797, 0.0062920042178610889, 0.0062842917988651529, 0.0062767817815384897, 0.0062694677816475409, 0.0062623260625842333, 0.0062553775496780872, 0.0062486151368339928, 0.006242034648680111, 0.0062356249405050362, 0.0062293832962397747, 0.0062233074325860433, 0.006217383750156953, 0.0062116150481134761, 0.0062059917726093507, 0.0062005197591248722, 0.0061951839697433004], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010321532788250844, 0.010138683761203846, 0.0099650756063852201, 0.0098003656211290251, 0.009644183508831991, 0.0094960773605269454, 0.0093555789745396172, 0.0092222877402034879, 0.0090956049624970146, 0.0089752344344756901, 0.0088607392599548609, 0.0087518093898004013, 0.0086481188405041834, 0.0085493150712680661, 0.0084551752979404073, 0.0083653821862350233, 0.0082796057806417255, 0.0081976632980862198, 0.0081194343958931534, 0.0080446306559971009, 0.0079731289188583049, 0.0079047361700197421, 0.0078392829030486579, 0.0077766166234614484, 0.007716523735545296, 0.0076589814399282627, 0.0076038068032765688, 0.007550844271537363, 0.0075000286704477682, 0.0074512263763977585, 0.0074043071619277912, 0.0073592099844814081, 0.0073158267090359238, 0.0072741020312298088, 0.0072339691293838567, 0.0071953311347881747, 0.0071581379174453464, 0.0071222351846235363, 0.0070876795761333003, 0.0070543123060550035, 0.007022160162648945, 0.0069911156714617404, 0.0069611629444851636, 0.0069322416108941916, 0.006904292058316417, 0.006877294741284741, 0.0068511939908079593, 0.0068259540768987065, 0.0068015609243936197, 0.0067779224273790484, 0.0067550702525397792, 0.0067329447548756327, 0.0067115253723067925, 0.0066907561124264093, 0.0066706407540457775, 0.0066511463625762973, 0.0066322579933530759, 0.0066139574855859102, 0.0065961782723211885, 0.0065789649800523957, 0.0065622468271190285, 0.0065460402358806452, 0.0065303005326193542, 0.0065150486557791955, 0.0065002298751329632, 0.006485825220492715, 0.0064718520681510579, 0.0064582630694851274, 0.0064450595662405357, 0.0064322356135797926, 0.0064197748535402581, 0.0064076642075366931, 0.0063958863988770581, 0.0063844216124858124, 0.0063732815150814911, 0.0063624487681510113, 0.006351927833113025, 0.006341682816841299, 0.0063317129417072432, 0.0063220138687894584, 0.0063125588410243745, 0.0063033534663820383, 0.0062944014956253071, 0.0062857087413633276, 0.0062772511048374106, 0.0062690007599951044, 0.0062609666731774111, 0.0062531517010317233, 0.0062455333275325507, 0.006238105102970546, 0.0062308622920254882, 0.0062238079356630666, 0.0062169380555846384, 0.0062102525504723824, 0.0062037285422470098, 0.0061973770900063344, 0.0061911943868906243, 0.0061851581650171896, 0.0061792767662200085, 0.0061735482228153973, 0.0061679699806783854], 'acc': [0.56238475740505423, 0.58881376763392457, 0.58881376737748181, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376785373274, 0.58881376772551131, 0.58881376785373274, 0.58881376763392457, 0.58881376800027152, 0.58881376737748181, 0.58881376737748181, 0.5888137674873859, 0.58881376785373274, 0.58881376726757773, 0.58881376737748181, 0.58881376772551131, 0.58881376800027152, 0.58881376800027152, 0.58881376763392457, 0.58881376785373274, 0.5888137674873859, 0.58881376800027152, 0.58881376774382865, 0.58881376772551131, 0.58881376774382865, 0.58881376811017561, 0.5888137674873859, 0.58881376774382865, 0.5888137674873859, 0.58881376726757773, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.5888137674873859, 0.5888137674873859, 0.58881376737748181, 0.58881376811017561, 0.58881376785373274, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.58881376763392457, 0.58881376737748181, 0.58881376774382865, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376774382865, 0.58881376811017561, 0.58881376726757773, 0.58881376811017561, 0.58881376811017561, 0.58881376785373274, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.5888137674873859, 0.58881376811017561, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376759728987, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376763392457, 0.58881376811017561, 0.58881376811017561, 0.58881376759728987, 0.5888137674873859, 0.58881376785373274, 0.5888137674873859, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376763392457, 0.58881376737748181, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865]}
[2017-11-13 17:37:07,856 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-13 17:37:07,994 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-13 17:37:07,994 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-13 17:37:08,577 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:141]: done!
[2017-11-13 17:37:08,577 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01 finished!
[2017-11-14 07:04:53,998 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01 was already executed!
[2017-11-18 14:56:41,661 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01 was already executed!
[2017-11-18 16:23:11,969 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01 was already executed!
[2017-11-18 18:34:37,630 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01
[2017-11-18 18:34:37,631 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 18:34:37,631 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17,15,13,11
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdbf998aeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdbf998f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:34:37,631 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 18:34:38,166 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-18 18:34:38,166 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:34:38,166 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 18:34:38,166 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdbf998aeb8>, 'discard_decoder_function': True}
[2017-11-18 18:34:38,367 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 18:35:17,062 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 18:35:17,063 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010194673580307944, 0.0099889077523162371, 0.0097993539168489026, 0.0096249894713325134, 0.009464263857158808, 0.0093157837672858436, 0.0091784391171371629, 0.0090510967710370465, 0.008932864978964887, 0.0088227197707918051, 0.0087200220618881708, 0.008624204382521955, 0.0085345688085573749, 0.0084505672722390152, 0.0083716990370788103, 0.0082975382134179865, 0.0082276341536508171, 0.0081616567368151746, 0.0080992810732813132, 0.0080402029408176597, 0.0079841516274944992, 0.0079308952114866792, 0.0078802241123243338, 0.0078319055911112, 0.0077857690305902609, 0.0077417193873885841, 0.0076995246981350239, 0.0076591357014048501, 0.007620388496542509, 0.0075831823760719773, 0.00754745227378208, 0.0075118040153583625, 0.0074766245462886682, 0.007442741911013552, 0.0074100915764953564, 0.0073785701988188747, 0.0073481497136689026, 0.0073187687368474925, 0.0072903762498808169, 0.007262926505442335, 0.0072363781877776059, 0.0072106829685155563, 0.0071858014620591274, 0.0071616972152656116, 0.0071374591488432707, 0.0071130549642482435, 0.0070894414829055612, 0.0070665877443984093, 0.0070445442478757588, 0.0070231732060668855, 0.0070017305493604073, 0.006981008320866797, 0.0069609071027667549, 0.0069414214785020372, 0.0069225054895539935, 0.0069043316608329471, 0.0068870215801362872, 0.0068701979631495737, 0.0068538416762140382, 0.0068379269417749239, 0.0068224493698061175, 0.0068074020134721329, 0.0067927387065243768, 0.0067784832513520712, 0.0067645973062011163, 0.0067510693611016279, 0.0067378931529958452, 0.0067250558164760081, 0.0067125580405130924, 0.0067003640176582953, 0.0066884867466127564, 0.0066769198396807485, 0.0066656328384594845, 0.0066546270551097655, 0.0066439060002676173, 0.0066334640357961884, 0.0066232765907054715, 0.0066133379264558118, 0.0066036433085356061, 0.0065941926365420496, 0.006584975740363385, 0.0065759717189052512, 0.0065671946683753153, 0.0065586379673816678, 0.0065502853974090634, 0.0065421416306501202, 0.0065342005511891225, 0.0065264464217518565, 0.0065188996483429877, 0.0065115228638080638, 0.0065043191356258983, 0.0064973088092132574, 0.0064904591757596426, 0.0064837805629053523, 0.0064772523551846969, 0.0064708842155021583, 0.0064646693164669674, 0.0064586158478320971, 0.0064527040181272975, 0.0064469325498134229, 0.0064413092968133743], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010300617424637244, 0.0100855226013134, 0.0098872083950771756, 0.0097046120277735886, 0.0095364331985012697, 0.0093811700268251873, 0.0092376127796729574, 0.0091045973977027083, 0.0089811442726702145, 0.0088663366179599599, 0.0087592291257034514, 0.0086592824771295103, 0.0085658938060133964, 0.0084783838897000158, 0.0083962632629381567, 0.0083190673697778762, 0.0082463558978494427, 0.0081777340133194192, 0.0081128548045391376, 0.008051435847794745, 0.0079931716360815766, 0.0079378344681853528, 0.0078851736179875245, 0.0078350007820235639, 0.0077870945121632741, 0.0077412922202066258, 0.0076975008185446881, 0.007655511949080848, 0.0076152867117819968, 0.0075766342353206255, 0.0075394952433331473, 0.0075034249998107046, 0.0074671386473782967, 0.0074319857726195286, 0.0073981006402515457, 0.0073654151927466842, 0.007333844073560975, 0.0073033365828558093, 0.0072738500134521423, 0.0072453309410923121, 0.0072177462225416975, 0.0071910533372292178, 0.0071651952094487163, 0.007140124490863535, 0.007115632860011753, 0.0070904530132602679, 0.0070658250512657134, 0.0070419737770947384, 0.0070189212027596017, 0.0069966224974139235, 0.0069746388813346789, 0.0069529381906928535, 0.0069319368554731416, 0.006911540664411903, 0.0068917674946666826, 0.0068725863126459742, 0.0068543898365297194, 0.0068368405941129648, 0.0068197706213407559, 0.0068031661613136259, 0.0067870024046170875, 0.0067712644758487154, 0.0067559544935240912, 0.0067410449581547021, 0.0067265264091174075, 0.0067123753847537155, 0.0066985893483973748, 0.0066851497474386965, 0.0066720557807799889, 0.0066592869089519089, 0.0066468253443801809, 0.0066346891737270007, 0.006622857010631966, 0.0066113031031958848, 0.0066000317745986865, 0.0065890505363833856, 0.0065783481299648196, 0.0065678999934988876, 0.0065577032571726033, 0.0065477469546197193, 0.0065380474901686582, 0.0065285650473465824, 0.0065193076004957081, 0.006510272129257361, 0.0065014659499803345, 0.0064928626596410174, 0.0064844712314494164, 0.0064762735378155146, 0.0064682726305809284, 0.0064604829129039981, 0.0064528678047580078, 0.0064454235674008568, 0.0064381686939108604, 0.0064310846917821204, 0.0064241675117362772, 0.0064174067592517358, 0.0064108065709004613, 0.0064043590888271098, 0.0063980726127930041, 0.0063919314285185011, 0.0063859352363432632], 'acc': [0.57713583326075957, 0.58881376774382865, 0.58881376737748181, 0.5888137674873859, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865, 0.58881376759728987, 0.5888137674873859, 0.58881376800027152, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376774382865, 0.58881376785373274, 0.58881376800027152, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376811017561, 0.58881376763392457, 0.58881376746906855, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376737748181, 0.58881376785373274, 0.58881376726757773, 0.58881376811017561, 0.5888137674873859, 0.5888137674873859, 0.58881376789036743, 0.58881376737748181, 0.58881376774382865, 0.58881376763392457, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376726757773, 0.5888137674873859, 0.58881376785373274, 0.58881376737748181, 0.5888137674873859, 0.58881376774382865, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.58881376811017561, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.5888137674873859, 0.58881376763392457, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376763392457, 0.58881376726757773, 0.5888137674873859, 0.58881376726757773, 0.58881376789036743, 0.58881376774382865, 0.58881376759728987, 0.5888137674873859, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376800027152, 0.58881376800027152, 0.58881376800027152, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376811017561, 0.58881376726757773, 0.58881376785373274, 0.5888137674873859, 0.58881376726757773, 0.58881376772551131, 0.58881376800027152, 0.58881376785373274, 0.58881376763392457, 0.58881376800027152, 0.58881376811017561, 0.58881376811017561, 0.58881376772551131, 0.58881376737748181, 0.58881376759728987]}
[2017-11-18 18:35:17,063 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:95]: done!
[2017-11-18 18:35:17,063 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 18:35:17,063 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 18:35:17,063 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdbf998f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:35:17,107 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 18:36:54,765 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 18:36:54,766 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010194673580307944, 0.0099889077523162371, 0.0097993539168489026, 0.0096249894713325134, 0.009464263857158808, 0.0093157837672858436, 0.0091784391171371629, 0.0090510967710370465, 0.008932864978964887, 0.0088227197707918051, 0.0087200220618881708, 0.008624204382521955, 0.0085345688085573749, 0.0084505672722390152, 0.0083716990370788103, 0.0082975382134179865, 0.0082276341536508171, 0.0081616567368151746, 0.0080992810732813132, 0.0080402029408176597, 0.0079841516274944992, 0.0079308952114866792, 0.0078802241123243338, 0.0078319055911112, 0.0077857690305902609, 0.0077417193873885841, 0.0076995246981350239, 0.0076591357014048501, 0.007620388496542509, 0.0075831823760719773, 0.00754745227378208, 0.0075118040153583625, 0.0074766245462886682, 0.007442741911013552, 0.0074100915764953564, 0.0073785701988188747, 0.0073481497136689026, 0.0073187687368474925, 0.0072903762498808169, 0.007262926505442335, 0.0072363781877776059, 0.0072106829685155563, 0.0071858014620591274, 0.0071616972152656116, 0.0071374591488432707, 0.0071130549642482435, 0.0070894414829055612, 0.0070665877443984093, 0.0070445442478757588, 0.0070231732060668855, 0.0070017305493604073, 0.006981008320866797, 0.0069609071027667549, 0.0069414214785020372, 0.0069225054895539935, 0.0069043316608329471, 0.0068870215801362872, 0.0068701979631495737, 0.0068538416762140382, 0.0068379269417749239, 0.0068224493698061175, 0.0068074020134721329, 0.0067927387065243768, 0.0067784832513520712, 0.0067645973062011163, 0.0067510693611016279, 0.0067378931529958452, 0.0067250558164760081, 0.0067125580405130924, 0.0067003640176582953, 0.0066884867466127564, 0.0066769198396807485, 0.0066656328384594845, 0.0066546270551097655, 0.0066439060002676173, 0.0066334640357961884, 0.0066232765907054715, 0.0066133379264558118, 0.0066036433085356061, 0.0065941926365420496, 0.006584975740363385, 0.0065759717189052512, 0.0065671946683753153, 0.0065586379673816678, 0.0065502853974090634, 0.0065421416306501202, 0.0065342005511891225, 0.0065264464217518565, 0.0065188996483429877, 0.0065115228638080638, 0.0065043191356258983, 0.0064973088092132574, 0.0064904591757596426, 0.0064837805629053523, 0.0064772523551846969, 0.0064708842155021583, 0.0064646693164669674, 0.0064586158478320971, 0.0064527040181272975, 0.0064469325498134229, 0.0064413092968133743], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010300617424637244, 0.0100855226013134, 0.0098872083950771756, 0.0097046120277735886, 0.0095364331985012697, 0.0093811700268251873, 0.0092376127796729574, 0.0091045973977027083, 0.0089811442726702145, 0.0088663366179599599, 0.0087592291257034514, 0.0086592824771295103, 0.0085658938060133964, 0.0084783838897000158, 0.0083962632629381567, 0.0083190673697778762, 0.0082463558978494427, 0.0081777340133194192, 0.0081128548045391376, 0.008051435847794745, 0.0079931716360815766, 0.0079378344681853528, 0.0078851736179875245, 0.0078350007820235639, 0.0077870945121632741, 0.0077412922202066258, 0.0076975008185446881, 0.007655511949080848, 0.0076152867117819968, 0.0075766342353206255, 0.0075394952433331473, 0.0075034249998107046, 0.0074671386473782967, 0.0074319857726195286, 0.0073981006402515457, 0.0073654151927466842, 0.007333844073560975, 0.0073033365828558093, 0.0072738500134521423, 0.0072453309410923121, 0.0072177462225416975, 0.0071910533372292178, 0.0071651952094487163, 0.007140124490863535, 0.007115632860011753, 0.0070904530132602679, 0.0070658250512657134, 0.0070419737770947384, 0.0070189212027596017, 0.0069966224974139235, 0.0069746388813346789, 0.0069529381906928535, 0.0069319368554731416, 0.006911540664411903, 0.0068917674946666826, 0.0068725863126459742, 0.0068543898365297194, 0.0068368405941129648, 0.0068197706213407559, 0.0068031661613136259, 0.0067870024046170875, 0.0067712644758487154, 0.0067559544935240912, 0.0067410449581547021, 0.0067265264091174075, 0.0067123753847537155, 0.0066985893483973748, 0.0066851497474386965, 0.0066720557807799889, 0.0066592869089519089, 0.0066468253443801809, 0.0066346891737270007, 0.006622857010631966, 0.0066113031031958848, 0.0066000317745986865, 0.0065890505363833856, 0.0065783481299648196, 0.0065678999934988876, 0.0065577032571726033, 0.0065477469546197193, 0.0065380474901686582, 0.0065285650473465824, 0.0065193076004957081, 0.006510272129257361, 0.0065014659499803345, 0.0064928626596410174, 0.0064844712314494164, 0.0064762735378155146, 0.0064682726305809284, 0.0064604829129039981, 0.0064528678047580078, 0.0064454235674008568, 0.0064381686939108604, 0.0064310846917821204, 0.0064241675117362772, 0.0064174067592517358, 0.0064108065709004613, 0.0064043590888271098, 0.0063980726127930041, 0.0063919314285185011, 0.0063859352363432632], 'acc': [0.57713583326075957, 0.58881376774382865, 0.58881376737748181, 0.5888137674873859, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865, 0.58881376759728987, 0.5888137674873859, 0.58881376800027152, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376774382865, 0.58881376785373274, 0.58881376800027152, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376811017561, 0.58881376763392457, 0.58881376746906855, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376737748181, 0.58881376785373274, 0.58881376726757773, 0.58881376811017561, 0.5888137674873859, 0.5888137674873859, 0.58881376789036743, 0.58881376737748181, 0.58881376774382865, 0.58881376763392457, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376726757773, 0.5888137674873859, 0.58881376785373274, 0.58881376737748181, 0.5888137674873859, 0.58881376774382865, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.58881376811017561, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376811017561, 0.58881376800027152, 0.58881376785373274, 0.5888137674873859, 0.58881376763392457, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376763392457, 0.58881376726757773, 0.5888137674873859, 0.58881376726757773, 0.58881376789036743, 0.58881376774382865, 0.58881376759728987, 0.5888137674873859, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376800027152, 0.58881376800027152, 0.58881376800027152, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376811017561, 0.58881376726757773, 0.58881376785373274, 0.5888137674873859, 0.58881376726757773, 0.58881376772551131, 0.58881376800027152, 0.58881376785373274, 0.58881376763392457, 0.58881376800027152, 0.58881376811017561, 0.58881376811017561, 0.58881376772551131, 0.58881376737748181, 0.58881376759728987]}
[2017-11-18 18:36:54,767 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 18:36:54,860 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 18:36:54,860 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 18:36:55,471 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:141]: done!
[2017-11-18 18:36:55,471 AE_UNIGRAMA_10L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_01 finished!
