[2017-11-29 00:47:07,980 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_03
[2017-11-29 00:47:07,980 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-29 00:47:07,980 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48,40,32,24,17
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5a28155e48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5a28159390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-29 00:47:07,980 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-29 00:47:10,138 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-29 00:47:10,138 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-29 00:47:10,138 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:60]: =======================================
[2017-11-29 00:47:10,138 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5a28155e48>, 'discard_decoder_function': True}
[2017-11-29 00:47:10,340 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-29 00:49:12,173 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-29 00:49:12,174 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.009475766401156065, 0.0087345964133257546, 0.0081568889098104329, 0.0076969789018671722, 0.0073209070872333349, 0.0070228002178566564, 0.0067835213771881928, 0.0065892981103484859, 0.0064301647809606203, 0.0062985267849192048, 0.0061889053079361581, 0.0060969945661126694, 0.0060193169956499057, 0.0059533560823461602, 0.0058972063610068046, 0.0058491375474091544, 0.0058078788350432436, 0.0057723417379973796, 0.0057416865070758112, 0.0057152536197454945, 0.0056924018355135044, 0.0056726053817138123, 0.0056554130362384417, 0.0056404858872599736, 0.0056274797380119783, 0.0056162075063768873, 0.0056063705407191191, 0.0055977902755939436, 0.0055903191813423498, 0.0055837998393777925, 0.005578117796881497, 0.0055731357951833019, 0.0055687840177771012, 0.005564978619361791, 0.0055616433448639098, 0.0055587173545495559, 0.0055561490013452024, 0.0055538800293295611, 0.0055518803738286255, 0.0055501165554900844, 0.0055485817585626497, 0.0055472281772077896, 0.0055460382259948171, 0.0055449818392229108, 0.0055439739323945737, 0.0055431506033639059, 0.0055424293694153115, 0.0055417907501282343, 0.005541217944217529, 0.0055407123846056344, 0.0055402659803207239, 0.005539863931942007, 0.0055394627217022659, 0.005539114867843269, 0.0055388211071914287, 0.0055385581754217829, 0.0055383084746107088, 0.005538075181642922, 0.0055378397983334238, 0.0055376070934747921, 0.0055374027191682175, 0.0055372349773963195, 0.0055370917815019578, 0.0055369602038652715, 0.0055368407067248257, 0.005536725265338458, 0.0055366187554587998, 0.0055365239073053817, 0.0055364321679245163, 0.0055363464060703953, 0.0055362615794749799, 0.005536179770436583, 0.0055361086007574547, 0.0055360456504877859, 0.0055359773335616263, 0.0055359155133890949, 0.0055358581990585451, 0.0055358051720291969, 0.0055357526015909235, 0.005535697037297979, 0.005535647163450997, 0.0055356038396665334, 0.0055355556126620974, 0.0055355068093568948, 0.0055354591634450357, 0.0055354100889747071, 0.0055353625478837005, 0.0055353152802681566, 0.0055352691907534233, 0.0055352204135464735, 0.0055351789072272325, 0.0055351267191069732, 0.0055350755050933096, 0.0055350270256631483, 0.0055349789982033874, 0.0055349324295076155, 0.0055348869052553708, 0.0055348440687809086, 0.0055347950352976722, 0.0055347485457523391, 0.0055347000789862481], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099316457567920104, 0.0090949004933254494, 0.0084415164709729512, 0.0079293617402774151, 0.0075133504278338719, 0.0071802050025240403, 0.0069146842991962259, 0.0067006973814933935, 0.0065262764898644712, 0.0063828671602224763, 0.0062639830203374113, 0.0061647115739153196, 0.0060812958719775149, 0.0060106605073368281, 0.0059506667198777211, 0.0058995385954232656, 0.005855748341300487, 0.0058181411004839603, 0.0057857808160521407, 0.0057578439196923565, 0.0057338056017028436, 0.0057130070744219278, 0.0056950177476532519, 0.0056794172778636002, 0.0056658592306596924, 0.0056540875692102054, 0.0056438870513447047, 0.0056349974491659649, 0.0056272592594794725, 0.0056205348553401433, 0.0056146776576975607, 0.0056095741573975863, 0.0056051126207662047, 0.0056012328115694395, 0.005597836838110804, 0.0055948686574513601, 0.0055922774366057729, 0.0055900048418810752, 0.0055880000294320263, 0.0055862376317784247, 0.0055846951229627422, 0.0055833442124756582, 0.005582167811628202, 0.0055811314185027537, 0.0055801731063782568, 0.0055793347382444508, 0.0055786337779142802, 0.0055780182118735991, 0.0055774751691346821, 0.0055769952555940723, 0.0055765718572839459, 0.0055761961412149784, 0.0055758496199424601, 0.0055754999081442198, 0.0055752184026069485, 0.0055749757607251758, 0.0055747565858974201, 0.0055745533942203225, 0.0055743481607668033, 0.0055741416948284018, 0.0055739455361399817, 0.005573784123431254, 0.0055736487910125875, 0.0055735303140807234, 0.0055734272639294466, 0.0055733332335578568, 0.0055732374876642484, 0.0055731509127316331, 0.0055730705229720739, 0.0055730001004903182, 0.005572930971709013, 0.0055728583622138986, 0.0055727946401791031, 0.0055727351511637348, 0.0055726811041609892, 0.005572629800713145, 0.0055725790996470747, 0.0055725265133586841, 0.0055724800281648232, 0.0055724356380180739, 0.0055723929369294696, 0.0055723468026248491, 0.0055723057280641997, 0.0055722605837827972, 0.0055722195502039993, 0.0055721754587046337, 0.0055721289961451004, 0.0055720871168655041, 0.0055720483723260134, 0.0055720000619822532, 0.0055719532328723535, 0.005571908112425584, 0.0055718628229072444, 0.0055718193717421609, 0.0055717714358936446, 0.0055717289565757281, 0.0055716840856781403, 0.0055716409388761792, 0.0055715975635018001, 0.0055715548213741868, 0.0055715074436104642], 'acc': [0.58058180928054703, 0.59383822270254427, 0.59383822265133124, 0.59383822262938279, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822267327968, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.59383822267327968, 0.59383822264767316, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822266596353, 0.59383822267327968, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822272449271, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822270986042, 0.59383822265133124, 0.59383822268791198]}
[2017-11-29 00:49:12,175 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:95]: done!
[2017-11-29 00:49:12,175 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-29 00:49:12,175 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:100]: =======================================
[2017-11-29 00:49:12,175 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5a28159390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-29 00:49:12,217 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:113]: training ... 
[2017-11-29 00:51:33,248 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:125]: trained!
[2017-11-29 00:51:33,250 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.009475766401156065, 0.0087345964133257546, 0.0081568889098104329, 0.0076969789018671722, 0.0073209070872333349, 0.0070228002178566564, 0.0067835213771881928, 0.0065892981103484859, 0.0064301647809606203, 0.0062985267849192048, 0.0061889053079361581, 0.0060969945661126694, 0.0060193169956499057, 0.0059533560823461602, 0.0058972063610068046, 0.0058491375474091544, 0.0058078788350432436, 0.0057723417379973796, 0.0057416865070758112, 0.0057152536197454945, 0.0056924018355135044, 0.0056726053817138123, 0.0056554130362384417, 0.0056404858872599736, 0.0056274797380119783, 0.0056162075063768873, 0.0056063705407191191, 0.0055977902755939436, 0.0055903191813423498, 0.0055837998393777925, 0.005578117796881497, 0.0055731357951833019, 0.0055687840177771012, 0.005564978619361791, 0.0055616433448639098, 0.0055587173545495559, 0.0055561490013452024, 0.0055538800293295611, 0.0055518803738286255, 0.0055501165554900844, 0.0055485817585626497, 0.0055472281772077896, 0.0055460382259948171, 0.0055449818392229108, 0.0055439739323945737, 0.0055431506033639059, 0.0055424293694153115, 0.0055417907501282343, 0.005541217944217529, 0.0055407123846056344, 0.0055402659803207239, 0.005539863931942007, 0.0055394627217022659, 0.005539114867843269, 0.0055388211071914287, 0.0055385581754217829, 0.0055383084746107088, 0.005538075181642922, 0.0055378397983334238, 0.0055376070934747921, 0.0055374027191682175, 0.0055372349773963195, 0.0055370917815019578, 0.0055369602038652715, 0.0055368407067248257, 0.005536725265338458, 0.0055366187554587998, 0.0055365239073053817, 0.0055364321679245163, 0.0055363464060703953, 0.0055362615794749799, 0.005536179770436583, 0.0055361086007574547, 0.0055360456504877859, 0.0055359773335616263, 0.0055359155133890949, 0.0055358581990585451, 0.0055358051720291969, 0.0055357526015909235, 0.005535697037297979, 0.005535647163450997, 0.0055356038396665334, 0.0055355556126620974, 0.0055355068093568948, 0.0055354591634450357, 0.0055354100889747071, 0.0055353625478837005, 0.0055353152802681566, 0.0055352691907534233, 0.0055352204135464735, 0.0055351789072272325, 0.0055351267191069732, 0.0055350755050933096, 0.0055350270256631483, 0.0055349789982033874, 0.0055349324295076155, 0.0055348869052553708, 0.0055348440687809086, 0.0055347950352976722, 0.0055347485457523391, 0.0055347000789862481], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099316457567920104, 0.0090949004933254494, 0.0084415164709729512, 0.0079293617402774151, 0.0075133504278338719, 0.0071802050025240403, 0.0069146842991962259, 0.0067006973814933935, 0.0065262764898644712, 0.0063828671602224763, 0.0062639830203374113, 0.0061647115739153196, 0.0060812958719775149, 0.0060106605073368281, 0.0059506667198777211, 0.0058995385954232656, 0.005855748341300487, 0.0058181411004839603, 0.0057857808160521407, 0.0057578439196923565, 0.0057338056017028436, 0.0057130070744219278, 0.0056950177476532519, 0.0056794172778636002, 0.0056658592306596924, 0.0056540875692102054, 0.0056438870513447047, 0.0056349974491659649, 0.0056272592594794725, 0.0056205348553401433, 0.0056146776576975607, 0.0056095741573975863, 0.0056051126207662047, 0.0056012328115694395, 0.005597836838110804, 0.0055948686574513601, 0.0055922774366057729, 0.0055900048418810752, 0.0055880000294320263, 0.0055862376317784247, 0.0055846951229627422, 0.0055833442124756582, 0.005582167811628202, 0.0055811314185027537, 0.0055801731063782568, 0.0055793347382444508, 0.0055786337779142802, 0.0055780182118735991, 0.0055774751691346821, 0.0055769952555940723, 0.0055765718572839459, 0.0055761961412149784, 0.0055758496199424601, 0.0055754999081442198, 0.0055752184026069485, 0.0055749757607251758, 0.0055747565858974201, 0.0055745533942203225, 0.0055743481607668033, 0.0055741416948284018, 0.0055739455361399817, 0.005573784123431254, 0.0055736487910125875, 0.0055735303140807234, 0.0055734272639294466, 0.0055733332335578568, 0.0055732374876642484, 0.0055731509127316331, 0.0055730705229720739, 0.0055730001004903182, 0.005572930971709013, 0.0055728583622138986, 0.0055727946401791031, 0.0055727351511637348, 0.0055726811041609892, 0.005572629800713145, 0.0055725790996470747, 0.0055725265133586841, 0.0055724800281648232, 0.0055724356380180739, 0.0055723929369294696, 0.0055723468026248491, 0.0055723057280641997, 0.0055722605837827972, 0.0055722195502039993, 0.0055721754587046337, 0.0055721289961451004, 0.0055720871168655041, 0.0055720483723260134, 0.0055720000619822532, 0.0055719532328723535, 0.005571908112425584, 0.0055718628229072444, 0.0055718193717421609, 0.0055717714358936446, 0.0055717289565757281, 0.0055716840856781403, 0.0055716409388761792, 0.0055715975635018001, 0.0055715548213741868, 0.0055715074436104642], 'acc': [0.58058180928054703, 0.59383822270254427, 0.59383822265133124, 0.59383822262938279, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822267327968, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.59383822267327968, 0.59383822264767316, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822266596353, 0.59383822267327968, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822272449271, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822270986042, 0.59383822265133124, 0.59383822268791198]}
[2017-11-29 00:51:33,251 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-29 00:51:33,451 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-29 00:51:33,452 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-29 00:51:34,314 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:141]: done!
[2017-11-29 00:51:34,314 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_03 finished!
