[2017-11-14 07:14:34,942 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_04
[2017-11-14 07:14:34,942 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-14 07:14:34,942 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,34,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f70eec8eeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f70eec93400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 07:14:34,942 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-14 07:14:35,482 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-14 07:14:35,482 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-14 07:14:35,482 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-14 07:14:35,482 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f70eec8eeb8>, 'discard_decoder_function': True}
[2017-11-14 07:14:35,677 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-14 07:15:53,792 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-14 07:15:53,793 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.010199879860456991, 0.0099930060771207391, 0.0097980313937847934, 0.0096143115533439648, 0.0094413469618248678, 0.00927828794144454, 0.0091245931583598637, 0.0089795270685425043, 0.0088426238549076941, 0.0087132910162653621, 0.0085909966254766098, 0.008475273189768472, 0.0083657026110860941, 0.0082619925614681837, 0.0081637113400108308, 0.0080705108605740681, 0.0079820870255642891, 0.0078981445866834268, 0.0078184693397393232, 0.0077427288181525847, 0.007670696452606234, 0.00760221719693351, 0.0075370591119984266, 0.0074750062192489005, 0.0074159379210669311, 0.0073595890640298454, 0.0073058801048805719, 0.0072546331108059581, 0.0072057373634778436, 0.0071589914583306772, 0.007114395194558849, 0.0070717630295089855, 0.0070309993814413876, 0.0069919998158586511, 0.0069546973069638121, 0.0069190236310505736, 0.0068848623260578702, 0.006852128070374071, 0.0068207496057046393, 0.0067906997800150325, 0.0067618812233569674, 0.0067342236174138944, 0.0067077170828959759, 0.0066822634258594873, 0.006657781165965649, 0.0066342926878468255, 0.0066117049492618631, 0.0065900058291686291, 0.0065691463483088961, 0.006549081335806714, 0.0065297767706907813, 0.0065112230662242631, 0.0064933669587188712, 0.0064761623754044893, 0.0064596296842019578, 0.0064436797724281986, 0.0064282998525741816, 0.0064134827008311629, 0.0063992043122732285, 0.0063854562998039571, 0.0063721872225653061, 0.0063594151946082438, 0.0063470549964550257, 0.0063351263832231658, 0.0063236478740370189, 0.0063125350872629419, 0.0063018298112409929, 0.006291492424946846, 0.0062815107692545452, 0.0062718554313353448, 0.0062625327123308266, 0.006253521183166362, 0.0062448358938762688, 0.0062364332523321573, 0.006228314456443361, 0.0062204435118041294, 0.0062128469663010879, 0.006205498883119857, 0.0061983904856703761, 0.0061915205033378305, 0.0061848714210259205, 0.0061784464204649274, 0.0061722348312601505, 0.0061662174522405886, 0.0061603914773209392, 0.006154758654894882, 0.0061493066163754379, 0.0061440270075567589, 0.0061389139860342206, 0.006133950869362372, 0.0061291554513418544, 0.0061245130766252381, 0.0061200165300591951, 0.0061156654585028227, 0.0061114422845408379, 0.0061073554645129742, 0.0061033865900841791, 0.0060995504793236689, 0.0060958399880525127, 0.0060922371458996183, 0.0060887379817609229], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010304047295637084, 0.010090322522807137, 0.0098887444448044273, 0.0096986615983397223, 0.0095195982166747413, 0.0093508944757965048, 0.0091918163280876857, 0.0090417513153306824, 0.008900032229904719, 0.008766231233552876, 0.0086397325383074531, 0.0085200188176611409, 0.0084067083484210998, 0.0082993480470203232, 0.0081976942853119444, 0.0081012922750709239, 0.0080098140545157327, 0.007922969660054853, 0.007840483662338622, 0.0077621421010245486, 0.0076876084521165563, 0.0076167084618409169, 0.0075492361190110059, 0.0074849973335981224, 0.0074237868099369811, 0.0073654795779326283, 0.0073098183575772621, 0.0072567216255178318, 0.0072060485871894529, 0.0071576404263343852, 0.0071113593547222033, 0.0070671639365121747, 0.0070248804680233768, 0.0069844358264094823, 0.0069457108916780039, 0.0069086441418731879, 0.006873169594193043, 0.006839176351416309, 0.006806589743739524, 0.0067753103225690571, 0.0067453411114118773, 0.0067165838440018119, 0.0066889662830217451, 0.0066624712937390727, 0.0066370229899640563, 0.0066125317183039862, 0.0065890088947587171, 0.0065663779828727207, 0.0065446241925337162, 0.006523690499839291, 0.0065035451024418132, 0.0064841481827236092, 0.0064654956292990676, 0.0064475194395925634, 0.0064302070793874917, 0.0064135406128535549, 0.0063974574808152674, 0.006381937975525288, 0.0063669918412394182, 0.00635256042753214, 0.0063386579349261523, 0.0063252403153554199, 0.0063123109955947384, 0.0062997860346875566, 0.0062876978208503808, 0.0062760416453803841, 0.0062647789256497256, 0.0062539044180318264, 0.0062433988523921975, 0.006233232845417748, 0.0062234215896299593, 0.0062139131516314354, 0.0062047348789339533, 0.0061958694750970872, 0.0061872843006132352, 0.0061789962171720598, 0.0061709663147231555, 0.0061632001729019226, 0.006155690333972552, 0.006148402939751497, 0.0061413536392628558, 0.0061345453438198519, 0.0061279489583213895, 0.0061215667266423853, 0.0061153973817376544, 0.0061094035464897061, 0.006103619942859447, 0.0060980010536724281, 0.0060925686004392448, 0.0060872861814410982, 0.0060821726618273978, 0.0060772229943106201, 0.006072435079837366, 0.006067785681136635, 0.0060632916189702693, 0.006058908089395491, 0.0060546778908918695, 0.0060505713708240818, 0.0060466054647235912, 0.0060427505065032729, 0.0060390111945624464], 'acc': [0.57344806362825007, 0.58881376800027152, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376737748181, 0.58881376763392457, 0.58881376774382865, 0.58881376800027152, 0.58881376800027152, 0.58881376774382865, 0.58881376772551131, 0.58881376726757773, 0.58881376746906855, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376774382865, 0.58881376759728987, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457, 0.5888137674873859, 0.58881376811017561, 0.5888137674873859, 0.58881376800027152, 0.58881376763392457, 0.58881376737748181, 0.58881376774382865, 0.58881376737748181, 0.58881376770719396, 0.5888137674873859, 0.58881376800027152, 0.58881376811017561, 0.58881376800027152, 0.58881376763392457, 0.58881376737748181, 0.58881376763392457, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376759728987, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457, 0.58881376800027152, 0.58881376785373274, 0.58881376774382865, 0.58881376783541539, 0.58881376800027152, 0.58881376763392457, 0.5888137674873859, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376774382865, 0.58881376763392457, 0.58881376800027152, 0.5888137674873859, 0.58881376763392457, 0.58881376811017561, 0.58881376726757773, 0.58881376800027152, 0.58881376800027152, 0.58881376726757773, 0.58881376737748181, 0.58881376800027152, 0.58881376774382865, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376763392457, 0.58881376772551131, 0.58881376785373274, 0.58881376726757773, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376746906855, 0.58881376774382865, 0.58881376726757773]}
[2017-11-14 07:15:53,793 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:95]: done!
[2017-11-14 07:15:53,793 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-14 07:15:53,793 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-14 07:15:53,793 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f70eec93400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 07:15:53,826 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-14 07:17:38,042 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:125]: trained!
[2017-11-14 07:17:38,043 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.010199879860456991, 0.0099930060771207391, 0.0097980313937847934, 0.0096143115533439648, 0.0094413469618248678, 0.00927828794144454, 0.0091245931583598637, 0.0089795270685425043, 0.0088426238549076941, 0.0087132910162653621, 0.0085909966254766098, 0.008475273189768472, 0.0083657026110860941, 0.0082619925614681837, 0.0081637113400108308, 0.0080705108605740681, 0.0079820870255642891, 0.0078981445866834268, 0.0078184693397393232, 0.0077427288181525847, 0.007670696452606234, 0.00760221719693351, 0.0075370591119984266, 0.0074750062192489005, 0.0074159379210669311, 0.0073595890640298454, 0.0073058801048805719, 0.0072546331108059581, 0.0072057373634778436, 0.0071589914583306772, 0.007114395194558849, 0.0070717630295089855, 0.0070309993814413876, 0.0069919998158586511, 0.0069546973069638121, 0.0069190236310505736, 0.0068848623260578702, 0.006852128070374071, 0.0068207496057046393, 0.0067906997800150325, 0.0067618812233569674, 0.0067342236174138944, 0.0067077170828959759, 0.0066822634258594873, 0.006657781165965649, 0.0066342926878468255, 0.0066117049492618631, 0.0065900058291686291, 0.0065691463483088961, 0.006549081335806714, 0.0065297767706907813, 0.0065112230662242631, 0.0064933669587188712, 0.0064761623754044893, 0.0064596296842019578, 0.0064436797724281986, 0.0064282998525741816, 0.0064134827008311629, 0.0063992043122732285, 0.0063854562998039571, 0.0063721872225653061, 0.0063594151946082438, 0.0063470549964550257, 0.0063351263832231658, 0.0063236478740370189, 0.0063125350872629419, 0.0063018298112409929, 0.006291492424946846, 0.0062815107692545452, 0.0062718554313353448, 0.0062625327123308266, 0.006253521183166362, 0.0062448358938762688, 0.0062364332523321573, 0.006228314456443361, 0.0062204435118041294, 0.0062128469663010879, 0.006205498883119857, 0.0061983904856703761, 0.0061915205033378305, 0.0061848714210259205, 0.0061784464204649274, 0.0061722348312601505, 0.0061662174522405886, 0.0061603914773209392, 0.006154758654894882, 0.0061493066163754379, 0.0061440270075567589, 0.0061389139860342206, 0.006133950869362372, 0.0061291554513418544, 0.0061245130766252381, 0.0061200165300591951, 0.0061156654585028227, 0.0061114422845408379, 0.0061073554645129742, 0.0061033865900841791, 0.0060995504793236689, 0.0060958399880525127, 0.0060922371458996183, 0.0060887379817609229], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010304047295637084, 0.010090322522807137, 0.0098887444448044273, 0.0096986615983397223, 0.0095195982166747413, 0.0093508944757965048, 0.0091918163280876857, 0.0090417513153306824, 0.008900032229904719, 0.008766231233552876, 0.0086397325383074531, 0.0085200188176611409, 0.0084067083484210998, 0.0082993480470203232, 0.0081976942853119444, 0.0081012922750709239, 0.0080098140545157327, 0.007922969660054853, 0.007840483662338622, 0.0077621421010245486, 0.0076876084521165563, 0.0076167084618409169, 0.0075492361190110059, 0.0074849973335981224, 0.0074237868099369811, 0.0073654795779326283, 0.0073098183575772621, 0.0072567216255178318, 0.0072060485871894529, 0.0071576404263343852, 0.0071113593547222033, 0.0070671639365121747, 0.0070248804680233768, 0.0069844358264094823, 0.0069457108916780039, 0.0069086441418731879, 0.006873169594193043, 0.006839176351416309, 0.006806589743739524, 0.0067753103225690571, 0.0067453411114118773, 0.0067165838440018119, 0.0066889662830217451, 0.0066624712937390727, 0.0066370229899640563, 0.0066125317183039862, 0.0065890088947587171, 0.0065663779828727207, 0.0065446241925337162, 0.006523690499839291, 0.0065035451024418132, 0.0064841481827236092, 0.0064654956292990676, 0.0064475194395925634, 0.0064302070793874917, 0.0064135406128535549, 0.0063974574808152674, 0.006381937975525288, 0.0063669918412394182, 0.00635256042753214, 0.0063386579349261523, 0.0063252403153554199, 0.0063123109955947384, 0.0062997860346875566, 0.0062876978208503808, 0.0062760416453803841, 0.0062647789256497256, 0.0062539044180318264, 0.0062433988523921975, 0.006233232845417748, 0.0062234215896299593, 0.0062139131516314354, 0.0062047348789339533, 0.0061958694750970872, 0.0061872843006132352, 0.0061789962171720598, 0.0061709663147231555, 0.0061632001729019226, 0.006155690333972552, 0.006148402939751497, 0.0061413536392628558, 0.0061345453438198519, 0.0061279489583213895, 0.0061215667266423853, 0.0061153973817376544, 0.0061094035464897061, 0.006103619942859447, 0.0060980010536724281, 0.0060925686004392448, 0.0060872861814410982, 0.0060821726618273978, 0.0060772229943106201, 0.006072435079837366, 0.006067785681136635, 0.0060632916189702693, 0.006058908089395491, 0.0060546778908918695, 0.0060505713708240818, 0.0060466054647235912, 0.0060427505065032729, 0.0060390111945624464], 'acc': [0.57344806362825007, 0.58881376800027152, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376737748181, 0.58881376763392457, 0.58881376774382865, 0.58881376800027152, 0.58881376800027152, 0.58881376774382865, 0.58881376772551131, 0.58881376726757773, 0.58881376746906855, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376774382865, 0.58881376759728987, 0.58881376737748181, 0.58881376774382865, 0.5888137674873859, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457, 0.5888137674873859, 0.58881376811017561, 0.5888137674873859, 0.58881376800027152, 0.58881376763392457, 0.58881376737748181, 0.58881376774382865, 0.58881376737748181, 0.58881376770719396, 0.5888137674873859, 0.58881376800027152, 0.58881376811017561, 0.58881376800027152, 0.58881376763392457, 0.58881376737748181, 0.58881376763392457, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376759728987, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457, 0.58881376800027152, 0.58881376785373274, 0.58881376774382865, 0.58881376783541539, 0.58881376800027152, 0.58881376763392457, 0.5888137674873859, 0.58881376763392457, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376774382865, 0.58881376763392457, 0.58881376800027152, 0.5888137674873859, 0.58881376763392457, 0.58881376811017561, 0.58881376726757773, 0.58881376800027152, 0.58881376800027152, 0.58881376726757773, 0.58881376737748181, 0.58881376800027152, 0.58881376774382865, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376763392457, 0.58881376772551131, 0.58881376785373274, 0.58881376726757773, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376746906855, 0.58881376774382865, 0.58881376726757773]}
[2017-11-14 07:17:38,043 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-14 07:17:38,174 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-14 07:17:38,175 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-14 07:17:38,769 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:141]: done!
[2017-11-14 07:17:38,770 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_04 finished!
[2017-11-18 16:23:38,932 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_10L_FULLDS_OVER_04 was already executed!
[2017-11-18 19:08:25,088 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_04
[2017-11-18 19:08:25,088 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 19:08:25,088 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,34,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f08e1996eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f08e199b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:08:25,088 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 19:08:25,649 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-18 19:08:25,649 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:08:25,649 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 19:08:25,649 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f08e1996eb8>, 'discard_decoder_function': True}
[2017-11-18 19:08:25,864 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 19:09:20,378 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 19:09:20,379 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.010310292569401096, 0.0102113191536922, 0.010117868768210527, 0.010030241603495684, 0.0099484904679611706, 0.0098722998890679557, 0.0098012147582098013, 0.0097349284971513707, 0.0096730205462379967, 0.0096152364916850201, 0.0095611307527662202, 0.0095105675121831632, 0.0094632961022144794, 0.0094190620155970399, 0.0093776736214590782, 0.0093388754327445676, 0.0093025821347662071, 0.0092685456945107332, 0.0092365911618207466, 0.009206636216782282, 0.0091784876116921908, 0.0091520419351230325, 0.0091271897237817159, 0.0091038253920007368, 0.009081838638642906, 0.0090611361410316473, 0.0090416240814006898, 0.0090232581405668456, 0.0090059475370831647, 0.0089895788053930021, 0.0089741357875690146, 0.0089595433511532371, 0.0089457496467520749, 0.0089327121243490161, 0.008920354664768872, 0.0089086754849963031, 0.0088976024404223523, 0.0088871022319372706, 0.0088771415881286325, 0.0088676952836571135, 0.0088587022251466838, 0.0088501761158492048, 0.0088420825937700533, 0.0088343756467270142, 0.0088270364197656562, 0.0088200450123575094, 0.008813371442147569, 0.0088070268676959003, 0.0088009695906787564, 0.0087951952210700204, 0.0087896944214087887, 0.0087844172707277606, 0.0087793825547380511, 0.0087745669730644685, 0.0087699456119625981, 0.0087655375445033091, 0.0087613023291290022, 0.0087572541468704055, 0.0087533785466478668, 0.0087496535783308151, 0.0087460856884717941, 0.0087426525495641737, 0.0087393479781800038, 0.0087361790786833118, 0.0087331427178141355, 0.0087302152870645314, 0.0087273975965812753, 0.008724687790643549, 0.0087220744267936974, 0.0087195642943386689, 0.0087171420524222252, 0.0087147990525544353, 0.0087125504694075834, 0.0087103841750152053, 0.0087082910084868449, 0.0087062721331101819, 0.0087043214520114067, 0.0087024445773611278, 0.0087006265803008277, 0.0086988736027124643, 0.0086971788310539321, 0.0086955409220049375, 0.0086939608345853788, 0.0086924342237772994, 0.0086909526661315371, 0.0086895258730228953, 0.0086881401688968379, 0.0086868005358098164, 0.0086855031723038854, 0.0086842498336970591, 0.0086830309609498228, 0.0086818534714692593, 0.0086807129786914163, 0.0086796081046743457, 0.0086785364328263864, 0.0086774974749821709, 0.0086764925052186821, 0.0086755137198144174, 0.0086745639161992689, 0.008673647931018727, 0.0086727554227838278], 'val_acc': [0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691], 'loss': [0.010354826141540339, 0.01025568857759274, 0.010159276113871166, 0.010068631123639208, 0.0099838604113360666, 0.0099048603929409815, 0.0098312147300559909, 0.0097624943703275638, 0.0096983753852248559, 0.0096384934038061185, 0.0095825405549841858, 0.0095301747520138824, 0.0094812352630437406, 0.0094354582169695941, 0.0093926108295135733, 0.0093524939745215814, 0.0093149149558004896, 0.0092797170169353852, 0.0092467228935249543, 0.0092157265400375481, 0.0091866585612068088, 0.0091593342861269397, 0.0091336628023738799, 0.0091095297833756941, 0.0090868266530623448, 0.0090654639603905546, 0.0090453307308627547, 0.0090263704732106223, 0.0090084995945071845, 0.0089916531437322193, 0.0089757230903291605, 0.0089606806417193308, 0.0089464717067791848, 0.0089330284397753749, 0.0089203176903180654, 0.0089082705674403337, 0.0088968773864177599, 0.0088860684749341185, 0.0088758134084496679, 0.0088660890979494287, 0.0088568595836205789, 0.0088480735625831274, 0.0088397390395173938, 0.0088318186865337586, 0.008824287108348863, 0.0088170923741411854, 0.008810248868751723, 0.0088037260520124842, 0.0087975092397083437, 0.0087915737560842026, 0.0087859145369662342, 0.0087805154550758772, 0.0087753394744562157, 0.0087703971865403189, 0.0087656712946015489, 0.0087611329024537398, 0.0087568037602283426, 0.0087526490334844977, 0.0087486666993002761, 0.0087448606741532785, 0.0087411973892167882, 0.0087376872464538201, 0.0087343115822057747, 0.0087310594484237489, 0.0087279407450609869, 0.0087249494067862046, 0.0087220658758253352, 0.0087192988866904644, 0.0087166230126152974, 0.0087140517443253639, 0.0087115803422073163, 0.008709189131141588, 0.0087068840098860952, 0.0087046656344308034, 0.0087025331593156962, 0.0087004735191211283, 0.0086984854053016748, 0.0086965663049463921, 0.0086947161819930091, 0.0086929248147898826, 0.0086911964598303561, 0.0086895227506665201, 0.0086879134326990053, 0.0086863609700570752, 0.0086848461632997483, 0.0086833904969569504, 0.0086819869675058194, 0.0086806140532093169, 0.0086793016313764671, 0.0086780199443334139, 0.008676783051215841, 0.0086755851425628899, 0.0086744260563805346, 0.0086733005831010068, 0.0086722086609032668, 0.0086711491323599958, 0.0086701292780439181, 0.0086691394275410383, 0.0086681746305885231, 0.0086672398912564109, 0.0086663346308310414], 'acc': [0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057]}
[2017-11-18 19:09:20,379 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:95]: done!
[2017-11-18 19:09:20,379 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 19:09:20,379 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 19:09:20,379 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f08e199b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:09:20,412 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 19:11:08,468 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:125]: trained!
[2017-11-18 19:11:08,470 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.010310292569401096, 0.0102113191536922, 0.010117868768210527, 0.010030241603495684, 0.0099484904679611706, 0.0098722998890679557, 0.0098012147582098013, 0.0097349284971513707, 0.0096730205462379967, 0.0096152364916850201, 0.0095611307527662202, 0.0095105675121831632, 0.0094632961022144794, 0.0094190620155970399, 0.0093776736214590782, 0.0093388754327445676, 0.0093025821347662071, 0.0092685456945107332, 0.0092365911618207466, 0.009206636216782282, 0.0091784876116921908, 0.0091520419351230325, 0.0091271897237817159, 0.0091038253920007368, 0.009081838638642906, 0.0090611361410316473, 0.0090416240814006898, 0.0090232581405668456, 0.0090059475370831647, 0.0089895788053930021, 0.0089741357875690146, 0.0089595433511532371, 0.0089457496467520749, 0.0089327121243490161, 0.008920354664768872, 0.0089086754849963031, 0.0088976024404223523, 0.0088871022319372706, 0.0088771415881286325, 0.0088676952836571135, 0.0088587022251466838, 0.0088501761158492048, 0.0088420825937700533, 0.0088343756467270142, 0.0088270364197656562, 0.0088200450123575094, 0.008813371442147569, 0.0088070268676959003, 0.0088009695906787564, 0.0087951952210700204, 0.0087896944214087887, 0.0087844172707277606, 0.0087793825547380511, 0.0087745669730644685, 0.0087699456119625981, 0.0087655375445033091, 0.0087613023291290022, 0.0087572541468704055, 0.0087533785466478668, 0.0087496535783308151, 0.0087460856884717941, 0.0087426525495641737, 0.0087393479781800038, 0.0087361790786833118, 0.0087331427178141355, 0.0087302152870645314, 0.0087273975965812753, 0.008724687790643549, 0.0087220744267936974, 0.0087195642943386689, 0.0087171420524222252, 0.0087147990525544353, 0.0087125504694075834, 0.0087103841750152053, 0.0087082910084868449, 0.0087062721331101819, 0.0087043214520114067, 0.0087024445773611278, 0.0087006265803008277, 0.0086988736027124643, 0.0086971788310539321, 0.0086955409220049375, 0.0086939608345853788, 0.0086924342237772994, 0.0086909526661315371, 0.0086895258730228953, 0.0086881401688968379, 0.0086868005358098164, 0.0086855031723038854, 0.0086842498336970591, 0.0086830309609498228, 0.0086818534714692593, 0.0086807129786914163, 0.0086796081046743457, 0.0086785364328263864, 0.0086774974749821709, 0.0086764925052186821, 0.0086755137198144174, 0.0086745639161992689, 0.008673647931018727, 0.0086727554227838278], 'val_acc': [0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691], 'loss': [0.010354826141540339, 0.01025568857759274, 0.010159276113871166, 0.010068631123639208, 0.0099838604113360666, 0.0099048603929409815, 0.0098312147300559909, 0.0097624943703275638, 0.0096983753852248559, 0.0096384934038061185, 0.0095825405549841858, 0.0095301747520138824, 0.0094812352630437406, 0.0094354582169695941, 0.0093926108295135733, 0.0093524939745215814, 0.0093149149558004896, 0.0092797170169353852, 0.0092467228935249543, 0.0092157265400375481, 0.0091866585612068088, 0.0091593342861269397, 0.0091336628023738799, 0.0091095297833756941, 0.0090868266530623448, 0.0090654639603905546, 0.0090453307308627547, 0.0090263704732106223, 0.0090084995945071845, 0.0089916531437322193, 0.0089757230903291605, 0.0089606806417193308, 0.0089464717067791848, 0.0089330284397753749, 0.0089203176903180654, 0.0089082705674403337, 0.0088968773864177599, 0.0088860684749341185, 0.0088758134084496679, 0.0088660890979494287, 0.0088568595836205789, 0.0088480735625831274, 0.0088397390395173938, 0.0088318186865337586, 0.008824287108348863, 0.0088170923741411854, 0.008810248868751723, 0.0088037260520124842, 0.0087975092397083437, 0.0087915737560842026, 0.0087859145369662342, 0.0087805154550758772, 0.0087753394744562157, 0.0087703971865403189, 0.0087656712946015489, 0.0087611329024537398, 0.0087568037602283426, 0.0087526490334844977, 0.0087486666993002761, 0.0087448606741532785, 0.0087411973892167882, 0.0087376872464538201, 0.0087343115822057747, 0.0087310594484237489, 0.0087279407450609869, 0.0087249494067862046, 0.0087220658758253352, 0.0087192988866904644, 0.0087166230126152974, 0.0087140517443253639, 0.0087115803422073163, 0.008709189131141588, 0.0087068840098860952, 0.0087046656344308034, 0.0087025331593156962, 0.0087004735191211283, 0.0086984854053016748, 0.0086965663049463921, 0.0086947161819930091, 0.0086929248147898826, 0.0086911964598303561, 0.0086895227506665201, 0.0086879134326990053, 0.0086863609700570752, 0.0086848461632997483, 0.0086833904969569504, 0.0086819869675058194, 0.0086806140532093169, 0.0086793016313764671, 0.0086780199443334139, 0.008676783051215841, 0.0086755851425628899, 0.0086744260563805346, 0.0086733005831010068, 0.0086722086609032668, 0.0086711491323599958, 0.0086701292780439181, 0.0086691394275410383, 0.0086681746305885231, 0.0086672398912564109, 0.0086663346308310414], 'acc': [0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844544871424, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057, 0.0018438844499078057]}
[2017-11-18 19:11:08,470 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 19:11:08,608 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 19:11:08,608 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 19:11:09,195 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:141]: done!
[2017-11-18 19:11:09,195 AE_UNIGRAMA_10L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_04 finished!
