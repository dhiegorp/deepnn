[2017-11-13 18:08:18,042 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02
[2017-11-13 18:08:18,043 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:150]: >> Printing header log
[2017-11-13 18:08:18,043 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:39]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22,16
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7faac105ce80>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7faac0fe13c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 18:08:18,043 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:152]: >> Loading dataset... 
[2017-11-13 18:08:18,615 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:56]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-13 18:08:18,615 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:154]: >> Executing autoencoder part ... 
[2017-11-13 18:08:18,615 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:61]: =======================================
[2017-11-13 18:08:18,615 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:66]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7faac105ce80>, 'discard_decoder_function': True}
[2017-11-13 18:08:18,813 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:77]: training and evaluate autoencoder
[2017-11-13 18:09:44,634 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:89]: trained and evaluated!
[2017-11-13 18:09:44,635 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:92]: Training history: 
{'val_loss': [0.010136776544901518, 0.0098815868542872394, 0.0096442861392484723, 0.0094255998065923673, 0.0092238839784962532, 0.009037347586624684, 0.0088645104512738472, 0.0087040531237827807, 0.0085548476201783331, 0.0084157057494257462, 0.008285867027786031, 0.0081644664002672451, 0.0080507996987177529, 0.0079441906496550072, 0.0078440483635270689, 0.0077498215493022509, 0.0076609910829304323, 0.0075771739502129279, 0.0074979857624712706, 0.0074230611054261382, 0.0073521162061276936, 0.0072848593805774657, 0.0072210604172601575, 0.007160457991908363, 0.0071028698942032006, 0.0070480410854391008, 0.0069958174490407938, 0.0069460602941123087, 0.0068985700337250884, 0.0068531603929777125, 0.0068097652756647104, 0.0067682976550578408, 0.006728618047425184, 0.0066905691284949451, 0.0066541101555011089, 0.0066181789273500003, 0.0065828775571569187, 0.006548885953678407, 0.006516394499675492, 0.0064851883764216007, 0.0064551950809736231, 0.0064263883960817602, 0.0063987391097228763, 0.006372136292376704, 0.0063465694000175892, 0.0063219922560104431, 0.006298348054871462, 0.0062755621661567109, 0.0062535759511656479, 0.0062324359967999964, 0.0062120878397310536, 0.0061924431549184381, 0.0061735208267449894, 0.0061552780870777523, 0.0061377043243788431, 0.0061206789410302633, 0.0061042391795484994, 0.0060884132167691417, 0.00607312329418154, 0.0060583815726427343, 0.0060440996093987093, 0.0060303433777480538, 0.0060170452356283106, 0.0060041887239037171, 0.0059917640446453292, 0.0059797779871600936, 0.0059681764499156225, 0.0059569656024912035, 0.0059461098919072119, 0.00593563375239811, 0.0059254889542645463, 0.0059156621975969652, 0.0059061712294567695, 0.005896959014126138, 0.0058880420349759904, 0.0058794104282962343, 0.0058710541641928231, 0.0058629695987363513, 0.0058551729487109801, 0.0058476128355776508, 0.0058402930313658976, 0.0058331991594326319, 0.0058263327690970057, 0.0058196629830341799, 0.0058131963776279112, 0.0058069371126702948, 0.0058008744641030591, 0.0057949957569375576, 0.0057892950362487799, 0.0057837637799158419, 0.005778397031848537, 0.0057731994953989759, 0.0057681588054423437, 0.0057632677416320629, 0.0057585190766972234, 0.0057539142076216887, 0.0057494485349183187, 0.0057451093299349006, 0.0057408961616318022, 0.0057368242237232211, 0.0057328580999850788], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010270095243706576, 0.010004458449249737, 0.0097578796738393477, 0.0095298610766176139, 0.0093194698936637371, 0.009125156406503224, 0.0089451958538109208, 0.0087782327834454946, 0.0086230203657014348, 0.0084784950633987229, 0.0083435387525206042, 0.0082174259648368116, 0.0080993858314295005, 0.0079887065762847421, 0.007884755010528292, 0.0077869878594145937, 0.0076948636246944729, 0.0076079225349660728, 0.0075257758334617928, 0.0074480545415686701, 0.0073744456733667967, 0.0073046434450878567, 0.0072384197771498855, 0.0071755642232787928, 0.0071157671190047274, 0.0070588839630760626, 0.0070046370144367914, 0.006952941135206267, 0.006903613191418528, 0.0068564809891426756, 0.0068113705653928512, 0.0067682309158045633, 0.0067269450028386302, 0.0066874200602983066, 0.0066494895485885207, 0.0066126139792164335, 0.006576248180160108, 0.0065406943836261435, 0.0065066670436817369, 0.0064740699636346372, 0.0064427098167743066, 0.006412575306736056, 0.0063836108083185896, 0.0063557586021327538, 0.006328987638273156, 0.0063032226387431962, 0.0062784219533319518, 0.0062545444198140497, 0.0062315124897005811, 0.0062092763478235188, 0.0061878870812616211, 0.0061672677731882154, 0.0061473397028042297, 0.006128138550010538, 0.0061096298452821621, 0.0060917319954311693, 0.0060743933735895022, 0.0060576672537553397, 0.0060415485448512517, 0.0060259752967535126, 0.0060109296071182271, 0.0059963536993145354, 0.0059822996612924444, 0.0059687018064757983, 0.0059555471953767055, 0.0059428214563197641, 0.0059305423196375408, 0.005918642321112666, 0.0059071363982548175, 0.0058959764228090784, 0.0058852061789572132, 0.0058747765893768008, 0.0058646526788123819, 0.0058548590629152637, 0.0058453659233353812, 0.0058361695791447569, 0.0058272494908740494, 0.0058186095827284885, 0.0058102673738187416, 0.0058022041317961591, 0.0057943780395902401, 0.0057867938213590729, 0.0057794388083680396, 0.0057723118411863623, 0.0057654023432638212, 0.0057586733836820321, 0.0057521649005524604, 0.0057458497847750391, 0.0057397375218730508, 0.0057337909871649365, 0.0057280194749866776, 0.0057224048872277387, 0.005716981078064746, 0.0057117011599567818, 0.0057065837075515949, 0.0057016130432042339, 0.005696781975352826, 0.0056921003160845963, 0.0056875279501249947, 0.0056831102529752448, 0.0056788246785579614], 'acc': [0.56484327026137415, 0.58881376785373274, 0.58881376759728987, 0.58881376800027152, 0.58881376774382865, 0.58881376774382865, 0.58881376774382865, 0.58881376763392457, 0.58881376785373274, 0.58881376763392457, 0.58881376763392457, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376785373274, 0.58881376737748181, 0.58881376811017561, 0.58881376800027152, 0.58881376763392457, 0.58881376774382865, 0.58881376726757773, 0.5888137674873859, 0.58881376772551131, 0.58881376737748181, 0.58881376774382865, 0.58881376726757773, 0.58881376737748181, 0.5888137674873859, 0.58881376785373274, 0.58881376800027152, 0.58881376800027152, 0.58881376811017561, 0.5888137674873859, 0.58881376800027152, 0.58881376763392457, 0.58881376770719396, 0.58881376789036743, 0.58881376811017561, 0.58881376772551131, 0.58881376763392457, 0.58881376737748181, 0.58881376800027152, 0.58881376772551131, 0.58881376774382865, 0.58881376800027152, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376778046335, 0.58881376774382865, 0.5888137674873859, 0.58881376800027152, 0.58881376811017561, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376811017561, 0.58881376772551131, 0.58881376737748181, 0.58881376811017561, 0.58881376726757773, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376774382865, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376737748181, 0.58881376783541539, 0.58881376785373274, 0.58881376800027152, 0.58881376811017561, 0.58881376800027152, 0.58881376726757773, 0.58881376763392457, 0.58881376800027152, 0.58881376789036743, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376774382865, 0.58881376800027152, 0.58881376763392457, 0.58881376774382865, 0.58881376785373274, 0.58881376811017561, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865, 0.58881376811017561, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376763392457, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865]}
[2017-11-13 18:09:44,635 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:96]: done!
[2017-11-13 18:09:44,635 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:156]: >> Executing classifier part ... 
[2017-11-13 18:09:44,635 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:101]: =======================================
[2017-11-13 18:09:44,635 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:105]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7faac0fe13c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 18:09:44,666 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:114]: training ... 
[2017-11-14 07:05:12,808 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02
[2017-11-14 07:05:12,808 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:150]: >> Printing header log
[2017-11-14 07:05:12,808 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:39]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22,16
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fabde481f28>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fabde467470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 07:05:12,808 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:152]: >> Loading dataset... 
[2017-11-14 07:05:13,330 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:56]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-14 07:05:13,330 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:154]: >> Executing autoencoder part ... 
[2017-11-14 07:05:13,330 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:61]: =======================================
[2017-11-14 07:05:13,330 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:66]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fabde481f28>, 'discard_decoder_function': True}
[2017-11-14 07:05:13,535 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:77]: training and evaluate autoencoder
[2017-11-14 07:06:19,983 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:89]: trained and evaluated!
[2017-11-14 07:06:19,985 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:92]: Training history: 
{'val_loss': [0.010201488953900825, 0.0099979133507908501, 0.0098054658649246937, 0.009620731073296647, 0.0094477710726092734, 0.009284658786809577, 0.0091314370013413377, 0.0089878754717986828, 0.0088530563053477659, 0.0087256917806141435, 0.0086057754995155951, 0.0084928777899773156, 0.008386441752259173, 0.0082860042109088386, 0.0081912680497898491, 0.0081016815312511415, 0.0080169374053972366, 0.0079367102875086901, 0.0078607216515477925, 0.0077886974411327603, 0.007720397558534123, 0.0076555049213058004, 0.0075938456802590853, 0.0075351922845530248, 0.0074794113784889971, 0.0074262696017119963, 0.0073755666402386686, 0.007327208525698535, 0.0072810870100186659, 0.0072370412409804123, 0.0071949692491483511, 0.0071547792819380536, 0.0071162696508863827, 0.007079448820988485, 0.0070441476481388496, 0.0070103095449701117, 0.0069778760285791851, 0.0069467147784549954, 0.0069168470661436316, 0.0068881354955990966, 0.0068605620739462204, 0.0068340505417921063, 0.0068085790822995642, 0.0067840704268543918, 0.0067605096119764127, 0.0067378181486380147, 0.0067159507897955996, 0.006694877684656461, 0.0066745679818620025, 0.0066549760171776585, 0.0066360701619886334, 0.006617821778991298, 0.0066002158268067476, 0.0065832047768241853, 0.0065667716523140776, 0.0065509060235022388, 0.006535542001913139, 0.0065193608642095304, 0.006501423243474783, 0.0064841781112756651, 0.0064675323266993002, 0.0064514440217758196, 0.006435897459231012, 0.0064208669117115248, 0.0064063466354844518, 0.0063922450683844799, 0.0063786565959730555, 0.0063655601371232018, 0.0063528874594732066, 0.0063406547019085029, 0.0063288203980704444, 0.0063173808088200683, 0.0063062890373918202, 0.0062955512100879149, 0.0062851648601152865, 0.006275108560130388, 0.006265367481677506, 0.0062559441884903434, 0.0062468194811289863, 0.006237987321576443, 0.0062294259466590934, 0.0062211331665571294, 0.0062130868857290219, 0.0062053085072831596, 0.0061977627863726648, 0.0061904472388936461, 0.0061833833804748762, 0.0061765231545252873, 0.0061698767242323064, 0.0061634402188946768, 0.0061571950137919874, 0.0061511315118009053, 0.0061452620157272618, 0.0061395728915625124, 0.0061340567597004559, 0.0061287165889481847, 0.0061235249901128077, 0.0061184987131520053, 0.0061136294263640081, 0.0061088953042562127, 0.0061043083536192833], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010303545932697056, 0.010094680576673959, 0.0098967592649221343, 0.0097075138961153305, 0.0095284277809063716, 0.0093603604916796847, 0.0092018436200884714, 0.0090532002085619498, 0.0089138261464406683, 0.0087825587201352927, 0.0086586053209000372, 0.0085419039273452527, 0.0084319612384529362, 0.008328260109744412, 0.0082303490707239784, 0.0081379225926351238, 0.0080504641680993697, 0.0079677018970045008, 0.0078892940323348777, 0.007814985699093023, 0.0077445151269454199, 0.0076776262834672739, 0.007614061584983527, 0.0075536065840247626, 0.0074960750618694233, 0.0074413203990365108, 0.0073890919956254427, 0.0073392547019622816, 0.0072916919516070938, 0.0072462995071250307, 0.0072029253674560003, 0.0071614573377092412, 0.0071218276156551023, 0.0070838306906856894, 0.0070474711037856273, 0.0070125964428993659, 0.0069791443257282938, 0.0069470532961446192, 0.0069162077350586595, 0.0068866266684690248, 0.0068581675264592834, 0.0068308258184175148, 0.006804521599716948, 0.0067792478496622073, 0.0067549041614334828, 0.0067314881606447639, 0.0067089286955679091, 0.0066871718519562473, 0.0066661801007155564, 0.0066459555729545912, 0.0066264227685789313, 0.0066075706161837968, 0.0065893567205574446, 0.0065717708208376671, 0.0065547801830680482, 0.0065383522885209882, 0.0065224779999889914, 0.0065068270190840457, 0.0064890283112973429, 0.0064710680983237094, 0.0064537763230951379, 0.0064370756635136707, 0.0064209172858203491, 0.0064053042687603904, 0.0063901930880293787, 0.0063755549427485939, 0.0063614129445434863, 0.0063477506790683364, 0.0063345707951831393, 0.0063218062044623335, 0.0063094801997013745, 0.0062975454070910439, 0.006286008047373861, 0.0062748214877345072, 0.0062639820418070452, 0.0062534910295852396, 0.0062433254805444463, 0.0062334874923070226, 0.0062239549793051147, 0.0062147222205163073, 0.0062057822235798681, 0.0061971060845820028, 0.0061887109943521883, 0.0061805395128408051, 0.0061726447188518094, 0.0061649903388878245, 0.0061575617265132538, 0.0061503870512307898, 0.0061434116924310948, 0.0061366489015693632, 0.00613009406553642, 0.0061237370213533772, 0.0061175570993260075, 0.0061115818942502629, 0.0061057783759438924, 0.0061001429988555584, 0.0060946929260525112, 0.0060893943780585529, 0.0060842514582454569, 0.0060792650650218173, 0.0060744234048787189], 'acc': [0.56976029482002122, 0.58881376811017561, 0.58881376811017561, 0.58881376772551131, 0.58881376785373274, 0.58881376737748181, 0.58881376737748181, 0.58881376759728987, 0.58881376811017561, 0.58881376763392457, 0.58881376774382865, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.58881376785373274, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.5888137674873859, 0.5888137674873859, 0.58881376759728987, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.5888137674873859, 0.58881376785373274, 0.58881376737748181, 0.58881376800027152, 0.5888137674873859, 0.58881376737748181, 0.58881376737748181, 0.58881376746906855, 0.58881376763392457, 0.58881376785373274, 0.58881376811017561, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.5888137674873859, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.58881376774382865, 0.58881376752402059, 0.58881376774382865, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.5888137674873859, 0.58881376811017561, 0.58881376737748181, 0.58881376763392457, 0.58881376785373274, 0.58881376772551131, 0.58881376811017561, 0.58881376772551131, 0.58881376737748181, 0.58881376783541539, 0.5888137674873859, 0.5888137674873859, 0.5888137674873859, 0.58881376737748181, 0.58881376811017561, 0.58881376800027152, 0.58881376763392457, 0.58881376763392457, 0.58881376763392457, 0.5888137674873859, 0.58881376800027152, 0.58881376772551131, 0.58881376772551131, 0.58881376772551131, 0.58881376800027152, 0.58881376763392457, 0.58881376763392457, 0.58881376800027152, 0.58881376800027152, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865, 0.5888137674873859, 0.58881376737748181, 0.58881376789036743, 0.58881376800027152, 0.58881376726757773, 0.58881376752402059, 0.58881376772551131, 0.58881376763392457, 0.58881376774382865, 0.5888137674873859, 0.58881376726757773, 0.58881376737748181, 0.58881376800027152, 0.58881376737748181, 0.58881376800027152, 0.58881376772551131, 0.58881376800027152, 0.58881376785373274, 0.58881376785373274, 0.58881376737748181, 0.5888137674873859]}
[2017-11-14 07:06:19,985 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:96]: done!
[2017-11-14 07:06:19,985 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:156]: >> Executing classifier part ... 
[2017-11-14 07:06:19,985 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:101]: =======================================
[2017-11-14 07:06:19,985 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:105]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fabde467470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 07:06:20,049 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:114]: training ... 
[2017-11-14 07:07:37,323 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:126]: trained!
[2017-11-14 07:07:37,323 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:129]: Training history: 
{'val_loss': [0.010201488953900825, 0.0099979133507908501, 0.0098054658649246937, 0.009620731073296647, 0.0094477710726092734, 0.009284658786809577, 0.0091314370013413377, 0.0089878754717986828, 0.0088530563053477659, 0.0087256917806141435, 0.0086057754995155951, 0.0084928777899773156, 0.008386441752259173, 0.0082860042109088386, 0.0081912680497898491, 0.0081016815312511415, 0.0080169374053972366, 0.0079367102875086901, 0.0078607216515477925, 0.0077886974411327603, 0.007720397558534123, 0.0076555049213058004, 0.0075938456802590853, 0.0075351922845530248, 0.0074794113784889971, 0.0074262696017119963, 0.0073755666402386686, 0.007327208525698535, 0.0072810870100186659, 0.0072370412409804123, 0.0071949692491483511, 0.0071547792819380536, 0.0071162696508863827, 0.007079448820988485, 0.0070441476481388496, 0.0070103095449701117, 0.0069778760285791851, 0.0069467147784549954, 0.0069168470661436316, 0.0068881354955990966, 0.0068605620739462204, 0.0068340505417921063, 0.0068085790822995642, 0.0067840704268543918, 0.0067605096119764127, 0.0067378181486380147, 0.0067159507897955996, 0.006694877684656461, 0.0066745679818620025, 0.0066549760171776585, 0.0066360701619886334, 0.006617821778991298, 0.0066002158268067476, 0.0065832047768241853, 0.0065667716523140776, 0.0065509060235022388, 0.006535542001913139, 0.0065193608642095304, 0.006501423243474783, 0.0064841781112756651, 0.0064675323266993002, 0.0064514440217758196, 0.006435897459231012, 0.0064208669117115248, 0.0064063466354844518, 0.0063922450683844799, 0.0063786565959730555, 0.0063655601371232018, 0.0063528874594732066, 0.0063406547019085029, 0.0063288203980704444, 0.0063173808088200683, 0.0063062890373918202, 0.0062955512100879149, 0.0062851648601152865, 0.006275108560130388, 0.006265367481677506, 0.0062559441884903434, 0.0062468194811289863, 0.006237987321576443, 0.0062294259466590934, 0.0062211331665571294, 0.0062130868857290219, 0.0062053085072831596, 0.0061977627863726648, 0.0061904472388936461, 0.0061833833804748762, 0.0061765231545252873, 0.0061698767242323064, 0.0061634402188946768, 0.0061571950137919874, 0.0061511315118009053, 0.0061452620157272618, 0.0061395728915625124, 0.0061340567597004559, 0.0061287165889481847, 0.0061235249901128077, 0.0061184987131520053, 0.0061136294263640081, 0.0061088953042562127, 0.0061043083536192833], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010303545932697056, 0.010094680576673959, 0.0098967592649221343, 0.0097075138961153305, 0.0095284277809063716, 0.0093603604916796847, 0.0092018436200884714, 0.0090532002085619498, 0.0089138261464406683, 0.0087825587201352927, 0.0086586053209000372, 0.0085419039273452527, 0.0084319612384529362, 0.008328260109744412, 0.0082303490707239784, 0.0081379225926351238, 0.0080504641680993697, 0.0079677018970045008, 0.0078892940323348777, 0.007814985699093023, 0.0077445151269454199, 0.0076776262834672739, 0.007614061584983527, 0.0075536065840247626, 0.0074960750618694233, 0.0074413203990365108, 0.0073890919956254427, 0.0073392547019622816, 0.0072916919516070938, 0.0072462995071250307, 0.0072029253674560003, 0.0071614573377092412, 0.0071218276156551023, 0.0070838306906856894, 0.0070474711037856273, 0.0070125964428993659, 0.0069791443257282938, 0.0069470532961446192, 0.0069162077350586595, 0.0068866266684690248, 0.0068581675264592834, 0.0068308258184175148, 0.006804521599716948, 0.0067792478496622073, 0.0067549041614334828, 0.0067314881606447639, 0.0067089286955679091, 0.0066871718519562473, 0.0066661801007155564, 0.0066459555729545912, 0.0066264227685789313, 0.0066075706161837968, 0.0065893567205574446, 0.0065717708208376671, 0.0065547801830680482, 0.0065383522885209882, 0.0065224779999889914, 0.0065068270190840457, 0.0064890283112973429, 0.0064710680983237094, 0.0064537763230951379, 0.0064370756635136707, 0.0064209172858203491, 0.0064053042687603904, 0.0063901930880293787, 0.0063755549427485939, 0.0063614129445434863, 0.0063477506790683364, 0.0063345707951831393, 0.0063218062044623335, 0.0063094801997013745, 0.0062975454070910439, 0.006286008047373861, 0.0062748214877345072, 0.0062639820418070452, 0.0062534910295852396, 0.0062433254805444463, 0.0062334874923070226, 0.0062239549793051147, 0.0062147222205163073, 0.0062057822235798681, 0.0061971060845820028, 0.0061887109943521883, 0.0061805395128408051, 0.0061726447188518094, 0.0061649903388878245, 0.0061575617265132538, 0.0061503870512307898, 0.0061434116924310948, 0.0061366489015693632, 0.00613009406553642, 0.0061237370213533772, 0.0061175570993260075, 0.0061115818942502629, 0.0061057783759438924, 0.0061001429988555584, 0.0060946929260525112, 0.0060893943780585529, 0.0060842514582454569, 0.0060792650650218173, 0.0060744234048787189], 'acc': [0.56976029482002122, 0.58881376811017561, 0.58881376811017561, 0.58881376772551131, 0.58881376785373274, 0.58881376737748181, 0.58881376737748181, 0.58881376759728987, 0.58881376811017561, 0.58881376763392457, 0.58881376774382865, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.58881376785373274, 0.58881376774382865, 0.58881376811017561, 0.58881376800027152, 0.5888137674873859, 0.5888137674873859, 0.58881376759728987, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.5888137674873859, 0.58881376785373274, 0.58881376737748181, 0.58881376800027152, 0.5888137674873859, 0.58881376737748181, 0.58881376737748181, 0.58881376746906855, 0.58881376763392457, 0.58881376785373274, 0.58881376811017561, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.5888137674873859, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.58881376774382865, 0.58881376752402059, 0.58881376774382865, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.5888137674873859, 0.58881376811017561, 0.58881376737748181, 0.58881376763392457, 0.58881376785373274, 0.58881376772551131, 0.58881376811017561, 0.58881376772551131, 0.58881376737748181, 0.58881376783541539, 0.5888137674873859, 0.5888137674873859, 0.5888137674873859, 0.58881376737748181, 0.58881376811017561, 0.58881376800027152, 0.58881376763392457, 0.58881376763392457, 0.58881376763392457, 0.5888137674873859, 0.58881376800027152, 0.58881376772551131, 0.58881376772551131, 0.58881376772551131, 0.58881376800027152, 0.58881376763392457, 0.58881376763392457, 0.58881376800027152, 0.58881376800027152, 0.58881376763392457, 0.58881376811017561, 0.58881376774382865, 0.5888137674873859, 0.58881376737748181, 0.58881376789036743, 0.58881376800027152, 0.58881376726757773, 0.58881376752402059, 0.58881376772551131, 0.58881376763392457, 0.58881376774382865, 0.5888137674873859, 0.58881376726757773, 0.58881376737748181, 0.58881376800027152, 0.58881376737748181, 0.58881376800027152, 0.58881376772551131, 0.58881376800027152, 0.58881376785373274, 0.58881376785373274, 0.58881376737748181, 0.5888137674873859]}
[2017-11-14 07:07:37,323 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:133]: evaluating model ... 
[2017-11-14 07:07:37,390 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:137]: evaluated! 
[2017-11-14 07:07:37,390 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:139]: generating reports ... 
[2017-11-14 07:07:37,946 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:142]: done!
[2017-11-14 07:07:37,946 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:158]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02 finished!
[2017-11-18 16:23:31,101 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:147]: The experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02 was already executed!
[2017-11-18 19:00:15,175 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02
[2017-11-18 19:00:15,175 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:150]: >> Printing header log
[2017-11-18 19:00:15,175 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:39]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22,16
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa477bb5ef0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa477b9c438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:00:15,175 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:152]: >> Loading dataset... 
[2017-11-18 19:00:15,732 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:56]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-18 19:00:15,732 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:154]: >> Executing autoencoder part ... 
[2017-11-18 19:00:15,732 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:61]: =======================================
[2017-11-18 19:00:15,732 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:66]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa477bb5ef0>, 'discard_decoder_function': True}
[2017-11-18 19:00:15,954 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:77]: training and evaluate autoencoder
[2017-11-18 19:01:00,121 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:89]: trained and evaluated!
[2017-11-18 19:01:00,123 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:92]: Training history: 
{'val_loss': [0.010159469884733728, 0.0099173194614540251, 0.0096932741844521133, 0.0094845640061070047, 0.0092913402680681548, 0.009112399923147765, 0.0089465997122975972, 0.0087926670507316694, 0.0086496260439540822, 0.0085165545475915025, 0.0083927318495334753, 0.0082773425162780238, 0.0081696538410416103, 0.0080682443918791841, 0.0079724288001988899, 0.007882658961717191, 0.0077983989470316352, 0.0077193186594152535, 0.00764500614615732, 0.0075750485665016017, 0.0075091094654538152, 0.007446938732701274, 0.0073882950847227553, 0.0073328596335527621, 0.0072805011838840729, 0.0072309115544986324, 0.0071839282348004196, 0.0071393734598913161, 0.0070970780856658092, 0.0070567958586638078, 0.0070184943418548232, 0.0069820776851813142, 0.0069473908632495147, 0.0069143343093669993, 0.0068828215974912768, 0.0068525076362557129, 0.0068234514451990785, 0.006795711746113894, 0.0067692424921962854, 0.006743977448754151, 0.0067197909270548242, 0.0066966310534695489, 0.0066744774254558258, 0.0066532153656990115, 0.0066328336740930508, 0.0066132756230528689, 0.0065943921801935338, 0.0065763323380850728, 0.0065589675620946076, 0.0065422942602252204, 0.0065262920697493178, 0.0065109342973693153, 0.0064961539069017509, 0.0064819483017223472, 0.006468260650381058, 0.0064549719790156007, 0.0064421845115305767, 0.0064298581075768043, 0.0064179864902478611, 0.006406544721564174, 0.0063955297184671829, 0.0063849023290560147, 0.0063746439182237619, 0.0063647464554770728, 0.0063551866058190959, 0.0063459529285232593, 0.0063370602987845148, 0.0063284562734478465, 0.0063201330539850052, 0.0063120968134374421, 0.0063043315029360329, 0.0062968202392297166, 0.006289553162070566, 0.0062825395431383392, 0.0062757583670872072, 0.0062691937425765846, 0.0062628529626585295, 0.0062567076704648349, 0.0062507539641347516, 0.0062449830514984721, 0.0062393938315873027, 0.006233980190216609, 0.0062287357033379235, 0.0062236587264225384, 0.0062187349572639262, 0.006213962586880506, 0.0062093315940336445, 0.0062048371645819301, 0.0062004771035123049, 0.0061962601216336826, 0.0061921664967191266, 0.0061881894862009243, 0.0061843461879844113, 0.0061806233402438545, 0.0061770127324532846, 0.0061735034224379903, 0.006170101604012419, 0.0061668072789076538, 0.0061635950452139168, 0.0061604828681090509, 0.0061574500299934783], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010284905552007739, 0.010033376537235917, 0.009800446295873769, 0.0095840375017564802, 0.0093829521706720476, 0.0091968483572623157, 0.0090243682991106525, 0.0088644136108581677, 0.0087158003307938499, 0.0085775825935149753, 0.0084489371711142097, 0.0083291250239249451, 0.0082173876535346635, 0.0081128339187574658, 0.0080137492467196505, 0.0079206868407408672, 0.0078334330241112849, 0.0077514630028566994, 0.0076744623474213486, 0.0076020223262577282, 0.0075337887640307489, 0.0074693996770640566, 0.0074086529872487237, 0.007351283592211464, 0.0072970213308431254, 0.0072457053445018575, 0.0071970639242627497, 0.0071509344009287566, 0.0071071364345016404, 0.0070654809395951515, 0.0070258062536076634, 0.0069880621847207185, 0.0069521358568672394, 0.0069178790944504206, 0.0068851957711853094, 0.0068539440635873375, 0.0068238221721972107, 0.0067950242880752427, 0.0067675036381639325, 0.0067412356454501247, 0.0067161094450541234, 0.0066920439380701328, 0.006668973530939773, 0.006646884955035336, 0.0066256581547486319, 0.0066052982612262862, 0.0065856762350603856, 0.0065668053746443262, 0.0065487102011805966, 0.0065313119901494153, 0.0065145884813957227, 0.0064985192891441577, 0.0064830813361142926, 0.0064681985203151552, 0.0064538875242698647, 0.0064400475828255256, 0.0064266132787282144, 0.0064136831512870453, 0.0064012371530251478, 0.0063892041256315849, 0.0063776069620684857, 0.0063664338482199235, 0.0063556387700534301, 0.0063452159578911383, 0.0063351479747642313, 0.0063254093910443251, 0.0063159984502696373, 0.0063069222698740306, 0.0062981443585554331, 0.0062896329878080123, 0.006281416859768546, 0.0062734629774549733, 0.006265765606393075, 0.0062583267042492351, 0.0062511256611468089, 0.0062441596413316284, 0.0062374154050830466, 0.0062308814654214919, 0.0062245458499577124, 0.0062184120421357953, 0.0062124516374758403, 0.0062066788605420632, 0.0062010778519470929, 0.0061956579237718414, 0.0061903970806041451, 0.0061852977457716738, 0.006180336175986738, 0.0061755278411068908, 0.0061708478192376926, 0.0061663107376387681, 0.0061619136117275096, 0.0061576484565719842, 0.006153499937118858, 0.0061494889254117939, 0.0061455978035981768, 0.0061418217682401568, 0.0061381359243468962, 0.0061345646405717349, 0.0061311044417706349, 0.0061277356880276787, 0.0061244562805756768], 'acc': [0.57836508945079401, 0.58881376774382865, 0.58881376811017561, 0.5888137674873859, 0.58881376811017561, 0.58881376763392457, 0.58881376774382865, 0.58881376752402059, 0.58881376789036743, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865, 0.58881376737748181, 0.58881376800027152, 0.5888137674873859, 0.5888137674873859, 0.58881376800027152, 0.58881376737748181, 0.58881376774382865, 0.58881376785373274, 0.58881376800027152, 0.58881376763392457, 0.5888137674873859, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865, 0.58881376763392457, 0.58881376811017561, 0.58881376811017561, 0.58881376774382865, 0.58881376737748181, 0.5888137674873859, 0.58881376800027152, 0.58881376726757773, 0.58881376811017561, 0.58881376726757773, 0.58881376772551131, 0.58881376811017561, 0.58881376763392457, 0.58881376763392457, 0.58881376772551131, 0.58881376800027152, 0.58881376783541539, 0.58881376772551131, 0.58881376774382865, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376726757773, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376811017561, 0.58881376726757773, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376774382865, 0.58881376726757773, 0.58881376774382865, 0.58881376726757773, 0.58881376789036743, 0.58881376726757773, 0.58881376800027152, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376759728987, 0.58881376785373274, 0.58881376726757773, 0.58881376763392457, 0.58881376811017561, 0.58881376772551131, 0.58881376800027152, 0.5888137674873859, 0.58881376785373274, 0.58881376800027152, 0.58881376774382865, 0.58881376726757773]}
[2017-11-18 19:01:00,123 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:96]: done!
[2017-11-18 19:01:00,123 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:156]: >> Executing classifier part ... 
[2017-11-18 19:01:00,123 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:101]: =======================================
[2017-11-18 19:01:00,124 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:105]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa477b9c438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:01:00,187 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:114]: training ... 
[2017-11-18 19:02:10,163 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:126]: trained!
[2017-11-18 19:02:10,163 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:129]: Training history: 
{'val_loss': [0.010159469884733728, 0.0099173194614540251, 0.0096932741844521133, 0.0094845640061070047, 0.0092913402680681548, 0.009112399923147765, 0.0089465997122975972, 0.0087926670507316694, 0.0086496260439540822, 0.0085165545475915025, 0.0083927318495334753, 0.0082773425162780238, 0.0081696538410416103, 0.0080682443918791841, 0.0079724288001988899, 0.007882658961717191, 0.0077983989470316352, 0.0077193186594152535, 0.00764500614615732, 0.0075750485665016017, 0.0075091094654538152, 0.007446938732701274, 0.0073882950847227553, 0.0073328596335527621, 0.0072805011838840729, 0.0072309115544986324, 0.0071839282348004196, 0.0071393734598913161, 0.0070970780856658092, 0.0070567958586638078, 0.0070184943418548232, 0.0069820776851813142, 0.0069473908632495147, 0.0069143343093669993, 0.0068828215974912768, 0.0068525076362557129, 0.0068234514451990785, 0.006795711746113894, 0.0067692424921962854, 0.006743977448754151, 0.0067197909270548242, 0.0066966310534695489, 0.0066744774254558258, 0.0066532153656990115, 0.0066328336740930508, 0.0066132756230528689, 0.0065943921801935338, 0.0065763323380850728, 0.0065589675620946076, 0.0065422942602252204, 0.0065262920697493178, 0.0065109342973693153, 0.0064961539069017509, 0.0064819483017223472, 0.006468260650381058, 0.0064549719790156007, 0.0064421845115305767, 0.0064298581075768043, 0.0064179864902478611, 0.006406544721564174, 0.0063955297184671829, 0.0063849023290560147, 0.0063746439182237619, 0.0063647464554770728, 0.0063551866058190959, 0.0063459529285232593, 0.0063370602987845148, 0.0063284562734478465, 0.0063201330539850052, 0.0063120968134374421, 0.0063043315029360329, 0.0062968202392297166, 0.006289553162070566, 0.0062825395431383392, 0.0062757583670872072, 0.0062691937425765846, 0.0062628529626585295, 0.0062567076704648349, 0.0062507539641347516, 0.0062449830514984721, 0.0062393938315873027, 0.006233980190216609, 0.0062287357033379235, 0.0062236587264225384, 0.0062187349572639262, 0.006213962586880506, 0.0062093315940336445, 0.0062048371645819301, 0.0062004771035123049, 0.0061962601216336826, 0.0061921664967191266, 0.0061881894862009243, 0.0061843461879844113, 0.0061806233402438545, 0.0061770127324532846, 0.0061735034224379903, 0.006170101604012419, 0.0061668072789076538, 0.0061635950452139168, 0.0061604828681090509, 0.0061574500299934783], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010284905552007739, 0.010033376537235917, 0.009800446295873769, 0.0095840375017564802, 0.0093829521706720476, 0.0091968483572623157, 0.0090243682991106525, 0.0088644136108581677, 0.0087158003307938499, 0.0085775825935149753, 0.0084489371711142097, 0.0083291250239249451, 0.0082173876535346635, 0.0081128339187574658, 0.0080137492467196505, 0.0079206868407408672, 0.0078334330241112849, 0.0077514630028566994, 0.0076744623474213486, 0.0076020223262577282, 0.0075337887640307489, 0.0074693996770640566, 0.0074086529872487237, 0.007351283592211464, 0.0072970213308431254, 0.0072457053445018575, 0.0071970639242627497, 0.0071509344009287566, 0.0071071364345016404, 0.0070654809395951515, 0.0070258062536076634, 0.0069880621847207185, 0.0069521358568672394, 0.0069178790944504206, 0.0068851957711853094, 0.0068539440635873375, 0.0068238221721972107, 0.0067950242880752427, 0.0067675036381639325, 0.0067412356454501247, 0.0067161094450541234, 0.0066920439380701328, 0.006668973530939773, 0.006646884955035336, 0.0066256581547486319, 0.0066052982612262862, 0.0065856762350603856, 0.0065668053746443262, 0.0065487102011805966, 0.0065313119901494153, 0.0065145884813957227, 0.0064985192891441577, 0.0064830813361142926, 0.0064681985203151552, 0.0064538875242698647, 0.0064400475828255256, 0.0064266132787282144, 0.0064136831512870453, 0.0064012371530251478, 0.0063892041256315849, 0.0063776069620684857, 0.0063664338482199235, 0.0063556387700534301, 0.0063452159578911383, 0.0063351479747642313, 0.0063254093910443251, 0.0063159984502696373, 0.0063069222698740306, 0.0062981443585554331, 0.0062896329878080123, 0.006281416859768546, 0.0062734629774549733, 0.006265765606393075, 0.0062583267042492351, 0.0062511256611468089, 0.0062441596413316284, 0.0062374154050830466, 0.0062308814654214919, 0.0062245458499577124, 0.0062184120421357953, 0.0062124516374758403, 0.0062066788605420632, 0.0062010778519470929, 0.0061956579237718414, 0.0061903970806041451, 0.0061852977457716738, 0.006180336175986738, 0.0061755278411068908, 0.0061708478192376926, 0.0061663107376387681, 0.0061619136117275096, 0.0061576484565719842, 0.006153499937118858, 0.0061494889254117939, 0.0061455978035981768, 0.0061418217682401568, 0.0061381359243468962, 0.0061345646405717349, 0.0061311044417706349, 0.0061277356880276787, 0.0061244562805756768], 'acc': [0.57836508945079401, 0.58881376774382865, 0.58881376811017561, 0.5888137674873859, 0.58881376811017561, 0.58881376763392457, 0.58881376774382865, 0.58881376752402059, 0.58881376789036743, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865, 0.58881376737748181, 0.58881376800027152, 0.5888137674873859, 0.5888137674873859, 0.58881376800027152, 0.58881376737748181, 0.58881376774382865, 0.58881376785373274, 0.58881376800027152, 0.58881376763392457, 0.5888137674873859, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.58881376774382865, 0.5888137674873859, 0.58881376774382865, 0.58881376763392457, 0.58881376811017561, 0.58881376811017561, 0.58881376774382865, 0.58881376737748181, 0.5888137674873859, 0.58881376800027152, 0.58881376726757773, 0.58881376811017561, 0.58881376726757773, 0.58881376772551131, 0.58881376811017561, 0.58881376763392457, 0.58881376763392457, 0.58881376772551131, 0.58881376800027152, 0.58881376783541539, 0.58881376772551131, 0.58881376774382865, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376726757773, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376811017561, 0.58881376726757773, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376774382865, 0.58881376726757773, 0.58881376774382865, 0.58881376726757773, 0.58881376789036743, 0.58881376726757773, 0.58881376800027152, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376759728987, 0.58881376785373274, 0.58881376726757773, 0.58881376763392457, 0.58881376811017561, 0.58881376772551131, 0.58881376800027152, 0.5888137674873859, 0.58881376785373274, 0.58881376800027152, 0.58881376774382865, 0.58881376726757773]}
[2017-11-18 19:02:10,163 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:133]: evaluating model ... 
[2017-11-18 19:02:10,234 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:137]: evaluated! 
[2017-11-18 19:02:10,234 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:139]: generating reports ... 
[2017-11-18 19:02:10,798 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:142]: done!
[2017-11-18 19:02:10,798 AE_UNIGRAMA_10L_FULLDS_UNDER_02.py:158]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_02 finished!
