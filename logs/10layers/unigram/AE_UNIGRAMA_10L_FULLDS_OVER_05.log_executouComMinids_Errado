[2017-11-13 17:16:17,794 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_05
[2017-11-13 17:16:17,795 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-13 17:16:17,795 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42,25
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe59d60aeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe59d60f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 17:16:17,795 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-13 17:16:18,694 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-13 17:16:18,694 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-13 17:16:18,694 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-13 17:16:18,694 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe59d60aeb8>, 'discard_decoder_function': True}
[2017-11-13 17:16:19,007 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-13 17:18:22,158 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-13 17:18:22,159 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.010323309381128909, 0.010234609208170145, 0.010151508316176089, 0.010073646466805145, 0.010000706972298126, 0.0099323096037686534, 0.0098681042912558102, 0.0098078882418655994, 0.0097514024440573058, 0.0096984369209430921, 0.0096480878741656978, 0.0096005171426609987, 0.009555772590869864, 0.0095136584887163343, 0.009474004009482364, 0.0094366225735959507, 0.0094014250095171992, 0.0093682164388629134, 0.0093358407371770934, 0.009305347176095588, 0.0092766323372666278, 0.0092495394295919343, 0.0092240176804114452, 0.0091999356278311805, 0.0091771764479937606, 0.0091557436723082031, 0.0091354595116412331, 0.0091163088744125407, 0.0090981509404942443, 0.009081014965186554, 0.0090647698120390613, 0.0090489761910806359, 0.0090336655837840313, 0.0090191269528854742, 0.0090053097507656731, 0.008992200128761809, 0.0089797293109521552, 0.0089678702993685432, 0.0089565894486846528, 0.0089458344213415256, 0.008935608298666636, 0.0089258897571814107, 0.00891661918531674, 0.0089077740166765614, 0.0088993591848470013, 0.008891316958214936, 0.0088836639067054243, 0.0088763485444522706, 0.0088693774911163016, 0.0088627078850860939, 0.0088563391308691414, 0.0088502499707680208, 0.0088444249600615199, 0.0088388411965235024, 0.00883350327098569, 0.0088284116266052967, 0.0088235382544617665, 0.0088188609689972657, 0.0088143802029825059, 0.0088100727702937597, 0.0088059500649183657, 0.0088020185541818584, 0.0087982546261141294, 0.0087946189020424535, 0.0087911513976780455, 0.0087878157014241887, 0.0087846138732694777, 0.008781539089285308, 0.0087785986788764762, 0.008775746643709427, 0.0087730175881303822, 0.0087704056056846467, 0.0087678785570879849, 0.0087654435120827646, 0.0087631147451781872, 0.0087608738861230228, 0.0087587288978983914, 0.0087566554137820645, 0.0087546645646367823, 0.0087527415220068298, 0.0087508927497555768, 0.008749118258269524, 0.0087473941239836484, 0.0087457464793246915, 0.0087441516811630534, 0.0087426234327505955, 0.0087411381117307122, 0.0087397107127430707, 0.0087383297067758769, 0.0087370071629387733, 0.0087357296134071716, 0.0087344954794335104, 0.0087333027806590045, 0.0087321403135154334, 0.0087310236369754751, 0.0087299461313783012, 0.0087289001453377049, 0.0087279035297800622, 0.0087269332232196087, 0.0087259813596158673, 0.0087250561858475423], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691], 'loss': [0.010364809700304478, 0.010274491541902749, 0.01018935970655232, 0.010109607779410036, 0.010034856134046788, 0.0099648526682533881, 0.0098991986248497948, 0.0098375601530276569, 0.0097797829875311531, 0.0097255741383997143, 0.0096745701808970113, 0.0096260289654144862, 0.0095803473281004924, 0.0095373828264014009, 0.0094969417549527792, 0.0094588457846575599, 0.0094229404997142382, 0.0093891188169164964, 0.0093567399124911983, 0.0093256125607846622, 0.0092963233627905567, 0.0092687629639516232, 0.0092427594061727965, 0.009218230908227135, 0.0091950983832548502, 0.0091732333957480379, 0.0091526318534970574, 0.0091331294790991044, 0.0091147067290905364, 0.0090972502322635117, 0.009080745946082441, 0.0090649990123349167, 0.0090495344748252292, 0.0090347733131089531, 0.0090207640464018655, 0.0090074480076783557, 0.0089948030438253539, 0.0089827590165791442, 0.0089713192568346631, 0.0089604313649608077, 0.0089500322107960648, 0.0089401582561630232, 0.0089307619412169175, 0.0089217999723374148, 0.0089132312345235488, 0.0089050867098492935, 0.0088972983556698266, 0.0088898802574520173, 0.0088827933523101029, 0.0088760218564157625, 0.0088695567192826896, 0.0088633657848094967, 0.0088574407884385153, 0.0088517759928334397, 0.0088463407353290262, 0.0088411543750706156, 0.0088361830312641918, 0.0088314313754054696, 0.0088268624591173461, 0.008822484856062714, 0.0088182841338899573, 0.00881426423254578, 0.0088104125926272234, 0.0088067161069281929, 0.0088031634925358048, 0.0087997480275563908, 0.0087964786147926577, 0.0087933394332091793, 0.0087903025877772486, 0.008787408137960747, 0.0087846064826756359, 0.0087819191224795222, 0.0087793264148806095, 0.0087768381001277797, 0.0087744304480989362, 0.0087721144898434533, 0.008769902131063996, 0.0087677720606730031, 0.0087657264424070083, 0.0087637384653952346, 0.0087618171114339453, 0.0087599844609392366, 0.0087582059101543319, 0.0087564914179914331, 0.008754841926076621, 0.0087532550411341236, 0.008751710659303984, 0.0087502308272296991, 0.0087487960277788102, 0.0087474183252135088, 0.0087460769682701344, 0.0087447994610165333, 0.0087435518751480708, 0.0087423467820884632, 0.0087411747111972669, 0.0087400467713725817, 0.0087389584284987849, 0.0087379065920961153, 0.0087368884556036676, 0.0087358973898593456, 0.0087349345568698018], 'acc': [0.00061462814996926854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462815454860513, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854]}
[2017-11-13 17:18:22,159 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:95]: done!
[2017-11-13 17:18:22,159 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-13 17:18:22,159 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-13 17:18:22,159 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe59d60f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 17:18:22,197 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-13 17:21:12,299 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:125]: trained!
[2017-11-13 17:21:12,300 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.010323309381128909, 0.010234609208170145, 0.010151508316176089, 0.010073646466805145, 0.010000706972298126, 0.0099323096037686534, 0.0098681042912558102, 0.0098078882418655994, 0.0097514024440573058, 0.0096984369209430921, 0.0096480878741656978, 0.0096005171426609987, 0.009555772590869864, 0.0095136584887163343, 0.009474004009482364, 0.0094366225735959507, 0.0094014250095171992, 0.0093682164388629134, 0.0093358407371770934, 0.009305347176095588, 0.0092766323372666278, 0.0092495394295919343, 0.0092240176804114452, 0.0091999356278311805, 0.0091771764479937606, 0.0091557436723082031, 0.0091354595116412331, 0.0091163088744125407, 0.0090981509404942443, 0.009081014965186554, 0.0090647698120390613, 0.0090489761910806359, 0.0090336655837840313, 0.0090191269528854742, 0.0090053097507656731, 0.008992200128761809, 0.0089797293109521552, 0.0089678702993685432, 0.0089565894486846528, 0.0089458344213415256, 0.008935608298666636, 0.0089258897571814107, 0.00891661918531674, 0.0089077740166765614, 0.0088993591848470013, 0.008891316958214936, 0.0088836639067054243, 0.0088763485444522706, 0.0088693774911163016, 0.0088627078850860939, 0.0088563391308691414, 0.0088502499707680208, 0.0088444249600615199, 0.0088388411965235024, 0.00883350327098569, 0.0088284116266052967, 0.0088235382544617665, 0.0088188609689972657, 0.0088143802029825059, 0.0088100727702937597, 0.0088059500649183657, 0.0088020185541818584, 0.0087982546261141294, 0.0087946189020424535, 0.0087911513976780455, 0.0087878157014241887, 0.0087846138732694777, 0.008781539089285308, 0.0087785986788764762, 0.008775746643709427, 0.0087730175881303822, 0.0087704056056846467, 0.0087678785570879849, 0.0087654435120827646, 0.0087631147451781872, 0.0087608738861230228, 0.0087587288978983914, 0.0087566554137820645, 0.0087546645646367823, 0.0087527415220068298, 0.0087508927497555768, 0.008749118258269524, 0.0087473941239836484, 0.0087457464793246915, 0.0087441516811630534, 0.0087426234327505955, 0.0087411381117307122, 0.0087397107127430707, 0.0087383297067758769, 0.0087370071629387733, 0.0087357296134071716, 0.0087344954794335104, 0.0087333027806590045, 0.0087321403135154334, 0.0087310236369754751, 0.0087299461313783012, 0.0087289001453377049, 0.0087279035297800622, 0.0087269332232196087, 0.0087259813596158673, 0.0087250561858475423], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691], 'loss': [0.010364809700304478, 0.010274491541902749, 0.01018935970655232, 0.010109607779410036, 0.010034856134046788, 0.0099648526682533881, 0.0098991986248497948, 0.0098375601530276569, 0.0097797829875311531, 0.0097255741383997143, 0.0096745701808970113, 0.0096260289654144862, 0.0095803473281004924, 0.0095373828264014009, 0.0094969417549527792, 0.0094588457846575599, 0.0094229404997142382, 0.0093891188169164964, 0.0093567399124911983, 0.0093256125607846622, 0.0092963233627905567, 0.0092687629639516232, 0.0092427594061727965, 0.009218230908227135, 0.0091950983832548502, 0.0091732333957480379, 0.0091526318534970574, 0.0091331294790991044, 0.0091147067290905364, 0.0090972502322635117, 0.009080745946082441, 0.0090649990123349167, 0.0090495344748252292, 0.0090347733131089531, 0.0090207640464018655, 0.0090074480076783557, 0.0089948030438253539, 0.0089827590165791442, 0.0089713192568346631, 0.0089604313649608077, 0.0089500322107960648, 0.0089401582561630232, 0.0089307619412169175, 0.0089217999723374148, 0.0089132312345235488, 0.0089050867098492935, 0.0088972983556698266, 0.0088898802574520173, 0.0088827933523101029, 0.0088760218564157625, 0.0088695567192826896, 0.0088633657848094967, 0.0088574407884385153, 0.0088517759928334397, 0.0088463407353290262, 0.0088411543750706156, 0.0088361830312641918, 0.0088314313754054696, 0.0088268624591173461, 0.008822484856062714, 0.0088182841338899573, 0.00881426423254578, 0.0088104125926272234, 0.0088067161069281929, 0.0088031634925358048, 0.0087997480275563908, 0.0087964786147926577, 0.0087933394332091793, 0.0087903025877772486, 0.008787408137960747, 0.0087846064826756359, 0.0087819191224795222, 0.0087793264148806095, 0.0087768381001277797, 0.0087744304480989362, 0.0087721144898434533, 0.008769902131063996, 0.0087677720606730031, 0.0087657264424070083, 0.0087637384653952346, 0.0087618171114339453, 0.0087599844609392366, 0.0087582059101543319, 0.0087564914179914331, 0.008754841926076621, 0.0087532550411341236, 0.008751710659303984, 0.0087502308272296991, 0.0087487960277788102, 0.0087474183252135088, 0.0087460769682701344, 0.0087447994610165333, 0.0087435518751480708, 0.0087423467820884632, 0.0087411747111972669, 0.0087400467713725817, 0.0087389584284987849, 0.0087379065920961153, 0.0087368884556036676, 0.0087358973898593456, 0.0087349345568698018], 'acc': [0.00061462814996926854, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462815454860513, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854, 0.00061462814996926854]}
[2017-11-13 17:21:12,301 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-13 17:21:12,422 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-13 17:21:12,422 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-13 17:21:13,046 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:141]: done!
[2017-11-13 17:21:13,046 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_05 finished!
[2017-11-14 07:04:46,718 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_10L_FULLDS_OVER_05 was already executed!
[2017-11-18 14:56:34,406 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_10L_FULLDS_OVER_05 was already executed!
[2017-11-18 16:23:04,293 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_10L_FULLDS_OVER_05 was already executed!
[2017-11-18 18:20:05,825 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_OVER_05
[2017-11-18 18:20:05,825 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 18:20:05,825 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42,25
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbceee85eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbceee8a400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:20:05,825 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 18:20:06,330 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-18 18:20:06,330 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:20:06,331 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 18:20:06,331 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbceee85eb8>, 'discard_decoder_function': True}
[2017-11-18 18:20:06,524 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 18:21:17,413 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 18:21:17,415 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.010231268893387237, 0.010050489536060719, 0.0098753275772120435, 0.0097084545312262384, 0.0095493493560133806, 0.0093974849506935666, 0.0092525333269987409, 0.0091139923601123926, 0.0089816098104899249, 0.0088550251074218395, 0.0087339425923434327, 0.0086181557782299013, 0.0085073182892511333, 0.0084011886324248785, 0.0082996371911914814, 0.0082023755861896346, 0.0081092135939179293, 0.008020006923427369, 0.0079345485285533847, 0.0078525858668118832, 0.0077740926136259251, 0.0076988482653928512, 0.0076266376935222556, 0.0075573594513657369, 0.0074909720327497415, 0.00742726164721091, 0.0073660936165033221, 0.0073074086648879438, 0.007251016380175339, 0.0071968911527257873, 0.0071445376799202983, 0.0070938289037396698, 0.0070451896146050616, 0.0069984538051330912, 0.0069535958622218728, 0.0069105488085447631, 0.0068692197057255806, 0.0068294999906343152, 0.0067913050219748985, 0.0067546628138611311, 0.0067194329581628503, 0.0066855947684399701, 0.006653124270926067, 0.0066219177425987878, 0.006591883275076248, 0.0065630212232304329, 0.0065352957865368703, 0.006508643259415507, 0.0064830017123772973, 0.0064583390632637367, 0.0064346449099979657, 0.0064118505459015698, 0.0063899696119074263, 0.0063689121297910312, 0.0063486642197300731, 0.0063291898163444051, 0.0063104446108373348, 0.0062924260654414008, 0.0062751061141103175, 0.0062584179353148963, 0.0062423392292458328, 0.0062268808497926119, 0.0062120030564861888, 0.0061976595601710913, 0.0061838708464817928, 0.0061706012880021087, 0.0061578329455204391, 0.0061455279013979836, 0.0061336808394793019, 0.0061222779768827238, 0.0061113011874397005, 0.0061007281488368505, 0.0060905382213733228, 0.0060807167791300989, 0.0060712598960112685, 0.0060621609038856838, 0.0060534054018750953, 0.0060449687774435075, 0.0060368359667079376, 0.0060289958214948172, 0.0060214386061941821, 0.0060141630069141493, 0.0060071447486798784, 0.0060003751051027092, 0.0059938585025614962, 0.005987578400559585, 0.0059815299676447328, 0.0059756828198507155, 0.0059700622431047567, 0.005964633285112984, 0.0059594226686013893, 0.0059543741160664413, 0.0059495146860642058, 0.0059448194233042819, 0.0059403031095031471, 0.0059359418643728512, 0.0059317373307110205, 0.0059276786632835865, 0.0059237590675903515, 0.0059199790785359188, 0.0059163471853505949], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010318913539389598, 0.010136333524896898, 0.0099583362791854403, 0.0097874774303935239, 0.0096245758869692669, 0.0094691952324135222, 0.0093208439361942858, 0.0091791640018063156, 0.0090437146028493464, 0.0089142720644907782, 0.0087904669418839426, 0.0086719991946072033, 0.0085587107777348233, 0.0084502498677072532, 0.0083463634613308354, 0.0082469276967100675, 0.0081516651582080445, 0.0080604066513593232, 0.0079730067610484217, 0.0078892429733045562, 0.0078089062814825725, 0.0077319403895083644, 0.0076581372438111993, 0.0075873068397030114, 0.0075193291321653272, 0.00745418009942955, 0.0073916411889372391, 0.0073315704169270449, 0.0072739198826798357, 0.0072185009369911705, 0.0071652388539607164, 0.0071133957401870512, 0.0070635246049404405, 0.0070156525035137479, 0.006969640960776062, 0.0069254725998623571, 0.0068830686936769735, 0.0068423436149226682, 0.0068031848304101897, 0.006765531603826213, 0.0067293784270874733, 0.0066946289993218104, 0.0066612336682138557, 0.0066291874065106827, 0.0065983551664285925, 0.0065686801218352731, 0.0065401656311016802, 0.0065127601014185734, 0.0064863969623978404, 0.0064610213793461577, 0.0064366141179051034, 0.006413161738580476, 0.0063905917816711264, 0.0063689061315740517, 0.0063480276671096861, 0.0063279493770275327, 0.00630862693363582, 0.0062900234566750741, 0.0062721402406665031, 0.0062549229443402982, 0.0062383275293615165, 0.0062223435170632533, 0.0062069651844196333, 0.0061921492724415529, 0.0061778621012533851, 0.0061641229152308514, 0.0061508930501766781, 0.0061381543882319404, 0.0061258680803086508, 0.0061140429359055328, 0.0061026455619279125, 0.0060916763189985445, 0.006081103856406863, 0.0060709056801654367, 0.0060610735394546018, 0.0060515951613661478, 0.0060424702107498779, 0.0060337003868258686, 0.0060252198776586255, 0.0060170582909487326, 0.0060091804196118169, 0.0060015696629804006, 0.0059942493144223572, 0.0059871677596628047, 0.0059803556802567525, 0.0059737803694375948, 0.0059674496063533266, 0.0059613236051554242, 0.0059554251706537909, 0.0059497399609387104, 0.0059442431508542276, 0.0059389706776026901, 0.0059338517374855357, 0.0059289195867897578, 0.0059241419592236883, 0.0059195535541377558, 0.0059151137674132333, 0.0059108454716914477, 0.0059066979760062531, 0.0059026991836864046, 0.0058988455259976723], 'acc': [0.57713583315085548, 0.58881376726757773, 0.5888137674873859, 0.58881376800027152, 0.5888137674873859, 0.58881376800027152, 0.5888137674873859, 0.58881376785373274, 0.58881376783541539, 0.58881376759728987, 0.58881376811017561, 0.58881376772551131, 0.5888137674873859, 0.58881376763392457, 0.58881376800027152, 0.58881376789036743, 0.58881376763392457, 0.58881376772551131, 0.58881376774382865, 0.58881376800027152, 0.58881376785373274, 0.58881376772551131, 0.5888137674873859, 0.58881376726757773, 0.58881376811017561, 0.58881376737748181, 0.58881376763392457, 0.58881376774382865, 0.58881376726757773, 0.58881376774382865, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.5888137681468103, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376772551131, 0.5888137674873859, 0.58881376800027152, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376789036743, 0.58881376789036743, 0.58881376811017561, 0.58881376726757773, 0.58881376785373274, 0.58881376785373274, 0.58881376785373274, 0.58881376811017561, 0.58881376811017561, 0.58881376785373274, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376774382865, 0.58881376774382865, 0.58881376763392457, 0.58881376763392457, 0.58881376785373274, 0.58881376737748181, 0.58881376763392457, 0.58881376772551131, 0.58881376800027152, 0.58881376811017561, 0.5888137674873859, 0.58881376774382865, 0.58881376726757773, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376811017561, 0.58881376811017561, 0.58881376737748181, 0.58881376800027152, 0.58881376811017561, 0.58881376726757773, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.58881376785373274, 0.58881376737748181, 0.58881376783541539, 0.58881376763392457, 0.58881376811017561, 0.58881376789036743, 0.58881376811017561, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457]}
[2017-11-18 18:21:17,415 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:95]: done!
[2017-11-18 18:21:17,415 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 18:21:17,416 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 18:21:17,416 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbceee8a400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:21:17,485 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 18:23:25,755 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:125]: trained!
[2017-11-18 18:23:25,755 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.010231268893387237, 0.010050489536060719, 0.0098753275772120435, 0.0097084545312262384, 0.0095493493560133806, 0.0093974849506935666, 0.0092525333269987409, 0.0091139923601123926, 0.0089816098104899249, 0.0088550251074218395, 0.0087339425923434327, 0.0086181557782299013, 0.0085073182892511333, 0.0084011886324248785, 0.0082996371911914814, 0.0082023755861896346, 0.0081092135939179293, 0.008020006923427369, 0.0079345485285533847, 0.0078525858668118832, 0.0077740926136259251, 0.0076988482653928512, 0.0076266376935222556, 0.0075573594513657369, 0.0074909720327497415, 0.00742726164721091, 0.0073660936165033221, 0.0073074086648879438, 0.007251016380175339, 0.0071968911527257873, 0.0071445376799202983, 0.0070938289037396698, 0.0070451896146050616, 0.0069984538051330912, 0.0069535958622218728, 0.0069105488085447631, 0.0068692197057255806, 0.0068294999906343152, 0.0067913050219748985, 0.0067546628138611311, 0.0067194329581628503, 0.0066855947684399701, 0.006653124270926067, 0.0066219177425987878, 0.006591883275076248, 0.0065630212232304329, 0.0065352957865368703, 0.006508643259415507, 0.0064830017123772973, 0.0064583390632637367, 0.0064346449099979657, 0.0064118505459015698, 0.0063899696119074263, 0.0063689121297910312, 0.0063486642197300731, 0.0063291898163444051, 0.0063104446108373348, 0.0062924260654414008, 0.0062751061141103175, 0.0062584179353148963, 0.0062423392292458328, 0.0062268808497926119, 0.0062120030564861888, 0.0061976595601710913, 0.0061838708464817928, 0.0061706012880021087, 0.0061578329455204391, 0.0061455279013979836, 0.0061336808394793019, 0.0061222779768827238, 0.0061113011874397005, 0.0061007281488368505, 0.0060905382213733228, 0.0060807167791300989, 0.0060712598960112685, 0.0060621609038856838, 0.0060534054018750953, 0.0060449687774435075, 0.0060368359667079376, 0.0060289958214948172, 0.0060214386061941821, 0.0060141630069141493, 0.0060071447486798784, 0.0060003751051027092, 0.0059938585025614962, 0.005987578400559585, 0.0059815299676447328, 0.0059756828198507155, 0.0059700622431047567, 0.005964633285112984, 0.0059594226686013893, 0.0059543741160664413, 0.0059495146860642058, 0.0059448194233042819, 0.0059403031095031471, 0.0059359418643728512, 0.0059317373307110205, 0.0059276786632835865, 0.0059237590675903515, 0.0059199790785359188, 0.0059163471853505949], 'val_acc': [0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010318913539389598, 0.010136333524896898, 0.0099583362791854403, 0.0097874774303935239, 0.0096245758869692669, 0.0094691952324135222, 0.0093208439361942858, 0.0091791640018063156, 0.0090437146028493464, 0.0089142720644907782, 0.0087904669418839426, 0.0086719991946072033, 0.0085587107777348233, 0.0084502498677072532, 0.0083463634613308354, 0.0082469276967100675, 0.0081516651582080445, 0.0080604066513593232, 0.0079730067610484217, 0.0078892429733045562, 0.0078089062814825725, 0.0077319403895083644, 0.0076581372438111993, 0.0075873068397030114, 0.0075193291321653272, 0.00745418009942955, 0.0073916411889372391, 0.0073315704169270449, 0.0072739198826798357, 0.0072185009369911705, 0.0071652388539607164, 0.0071133957401870512, 0.0070635246049404405, 0.0070156525035137479, 0.006969640960776062, 0.0069254725998623571, 0.0068830686936769735, 0.0068423436149226682, 0.0068031848304101897, 0.006765531603826213, 0.0067293784270874733, 0.0066946289993218104, 0.0066612336682138557, 0.0066291874065106827, 0.0065983551664285925, 0.0065686801218352731, 0.0065401656311016802, 0.0065127601014185734, 0.0064863969623978404, 0.0064610213793461577, 0.0064366141179051034, 0.006413161738580476, 0.0063905917816711264, 0.0063689061315740517, 0.0063480276671096861, 0.0063279493770275327, 0.00630862693363582, 0.0062900234566750741, 0.0062721402406665031, 0.0062549229443402982, 0.0062383275293615165, 0.0062223435170632533, 0.0062069651844196333, 0.0061921492724415529, 0.0061778621012533851, 0.0061641229152308514, 0.0061508930501766781, 0.0061381543882319404, 0.0061258680803086508, 0.0061140429359055328, 0.0061026455619279125, 0.0060916763189985445, 0.006081103856406863, 0.0060709056801654367, 0.0060610735394546018, 0.0060515951613661478, 0.0060424702107498779, 0.0060337003868258686, 0.0060252198776586255, 0.0060170582909487326, 0.0060091804196118169, 0.0060015696629804006, 0.0059942493144223572, 0.0059871677596628047, 0.0059803556802567525, 0.0059737803694375948, 0.0059674496063533266, 0.0059613236051554242, 0.0059554251706537909, 0.0059497399609387104, 0.0059442431508542276, 0.0059389706776026901, 0.0059338517374855357, 0.0059289195867897578, 0.0059241419592236883, 0.0059195535541377558, 0.0059151137674132333, 0.0059108454716914477, 0.0059066979760062531, 0.0059026991836864046, 0.0058988455259976723], 'acc': [0.57713583315085548, 0.58881376726757773, 0.5888137674873859, 0.58881376800027152, 0.5888137674873859, 0.58881376800027152, 0.5888137674873859, 0.58881376785373274, 0.58881376783541539, 0.58881376759728987, 0.58881376811017561, 0.58881376772551131, 0.5888137674873859, 0.58881376763392457, 0.58881376800027152, 0.58881376789036743, 0.58881376763392457, 0.58881376772551131, 0.58881376774382865, 0.58881376800027152, 0.58881376785373274, 0.58881376772551131, 0.5888137674873859, 0.58881376726757773, 0.58881376811017561, 0.58881376737748181, 0.58881376763392457, 0.58881376774382865, 0.58881376726757773, 0.58881376774382865, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376774382865, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.5888137681468103, 0.58881376811017561, 0.58881376800027152, 0.58881376800027152, 0.58881376772551131, 0.5888137674873859, 0.58881376800027152, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376789036743, 0.58881376789036743, 0.58881376811017561, 0.58881376726757773, 0.58881376785373274, 0.58881376785373274, 0.58881376785373274, 0.58881376811017561, 0.58881376811017561, 0.58881376785373274, 0.58881376785373274, 0.58881376811017561, 0.58881376800027152, 0.58881376774382865, 0.58881376774382865, 0.58881376763392457, 0.58881376763392457, 0.58881376785373274, 0.58881376737748181, 0.58881376763392457, 0.58881376772551131, 0.58881376800027152, 0.58881376811017561, 0.5888137674873859, 0.58881376774382865, 0.58881376726757773, 0.58881376737748181, 0.58881376774382865, 0.58881376811017561, 0.58881376811017561, 0.58881376811017561, 0.58881376737748181, 0.58881376800027152, 0.58881376811017561, 0.58881376726757773, 0.58881376800027152, 0.58881376774382865, 0.58881376811017561, 0.58881376737748181, 0.58881376774382865, 0.58881376785373274, 0.58881376737748181, 0.58881376783541539, 0.58881376763392457, 0.58881376811017561, 0.58881376789036743, 0.58881376811017561, 0.58881376811017561, 0.58881376811017561, 0.58881376800027152, 0.58881376811017561, 0.58881376774382865, 0.58881376763392457]}
[2017-11-18 18:23:25,756 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 18:23:25,850 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 18:23:25,851 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 18:23:26,436 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:141]: done!
[2017-11-18 18:23:26,436 AE_UNIGRAMA_10L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_10L_FULLDS_OVER_05 finished!
