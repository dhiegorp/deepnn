[2017-10-21 21:42:41,174 AE_UNIGRAMA_10L_UNDER_02.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_10L_UNDER_02
[2017-10-21 21:42:41,174 AE_UNIGRAMA_10L_UNDER_02.py:150]: >> Printing header log
[2017-10-21 21:42:41,174 AE_UNIGRAMA_10L_UNDER_02.py:39]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22,16,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fad068d27f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fad068d28d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 21:42:41,174 AE_UNIGRAMA_10L_UNDER_02.py:152]: >> Loading dataset... 
[2017-10-21 21:42:41,687 AE_UNIGRAMA_10L_UNDER_02.py:56]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 21:42:41,688 AE_UNIGRAMA_10L_UNDER_02.py:154]: >> Executing autoencoder part ... 
[2017-10-21 21:42:41,688 AE_UNIGRAMA_10L_UNDER_02.py:61]: =======================================
[2017-10-21 21:42:41,688 AE_UNIGRAMA_10L_UNDER_02.py:66]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fad068d27f0>, 'discard_decoder_function': True}
[2017-10-21 21:42:41,893 AE_UNIGRAMA_10L_UNDER_02.py:77]: training and evaluate autoencoder
[2017-10-21 21:43:34,993 AE_UNIGRAMA_10L_UNDER_02.py:89]: trained and evaluated!
[2017-10-21 21:43:34,994 AE_UNIGRAMA_10L_UNDER_02.py:92]: Training history: 
{'val_loss': [0.010168603368685148, 0.0099310812135278963, 0.009710300149444533, 0.0095048692617496142, 0.0093135071475211138, 0.0091348736681958111, 0.0089678856609977757, 0.0088116121149473033, 0.0086650102326584124, 0.0085275073684613501, 0.0083982877945700547, 0.0082767917237981988, 0.0081623815931379795, 0.0080544881723461099, 0.0079526735788218155, 0.0078563826612186478, 0.0077653323822969838, 0.0076792070652500185, 0.007597537081148545, 0.0075201320576180316, 0.0074466704858335417, 0.0073767895516021987, 0.0073103176561430038, 0.0072470430499392818, 0.0071867595852584641, 0.0071292015356894537, 0.0070743369939131147, 0.0070218806861307766, 0.0069717593304120477, 0.0069238434140622392, 0.0068779199809999268, 0.0068339320993722596, 0.0067917858752453196, 0.0067515432121419113, 0.0067129286757382986, 0.0066758952255890494, 0.0066403515609223607, 0.006606190413458197, 0.0065733412848473921, 0.0065417925006671911, 0.0065114605950267789, 0.0064822199034286479, 0.0064540712550614845, 0.006426978397588194, 0.0064008360829024289, 0.006375656317794855, 0.0063513521084278043, 0.0063279396040732093, 0.0063053273897077959, 0.0062835244358029063, 0.0062624805219139087, 0.0062421239240849774, 0.0062224403764623249, 0.0062034578135299421, 0.0061851007929660355, 0.0061673613258232413, 0.0061501993946592604, 0.006133619849968245, 0.0061175591852446693, 0.006102011968350543, 0.0060869896278948586, 0.0060724324830651946, 0.0060583390589789609, 0.0060446923183187229, 0.0060314737558087896, 0.0060186803974488189, 0.0060062961684034435, 0.0059943063700481636, 0.0059826649157641992, 0.0059714050336869013, 0.0059604868344741019, 0.0059491645659018851, 0.0059375524257749427, 0.0059263135521191428, 0.0059154390402442903, 0.0059049223483882869, 0.0058947608349186999, 0.0058845526670351566, 0.0058742707377112706, 0.0058643441183360975, 0.0058547587473236273, 0.0058454984961749234, 0.0058365494712190116, 0.0058279022293989324, 0.0058195487246415871, 0.0058114654124891002, 0.0058036499594417866, 0.0057960856501636229, 0.0057887833835522477, 0.0057817144894134597, 0.0057748756319506017, 0.0057682528759467116, 0.0057618360547521969, 0.0057556294441417025, 0.0057496120235761526, 0.0057437962239615097, 0.0057381602128808379, 0.0057327125782361708, 0.0057274331736852689, 0.0057223178411671223, 0.0057173650573288199, 0.0057125552730517091], 'loss': [0.010290166359113159, 0.010044365724034667, 0.0098149935418960863, 0.0096016643052553204, 0.0094030102939283693, 0.0092177433788904611, 0.0090447342728471273, 0.00888284688418217, 0.0087311488010112896, 0.0085888266095178363, 0.0084552401241737053, 0.0083295934849041478, 0.0082113615019085515, 0.0080999548878399382, 0.0079948248424107637, 0.0078955138916150889, 0.0078015567107468419, 0.0077126539937954928, 0.0076285066236481394, 0.0075486546431535878, 0.0074729305012558016, 0.007400994916625674, 0.0073325301903473432, 0.0072673632544090431, 0.0072052858165421218, 0.0071460997849501348, 0.0070895722153646382, 0.0070356415311640472, 0.0069840517090822406, 0.0069347333017629057, 0.006887539526586179, 0.0068422974683756506, 0.0067989365483926683, 0.0067574415958675969, 0.0067177542998182425, 0.0066796321371488943, 0.0066430600415560356, 0.0066079233641969182, 0.0065741373215170637, 0.0065416457456637907, 0.0065104272033384997, 0.0064803757930899149, 0.0064514037585154992, 0.0064234940109622208, 0.0063966243426511827, 0.0063706818434564926, 0.0063456722192315141, 0.0063215335052558891, 0.0062982681208503671, 0.0062757800075614201, 0.006254091472768516, 0.006233147787961699, 0.0062128837001707449, 0.0061932704992450375, 0.0061743525569524661, 0.0061560549046878587, 0.0061383601195066162, 0.0061212345604574709, 0.0061046785306352628, 0.0060886347164945433, 0.0060731070957615397, 0.0060580954723834035, 0.0060435391418159597, 0.0060294332130415426, 0.0060157724701958015, 0.0060025388792789118, 0.0059897187194536822, 0.0059773046363055813, 0.005965282771617321, 0.0059536056568446558, 0.0059423050187761683, 0.0059311556902879505, 0.0059193272038277631, 0.0059077221025571405, 0.0058964834672747468, 0.0058856086053306802, 0.0058750775327863656, 0.0058648213689783887, 0.0058543192501481541, 0.0058440541228612615, 0.0058341398225558007, 0.0058245609769713279, 0.0058153049542941267, 0.0058063482776966541, 0.0057976866743716824, 0.0057893163426112346, 0.0057812115076194348, 0.00577336862871049, 0.0057657802392761257, 0.0057584422471066996, 0.0057513302583625222, 0.0057444556967710782, 0.0057377805970563397, 0.0057313202023986992, 0.0057250627527756417, 0.0057189986498977193, 0.0057131189935381013, 0.0057074295055778322, 0.005701924785261844, 0.0056965872708343987, 0.0056913987949224944, 0.005686391878257189]}
[2017-10-21 21:43:34,994 AE_UNIGRAMA_10L_UNDER_02.py:96]: done!
[2017-10-21 21:43:34,994 AE_UNIGRAMA_10L_UNDER_02.py:156]: >> Executing classifier part ... 
[2017-10-21 21:43:34,994 AE_UNIGRAMA_10L_UNDER_02.py:101]: =======================================
[2017-10-21 21:43:34,994 AE_UNIGRAMA_10L_UNDER_02.py:105]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fad068d28d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-21 21:43:35,037 AE_UNIGRAMA_10L_UNDER_02.py:114]: training ... 
[2017-10-21 21:45:04,897 AE_UNIGRAMA_10L_UNDER_02.py:126]: trained!
[2017-10-21 21:45:04,898 AE_UNIGRAMA_10L_UNDER_02.py:129]: Training history: 
{'val_loss': [0.010168603368685148, 0.0099310812135278963, 0.009710300149444533, 0.0095048692617496142, 0.0093135071475211138, 0.0091348736681958111, 0.0089678856609977757, 0.0088116121149473033, 0.0086650102326584124, 0.0085275073684613501, 0.0083982877945700547, 0.0082767917237981988, 0.0081623815931379795, 0.0080544881723461099, 0.0079526735788218155, 0.0078563826612186478, 0.0077653323822969838, 0.0076792070652500185, 0.007597537081148545, 0.0075201320576180316, 0.0074466704858335417, 0.0073767895516021987, 0.0073103176561430038, 0.0072470430499392818, 0.0071867595852584641, 0.0071292015356894537, 0.0070743369939131147, 0.0070218806861307766, 0.0069717593304120477, 0.0069238434140622392, 0.0068779199809999268, 0.0068339320993722596, 0.0067917858752453196, 0.0067515432121419113, 0.0067129286757382986, 0.0066758952255890494, 0.0066403515609223607, 0.006606190413458197, 0.0065733412848473921, 0.0065417925006671911, 0.0065114605950267789, 0.0064822199034286479, 0.0064540712550614845, 0.006426978397588194, 0.0064008360829024289, 0.006375656317794855, 0.0063513521084278043, 0.0063279396040732093, 0.0063053273897077959, 0.0062835244358029063, 0.0062624805219139087, 0.0062421239240849774, 0.0062224403764623249, 0.0062034578135299421, 0.0061851007929660355, 0.0061673613258232413, 0.0061501993946592604, 0.006133619849968245, 0.0061175591852446693, 0.006102011968350543, 0.0060869896278948586, 0.0060724324830651946, 0.0060583390589789609, 0.0060446923183187229, 0.0060314737558087896, 0.0060186803974488189, 0.0060062961684034435, 0.0059943063700481636, 0.0059826649157641992, 0.0059714050336869013, 0.0059604868344741019, 0.0059491645659018851, 0.0059375524257749427, 0.0059263135521191428, 0.0059154390402442903, 0.0059049223483882869, 0.0058947608349186999, 0.0058845526670351566, 0.0058742707377112706, 0.0058643441183360975, 0.0058547587473236273, 0.0058454984961749234, 0.0058365494712190116, 0.0058279022293989324, 0.0058195487246415871, 0.0058114654124891002, 0.0058036499594417866, 0.0057960856501636229, 0.0057887833835522477, 0.0057817144894134597, 0.0057748756319506017, 0.0057682528759467116, 0.0057618360547521969, 0.0057556294441417025, 0.0057496120235761526, 0.0057437962239615097, 0.0057381602128808379, 0.0057327125782361708, 0.0057274331736852689, 0.0057223178411671223, 0.0057173650573288199, 0.0057125552730517091], 'loss': [0.010290166359113159, 0.010044365724034667, 0.0098149935418960863, 0.0096016643052553204, 0.0094030102939283693, 0.0092177433788904611, 0.0090447342728471273, 0.00888284688418217, 0.0087311488010112896, 0.0085888266095178363, 0.0084552401241737053, 0.0083295934849041478, 0.0082113615019085515, 0.0080999548878399382, 0.0079948248424107637, 0.0078955138916150889, 0.0078015567107468419, 0.0077126539937954928, 0.0076285066236481394, 0.0075486546431535878, 0.0074729305012558016, 0.007400994916625674, 0.0073325301903473432, 0.0072673632544090431, 0.0072052858165421218, 0.0071460997849501348, 0.0070895722153646382, 0.0070356415311640472, 0.0069840517090822406, 0.0069347333017629057, 0.006887539526586179, 0.0068422974683756506, 0.0067989365483926683, 0.0067574415958675969, 0.0067177542998182425, 0.0066796321371488943, 0.0066430600415560356, 0.0066079233641969182, 0.0065741373215170637, 0.0065416457456637907, 0.0065104272033384997, 0.0064803757930899149, 0.0064514037585154992, 0.0064234940109622208, 0.0063966243426511827, 0.0063706818434564926, 0.0063456722192315141, 0.0063215335052558891, 0.0062982681208503671, 0.0062757800075614201, 0.006254091472768516, 0.006233147787961699, 0.0062128837001707449, 0.0061932704992450375, 0.0061743525569524661, 0.0061560549046878587, 0.0061383601195066162, 0.0061212345604574709, 0.0061046785306352628, 0.0060886347164945433, 0.0060731070957615397, 0.0060580954723834035, 0.0060435391418159597, 0.0060294332130415426, 0.0060157724701958015, 0.0060025388792789118, 0.0059897187194536822, 0.0059773046363055813, 0.005965282771617321, 0.0059536056568446558, 0.0059423050187761683, 0.0059311556902879505, 0.0059193272038277631, 0.0059077221025571405, 0.0058964834672747468, 0.0058856086053306802, 0.0058750775327863656, 0.0058648213689783887, 0.0058543192501481541, 0.0058440541228612615, 0.0058341398225558007, 0.0058245609769713279, 0.0058153049542941267, 0.0058063482776966541, 0.0057976866743716824, 0.0057893163426112346, 0.0057812115076194348, 0.00577336862871049, 0.0057657802392761257, 0.0057584422471066996, 0.0057513302583625222, 0.0057444556967710782, 0.0057377805970563397, 0.0057313202023986992, 0.0057250627527756417, 0.0057189986498977193, 0.0057131189935381013, 0.0057074295055778322, 0.005701924785261844, 0.0056965872708343987, 0.0056913987949224944, 0.005686391878257189]}
[2017-10-21 21:45:04,899 AE_UNIGRAMA_10L_UNDER_02.py:133]: evaluating model ... 
[2017-10-21 21:45:05,001 AE_UNIGRAMA_10L_UNDER_02.py:137]: evaluated! 
[2017-10-21 21:45:05,001 AE_UNIGRAMA_10L_UNDER_02.py:139]: generating reports ... 
[2017-10-21 21:45:05,587 AE_UNIGRAMA_10L_UNDER_02.py:142]: done!
[2017-10-21 21:45:05,587 AE_UNIGRAMA_10L_UNDER_02.py:158]: >> experiment AE_UNIGRAMA_10L_UNDER_02 finished!
