[2018-07-21 00:52:16,522 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_03
[2018-07-21 00:52:16,522 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:146]: >> Printing header log
[2018-07-21 00:52:16,523 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_03
	layers = 96,19,18,17,16,15,14,13,12,11,10
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5ebf65c668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5ebf65ce48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,523 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,456 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,457 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,457 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:57]: =======================================
[2018-07-21 00:52:18,457 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5ebf65c668>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,836 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:73]: training and evaluate autoencoder
[2018-07-21 01:16:32,139 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_03
[2018-07-21 01:16:32,139 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:146]: >> Printing header log
[2018-07-21 01:16:32,139 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_03
	layers = 96,19,18,17,16,15,14,13,12,11,10
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb432bd7668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fb432bd7e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 01:16:32,139 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:148]: >> Loading dataset... 
[2018-07-21 01:16:34,067 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 01:16:34,067 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:150]: >> Executing autoencoder part ... 
[2018-07-21 01:16:34,067 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:57]: =======================================
[2018-07-21 01:16:34,067 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb432bd7668>, 'discard_decoder_function': True}
[2018-07-21 01:16:34,437 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:73]: training and evaluate autoencoder
[2018-07-21 01:18:50,150 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_10L_FULLDS_UNDER_03
[2018-07-21 01:18:50,150 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:146]: >> Printing header log
[2018-07-21 01:18:50,151 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_FULLDS_UNDER_03
	layers = 96,19,18,17,16,15,14,13,12,11,10
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8602961668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8602961e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 01:18:50,151 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:148]: >> Loading dataset... 
[2018-07-21 01:18:52,158 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 01:18:52,158 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:150]: >> Executing autoencoder part ... 
[2018-07-21 01:18:52,158 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:57]: =======================================
[2018-07-21 01:18:52,158 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8602961668>, 'discard_decoder_function': True}
[2018-07-21 01:18:52,524 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:73]: training and evaluate autoencoder
[2018-07-21 01:20:35,805 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:85]: trained and evaluated!
[2018-07-21 01:20:35,806 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:88]: Training history: 
{'val_loss': [0.009801699560188998, 0.00929801285202529, 0.008880425579654233, 0.008529589650758878, 0.008231620176790097, 0.00797605841071131, 0.007755413776737984, 0.0075634648603787975, 0.007395735740913533, 0.007248401935515225, 0.0071186362082896444, 0.007004042322727215, 0.006902602115643951, 0.00681260577137748, 0.006732665091165667, 0.00666157441375964, 0.006598295267939688, 0.006541925751306705, 0.0064916894665054325, 0.006446857011518641, 0.006406864581423586, 0.006371169422405064, 0.006339285710264505, 0.006310809906626867, 0.006285412196317761, 0.006262680508630355, 0.006242385666676411, 0.006224242367434977, 0.006207989884567136, 0.006193467869550997, 0.006180472918421589, 0.0061688394946666026, 0.006158442358417558, 0.00614914859863096, 0.006140844173471346, 0.006133417939036148, 0.006126770276240169, 0.006120824078008949, 0.006115492843009342, 0.006110722178888316, 0.006106447079775116, 0.006102623793788361, 0.006099183696983755, 0.006096103470187219, 0.006093358606711381, 0.006090890318401725, 0.006088683906037638, 0.006086702061867021, 0.0060849194335335375, 0.00608333000945436, 0.006081900801780013, 0.006080619240137216, 0.0060794690089250305, 0.0060784332345533145, 0.00607749887431319, 0.006076662571284782, 0.006075912621984644, 0.006075232530947814, 0.0060746188463594595, 0.006074063644618842, 0.006073565412968539, 0.006073122675702091, 0.006072726582174588, 0.006072367937928726, 0.006072042929111285, 0.006071750915331033, 0.006071487818158361, 0.0060712507549770525, 0.006071035971061403, 0.006070842042644753, 0.006070663748279581, 0.0060705036551782976, 0.006070358326586045, 0.006070226614265259, 0.006070106841424581, 0.00606999982677904, 0.006069901844696065, 0.006069810581586924, 0.0060697285285084696, 0.0060696538844245435, 0.00606958666225592, 0.006069521369389951, 0.006069462668600409, 0.006069408557851802, 0.006069359215211229, 0.006069314235599574, 0.006069272624545048, 0.006069233362162154, 0.0060691985197964945, 0.0060691651047057845, 0.006069136527461061, 0.006069107858487396, 0.006069079936865015, 0.006069055427439464, 0.006069031867904753, 0.0060690110693085025, 0.006068990594501724, 0.006068970553097081, 0.006068952678104138, 0.006068935821884309, 0.006068918499832056], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.010100651539499092, 0.009545053261086095, 0.009087990418307889, 0.008706863501788327, 0.008385059875288089, 0.008110620770171308, 0.00787452392303422, 0.007670053097643383, 0.0074919050635878105, 0.007335922766131182, 0.007198792168367812, 0.007077919005878051, 0.006971121187640437, 0.006876535553117518, 0.006792624408089524, 0.006718111095239655, 0.006651832338315538, 0.006592869602623429, 0.006540378032836799, 0.006493615729242062, 0.0064519178733866145, 0.006414729717840436, 0.006381577259937638, 0.006351983877317505, 0.006325580561331233, 0.006302053978518282, 0.00628101493418171, 0.006262258076209246, 0.006245495839008099, 0.0062305105869419715, 0.006217133000834165, 0.006205185589258131, 0.006194503761153946, 0.006184972059100544, 0.0061764725460176475, 0.006168887827591588, 0.006162112602069873, 0.006156060578706452, 0.006150663469448124, 0.006145829604409349, 0.006141517688230465, 0.006137663602204363, 0.006134223475916478, 0.006131138308475584, 0.006128382187977303, 0.00612593486795813, 0.006123741035721991, 0.006121787533751145, 0.006120035949704877, 0.006118468570049587, 0.00611707761692144, 0.0061158287749073946, 0.006114715111730098, 0.006113722725682545, 0.006112827655470735, 0.0061120267838447265, 0.006111314766588197, 0.0061106795597809125, 0.006110104335371619, 0.006109592833340066, 0.0061091322650051755, 0.006108718924395849, 0.006108355581245076, 0.00610803057784513, 0.0061077439027073755, 0.006107483220294555, 0.006107250060767257, 0.006107042117824642, 0.0061068598622721635, 0.006106692110636991, 0.006106544417817599, 0.00610640969669726, 0.006106288847333451, 0.006106179950095103, 0.00610608416396269, 0.006105997358399991, 0.00610592231662914, 0.0061058512009425124, 0.006105789234954326, 0.006105732391697561, 0.006105680878367766, 0.006105634956002763, 0.006105593057175337, 0.006105553367481182, 0.006105518434768285, 0.006105488177987459, 0.006105459671023087, 0.006105433219381439, 0.006105408809687684, 0.006105386575175708, 0.0061053666393626384, 0.00610534765533449, 0.006105331982719953, 0.00610531490877759, 0.00610529912722106, 0.006105285419048989, 0.0061052744227666255, 0.006105262375702734, 0.006105252935358944, 0.006105244313909135, 0.006105231250472467], 'acc': [0.5915060758634595, 0.593838222687912, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226732797, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226001182, 0.5938382226476732, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382226659635, 0.5938382226513312, 0.5938382227025443, 0.5938382226001182, 0.5938382227244927, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382226366989, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382227025443, 0.5938382226366989, 0.5938382226001182, 0.5938382226366989, 0.5938382226513312, 0.5938382227244927, 0.5938382227098604, 0.5938382226659635, 0.5938382226001182, 0.5938382226659635, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382226659635, 0.5938382226001182, 0.593838222687912, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.593838222687912, 0.5938382226366989, 0.5938382227244927, 0.5938382226842539, 0.5938382226659635, 0.5938382226513312, 0.5938382226366989, 0.593838222687912, 0.5938382227025443, 0.5938382226001182, 0.5938382226842539, 0.5938382226476732, 0.5938382226366989, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226513312, 0.5938382226659635, 0.5938382227244927, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382227244927, 0.5938382227025443, 0.5938382226366989, 0.5938382227025443, 0.593838222687912, 0.5938382226732797, 0.593838222687912, 0.5938382226001182, 0.5938382227025443, 0.593838222687912, 0.593838222687912, 0.5938382226659635, 0.5938382227025443, 0.5938382226001182]}
[2018-07-21 01:20:35,806 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:92]: done!
[2018-07-21 01:20:35,807 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:152]: >> Executing classifier part ... 
[2018-07-21 01:20:35,807 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:97]: =======================================
[2018-07-21 01:20:35,807 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8602961e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 01:20:35,850 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:110]: training ... 
[2018-07-21 01:25:11,000 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:122]: trained!
[2018-07-21 01:25:11,001 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:125]: Training history: 
{'val_loss': [0.009801699560188998, 0.00929801285202529, 0.008880425579654233, 0.008529589650758878, 0.008231620176790097, 0.00797605841071131, 0.007755413776737984, 0.0075634648603787975, 0.007395735740913533, 0.007248401935515225, 0.0071186362082896444, 0.007004042322727215, 0.006902602115643951, 0.00681260577137748, 0.006732665091165667, 0.00666157441375964, 0.006598295267939688, 0.006541925751306705, 0.0064916894665054325, 0.006446857011518641, 0.006406864581423586, 0.006371169422405064, 0.006339285710264505, 0.006310809906626867, 0.006285412196317761, 0.006262680508630355, 0.006242385666676411, 0.006224242367434977, 0.006207989884567136, 0.006193467869550997, 0.006180472918421589, 0.0061688394946666026, 0.006158442358417558, 0.00614914859863096, 0.006140844173471346, 0.006133417939036148, 0.006126770276240169, 0.006120824078008949, 0.006115492843009342, 0.006110722178888316, 0.006106447079775116, 0.006102623793788361, 0.006099183696983755, 0.006096103470187219, 0.006093358606711381, 0.006090890318401725, 0.006088683906037638, 0.006086702061867021, 0.0060849194335335375, 0.00608333000945436, 0.006081900801780013, 0.006080619240137216, 0.0060794690089250305, 0.0060784332345533145, 0.00607749887431319, 0.006076662571284782, 0.006075912621984644, 0.006075232530947814, 0.0060746188463594595, 0.006074063644618842, 0.006073565412968539, 0.006073122675702091, 0.006072726582174588, 0.006072367937928726, 0.006072042929111285, 0.006071750915331033, 0.006071487818158361, 0.0060712507549770525, 0.006071035971061403, 0.006070842042644753, 0.006070663748279581, 0.0060705036551782976, 0.006070358326586045, 0.006070226614265259, 0.006070106841424581, 0.00606999982677904, 0.006069901844696065, 0.006069810581586924, 0.0060697285285084696, 0.0060696538844245435, 0.00606958666225592, 0.006069521369389951, 0.006069462668600409, 0.006069408557851802, 0.006069359215211229, 0.006069314235599574, 0.006069272624545048, 0.006069233362162154, 0.0060691985197964945, 0.0060691651047057845, 0.006069136527461061, 0.006069107858487396, 0.006069079936865015, 0.006069055427439464, 0.006069031867904753, 0.0060690110693085025, 0.006068990594501724, 0.006068970553097081, 0.006068952678104138, 0.006068935821884309, 0.006068918499832056], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.010100651539499092, 0.009545053261086095, 0.009087990418307889, 0.008706863501788327, 0.008385059875288089, 0.008110620770171308, 0.00787452392303422, 0.007670053097643383, 0.0074919050635878105, 0.007335922766131182, 0.007198792168367812, 0.007077919005878051, 0.006971121187640437, 0.006876535553117518, 0.006792624408089524, 0.006718111095239655, 0.006651832338315538, 0.006592869602623429, 0.006540378032836799, 0.006493615729242062, 0.0064519178733866145, 0.006414729717840436, 0.006381577259937638, 0.006351983877317505, 0.006325580561331233, 0.006302053978518282, 0.00628101493418171, 0.006262258076209246, 0.006245495839008099, 0.0062305105869419715, 0.006217133000834165, 0.006205185589258131, 0.006194503761153946, 0.006184972059100544, 0.0061764725460176475, 0.006168887827591588, 0.006162112602069873, 0.006156060578706452, 0.006150663469448124, 0.006145829604409349, 0.006141517688230465, 0.006137663602204363, 0.006134223475916478, 0.006131138308475584, 0.006128382187977303, 0.00612593486795813, 0.006123741035721991, 0.006121787533751145, 0.006120035949704877, 0.006118468570049587, 0.00611707761692144, 0.0061158287749073946, 0.006114715111730098, 0.006113722725682545, 0.006112827655470735, 0.0061120267838447265, 0.006111314766588197, 0.0061106795597809125, 0.006110104335371619, 0.006109592833340066, 0.0061091322650051755, 0.006108718924395849, 0.006108355581245076, 0.00610803057784513, 0.0061077439027073755, 0.006107483220294555, 0.006107250060767257, 0.006107042117824642, 0.0061068598622721635, 0.006106692110636991, 0.006106544417817599, 0.00610640969669726, 0.006106288847333451, 0.006106179950095103, 0.00610608416396269, 0.006105997358399991, 0.00610592231662914, 0.0061058512009425124, 0.006105789234954326, 0.006105732391697561, 0.006105680878367766, 0.006105634956002763, 0.006105593057175337, 0.006105553367481182, 0.006105518434768285, 0.006105488177987459, 0.006105459671023087, 0.006105433219381439, 0.006105408809687684, 0.006105386575175708, 0.0061053666393626384, 0.00610534765533449, 0.006105331982719953, 0.00610531490877759, 0.00610529912722106, 0.006105285419048989, 0.0061052744227666255, 0.006105262375702734, 0.006105252935358944, 0.006105244313909135, 0.006105231250472467], 'acc': [0.5915060758634595, 0.593838222687912, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226732797, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226001182, 0.5938382226476732, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382226659635, 0.5938382226513312, 0.5938382227025443, 0.5938382226001182, 0.5938382227244927, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382226366989, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382227025443, 0.5938382226366989, 0.5938382226001182, 0.5938382226366989, 0.5938382226513312, 0.5938382227244927, 0.5938382227098604, 0.5938382226659635, 0.5938382226001182, 0.5938382226659635, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382226659635, 0.5938382226001182, 0.593838222687912, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.593838222687912, 0.5938382226366989, 0.5938382227244927, 0.5938382226842539, 0.5938382226659635, 0.5938382226513312, 0.5938382226366989, 0.593838222687912, 0.5938382227025443, 0.5938382226001182, 0.5938382226842539, 0.5938382226476732, 0.5938382226366989, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226513312, 0.5938382226659635, 0.5938382227244927, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382227244927, 0.5938382227025443, 0.5938382226366989, 0.5938382227025443, 0.593838222687912, 0.5938382226732797, 0.593838222687912, 0.5938382226001182, 0.5938382227025443, 0.593838222687912, 0.593838222687912, 0.5938382226659635, 0.5938382227025443, 0.5938382226001182]}
[2018-07-21 01:25:11,001 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:129]: evaluating model ... 
[2018-07-21 01:25:11,120 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:133]: evaluated! 
[2018-07-21 01:25:11,120 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:135]: generating reports ... 
[2018-07-21 01:25:12,133 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:138]: done!
[2018-07-21 01:25:12,133 AE_UNIGRAMA_10L_FULLDS_UNDER_03.py:154]: >> experiment AE_UNIGRAMA_10L_FULLDS_UNDER_03 finished!
