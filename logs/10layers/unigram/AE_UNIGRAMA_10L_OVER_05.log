[2017-10-20 01:40:34,792 AE_UNIGRAMA_10L_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_OVER_05
[2017-10-20 01:40:34,792 AE_UNIGRAMA_10L_OVER_05.py:149]: >> Printing header log
[2017-10-20 01:40:34,792 AE_UNIGRAMA_10L_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42,25,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6a955027b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6a95502898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:40:34,792 AE_UNIGRAMA_10L_OVER_05.py:151]: >> Loading dataset... 
[2017-10-20 01:40:35,415 AE_UNIGRAMA_10L_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:40:35,416 AE_UNIGRAMA_10L_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:40:35,416 AE_UNIGRAMA_10L_OVER_05.py:60]: =======================================
[2017-10-20 01:40:35,416 AE_UNIGRAMA_10L_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6a955027b8>, 'discard_decoder_function': True}
[2017-10-20 01:40:35,646 AE_UNIGRAMA_10L_OVER_05.py:76]: training and evaluate autoencoder
[2017-10-21 21:26:07,991 AE_UNIGRAMA_10L_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_10L_OVER_05
[2017-10-21 21:26:07,991 AE_UNIGRAMA_10L_OVER_05.py:149]: >> Printing header log
[2017-10-21 21:26:07,991 AE_UNIGRAMA_10L_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_10L_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42,25,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/10layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/10layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/10layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/10layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/10layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa418946780>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa418946860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 21:26:07,991 AE_UNIGRAMA_10L_OVER_05.py:151]: >> Loading dataset... 
[2017-10-21 21:26:08,520 AE_UNIGRAMA_10L_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 21:26:08,520 AE_UNIGRAMA_10L_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-10-21 21:26:08,520 AE_UNIGRAMA_10L_OVER_05.py:60]: =======================================
[2017-10-21 21:26:08,520 AE_UNIGRAMA_10L_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa418946780>, 'discard_decoder_function': True}
[2017-10-21 21:26:08,728 AE_UNIGRAMA_10L_OVER_05.py:76]: training and evaluate autoencoder
[2017-10-21 21:27:29,447 AE_UNIGRAMA_10L_OVER_05.py:88]: trained and evaluated!
[2017-10-21 21:27:29,447 AE_UNIGRAMA_10L_OVER_05.py:91]: Training history: 
{'val_loss': [0.010137767620994035, 0.0098679430305016087, 0.0096171716588192707, 0.0093838613563421488, 0.0091666000822496676, 0.0089639086227822472, 0.0087747626546701082, 0.0085982195063594551, 0.0084329845944634153, 0.0082785508432685218, 0.008133914570936927, 0.0079983363713944482, 0.0078712051464279349, 0.007751921448011824, 0.0076398914039384255, 0.0075346432716263713, 0.0074356573332641203, 0.0073424849042938991, 0.0072548691716502146, 0.0071723037139689166, 0.0070944816898900779, 0.007021106376233043, 0.0069518853030877265, 0.0068865293415339467, 0.0068247854332249185, 0.0067664590996575841, 0.0067112763658110537, 0.0066590838525513512, 0.0066097522514515653, 0.006562947435823847, 0.0065186431572589066, 0.0064766584570107632, 0.0064368512945381243, 0.0063990592198328675, 0.0063632128545564343, 0.0063291345948014114, 0.0062967993433286048, 0.0062659305215685118, 0.006236592108612278, 0.0062086724426915875, 0.0061821067241820257, 0.0061568154877252521, 0.0061327187971083868, 0.0061097921817442301, 0.0060879269642513034, 0.0060671099589715213, 0.006047240595184405, 0.0060283077714556208, 0.006010214791228115, 0.0059929626377569481, 0.0059764856458762762, 0.005960738670676393, 0.0059456715142167408, 0.0059312748096080076, 0.005917569515070286, 0.0059043714364637448, 0.0058917756656316359, 0.005879711674796383, 0.0058681412953121735, 0.0058570706396325594, 0.0058462030140052938, 0.0058351936975154731, 0.0058246360188107726, 0.0058145332461756183, 0.0058048672551725437, 0.0057955918120407264, 0.0057866863151631387, 0.0057781634654946708, 0.0057699711470549659, 0.0057621360237132, 0.0057545898025197608, 0.0057473880893180364, 0.0057404381655793649, 0.0057337688780684012, 0.0057273544388438914, 0.005721201569700551, 0.0057152804146524258, 0.0057096005396633561, 0.0057041552090899648, 0.0056989041769870147, 0.0056938663917874095, 0.0056890095705270328, 0.0056843446951955002, 0.0056798555247734913, 0.0056755364367039006, 0.0056713706966087943, 0.0056673697348282462, 0.0056635097230067931, 0.00565971259623212, 0.0056553476933237567, 0.0056511685633027862, 0.0056471584562115288, 0.0056433048338168836, 0.0056396092177406782, 0.0056360528828596984, 0.0056326445244031104, 0.0056293639596759386, 0.0056262049169650084, 0.0056231577108617611, 0.0056202332333395028, 0.0056174279426027185, 0.0056147112833079792], 'loss': [0.010276446133833687, 0.0099974436016859788, 0.0097368072916438186, 0.0094943454531470767, 0.0092686618894073005, 0.0090582992849481125, 0.0088619644236742311, 0.0086786670572529118, 0.0085074053533471423, 0.0083470716454276447, 0.0081971023419497562, 0.0080565273425168022, 0.0079247080592167261, 0.0078010169079970309, 0.0076849068541906332, 0.0075757554443192463, 0.0074731471991829335, 0.0073765931984715359, 0.0072856548539355402, 0.0072000865187992801, 0.0071193920062040906, 0.0070432761707529198, 0.0069714655316038118, 0.0069036674900432634, 0.0068396208444341201, 0.0067790614861191305, 0.0067218145059070198, 0.0066676004715355433, 0.0066163064350992827, 0.0065677583795189674, 0.0065216880252203582, 0.0064780222101465607, 0.0064366288473411762, 0.0063973259267791618, 0.0063600014479053522, 0.006324557268668078, 0.0062908253194014392, 0.0062587561678844284, 0.0062281510525926276, 0.0061990531174593091, 0.0061713317039948741, 0.0061449474671119442, 0.0061197835687586844, 0.0060957988693201987, 0.0060729559790858225, 0.0060511547087542319, 0.0060303687629162279, 0.0060105178738156014, 0.0059915815586522999, 0.005973489640524454, 0.0059562015837171765, 0.0059396708470018785, 0.0059238593981297341, 0.0059087130572525503, 0.0058942371704595615, 0.0058804163403039745, 0.0058671332367414815, 0.0058543990284877648, 0.005842214906456541, 0.0058305133466128563, 0.0058192584747202422, 0.0058078406459910045, 0.0057966708859340608, 0.0057859443269495997, 0.0057756669817065343, 0.005765817469568636, 0.0057563576566830466, 0.0057472774971301707, 0.005738574137983325, 0.0057302132897427017, 0.0057221893392865033, 0.0057144569494654487, 0.005707086161232354, 0.0056999559679080649, 0.005693095372434529, 0.0056865088740099259, 0.0056801736603829308, 0.0056740738821834712, 0.0056682188952823648, 0.0056625963912815425, 0.0056571720858329486, 0.0056519600778552528, 0.0056469305097878201, 0.0056421035192632096, 0.0056374360639521804, 0.0056329532403363797, 0.0056286247246214675, 0.005624446519046619, 0.0056204248795580043, 0.0056160855079533389, 0.005611627777957099, 0.0056073438277732543, 0.0056032133331612791, 0.0055992619143644395, 0.0055954537034428554, 0.0055918025405826783, 0.0055882874263774489, 0.0055848942264186399, 0.0055816312218640177, 0.0055784888204345141, 0.0055754575826864189, 0.0055725451320702852]}
[2017-10-21 21:27:29,448 AE_UNIGRAMA_10L_OVER_05.py:95]: done!
[2017-10-21 21:27:29,448 AE_UNIGRAMA_10L_OVER_05.py:155]: >> Executing classifier part ... 
[2017-10-21 21:27:29,448 AE_UNIGRAMA_10L_OVER_05.py:100]: =======================================
[2017-10-21 21:27:29,448 AE_UNIGRAMA_10L_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa418946860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-21 21:27:29,479 AE_UNIGRAMA_10L_OVER_05.py:113]: training ... 
[2017-10-21 21:29:28,868 AE_UNIGRAMA_10L_OVER_05.py:125]: trained!
[2017-10-21 21:29:28,869 AE_UNIGRAMA_10L_OVER_05.py:128]: Training history: 
{'val_loss': [0.010137767620994035, 0.0098679430305016087, 0.0096171716588192707, 0.0093838613563421488, 0.0091666000822496676, 0.0089639086227822472, 0.0087747626546701082, 0.0085982195063594551, 0.0084329845944634153, 0.0082785508432685218, 0.008133914570936927, 0.0079983363713944482, 0.0078712051464279349, 0.007751921448011824, 0.0076398914039384255, 0.0075346432716263713, 0.0074356573332641203, 0.0073424849042938991, 0.0072548691716502146, 0.0071723037139689166, 0.0070944816898900779, 0.007021106376233043, 0.0069518853030877265, 0.0068865293415339467, 0.0068247854332249185, 0.0067664590996575841, 0.0067112763658110537, 0.0066590838525513512, 0.0066097522514515653, 0.006562947435823847, 0.0065186431572589066, 0.0064766584570107632, 0.0064368512945381243, 0.0063990592198328675, 0.0063632128545564343, 0.0063291345948014114, 0.0062967993433286048, 0.0062659305215685118, 0.006236592108612278, 0.0062086724426915875, 0.0061821067241820257, 0.0061568154877252521, 0.0061327187971083868, 0.0061097921817442301, 0.0060879269642513034, 0.0060671099589715213, 0.006047240595184405, 0.0060283077714556208, 0.006010214791228115, 0.0059929626377569481, 0.0059764856458762762, 0.005960738670676393, 0.0059456715142167408, 0.0059312748096080076, 0.005917569515070286, 0.0059043714364637448, 0.0058917756656316359, 0.005879711674796383, 0.0058681412953121735, 0.0058570706396325594, 0.0058462030140052938, 0.0058351936975154731, 0.0058246360188107726, 0.0058145332461756183, 0.0058048672551725437, 0.0057955918120407264, 0.0057866863151631387, 0.0057781634654946708, 0.0057699711470549659, 0.0057621360237132, 0.0057545898025197608, 0.0057473880893180364, 0.0057404381655793649, 0.0057337688780684012, 0.0057273544388438914, 0.005721201569700551, 0.0057152804146524258, 0.0057096005396633561, 0.0057041552090899648, 0.0056989041769870147, 0.0056938663917874095, 0.0056890095705270328, 0.0056843446951955002, 0.0056798555247734913, 0.0056755364367039006, 0.0056713706966087943, 0.0056673697348282462, 0.0056635097230067931, 0.00565971259623212, 0.0056553476933237567, 0.0056511685633027862, 0.0056471584562115288, 0.0056433048338168836, 0.0056396092177406782, 0.0056360528828596984, 0.0056326445244031104, 0.0056293639596759386, 0.0056262049169650084, 0.0056231577108617611, 0.0056202332333395028, 0.0056174279426027185, 0.0056147112833079792], 'loss': [0.010276446133833687, 0.0099974436016859788, 0.0097368072916438186, 0.0094943454531470767, 0.0092686618894073005, 0.0090582992849481125, 0.0088619644236742311, 0.0086786670572529118, 0.0085074053533471423, 0.0083470716454276447, 0.0081971023419497562, 0.0080565273425168022, 0.0079247080592167261, 0.0078010169079970309, 0.0076849068541906332, 0.0075757554443192463, 0.0074731471991829335, 0.0073765931984715359, 0.0072856548539355402, 0.0072000865187992801, 0.0071193920062040906, 0.0070432761707529198, 0.0069714655316038118, 0.0069036674900432634, 0.0068396208444341201, 0.0067790614861191305, 0.0067218145059070198, 0.0066676004715355433, 0.0066163064350992827, 0.0065677583795189674, 0.0065216880252203582, 0.0064780222101465607, 0.0064366288473411762, 0.0063973259267791618, 0.0063600014479053522, 0.006324557268668078, 0.0062908253194014392, 0.0062587561678844284, 0.0062281510525926276, 0.0061990531174593091, 0.0061713317039948741, 0.0061449474671119442, 0.0061197835687586844, 0.0060957988693201987, 0.0060729559790858225, 0.0060511547087542319, 0.0060303687629162279, 0.0060105178738156014, 0.0059915815586522999, 0.005973489640524454, 0.0059562015837171765, 0.0059396708470018785, 0.0059238593981297341, 0.0059087130572525503, 0.0058942371704595615, 0.0058804163403039745, 0.0058671332367414815, 0.0058543990284877648, 0.005842214906456541, 0.0058305133466128563, 0.0058192584747202422, 0.0058078406459910045, 0.0057966708859340608, 0.0057859443269495997, 0.0057756669817065343, 0.005765817469568636, 0.0057563576566830466, 0.0057472774971301707, 0.005738574137983325, 0.0057302132897427017, 0.0057221893392865033, 0.0057144569494654487, 0.005707086161232354, 0.0056999559679080649, 0.005693095372434529, 0.0056865088740099259, 0.0056801736603829308, 0.0056740738821834712, 0.0056682188952823648, 0.0056625963912815425, 0.0056571720858329486, 0.0056519600778552528, 0.0056469305097878201, 0.0056421035192632096, 0.0056374360639521804, 0.0056329532403363797, 0.0056286247246214675, 0.005624446519046619, 0.0056204248795580043, 0.0056160855079533389, 0.005611627777957099, 0.0056073438277732543, 0.0056032133331612791, 0.0055992619143644395, 0.0055954537034428554, 0.0055918025405826783, 0.0055882874263774489, 0.0055848942264186399, 0.0055816312218640177, 0.0055784888204345141, 0.0055754575826864189, 0.0055725451320702852]}
[2017-10-21 21:29:28,869 AE_UNIGRAMA_10L_OVER_05.py:132]: evaluating model ... 
[2017-10-21 21:29:28,973 AE_UNIGRAMA_10L_OVER_05.py:136]: evaluated! 
[2017-10-21 21:29:28,973 AE_UNIGRAMA_10L_OVER_05.py:138]: generating reports ... 
[2017-10-21 21:29:29,566 AE_UNIGRAMA_10L_OVER_05.py:141]: done!
[2017-10-21 21:29:29,566 AE_UNIGRAMA_10L_OVER_05.py:157]: >> experiment AE_UNIGRAMA_10L_OVER_05 finished!
