[2017-10-15 11:11:38,023 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_3L_UNDER_96_86_76_66_9
[2017-10-15 11:11:38,023 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:150]: >> Printing header log
[2017-10-15 11:11:38,023 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:40]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_UNDER_96_86_76_66_9
	layers = 96,86,76,66,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0db9c377f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0da5afaa20>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 11:11:38,023 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:152]: >> Loading dataset... 
[2017-10-15 11:11:38,548 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:57]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 11:11:38,548 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:154]: >> Executing autoencoder part ... 
[2017-10-15 11:11:38,548 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:62]: =======================================
[2017-10-15 11:11:38,548 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:67]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0db9c377f0>, 'discard_decoder_function': True}
[2017-10-15 11:11:38,631 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:78]: training and evaluate autoencoder
[2017-10-15 11:12:17,681 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:89]: trained and evaluated!
[2017-10-15 11:12:17,682 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:92]: Training history: 
{'val_loss': [0.010027782873814877, 0.009884400736388221, 0.0097424189376620549, 0.0096033241800603814, 0.0094680104259276913, 0.0093377996478437499, 0.0092123678944257114, 0.0090917828821726002, 0.0089752851954235466, 0.0088623852147045636, 0.0087519160689973029, 0.0086439191000224486, 0.0085377776579841358, 0.0084342192823835902, 0.0083338807070399302, 0.0082371058842672738, 0.0081443368806936485, 0.0080555471640121768, 0.0079704843648470466, 0.0078889017433038874, 0.0078104061237276711, 0.0077347657141244542, 0.0076621145574327513, 0.007592309858359147, 0.0075252499815672081, 0.007460685438202992, 0.0073983897887807352, 0.0073383019935879786, 0.0072805607175544518, 0.0072249936192646125, 0.0071716933757011332, 0.0071205775578918286, 0.0070715989765181416, 0.0070246255049502765, 0.0069795474323502927, 0.0069363002256805344, 0.0068946995246172175, 0.0068547057064049302, 0.0068162973990947787, 0.0067793125179371203, 0.0067437410745838982, 0.006709505840235816, 0.0066765208337386745, 0.0066447537340445367, 0.0066141081769642554, 0.006584584370227773, 0.0065561080157590622, 0.0065286325595469725, 0.0065021260908102018, 0.0064765700073324169, 0.0064518932775909348, 0.0064280450960351185, 0.0064050290183091472, 0.0063827793428944393, 0.006361291633025643, 0.0063405248620391555, 0.0063204514278188961, 0.0063010199916407076, 0.0062822456727822254, 0.0062640780378756247, 0.0062465185929629881, 0.006229517479395999, 0.0062130697566641973, 0.0061971297916925084, 0.0061816892943251534, 0.0061667420932517616, 0.00615224574058971, 0.0061382034994301744, 0.0061246003820578186, 0.006111412059834234, 0.0060986008903627948, 0.006086179519203737, 0.0060741288992524371, 0.0060624438805374067, 0.0060511196818078096, 0.0060401318982575905, 0.0060294596495653842, 0.0060190889901277304, 0.0060090181750131139, 0.0059992468026103139, 0.0059897603023949609, 0.0059805430478821458, 0.0059715882947730756, 0.0059628797414605283, 0.0059544289567712069, 0.0059462078244574227, 0.0059382128390763995, 0.0059304432285651838, 0.0059228741934308328, 0.0059155065126606302, 0.005908359754415139, 0.0059013892775297604, 0.0058946197083891549, 0.0058880335924849187, 0.005881620408295477, 0.0058753750612439938, 0.0058693042610076058, 0.0058633964906920953, 0.0058576488299606905, 0.0058520577266313774, 0.0058466083020470398, 0.0058413186875694743], 'loss': [0.010092717998380045, 0.0099490845859847559, 0.0098053418568117383, 0.0096640692973428144, 0.0095258925376848057, 0.0093921764508191983, 0.0092635823559123597, 0.0091398121873815519, 0.0090205710267930866, 0.0089052126868258748, 0.0087929669133380069, 0.0086831304730679189, 0.0085755647964358851, 0.0084701143016268233, 0.0083675917001016387, 0.0082684622055174892, 0.0081731340348189345, 0.0080818693023621494, 0.007994479603078572, 0.0079106654389117428, 0.0078301585554737731, 0.0077526099366246369, 0.0076779127948114348, 0.0076061841017453858, 0.007537192458111722, 0.0074708781018509741, 0.0074069213280116555, 0.0073452084130632162, 0.0072858449441999583, 0.0072287548500552237, 0.0071739192085241016, 0.0071213302802415846, 0.0070708889363089731, 0.0070225436626243755, 0.0069761640399685285, 0.0069316452481860058, 0.0068889088183412463, 0.0068477756637431901, 0.006808235771100013, 0.0067702375284265032, 0.0067336359582200293, 0.0066984306483403007, 0.006664525441591844, 0.006631858375830176, 0.0066003782675242637, 0.0065700154927271267, 0.0065407479841882599, 0.0065125018119532672, 0.006485256451721857, 0.006458948761311754, 0.00643358256532762, 0.0064090809529531601, 0.0063854009267938746, 0.006362546083918637, 0.0063404393289066491, 0.0063190897245511881, 0.0062984512948855232, 0.0062784945217923436, 0.0062591859921423765, 0.0062405113774777077, 0.0062224503432543052, 0.0062049860060306586, 0.0061880708686416694, 0.0061716959166633039, 0.0061558253920597572, 0.0061404475379568087, 0.0061255593880891945, 0.0061111122558091448, 0.0060971150399124468, 0.0060835544972439523, 0.0060703998964483667, 0.0060576159245441605, 0.0060452248041930742, 0.0060332020130477839, 0.0060215344856886423, 0.0060102292574076618, 0.0059992592365634943, 0.0059885983498447612, 0.0059782376741279505, 0.0059681780334074367, 0.0059584115958728522, 0.0059489313545668318, 0.0059397149706269673, 0.005930757585949578, 0.0059220503549736632, 0.0059135906179633036, 0.0059053688003843597, 0.0058973736745621909, 0.0058895928230532748, 0.0058820156964972002, 0.0058746440648075509, 0.0058674844123249087, 0.0058605071090244232, 0.005853728401247405, 0.0058471361918176843, 0.0058407059850053289, 0.0058344481034935912, 0.0058283627519215737, 0.0058224445364032157, 0.0058166790423318333, 0.0058110746155483227, 0.0058056064832728918]}
[2017-10-15 11:12:17,682 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:96]: done!
[2017-10-15 11:12:17,682 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:156]: >> Executing classifier part ... 
[2017-10-15 11:12:17,682 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:101]: =======================================
[2017-10-15 11:12:17,682 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:105]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0da5afaa20>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 11:12:17,733 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:114]: training ... 
[2017-10-15 11:13:24,200 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:126]: trained!
[2017-10-15 11:13:24,201 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:129]: Training history: 
{'val_loss': [0.010027782873814877, 0.009884400736388221, 0.0097424189376620549, 0.0096033241800603814, 0.0094680104259276913, 0.0093377996478437499, 0.0092123678944257114, 0.0090917828821726002, 0.0089752851954235466, 0.0088623852147045636, 0.0087519160689973029, 0.0086439191000224486, 0.0085377776579841358, 0.0084342192823835902, 0.0083338807070399302, 0.0082371058842672738, 0.0081443368806936485, 0.0080555471640121768, 0.0079704843648470466, 0.0078889017433038874, 0.0078104061237276711, 0.0077347657141244542, 0.0076621145574327513, 0.007592309858359147, 0.0075252499815672081, 0.007460685438202992, 0.0073983897887807352, 0.0073383019935879786, 0.0072805607175544518, 0.0072249936192646125, 0.0071716933757011332, 0.0071205775578918286, 0.0070715989765181416, 0.0070246255049502765, 0.0069795474323502927, 0.0069363002256805344, 0.0068946995246172175, 0.0068547057064049302, 0.0068162973990947787, 0.0067793125179371203, 0.0067437410745838982, 0.006709505840235816, 0.0066765208337386745, 0.0066447537340445367, 0.0066141081769642554, 0.006584584370227773, 0.0065561080157590622, 0.0065286325595469725, 0.0065021260908102018, 0.0064765700073324169, 0.0064518932775909348, 0.0064280450960351185, 0.0064050290183091472, 0.0063827793428944393, 0.006361291633025643, 0.0063405248620391555, 0.0063204514278188961, 0.0063010199916407076, 0.0062822456727822254, 0.0062640780378756247, 0.0062465185929629881, 0.006229517479395999, 0.0062130697566641973, 0.0061971297916925084, 0.0061816892943251534, 0.0061667420932517616, 0.00615224574058971, 0.0061382034994301744, 0.0061246003820578186, 0.006111412059834234, 0.0060986008903627948, 0.006086179519203737, 0.0060741288992524371, 0.0060624438805374067, 0.0060511196818078096, 0.0060401318982575905, 0.0060294596495653842, 0.0060190889901277304, 0.0060090181750131139, 0.0059992468026103139, 0.0059897603023949609, 0.0059805430478821458, 0.0059715882947730756, 0.0059628797414605283, 0.0059544289567712069, 0.0059462078244574227, 0.0059382128390763995, 0.0059304432285651838, 0.0059228741934308328, 0.0059155065126606302, 0.005908359754415139, 0.0059013892775297604, 0.0058946197083891549, 0.0058880335924849187, 0.005881620408295477, 0.0058753750612439938, 0.0058693042610076058, 0.0058633964906920953, 0.0058576488299606905, 0.0058520577266313774, 0.0058466083020470398, 0.0058413186875694743], 'loss': [0.010092717998380045, 0.0099490845859847559, 0.0098053418568117383, 0.0096640692973428144, 0.0095258925376848057, 0.0093921764508191983, 0.0092635823559123597, 0.0091398121873815519, 0.0090205710267930866, 0.0089052126868258748, 0.0087929669133380069, 0.0086831304730679189, 0.0085755647964358851, 0.0084701143016268233, 0.0083675917001016387, 0.0082684622055174892, 0.0081731340348189345, 0.0080818693023621494, 0.007994479603078572, 0.0079106654389117428, 0.0078301585554737731, 0.0077526099366246369, 0.0076779127948114348, 0.0076061841017453858, 0.007537192458111722, 0.0074708781018509741, 0.0074069213280116555, 0.0073452084130632162, 0.0072858449441999583, 0.0072287548500552237, 0.0071739192085241016, 0.0071213302802415846, 0.0070708889363089731, 0.0070225436626243755, 0.0069761640399685285, 0.0069316452481860058, 0.0068889088183412463, 0.0068477756637431901, 0.006808235771100013, 0.0067702375284265032, 0.0067336359582200293, 0.0066984306483403007, 0.006664525441591844, 0.006631858375830176, 0.0066003782675242637, 0.0065700154927271267, 0.0065407479841882599, 0.0065125018119532672, 0.006485256451721857, 0.006458948761311754, 0.00643358256532762, 0.0064090809529531601, 0.0063854009267938746, 0.006362546083918637, 0.0063404393289066491, 0.0063190897245511881, 0.0062984512948855232, 0.0062784945217923436, 0.0062591859921423765, 0.0062405113774777077, 0.0062224503432543052, 0.0062049860060306586, 0.0061880708686416694, 0.0061716959166633039, 0.0061558253920597572, 0.0061404475379568087, 0.0061255593880891945, 0.0061111122558091448, 0.0060971150399124468, 0.0060835544972439523, 0.0060703998964483667, 0.0060576159245441605, 0.0060452248041930742, 0.0060332020130477839, 0.0060215344856886423, 0.0060102292574076618, 0.0059992592365634943, 0.0059885983498447612, 0.0059782376741279505, 0.0059681780334074367, 0.0059584115958728522, 0.0059489313545668318, 0.0059397149706269673, 0.005930757585949578, 0.0059220503549736632, 0.0059135906179633036, 0.0059053688003843597, 0.0058973736745621909, 0.0058895928230532748, 0.0058820156964972002, 0.0058746440648075509, 0.0058674844123249087, 0.0058605071090244232, 0.005853728401247405, 0.0058471361918176843, 0.0058407059850053289, 0.0058344481034935912, 0.0058283627519215737, 0.0058224445364032157, 0.0058166790423318333, 0.0058110746155483227, 0.0058056064832728918]}
[2017-10-15 11:13:24,201 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:133]: evaluating model ... 
[2017-10-15 11:13:24,259 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:137]: evaluated! 
[2017-10-15 11:13:24,259 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:139]: generating reports ... 
[2017-10-15 11:13:24,793 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:142]: done!
[2017-10-15 11:13:24,793 AE_UNIGRAMA_3L_UNDER_96_86_76_66_9.py:158]: >> experiment AE_UNIGRAMA_3L_UNDER_96_86_76_66_9 finished!
