[2017-10-15 11:13:43,163 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_OVER_96_134_124_114_9
[2017-10-15 11:13:43,164 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:149]: >> Printing header log
[2017-10-15 11:13:43,164 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_OVER_96_134_124_114_9
	layers = 96,134,124,114,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4632cc8c50>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f461eb840f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 11:13:43,164 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:151]: >> Loading dataset... 
[2017-10-15 11:13:43,681 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 11:13:43,682 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:153]: >> Executing autoencoder part ... 
[2017-10-15 11:13:43,682 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:60]: =======================================
[2017-10-15 11:13:43,682 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4632cc8c50>, 'discard_decoder_function': True}
[2017-10-15 11:13:43,763 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:76]: training and evaluate autoencoder
[2017-10-15 11:14:36,939 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:88]: trained and evaluated!
[2017-10-15 11:14:36,940 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:91]: Training history: 
{'val_loss': [0.01017201799193058, 0.010003568767310296, 0.0098314742041841763, 0.0096612628964797276, 0.0094953095436539348, 0.0093325888911144437, 0.0091750380828921237, 0.009024108576564098, 0.0088796796117905797, 0.0087409299351690426, 0.0086074665839676514, 0.0084805600137404791, 0.0083594616142458195, 0.0082441266162189414, 0.0081343224936867731, 0.0080295895922195062, 0.0079295520279487261, 0.0078341326118900427, 0.0077431128259928253, 0.0076562407146100664, 0.0075733236791946856, 0.0074941240351467106, 0.0074185488163926346, 0.0073465313797048031, 0.0072778267006919509, 0.0072123120126892639, 0.0071498897709090913, 0.0070904185026053161, 0.0070336822205704381, 0.0069795345721357814, 0.0069278304925583113, 0.0068784436145208801, 0.0068312512284844119, 0.0067861355065634704, 0.0067430433529848061, 0.0067018282385092904, 0.0066624079280460189, 0.0066246459586026497, 0.0065884885090822182, 0.0065537956595199259, 0.0065205030742215625, 0.006488182775842434, 0.0064570873466815422, 0.0064273095537378663, 0.0063987875038750992, 0.0063714689374330096, 0.0063452680342481037, 0.0063201684528982555, 0.0062960872537418371, 0.0062730267581609543, 0.0062509276315597575, 0.0062297192751862747, 0.00620938654379663, 0.00618987577555348, 0.0061711450211260621, 0.0061531700713206841, 0.006135901001707883, 0.0061193337303942904, 0.0061033983787584043, 0.006088074445586001, 0.0060733718049736712, 0.0060592429179241224, 0.0060456774654524701, 0.0060326280141574746, 0.0060200558172116489, 0.0060079571250895364, 0.0059962727382197479, 0.0059850273487680903, 0.0059741807575285659, 0.0059637473844213335, 0.0059536897238053133, 0.0059440081080484129, 0.0059347199778103698, 0.0059257676032091382, 0.0059171396681561121, 0.005908834637180802, 0.005900829052379473, 0.005893091989688049, 0.0058856382256297591, 0.0058784576333699174, 0.0058715434634164804, 0.0058648671736753781, 0.0058584166759950524, 0.0058522050054293801, 0.0058462130231263466, 0.0058404139198058157, 0.0058348255723604039, 0.0058294319596183123, 0.0058242301248900286, 0.0058192013724807472, 0.0058143516209627393, 0.0058096694071053572, 0.0058051340773590879, 0.0058007570516775088, 0.0057965311374113685, 0.0057924380681744075, 0.0057884934133258011, 0.0057846728303784772, 0.005780977283545586, 0.0057773998692687116, 0.0057739460023750163, 0.0057706085317612357], 'loss': [0.010250324689621162, 0.010085889761071118, 0.009914211248240554, 0.0097419855739525225, 0.0095732064005250792, 0.0094086139977491191, 0.0092479092925878553, 0.0090932635076403541, 0.0089451723984490163, 0.0088033900019777421, 0.0086667993184369116, 0.0085363607268640809, 0.0084120988171517887, 0.0082935967403060459, 0.0081807433941802812, 0.0080732000921867192, 0.0079705510488822916, 0.0078724975100665211, 0.0077789368934485176, 0.0076896323248304395, 0.0076043554229665257, 0.0075228775762131448, 0.0074450886615431231, 0.0073708320882562928, 0.0073000739211790131, 0.0072325115214023549, 0.0071681197512306425, 0.0071067293695464377, 0.0070482114305320184, 0.0069923312297364504, 0.0069389954852152064, 0.0068880264027949738, 0.0068393182252735798, 0.0067927470483966565, 0.0067481973277749496, 0.0067056416466342176, 0.0066648968186323347, 0.0066258786589630777, 0.0065884789876690213, 0.0065526433392658545, 0.0065182026603889378, 0.0064850240283529492, 0.0064528503675029807, 0.0064219934968867401, 0.0063924198290739569, 0.0063640846640155516, 0.0063369294357175244, 0.0063108616450156954, 0.0062858848560649553, 0.0062618902598215193, 0.0062389009017966681, 0.0062168575557133097, 0.0061956932444810027, 0.0061753676112651932, 0.0061558560306834856, 0.0061371246708835205, 0.006119123365805606, 0.00610181684797537, 0.006085195283839947, 0.0060691966597373201, 0.0060538064285462516, 0.0060390287932390882, 0.0060248270089329941, 0.0060111636132203364, 0.0059980151810773178, 0.0059853215895355038, 0.0059731049407628425, 0.005961288511409632, 0.0059499160158227541, 0.005938920651498974, 0.005928353528413732, 0.0059181589438032176, 0.0059083371661310374, 0.0058988962561743862, 0.0058897926386837296, 0.0058810002392028545, 0.0058725295203709863, 0.0058643685993821472, 0.0058564603767748726, 0.0058488496155641202, 0.0058414986733170875, 0.0058344031263946501, 0.005827569156042549, 0.0058209517946067255, 0.0058145644386501018, 0.0058084061691570698, 0.005802428352428439, 0.0057966638709628553, 0.0057911062075057572, 0.0057857240700193288, 0.0057805248810357309, 0.0057755112450526367, 0.0057706468762657032, 0.0057659316839468247, 0.0057613852593564668, 0.0057569925304669393, 0.0057527487367716717, 0.0057486333877429796, 0.0057446433611319488, 0.0057407925935770076, 0.005737055425624321, 0.0057334486039077202]}
[2017-10-15 11:14:36,940 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:95]: done!
[2017-10-15 11:14:36,940 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:155]: >> Executing classifier part ... 
[2017-10-15 11:14:36,940 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:100]: =======================================
[2017-10-15 11:14:36,940 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f461eb840f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 11:14:36,985 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:113]: training ... 
[2017-10-15 11:16:01,033 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:125]: trained!
[2017-10-15 11:16:01,034 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:128]: Training history: 
{'val_loss': [0.01017201799193058, 0.010003568767310296, 0.0098314742041841763, 0.0096612628964797276, 0.0094953095436539348, 0.0093325888911144437, 0.0091750380828921237, 0.009024108576564098, 0.0088796796117905797, 0.0087409299351690426, 0.0086074665839676514, 0.0084805600137404791, 0.0083594616142458195, 0.0082441266162189414, 0.0081343224936867731, 0.0080295895922195062, 0.0079295520279487261, 0.0078341326118900427, 0.0077431128259928253, 0.0076562407146100664, 0.0075733236791946856, 0.0074941240351467106, 0.0074185488163926346, 0.0073465313797048031, 0.0072778267006919509, 0.0072123120126892639, 0.0071498897709090913, 0.0070904185026053161, 0.0070336822205704381, 0.0069795345721357814, 0.0069278304925583113, 0.0068784436145208801, 0.0068312512284844119, 0.0067861355065634704, 0.0067430433529848061, 0.0067018282385092904, 0.0066624079280460189, 0.0066246459586026497, 0.0065884885090822182, 0.0065537956595199259, 0.0065205030742215625, 0.006488182775842434, 0.0064570873466815422, 0.0064273095537378663, 0.0063987875038750992, 0.0063714689374330096, 0.0063452680342481037, 0.0063201684528982555, 0.0062960872537418371, 0.0062730267581609543, 0.0062509276315597575, 0.0062297192751862747, 0.00620938654379663, 0.00618987577555348, 0.0061711450211260621, 0.0061531700713206841, 0.006135901001707883, 0.0061193337303942904, 0.0061033983787584043, 0.006088074445586001, 0.0060733718049736712, 0.0060592429179241224, 0.0060456774654524701, 0.0060326280141574746, 0.0060200558172116489, 0.0060079571250895364, 0.0059962727382197479, 0.0059850273487680903, 0.0059741807575285659, 0.0059637473844213335, 0.0059536897238053133, 0.0059440081080484129, 0.0059347199778103698, 0.0059257676032091382, 0.0059171396681561121, 0.005908834637180802, 0.005900829052379473, 0.005893091989688049, 0.0058856382256297591, 0.0058784576333699174, 0.0058715434634164804, 0.0058648671736753781, 0.0058584166759950524, 0.0058522050054293801, 0.0058462130231263466, 0.0058404139198058157, 0.0058348255723604039, 0.0058294319596183123, 0.0058242301248900286, 0.0058192013724807472, 0.0058143516209627393, 0.0058096694071053572, 0.0058051340773590879, 0.0058007570516775088, 0.0057965311374113685, 0.0057924380681744075, 0.0057884934133258011, 0.0057846728303784772, 0.005780977283545586, 0.0057773998692687116, 0.0057739460023750163, 0.0057706085317612357], 'loss': [0.010250324689621162, 0.010085889761071118, 0.009914211248240554, 0.0097419855739525225, 0.0095732064005250792, 0.0094086139977491191, 0.0092479092925878553, 0.0090932635076403541, 0.0089451723984490163, 0.0088033900019777421, 0.0086667993184369116, 0.0085363607268640809, 0.0084120988171517887, 0.0082935967403060459, 0.0081807433941802812, 0.0080732000921867192, 0.0079705510488822916, 0.0078724975100665211, 0.0077789368934485176, 0.0076896323248304395, 0.0076043554229665257, 0.0075228775762131448, 0.0074450886615431231, 0.0073708320882562928, 0.0073000739211790131, 0.0072325115214023549, 0.0071681197512306425, 0.0071067293695464377, 0.0070482114305320184, 0.0069923312297364504, 0.0069389954852152064, 0.0068880264027949738, 0.0068393182252735798, 0.0067927470483966565, 0.0067481973277749496, 0.0067056416466342176, 0.0066648968186323347, 0.0066258786589630777, 0.0065884789876690213, 0.0065526433392658545, 0.0065182026603889378, 0.0064850240283529492, 0.0064528503675029807, 0.0064219934968867401, 0.0063924198290739569, 0.0063640846640155516, 0.0063369294357175244, 0.0063108616450156954, 0.0062858848560649553, 0.0062618902598215193, 0.0062389009017966681, 0.0062168575557133097, 0.0061956932444810027, 0.0061753676112651932, 0.0061558560306834856, 0.0061371246708835205, 0.006119123365805606, 0.00610181684797537, 0.006085195283839947, 0.0060691966597373201, 0.0060538064285462516, 0.0060390287932390882, 0.0060248270089329941, 0.0060111636132203364, 0.0059980151810773178, 0.0059853215895355038, 0.0059731049407628425, 0.005961288511409632, 0.0059499160158227541, 0.005938920651498974, 0.005928353528413732, 0.0059181589438032176, 0.0059083371661310374, 0.0058988962561743862, 0.0058897926386837296, 0.0058810002392028545, 0.0058725295203709863, 0.0058643685993821472, 0.0058564603767748726, 0.0058488496155641202, 0.0058414986733170875, 0.0058344031263946501, 0.005827569156042549, 0.0058209517946067255, 0.0058145644386501018, 0.0058084061691570698, 0.005802428352428439, 0.0057966638709628553, 0.0057911062075057572, 0.0057857240700193288, 0.0057805248810357309, 0.0057755112450526367, 0.0057706468762657032, 0.0057659316839468247, 0.0057613852593564668, 0.0057569925304669393, 0.0057527487367716717, 0.0057486333877429796, 0.0057446433611319488, 0.0057407925935770076, 0.005737055425624321, 0.0057334486039077202]}
[2017-10-15 11:16:01,034 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:132]: evaluating model ... 
[2017-10-15 11:16:01,097 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:136]: evaluated! 
[2017-10-15 11:16:01,097 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:138]: generating reports ... 
[2017-10-15 11:16:01,665 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:141]: done!
[2017-10-15 11:16:01,665 AE_UNIGRAMA_3L_OVER_96_134_124_114_9.py:157]: >> experiment AE_UNIGRAMA_3L_OVER_96_134_124_114_9 finished!
