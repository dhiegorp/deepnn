[2017-11-18 17:38:55,336 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_9FULLDS_UNDER_02
[2017-11-18 17:38:55,336 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 17:38:55,336 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_9FULLDS_UNDER_02
	layers = 96,76,69,63,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdf7283deb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdf72842400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:38:55,336 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 17:38:57,810 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:38:57,810 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:38:57,810 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 17:38:57,811 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdf7283deb8>, 'discard_decoder_function': True}
[2017-11-18 17:38:57,914 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 17:40:36,619 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 17:40:36,620 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0094400349948301956, 0.0087383250513883119, 0.0081870673660384696, 0.007744767314637027, 0.0073752849563362075, 0.0070753776833198719, 0.0068323061858310344, 0.0066342783161876771, 0.0064699283119213028, 0.0063330447219123254, 0.0062194502661233981, 0.0061248304621507824, 0.006045599026179016, 0.0059788576269078041, 0.0059222783910460397, 0.0058741744939519863, 0.0058332616044875834, 0.005798273168104464, 0.0057681992298176249, 0.0057422641813802957, 0.0057197885217472981, 0.0057003632545860015, 0.0056834839237699863, 0.0056687572334188996, 0.0056558479101440568, 0.0056445760011004861, 0.0056346684352189128, 0.005625957482107989, 0.0056182793165306883, 0.0056114979012150869, 0.0056055032050710083, 0.0056001762512117043, 0.0055954378719986833, 0.0055911829216780196, 0.0055873560914629439, 0.0055839018495763672, 0.0055807703614470404, 0.0055779267502253831, 0.0055753237498360753, 0.005572952075461963, 0.0055707935874481458, 0.005568798567082504, 0.0055669434731418881, 0.0055651766329679261, 0.0055635386772620813, 0.005561993596425026, 0.0055605284914166248, 0.0055590798250560059, 0.0055575517721738405, 0.0055561649918731458, 0.0055548601908912525, 0.0055536045235927735, 0.0055523903579072931, 0.005551210578509806, 0.0055500677585169174, 0.005548946251983192, 0.0055478499294078958, 0.0055467700886922431, 0.0055457021239652092, 0.0055446427440231762, 0.0055435935329873143, 0.0055425444070916546, 0.0055415007569517387, 0.0055404498430262619, 0.005539401632451953, 0.0055383485799243909, 0.0055372958612833305, 0.0055362395747971692, 0.0055351741292788753, 0.0055341084372390508, 0.0055330430001064241, 0.0055319643649589219, 0.0055308686227916589, 0.0055297679918654228, 0.0055286591809765957, 0.0055275448309261045, 0.0055264194702366086, 0.0055252790008834159, 0.0055241293571814103, 0.005522966242844745, 0.0055218033628789479, 0.005520633887414003, 0.0055194571250601265, 0.0055182796311850539, 0.0055170706789036995, 0.0055158275575060449, 0.0055145638211411569, 0.0055132813050724136, 0.0055119848312301448, 0.0055106739751968597, 0.0055093466086386378, 0.0055080101541553246, 0.0055066536611766831, 0.0055052830486153467, 0.0055038838907261675, 0.005502477705390362, 0.0055010694101177643, 0.0054996553277928831, 0.005498233835874498, 0.0054968123592727932, 0.0054953762949456336], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098390349319447713, 0.0090786099247108561, 0.0084572384827597113, 0.0079651093373366167, 0.007562501743990058, 0.0072292807628357757, 0.0069599806427008189, 0.0067412640046745787, 0.0065620091118579688, 0.0064123841382108596, 0.0062884627539050407, 0.0061855081394973218, 0.0060995392670197155, 0.0060274144749490818, 0.0059664585866304725, 0.0059147665653904993, 0.0058708455858493096, 0.0058333988804326721, 0.0058013411060229862, 0.0057737464158954333, 0.0057499016479880434, 0.0057292623922427267, 0.0057113981748927335, 0.0056958618572472653, 0.0056822908993884036, 0.0056703958102622305, 0.0056600127958686781, 0.0056508929143808725, 0.0056428708890216353, 0.005635813692587149, 0.005629578770193309, 0.0056240664528344683, 0.0056191620017294764, 0.0056147915220277449, 0.0056108673141677789, 0.005607337729471076, 0.005604158452152657, 0.0056012702134817498, 0.0055986454223840602, 0.0055962427100526768, 0.005594048956750898, 0.0055920436161675307, 0.0055901932767193985, 0.0055884506667269011, 0.0055868175931638869, 0.0055852885941841185, 0.0055838412318524556, 0.0055824549304216466, 0.0055809982370311302, 0.0055795972341470624, 0.0055783048479156952, 0.00557706899646264, 0.0055758786422950516, 0.0055747160992005657, 0.0055735874387804968, 0.0055724901358211853, 0.0055714097736846661, 0.0055703533274591762, 0.0055693026527015256, 0.0055682727040722284, 0.0055672440904110205, 0.0055662274158433875, 0.0055652015194446814, 0.0055641778732182547, 0.0055631482630178865, 0.0055621194307868055, 0.005561085947944377, 0.0055600533779055277, 0.005559014057749943, 0.0055579711314772259, 0.0055569194207418125, 0.0055558619067018911, 0.0055547965087140135, 0.0055537189497475584, 0.0055526271743083291, 0.0055515335059876901, 0.0055504269089503601, 0.0055493172154112199, 0.0055481921249848102, 0.0055470558614882171, 0.0055459119275836901, 0.0055447658079804249, 0.0055436110132565577, 0.0055424499659710675, 0.0055412678580721549, 0.0055400486377631319, 0.0055388052026099097, 0.0055375434518271033, 0.0055362657244095803, 0.0055349739959455017, 0.0055336625223454195, 0.0055323418175976082, 0.0055310079542460677, 0.0055296592555786513, 0.0055282910234862176, 0.0055269117044026358, 0.0055255241173305684, 0.0055241297073804034, 0.0055227301250862001, 0.0055213270366431472, 0.0055199255983340526], 'acc': [0.44998158829276863, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822266596353, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427]}
[2017-11-18 17:40:36,621 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:95]: done!
[2017-11-18 17:40:36,621 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 17:40:36,621 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 17:40:36,621 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdf72842400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:40:36,662 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 17:44:01,706 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 17:44:01,707 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0094400349948301956, 0.0087383250513883119, 0.0081870673660384696, 0.007744767314637027, 0.0073752849563362075, 0.0070753776833198719, 0.0068323061858310344, 0.0066342783161876771, 0.0064699283119213028, 0.0063330447219123254, 0.0062194502661233981, 0.0061248304621507824, 0.006045599026179016, 0.0059788576269078041, 0.0059222783910460397, 0.0058741744939519863, 0.0058332616044875834, 0.005798273168104464, 0.0057681992298176249, 0.0057422641813802957, 0.0057197885217472981, 0.0057003632545860015, 0.0056834839237699863, 0.0056687572334188996, 0.0056558479101440568, 0.0056445760011004861, 0.0056346684352189128, 0.005625957482107989, 0.0056182793165306883, 0.0056114979012150869, 0.0056055032050710083, 0.0056001762512117043, 0.0055954378719986833, 0.0055911829216780196, 0.0055873560914629439, 0.0055839018495763672, 0.0055807703614470404, 0.0055779267502253831, 0.0055753237498360753, 0.005572952075461963, 0.0055707935874481458, 0.005568798567082504, 0.0055669434731418881, 0.0055651766329679261, 0.0055635386772620813, 0.005561993596425026, 0.0055605284914166248, 0.0055590798250560059, 0.0055575517721738405, 0.0055561649918731458, 0.0055548601908912525, 0.0055536045235927735, 0.0055523903579072931, 0.005551210578509806, 0.0055500677585169174, 0.005548946251983192, 0.0055478499294078958, 0.0055467700886922431, 0.0055457021239652092, 0.0055446427440231762, 0.0055435935329873143, 0.0055425444070916546, 0.0055415007569517387, 0.0055404498430262619, 0.005539401632451953, 0.0055383485799243909, 0.0055372958612833305, 0.0055362395747971692, 0.0055351741292788753, 0.0055341084372390508, 0.0055330430001064241, 0.0055319643649589219, 0.0055308686227916589, 0.0055297679918654228, 0.0055286591809765957, 0.0055275448309261045, 0.0055264194702366086, 0.0055252790008834159, 0.0055241293571814103, 0.005522966242844745, 0.0055218033628789479, 0.005520633887414003, 0.0055194571250601265, 0.0055182796311850539, 0.0055170706789036995, 0.0055158275575060449, 0.0055145638211411569, 0.0055132813050724136, 0.0055119848312301448, 0.0055106739751968597, 0.0055093466086386378, 0.0055080101541553246, 0.0055066536611766831, 0.0055052830486153467, 0.0055038838907261675, 0.005502477705390362, 0.0055010694101177643, 0.0054996553277928831, 0.005498233835874498, 0.0054968123592727932, 0.0054953762949456336], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098390349319447713, 0.0090786099247108561, 0.0084572384827597113, 0.0079651093373366167, 0.007562501743990058, 0.0072292807628357757, 0.0069599806427008189, 0.0067412640046745787, 0.0065620091118579688, 0.0064123841382108596, 0.0062884627539050407, 0.0061855081394973218, 0.0060995392670197155, 0.0060274144749490818, 0.0059664585866304725, 0.0059147665653904993, 0.0058708455858493096, 0.0058333988804326721, 0.0058013411060229862, 0.0057737464158954333, 0.0057499016479880434, 0.0057292623922427267, 0.0057113981748927335, 0.0056958618572472653, 0.0056822908993884036, 0.0056703958102622305, 0.0056600127958686781, 0.0056508929143808725, 0.0056428708890216353, 0.005635813692587149, 0.005629578770193309, 0.0056240664528344683, 0.0056191620017294764, 0.0056147915220277449, 0.0056108673141677789, 0.005607337729471076, 0.005604158452152657, 0.0056012702134817498, 0.0055986454223840602, 0.0055962427100526768, 0.005594048956750898, 0.0055920436161675307, 0.0055901932767193985, 0.0055884506667269011, 0.0055868175931638869, 0.0055852885941841185, 0.0055838412318524556, 0.0055824549304216466, 0.0055809982370311302, 0.0055795972341470624, 0.0055783048479156952, 0.00557706899646264, 0.0055758786422950516, 0.0055747160992005657, 0.0055735874387804968, 0.0055724901358211853, 0.0055714097736846661, 0.0055703533274591762, 0.0055693026527015256, 0.0055682727040722284, 0.0055672440904110205, 0.0055662274158433875, 0.0055652015194446814, 0.0055641778732182547, 0.0055631482630178865, 0.0055621194307868055, 0.005561085947944377, 0.0055600533779055277, 0.005559014057749943, 0.0055579711314772259, 0.0055569194207418125, 0.0055558619067018911, 0.0055547965087140135, 0.0055537189497475584, 0.0055526271743083291, 0.0055515335059876901, 0.0055504269089503601, 0.0055493172154112199, 0.0055481921249848102, 0.0055470558614882171, 0.0055459119275836901, 0.0055447658079804249, 0.0055436110132565577, 0.0055424499659710675, 0.0055412678580721549, 0.0055400486377631319, 0.0055388052026099097, 0.0055375434518271033, 0.0055362657244095803, 0.0055349739959455017, 0.0055336625223454195, 0.0055323418175976082, 0.0055310079542460677, 0.0055296592555786513, 0.0055282910234862176, 0.0055269117044026358, 0.0055255241173305684, 0.0055241297073804034, 0.0055227301250862001, 0.0055213270366431472, 0.0055199255983340526], 'acc': [0.44998158829276863, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822266596353, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427]}
[2017-11-18 17:44:01,708 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 17:44:01,840 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 17:44:01,840 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 17:44:02,721 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:141]: done!
[2017-11-18 17:44:02,721 AE_UNIGRAMA_3L_9FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_3L_9FULLDS_UNDER_02 finished!
