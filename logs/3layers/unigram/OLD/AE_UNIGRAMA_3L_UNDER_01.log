[2017-10-20 01:38:03,524 AE_UNIGRAMA_3L_UNDER_01.py:146]: >> Initializing execution of experiment AE_UNIGRAMA_3L_UNDER_01
[2017-10-20 01:38:03,524 AE_UNIGRAMA_3L_UNDER_01.py:147]: >> Printing header log
[2017-10-20 01:38:03,524 AE_UNIGRAMA_3L_UNDER_01.py:36]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_UNDER_01
	layers = 96,28,26,24,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdc5d8337b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdc5d833898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:38:03,524 AE_UNIGRAMA_3L_UNDER_01.py:149]: >> Loading dataset... 
[2017-10-20 01:38:04,144 AE_UNIGRAMA_3L_UNDER_01.py:53]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:38:04,144 AE_UNIGRAMA_3L_UNDER_01.py:151]: >> Executing autoencoder part ... 
[2017-10-20 01:38:04,144 AE_UNIGRAMA_3L_UNDER_01.py:58]: =======================================
[2017-10-20 01:38:04,145 AE_UNIGRAMA_3L_UNDER_01.py:63]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdc5d8337b8>, 'discard_decoder_function': True}
[2017-10-20 01:38:04,240 AE_UNIGRAMA_3L_UNDER_01.py:74]: training and evaluate autoencoder
[2017-10-20 01:38:28,669 AE_UNIGRAMA_3L_UNDER_01.py:86]: trained and evaluated!
[2017-10-20 01:38:28,670 AE_UNIGRAMA_3L_UNDER_01.py:89]: Training history: 
{'val_loss': [0.010210840533518659, 0.010084007025374356, 0.0099569862659979035, 0.0098318478064853901, 0.0097092938986797321, 0.0095896609092899852, 0.009472647349464406, 0.0093590528063725361, 0.0092494820026493875, 0.009143812692686085, 0.0090420531441343325, 0.0089441289758261256, 0.0088498774902084944, 0.0087591906053924654, 0.0086717346447717294, 0.0085873848318942861, 0.0085059116494090592, 0.0084272237307630952, 0.008351151409063862, 0.0082774424724640899, 0.0082058841674190475, 0.0081364586672375196, 0.0080691083995660003, 0.0080038502563109636, 0.0079406426845596186, 0.0078794516096770979, 0.007820128006202803, 0.0077625772583412639, 0.0077069015069051085, 0.0076531021800376889, 0.0076011020177802185, 0.0075508896573048545, 0.0075023460832033236, 0.0074554653145843721, 0.0074100659218474833, 0.0073660771383256499, 0.0073235206821843368, 0.0072823961725853193, 0.0072425994641220261, 0.0072040927776422861, 0.0071667990436064264, 0.0071306871077163516, 0.0070957293817046404, 0.0070618716619050195, 0.0070290172621469294, 0.0069972031289316904, 0.0069663617413726437, 0.0069364623381275008, 0.0069074672248671488, 0.0068793383194999183, 0.0068520470279992514, 0.0068255593103519379, 0.0067998710240767127, 0.0067749238282192818, 0.0067506905499721106, 0.0067271654092495546, 0.0067043120567738786, 0.0066821201839466961, 0.0066605629745635402, 0.0066396167266379947, 0.0066192777685433295, 0.006599509268029693, 0.0065803053948100395, 0.0065616281896995789, 0.0065434444262940424, 0.0065257920187700635, 0.006508622917460908, 0.0064919149333465716, 0.0064756518946510484, 0.0064598388267078583, 0.0064444403444524146, 0.0064294651309963055, 0.0064148815992707215, 0.0064006840384333331, 0.0063868955809442971, 0.0063734493377621956, 0.0063603581154379699, 0.0063476233698123007, 0.0063352234987022705, 0.0063231320961700498, 0.0063113513381867822, 0.0062998870481151851, 0.0062887138465495583, 0.0062778320364294, 0.0062672445796374716, 0.0062569002880538266, 0.0062468412668066839, 0.0062370300812293602, 0.006227456547361435, 0.0062181465310428884, 0.0062090668352978605, 0.0062002066529761018, 0.0061915702962049984, 0.0061831403000896529, 0.0061749150789581712, 0.0061668782671532663, 0.0061590272715128262, 0.0061513625784711326, 0.0061438760051995408, 0.0061365179128972571, 0.0061293242959700334, 0.0061222938838030551], 'loss': [0.010266980167178377, 0.010142008422518443, 0.010014638351648588, 0.009888380837467051, 0.0097643500926647368, 0.0096431382655291446, 0.0095246676252565277, 0.0094091007119638838, 0.0092972401133437944, 0.009189318044119146, 0.0090853314916588962, 0.0089852243579452429, 0.0088888651238595261, 0.0087960652077425164, 0.0087066744228100294, 0.0086204422839311051, 0.0085371686254422513, 0.0084566382116557405, 0.0083788282867033343, 0.0083034842274510648, 0.0082304269703907616, 0.0081594976274263434, 0.0080906588414749198, 0.0080238745536955133, 0.0079591863999886239, 0.0078965640565599113, 0.0078358901172335994, 0.0077769687878953657, 0.0077198718911461583, 0.007664633146072174, 0.0076112494593315611, 0.007559628005196199, 0.0075097555448040689, 0.0074615109770271989, 0.0074148896538389743, 0.0073696798055370343, 0.0073258857504357646, 0.0072835017978508526, 0.0072425189674170786, 0.007202832355406124, 0.0071644124966492558, 0.0071271815939423456, 0.0070911099554395009, 0.0070561716829889674, 0.0070223096113013177, 0.0069894362295409365, 0.0069575841789326753, 0.006926697004270484, 0.0068967358959631537, 0.006867658745866102, 0.0068394339270775274, 0.00681204327022097, 0.0067854461170842881, 0.0067596325104725312, 0.0067345484076313947, 0.0067101672037602495, 0.0066864924790416679, 0.0066634717969236449, 0.006641107091317257, 0.006619370404800335, 0.0065982441982276136, 0.0065777177216064988, 0.0065577518187472442, 0.0065383456253000722, 0.0065194564853172654, 0.0065010603435438291, 0.0064831944940967759, 0.0064657986437135963, 0.006448861564719648, 0.0064323601128617059, 0.0064163168748587679, 0.0064006790166151765, 0.0063854642913601812, 0.0063706328860554471, 0.0063561851327028759, 0.0063421507683693078, 0.0063284491240341717, 0.0063151101820450219, 0.0063021130775134113, 0.0062894558705178854, 0.0062771097455830869, 0.0062650657154747916, 0.0062533457507050211, 0.0062419116699103019, 0.0062307524251549538, 0.006219907197528865, 0.0062093001297493615, 0.0061989765724175241, 0.006188898937766381, 0.0061790690217544937, 0.0061694937552077573, 0.0061601482451387945, 0.0061510191009950619, 0.006142118664374821, 0.006133425770443077, 0.0061249232893327704, 0.0061166272719047812, 0.0061085187393849112, 0.0061005782112753971, 0.0060928177558453485, 0.0060852004310142501, 0.0060777496869922525]}
[2017-10-20 01:38:28,670 AE_UNIGRAMA_3L_UNDER_01.py:93]: done!
[2017-10-20 01:38:28,670 AE_UNIGRAMA_3L_UNDER_01.py:153]: >> Executing classifier part ... 
[2017-10-20 01:38:28,670 AE_UNIGRAMA_3L_UNDER_01.py:98]: =======================================
[2017-10-20 01:38:28,670 AE_UNIGRAMA_3L_UNDER_01.py:102]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdc5d833898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:38:28,706 AE_UNIGRAMA_3L_UNDER_01.py:111]: training ... 
[2017-10-20 01:39:14,326 AE_UNIGRAMA_3L_UNDER_01.py:123]: trained!
[2017-10-20 01:39:14,326 AE_UNIGRAMA_3L_UNDER_01.py:126]: Training history: 
{'val_loss': [0.010210840533518659, 0.010084007025374356, 0.0099569862659979035, 0.0098318478064853901, 0.0097092938986797321, 0.0095896609092899852, 0.009472647349464406, 0.0093590528063725361, 0.0092494820026493875, 0.009143812692686085, 0.0090420531441343325, 0.0089441289758261256, 0.0088498774902084944, 0.0087591906053924654, 0.0086717346447717294, 0.0085873848318942861, 0.0085059116494090592, 0.0084272237307630952, 0.008351151409063862, 0.0082774424724640899, 0.0082058841674190475, 0.0081364586672375196, 0.0080691083995660003, 0.0080038502563109636, 0.0079406426845596186, 0.0078794516096770979, 0.007820128006202803, 0.0077625772583412639, 0.0077069015069051085, 0.0076531021800376889, 0.0076011020177802185, 0.0075508896573048545, 0.0075023460832033236, 0.0074554653145843721, 0.0074100659218474833, 0.0073660771383256499, 0.0073235206821843368, 0.0072823961725853193, 0.0072425994641220261, 0.0072040927776422861, 0.0071667990436064264, 0.0071306871077163516, 0.0070957293817046404, 0.0070618716619050195, 0.0070290172621469294, 0.0069972031289316904, 0.0069663617413726437, 0.0069364623381275008, 0.0069074672248671488, 0.0068793383194999183, 0.0068520470279992514, 0.0068255593103519379, 0.0067998710240767127, 0.0067749238282192818, 0.0067506905499721106, 0.0067271654092495546, 0.0067043120567738786, 0.0066821201839466961, 0.0066605629745635402, 0.0066396167266379947, 0.0066192777685433295, 0.006599509268029693, 0.0065803053948100395, 0.0065616281896995789, 0.0065434444262940424, 0.0065257920187700635, 0.006508622917460908, 0.0064919149333465716, 0.0064756518946510484, 0.0064598388267078583, 0.0064444403444524146, 0.0064294651309963055, 0.0064148815992707215, 0.0064006840384333331, 0.0063868955809442971, 0.0063734493377621956, 0.0063603581154379699, 0.0063476233698123007, 0.0063352234987022705, 0.0063231320961700498, 0.0063113513381867822, 0.0062998870481151851, 0.0062887138465495583, 0.0062778320364294, 0.0062672445796374716, 0.0062569002880538266, 0.0062468412668066839, 0.0062370300812293602, 0.006227456547361435, 0.0062181465310428884, 0.0062090668352978605, 0.0062002066529761018, 0.0061915702962049984, 0.0061831403000896529, 0.0061749150789581712, 0.0061668782671532663, 0.0061590272715128262, 0.0061513625784711326, 0.0061438760051995408, 0.0061365179128972571, 0.0061293242959700334, 0.0061222938838030551], 'loss': [0.010266980167178377, 0.010142008422518443, 0.010014638351648588, 0.009888380837467051, 0.0097643500926647368, 0.0096431382655291446, 0.0095246676252565277, 0.0094091007119638838, 0.0092972401133437944, 0.009189318044119146, 0.0090853314916588962, 0.0089852243579452429, 0.0088888651238595261, 0.0087960652077425164, 0.0087066744228100294, 0.0086204422839311051, 0.0085371686254422513, 0.0084566382116557405, 0.0083788282867033343, 0.0083034842274510648, 0.0082304269703907616, 0.0081594976274263434, 0.0080906588414749198, 0.0080238745536955133, 0.0079591863999886239, 0.0078965640565599113, 0.0078358901172335994, 0.0077769687878953657, 0.0077198718911461583, 0.007664633146072174, 0.0076112494593315611, 0.007559628005196199, 0.0075097555448040689, 0.0074615109770271989, 0.0074148896538389743, 0.0073696798055370343, 0.0073258857504357646, 0.0072835017978508526, 0.0072425189674170786, 0.007202832355406124, 0.0071644124966492558, 0.0071271815939423456, 0.0070911099554395009, 0.0070561716829889674, 0.0070223096113013177, 0.0069894362295409365, 0.0069575841789326753, 0.006926697004270484, 0.0068967358959631537, 0.006867658745866102, 0.0068394339270775274, 0.00681204327022097, 0.0067854461170842881, 0.0067596325104725312, 0.0067345484076313947, 0.0067101672037602495, 0.0066864924790416679, 0.0066634717969236449, 0.006641107091317257, 0.006619370404800335, 0.0065982441982276136, 0.0065777177216064988, 0.0065577518187472442, 0.0065383456253000722, 0.0065194564853172654, 0.0065010603435438291, 0.0064831944940967759, 0.0064657986437135963, 0.006448861564719648, 0.0064323601128617059, 0.0064163168748587679, 0.0064006790166151765, 0.0063854642913601812, 0.0063706328860554471, 0.0063561851327028759, 0.0063421507683693078, 0.0063284491240341717, 0.0063151101820450219, 0.0063021130775134113, 0.0062894558705178854, 0.0062771097455830869, 0.0062650657154747916, 0.0062533457507050211, 0.0062419116699103019, 0.0062307524251549538, 0.006219907197528865, 0.0062093001297493615, 0.0061989765724175241, 0.006188898937766381, 0.0061790690217544937, 0.0061694937552077573, 0.0061601482451387945, 0.0061510191009950619, 0.006142118664374821, 0.006133425770443077, 0.0061249232893327704, 0.0061166272719047812, 0.0061085187393849112, 0.0061005782112753971, 0.0060928177558453485, 0.0060852004310142501, 0.0060777496869922525]}
[2017-10-20 01:39:14,326 AE_UNIGRAMA_3L_UNDER_01.py:130]: evaluating model ... 
[2017-10-20 01:39:14,372 AE_UNIGRAMA_3L_UNDER_01.py:134]: evaluated! 
[2017-10-20 01:39:14,373 AE_UNIGRAMA_3L_UNDER_01.py:136]: generating reports ... 
[2017-10-20 01:39:14,990 AE_UNIGRAMA_3L_UNDER_01.py:139]: done!
[2017-10-20 01:39:14,990 AE_UNIGRAMA_3L_UNDER_01.py:155]: >> experiment AE_UNIGRAMA_3L_UNDER_01 finished!
