[2017-10-15 11:16:10,775 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_3L_UNDER_96_28_25_22_9
[2017-10-15 11:16:10,775 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:148]: >> Printing header log
[2017-10-15 11:16:10,775 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_UNDER_96_28_25_22_9
	layers = 96,28,25,22,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdf5faf6860>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdf4b9c1128>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 11:16:10,775 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:150]: >> Loading dataset... 
[2017-10-15 11:16:11,294 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 11:16:11,294 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:152]: >> Executing autoencoder part ... 
[2017-10-15 11:16:11,294 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:60]: =======================================
[2017-10-15 11:16:11,295 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdf5faf6860>, 'discard_decoder_function': True}
[2017-10-15 11:16:11,375 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:76]: training and evaluate autoencoder
[2017-10-15 11:16:41,752 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:87]: trained and evaluated!
[2017-10-15 11:16:41,753 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:90]: Training history: 
{'val_loss': [0.010190135792424023, 0.010041371701098286, 0.0098968678566049018, 0.0097572086205823718, 0.0096222615409573206, 0.0094925772094039667, 0.0093679025312227836, 0.0092480253760588663, 0.0091322478717089147, 0.009020546707411238, 0.0089134940025864043, 0.0088108694873279356, 0.0087125627289363437, 0.0086183401731753442, 0.008528019852077651, 0.0084414497211741692, 0.008358375903315925, 0.0082786593025335597, 0.0082020931046276058, 0.0081285172623329453, 0.0080577461325933939, 0.0079897547791604653, 0.0079243607216663518, 0.0078614451472394757, 0.0078008735351624541, 0.007742565154655383, 0.0076863827775872995, 0.00763227600694312, 0.0075801121396424599, 0.0075298096105234774, 0.0074813411221406716, 0.007434634290995651, 0.0073895937136502516, 0.0073461775117481063, 0.0073043067946503819, 0.0072639217413269456, 0.0072249558712719321, 0.0071873477448927423, 0.0071510540193369179, 0.0071160173195943957, 0.0070822132287415426, 0.0070495453029594014, 0.0070179845119885354, 0.006987515677694494, 0.0069580881330132708, 0.0069296519967924708, 0.00690217195840407, 0.0068756503513477552, 0.0068499961951020479, 0.006825185032928411, 0.0068012203460344591, 0.0067780282777702939, 0.0067556190761464017, 0.0067339233835972149, 0.0067129282377743366, 0.0066926252636989253, 0.0066729782384622937, 0.006653963775135106, 0.0066355779787809436, 0.0066177496101471793, 0.0066005349069224416, 0.0065838629604909275, 0.0065677060579472533, 0.0065520693025236682, 0.0065369441755614537, 0.0065222426064894101, 0.0065080188301333041, 0.0064942517445931644, 0.0064809177950246183, 0.006467976004965465, 0.0064554550861558946, 0.006443319423297302, 0.0064315470766456153, 0.0064201491978365692, 0.0064090810193365173, 0.0063983518526401217, 0.0063879407031745498, 0.006377858923381146, 0.0063680843277020751, 0.0063585841553943532, 0.0063493658916602344, 0.0063404265607682969, 0.0063317567456278217, 0.0063233448549080296, 0.0063151761328586855, 0.0063072482598287684, 0.0062995478822451545, 0.0062920473651011857, 0.0062847820848060364, 0.0062777130971887743, 0.0062708374126693132, 0.0062641458859369432, 0.0062576418233599137, 0.0062513029891789846, 0.0062451390134080631, 0.0062391314115444524, 0.0062332977177263632, 0.0062276368275229373, 0.0062221298548202535, 0.0062167803414138276, 0.0062115835510609761, 0.0062065334907528639], 'loss': [0.010259113812586722, 0.010109197788544974, 0.0099621358211366903, 0.0098197096214614251, 0.0096821128353522315, 0.009549496512798239, 0.0094220484357920246, 0.0092994234351224895, 0.0091814041085032938, 0.0090673237051024855, 0.0089577474673155563, 0.0088526862996877089, 0.0087520187307371274, 0.0086555640581255679, 0.0085630967260579352, 0.0084744504885891133, 0.0083894341996313977, 0.0083078197807476568, 0.0082294831393583106, 0.0081542025817662352, 0.0080818341745575398, 0.0080122281210502754, 0.0079453188099411279, 0.0078809550123606353, 0.0078189895135140457, 0.0077593288840594361, 0.0077018771156297733, 0.0076465129036028178, 0.0075931779530240516, 0.0075417558002024068, 0.0074921580338902132, 0.0074443703488124499, 0.0073983074485289404, 0.0073538850028395247, 0.0073110368354652438, 0.0072696956862554132, 0.0072298185271912176, 0.0071913374816287897, 0.007154180369492719, 0.007118303346783655, 0.0070836692461749675, 0.0070502465375033383, 0.007017926645557354, 0.0069867088198982356, 0.0069565555571905295, 0.0069274345550802896, 0.0068992862074916976, 0.0068720840298317114, 0.0068458218611753933, 0.0068204072304069996, 0.0067958203430580049, 0.0067720735006574738, 0.006749080157178765, 0.006726858066423546, 0.0067053338991891372, 0.0066845051897890043, 0.0066643535433143618, 0.0066448426439089684, 0.0066259588880811316, 0.0066076875366636893, 0.0065899677723462993, 0.0065728570443372566, 0.0065562727047701738, 0.0065402019584062613, 0.0065246397573855766, 0.0065095709400971608, 0.0064949361199871415, 0.0064807616977894606, 0.0064670439542242001, 0.0064537502889943288, 0.0064408389374055082, 0.0064283451240008315, 0.0064162347879611094, 0.0064044774394910542, 0.0063930937577297738, 0.0063820410409361839, 0.0063713191191024149, 0.0063609227909607506, 0.0063508405947179684, 0.0063410577843379008, 0.0063315565124286892, 0.0063223268424023975, 0.0063133854667994423, 0.0063046951461686413, 0.0062962673082444, 0.0062880847103934968, 0.0062801338252557078, 0.0062724004586049214, 0.0062648754918371964, 0.0062575785994996814, 0.0062504745126869612, 0.0062435640227656349, 0.006236825880469192, 0.0062302855128501377, 0.0062239028939309847, 0.006217706017482387, 0.0062116669132027914, 0.0062057918627971363, 0.0062000919451116231, 0.0061945403412616389, 0.006189154529143823, 0.0061839121727578538]}
[2017-10-15 11:16:41,753 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:94]: done!
[2017-10-15 11:16:41,753 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:154]: >> Executing classifier part ... 
[2017-10-15 11:16:41,753 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:99]: =======================================
[2017-10-15 11:16:41,753 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdf4b9c1128>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 11:16:41,812 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:112]: training ... 
[2017-10-15 11:17:37,810 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:124]: trained!
[2017-10-15 11:17:37,811 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:127]: Training history: 
{'val_loss': [0.010190135792424023, 0.010041371701098286, 0.0098968678566049018, 0.0097572086205823718, 0.0096222615409573206, 0.0094925772094039667, 0.0093679025312227836, 0.0092480253760588663, 0.0091322478717089147, 0.009020546707411238, 0.0089134940025864043, 0.0088108694873279356, 0.0087125627289363437, 0.0086183401731753442, 0.008528019852077651, 0.0084414497211741692, 0.008358375903315925, 0.0082786593025335597, 0.0082020931046276058, 0.0081285172623329453, 0.0080577461325933939, 0.0079897547791604653, 0.0079243607216663518, 0.0078614451472394757, 0.0078008735351624541, 0.007742565154655383, 0.0076863827775872995, 0.00763227600694312, 0.0075801121396424599, 0.0075298096105234774, 0.0074813411221406716, 0.007434634290995651, 0.0073895937136502516, 0.0073461775117481063, 0.0073043067946503819, 0.0072639217413269456, 0.0072249558712719321, 0.0071873477448927423, 0.0071510540193369179, 0.0071160173195943957, 0.0070822132287415426, 0.0070495453029594014, 0.0070179845119885354, 0.006987515677694494, 0.0069580881330132708, 0.0069296519967924708, 0.00690217195840407, 0.0068756503513477552, 0.0068499961951020479, 0.006825185032928411, 0.0068012203460344591, 0.0067780282777702939, 0.0067556190761464017, 0.0067339233835972149, 0.0067129282377743366, 0.0066926252636989253, 0.0066729782384622937, 0.006653963775135106, 0.0066355779787809436, 0.0066177496101471793, 0.0066005349069224416, 0.0065838629604909275, 0.0065677060579472533, 0.0065520693025236682, 0.0065369441755614537, 0.0065222426064894101, 0.0065080188301333041, 0.0064942517445931644, 0.0064809177950246183, 0.006467976004965465, 0.0064554550861558946, 0.006443319423297302, 0.0064315470766456153, 0.0064201491978365692, 0.0064090810193365173, 0.0063983518526401217, 0.0063879407031745498, 0.006377858923381146, 0.0063680843277020751, 0.0063585841553943532, 0.0063493658916602344, 0.0063404265607682969, 0.0063317567456278217, 0.0063233448549080296, 0.0063151761328586855, 0.0063072482598287684, 0.0062995478822451545, 0.0062920473651011857, 0.0062847820848060364, 0.0062777130971887743, 0.0062708374126693132, 0.0062641458859369432, 0.0062576418233599137, 0.0062513029891789846, 0.0062451390134080631, 0.0062391314115444524, 0.0062332977177263632, 0.0062276368275229373, 0.0062221298548202535, 0.0062167803414138276, 0.0062115835510609761, 0.0062065334907528639], 'loss': [0.010259113812586722, 0.010109197788544974, 0.0099621358211366903, 0.0098197096214614251, 0.0096821128353522315, 0.009549496512798239, 0.0094220484357920246, 0.0092994234351224895, 0.0091814041085032938, 0.0090673237051024855, 0.0089577474673155563, 0.0088526862996877089, 0.0087520187307371274, 0.0086555640581255679, 0.0085630967260579352, 0.0084744504885891133, 0.0083894341996313977, 0.0083078197807476568, 0.0082294831393583106, 0.0081542025817662352, 0.0080818341745575398, 0.0080122281210502754, 0.0079453188099411279, 0.0078809550123606353, 0.0078189895135140457, 0.0077593288840594361, 0.0077018771156297733, 0.0076465129036028178, 0.0075931779530240516, 0.0075417558002024068, 0.0074921580338902132, 0.0074443703488124499, 0.0073983074485289404, 0.0073538850028395247, 0.0073110368354652438, 0.0072696956862554132, 0.0072298185271912176, 0.0071913374816287897, 0.007154180369492719, 0.007118303346783655, 0.0070836692461749675, 0.0070502465375033383, 0.007017926645557354, 0.0069867088198982356, 0.0069565555571905295, 0.0069274345550802896, 0.0068992862074916976, 0.0068720840298317114, 0.0068458218611753933, 0.0068204072304069996, 0.0067958203430580049, 0.0067720735006574738, 0.006749080157178765, 0.006726858066423546, 0.0067053338991891372, 0.0066845051897890043, 0.0066643535433143618, 0.0066448426439089684, 0.0066259588880811316, 0.0066076875366636893, 0.0065899677723462993, 0.0065728570443372566, 0.0065562727047701738, 0.0065402019584062613, 0.0065246397573855766, 0.0065095709400971608, 0.0064949361199871415, 0.0064807616977894606, 0.0064670439542242001, 0.0064537502889943288, 0.0064408389374055082, 0.0064283451240008315, 0.0064162347879611094, 0.0064044774394910542, 0.0063930937577297738, 0.0063820410409361839, 0.0063713191191024149, 0.0063609227909607506, 0.0063508405947179684, 0.0063410577843379008, 0.0063315565124286892, 0.0063223268424023975, 0.0063133854667994423, 0.0063046951461686413, 0.0062962673082444, 0.0062880847103934968, 0.0062801338252557078, 0.0062724004586049214, 0.0062648754918371964, 0.0062575785994996814, 0.0062504745126869612, 0.0062435640227656349, 0.006236825880469192, 0.0062302855128501377, 0.0062239028939309847, 0.006217706017482387, 0.0062116669132027914, 0.0062057918627971363, 0.0062000919451116231, 0.0061945403412616389, 0.006189154529143823, 0.0061839121727578538]}
[2017-10-15 11:17:37,811 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:131]: evaluating model ... 
[2017-10-15 11:17:37,863 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:135]: evaluated! 
[2017-10-15 11:17:37,864 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:137]: generating reports ... 
[2017-10-15 11:17:38,450 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:140]: done!
[2017-10-15 11:17:38,450 AE_UNIGRAMA_3L_UNDER_96_28_25_22_9.py:156]: >> experiment AE_UNIGRAMA_3L_UNDER_96_28_25_22_9 finished!
