[2017-10-20 01:39:31,147 AE_UNIGRAMA_3L_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_OVER_04
[2017-10-20 01:39:31,147 AE_UNIGRAMA_3L_OVER_04.py:149]: >> Printing header log
[2017-10-20 01:39:31,147 AE_UNIGRAMA_3L_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_OVER_04
	layers = 96,134,122,109,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f04f45577b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f04f4557898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:39:31,148 AE_UNIGRAMA_3L_OVER_04.py:151]: >> Loading dataset... 
[2017-10-20 01:39:31,766 AE_UNIGRAMA_3L_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:39:31,767 AE_UNIGRAMA_3L_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:39:31,767 AE_UNIGRAMA_3L_OVER_04.py:60]: =======================================
[2017-10-20 01:39:31,767 AE_UNIGRAMA_3L_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f04f45577b8>, 'discard_decoder_function': True}
[2017-10-20 01:39:31,859 AE_UNIGRAMA_3L_OVER_04.py:76]: training and evaluate autoencoder
[2017-10-20 01:40:07,851 AE_UNIGRAMA_3L_OVER_04.py:88]: trained and evaluated!
[2017-10-20 01:40:07,851 AE_UNIGRAMA_3L_OVER_04.py:91]: Training history: 
{'val_loss': [0.010220573436067228, 0.010146273005767604, 0.010073303445813604, 0.010002011817544145, 0.0099324084278265348, 0.0098656036416726479, 0.0098020958620708663, 0.0097418607569206162, 0.0096846015389911739, 0.0096304604686713573, 0.0095792230855687409, 0.0095306493611971681, 0.009484607047751047, 0.0094411861165305498, 0.009400226497766475, 0.0093615500526468103, 0.0093249735875976132, 0.0092901892710795641, 0.0092569888434390155, 0.0092255667779857792, 0.009195853481727018, 0.009167773818742609, 0.0091412053495423945, 0.0091160599516226896, 0.0090922779961035601, 0.0090697819789435346, 0.0090484427648239857, 0.0090282545407686984, 0.0090091392037815327, 0.0089909990273111372, 0.0089737506008613511, 0.0089573998862815165, 0.0089418752271280405, 0.0089271223470291684, 0.0089131253442578159, 0.0088998011753073855, 0.0088871533473517377, 0.0088751028191478287, 0.0088636224057705437, 0.0088527112243676279, 0.0088422811178137384, 0.0088323548117645607, 0.0088228880147342339, 0.0088138585515514182, 0.0088052226916010938, 0.0087969904855503024, 0.0087891305938750837, 0.0087816058779239207, 0.0087744247992297981, 0.0087675481106822811, 0.0087609796206636493, 0.0087547026449973694, 0.0087486704167491006, 0.0087429004094691527, 0.0087373741248061663, 0.0087320691071533802, 0.0087269929473091021, 0.0087221242265851963, 0.0087174551776129077, 0.0087129577378081118, 0.0087086341783515139, 0.0087044809851449211, 0.0087004797515843665, 0.0086966404746733183, 0.0086929464754284987, 0.0086893921226373835, 0.0086859686050882578, 0.0086826533494607228, 0.0086794664397780337, 0.0086763716237030948, 0.0086733524040163226, 0.0086704417370730615, 0.0086676541570449399, 0.00866497562658111, 0.0086623889092896072, 0.0086598810791747721, 0.0086574626577581842, 0.0086551170820391085, 0.0086528506133442245, 0.0086506601149514036, 0.0086485323059930005, 0.0086464632621041908, 0.0086444556906985527, 0.0086424990719855942, 0.0086405717241525865, 0.0086386424392378685, 0.0086366095091995245, 0.0086343737516455261, 0.0086315491091335343, 0.0086283752622020506, 0.0086252486651770249, 0.0086222447759599936, 0.0086193586194188397, 0.0086165905054173941, 0.0086139396099602205, 0.0086113860377120925, 0.0086089278360115557, 0.0086065681034969126, 0.0086042916637648001, 0.008602099579700085, 0.008599982801201618, 0.0085979471481699484], 'loss': [0.010251810490288248, 0.010179827218736764, 0.010106504042464015, 0.010034971678149832, 0.009965157289156425, 0.0098974413204693176, 0.0098329151264485142, 0.0097716720666010531, 0.009713550180668433, 0.0096584690755351088, 0.009606371824323362, 0.009557018428010558, 0.0095102716318589825, 0.0094660918721179328, 0.0094244570191434427, 0.0093851672226738254, 0.0093480479384336866, 0.0093128937934814377, 0.0092793192196987707, 0.0092474534448188147, 0.0092173354201060022, 0.0091888697946143055, 0.0091619641727870346, 0.0091365204663797252, 0.0091124471487648, 0.0090896798092837561, 0.0090681419060431017, 0.0090477111736185431, 0.0090283858569793415, 0.0090100825309167264, 0.0089927030653997875, 0.0089761931025586252, 0.008960549290891285, 0.0089456806996563651, 0.0089315551744697276, 0.0089181510653729146, 0.0089053945299913412, 0.0088932714799960545, 0.0088817295512458108, 0.0088707356620408226, 0.008860270888272721, 0.0088502790431990597, 0.0088407645985420016, 0.0088316927484815375, 0.0088230462460913168, 0.0088147707632671279, 0.008806876705978902, 0.0087993501845264107, 0.0087921426247418409, 0.0087852548577747758, 0.0087786723699903816, 0.0087723726625356779, 0.0087663501572063096, 0.008760560418409882, 0.0087550338947276572, 0.0087497270904760751, 0.0087446360479635048, 0.008739761493587208, 0.0087350812387442626, 0.0087306016842023538, 0.0087262771630999721, 0.0087221364743123777, 0.0087181401657102, 0.0087142990216310581, 0.0087106054804454418, 0.0087070542163849244, 0.0087036339018880839, 0.0087003346181119164, 0.0086971453254207857, 0.0086940679969363371, 0.0086910719654139882, 0.0086881532788862827, 0.0086853498880326129, 0.008682676833111521, 0.0086800773927430182, 0.0086775806520109026, 0.0086751585796512043, 0.0086728187670591199, 0.0086705597311020188, 0.008668362741720918, 0.0086662463194701524, 0.0086641868887802325, 0.0086621837890818575, 0.0086602336185003757, 0.0086583227266058948, 0.0086564239516359713, 0.0086544600424723686, 0.0086523354810232687, 0.0086498220428851899, 0.0086467439748378859, 0.0086435514605834804, 0.0086404541181085582, 0.0086374858493865753, 0.0086346319587540608, 0.0086318951566058504, 0.0086292721618472911, 0.0086267554637939926, 0.0086243297050683579, 0.0086219900951119161, 0.0086197462808695682, 0.0086175873314649244, 0.0086155046743799299]}
[2017-10-20 01:40:07,851 AE_UNIGRAMA_3L_OVER_04.py:95]: done!
[2017-10-20 01:40:07,852 AE_UNIGRAMA_3L_OVER_04.py:155]: >> Executing classifier part ... 
[2017-10-20 01:40:07,852 AE_UNIGRAMA_3L_OVER_04.py:100]: =======================================
[2017-10-20 01:40:07,852 AE_UNIGRAMA_3L_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f04f4557898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:40:07,888 AE_UNIGRAMA_3L_OVER_04.py:113]: training ... 
[2017-10-20 01:41:09,967 AE_UNIGRAMA_3L_OVER_04.py:125]: trained!
[2017-10-20 01:41:09,968 AE_UNIGRAMA_3L_OVER_04.py:128]: Training history: 
{'val_loss': [0.010220573436067228, 0.010146273005767604, 0.010073303445813604, 0.010002011817544145, 0.0099324084278265348, 0.0098656036416726479, 0.0098020958620708663, 0.0097418607569206162, 0.0096846015389911739, 0.0096304604686713573, 0.0095792230855687409, 0.0095306493611971681, 0.009484607047751047, 0.0094411861165305498, 0.009400226497766475, 0.0093615500526468103, 0.0093249735875976132, 0.0092901892710795641, 0.0092569888434390155, 0.0092255667779857792, 0.009195853481727018, 0.009167773818742609, 0.0091412053495423945, 0.0091160599516226896, 0.0090922779961035601, 0.0090697819789435346, 0.0090484427648239857, 0.0090282545407686984, 0.0090091392037815327, 0.0089909990273111372, 0.0089737506008613511, 0.0089573998862815165, 0.0089418752271280405, 0.0089271223470291684, 0.0089131253442578159, 0.0088998011753073855, 0.0088871533473517377, 0.0088751028191478287, 0.0088636224057705437, 0.0088527112243676279, 0.0088422811178137384, 0.0088323548117645607, 0.0088228880147342339, 0.0088138585515514182, 0.0088052226916010938, 0.0087969904855503024, 0.0087891305938750837, 0.0087816058779239207, 0.0087744247992297981, 0.0087675481106822811, 0.0087609796206636493, 0.0087547026449973694, 0.0087486704167491006, 0.0087429004094691527, 0.0087373741248061663, 0.0087320691071533802, 0.0087269929473091021, 0.0087221242265851963, 0.0087174551776129077, 0.0087129577378081118, 0.0087086341783515139, 0.0087044809851449211, 0.0087004797515843665, 0.0086966404746733183, 0.0086929464754284987, 0.0086893921226373835, 0.0086859686050882578, 0.0086826533494607228, 0.0086794664397780337, 0.0086763716237030948, 0.0086733524040163226, 0.0086704417370730615, 0.0086676541570449399, 0.00866497562658111, 0.0086623889092896072, 0.0086598810791747721, 0.0086574626577581842, 0.0086551170820391085, 0.0086528506133442245, 0.0086506601149514036, 0.0086485323059930005, 0.0086464632621041908, 0.0086444556906985527, 0.0086424990719855942, 0.0086405717241525865, 0.0086386424392378685, 0.0086366095091995245, 0.0086343737516455261, 0.0086315491091335343, 0.0086283752622020506, 0.0086252486651770249, 0.0086222447759599936, 0.0086193586194188397, 0.0086165905054173941, 0.0086139396099602205, 0.0086113860377120925, 0.0086089278360115557, 0.0086065681034969126, 0.0086042916637648001, 0.008602099579700085, 0.008599982801201618, 0.0085979471481699484], 'loss': [0.010251810490288248, 0.010179827218736764, 0.010106504042464015, 0.010034971678149832, 0.009965157289156425, 0.0098974413204693176, 0.0098329151264485142, 0.0097716720666010531, 0.009713550180668433, 0.0096584690755351088, 0.009606371824323362, 0.009557018428010558, 0.0095102716318589825, 0.0094660918721179328, 0.0094244570191434427, 0.0093851672226738254, 0.0093480479384336866, 0.0093128937934814377, 0.0092793192196987707, 0.0092474534448188147, 0.0092173354201060022, 0.0091888697946143055, 0.0091619641727870346, 0.0091365204663797252, 0.0091124471487648, 0.0090896798092837561, 0.0090681419060431017, 0.0090477111736185431, 0.0090283858569793415, 0.0090100825309167264, 0.0089927030653997875, 0.0089761931025586252, 0.008960549290891285, 0.0089456806996563651, 0.0089315551744697276, 0.0089181510653729146, 0.0089053945299913412, 0.0088932714799960545, 0.0088817295512458108, 0.0088707356620408226, 0.008860270888272721, 0.0088502790431990597, 0.0088407645985420016, 0.0088316927484815375, 0.0088230462460913168, 0.0088147707632671279, 0.008806876705978902, 0.0087993501845264107, 0.0087921426247418409, 0.0087852548577747758, 0.0087786723699903816, 0.0087723726625356779, 0.0087663501572063096, 0.008760560418409882, 0.0087550338947276572, 0.0087497270904760751, 0.0087446360479635048, 0.008739761493587208, 0.0087350812387442626, 0.0087306016842023538, 0.0087262771630999721, 0.0087221364743123777, 0.0087181401657102, 0.0087142990216310581, 0.0087106054804454418, 0.0087070542163849244, 0.0087036339018880839, 0.0087003346181119164, 0.0086971453254207857, 0.0086940679969363371, 0.0086910719654139882, 0.0086881532788862827, 0.0086853498880326129, 0.008682676833111521, 0.0086800773927430182, 0.0086775806520109026, 0.0086751585796512043, 0.0086728187670591199, 0.0086705597311020188, 0.008668362741720918, 0.0086662463194701524, 0.0086641868887802325, 0.0086621837890818575, 0.0086602336185003757, 0.0086583227266058948, 0.0086564239516359713, 0.0086544600424723686, 0.0086523354810232687, 0.0086498220428851899, 0.0086467439748378859, 0.0086435514605834804, 0.0086404541181085582, 0.0086374858493865753, 0.0086346319587540608, 0.0086318951566058504, 0.0086292721618472911, 0.0086267554637939926, 0.0086243297050683579, 0.0086219900951119161, 0.0086197462808695682, 0.0086175873314649244, 0.0086155046743799299]}
[2017-10-20 01:41:09,968 AE_UNIGRAMA_3L_OVER_04.py:132]: evaluating model ... 
[2017-10-20 01:41:10,022 AE_UNIGRAMA_3L_OVER_04.py:136]: evaluated! 
[2017-10-20 01:41:10,023 AE_UNIGRAMA_3L_OVER_04.py:138]: generating reports ... 
[2017-10-20 01:41:10,639 AE_UNIGRAMA_3L_OVER_04.py:141]: done!
[2017-10-20 01:41:10,639 AE_UNIGRAMA_3L_OVER_04.py:157]: >> experiment AE_UNIGRAMA_3L_OVER_04 finished!
