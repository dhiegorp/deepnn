[2017-10-20 01:41:26,776 AE_UNIGRAMA_3L_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_UNDER_02
[2017-10-20 01:41:26,776 AE_UNIGRAMA_3L_UNDER_02.py:149]: >> Printing header log
[2017-10-20 01:41:26,776 AE_UNIGRAMA_3L_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_UNDER_02
	layers = 96,76,69,63,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f87e4f557b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f87e4f55898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:41:26,776 AE_UNIGRAMA_3L_UNDER_02.py:151]: >> Loading dataset... 
[2017-10-20 01:41:27,365 AE_UNIGRAMA_3L_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:41:27,365 AE_UNIGRAMA_3L_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:41:27,365 AE_UNIGRAMA_3L_UNDER_02.py:60]: =======================================
[2017-10-20 01:41:27,365 AE_UNIGRAMA_3L_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f87e4f557b8>, 'discard_decoder_function': True}
[2017-10-20 01:41:27,458 AE_UNIGRAMA_3L_UNDER_02.py:76]: training and evaluate autoencoder
[2017-10-20 01:41:54,831 AE_UNIGRAMA_3L_UNDER_02.py:88]: trained and evaluated!
[2017-10-20 01:41:54,832 AE_UNIGRAMA_3L_UNDER_02.py:91]: Training history: 
{'val_loss': [0.010251403723923025, 0.010190397348656531, 0.010127720433429271, 0.010065654448500131, 0.010005729300658942, 0.0099486267768871383, 0.0098939163534171523, 0.0098414456637984753, 0.0097911641050171683, 0.0097431428799731132, 0.0096976915824479766, 0.0096545961675092197, 0.0096137994540280575, 0.0095751614908802015, 0.0095384842456495006, 0.009503552340469618, 0.009469906030894433, 0.0094374333643337163, 0.0094063129469918495, 0.0093762514884254741, 0.0093455263223069743, 0.0093143819363919328, 0.0092846921343896476, 0.0092563460542920799, 0.0092292526134438672, 0.0092032816898091584, 0.0091783025866325908, 0.0091543242778476721, 0.0091313222270860556, 0.0091092517724101433, 0.009088178719203489, 0.0090681061522557387, 0.0090489215754166411, 0.0090306122340677395, 0.009013136606455736, 0.0089964549053723492, 0.0089805372419410473, 0.0089653259087838656, 0.008950769994754108, 0.0089368615507193216, 0.0089235650548593701, 0.0089108219446413575, 0.0088985838674590489, 0.0088869118578316555, 0.008875719368540886, 0.0088649786849502744, 0.0088546794690330232, 0.0088447864101611103, 0.0088353002561623283, 0.0088261786128176183, 0.0088174273727330138, 0.0088090171559703397, 0.0088009212623076805, 0.0087931472669636, 0.0087856538974607299, 0.0087784409010609726, 0.0087714955820026898, 0.0087648188439111291, 0.0087583771799465988, 0.0087521577108526753, 0.0087461680776290737, 0.0087403691543411592, 0.0087347783037499422, 0.0087293756668729416, 0.0087241476027772775, 0.0087191034419995261, 0.0087142124924407122, 0.0087094446921160227, 0.0087047702594760627, 0.0087001048042317751, 0.0086954863375004344, 0.0086909866403635985, 0.0086866085067889946, 0.008682380998195547, 0.0086782921770359057, 0.0086743412989444442, 0.0086705203074615676, 0.0086668164271958264, 0.0086632413637294653, 0.008659780087801161, 0.0086564282959389425, 0.0086531811411108221, 0.0086500336620333462, 0.0086469722212358033, 0.0086440150193233031, 0.0086411419307266032, 0.0086383528273455707, 0.0086356489763328576, 0.0086330209121274239, 0.0086304689947945042, 0.0086279900391416486, 0.0086255722564946326, 0.0086232205527422591, 0.0086209284328616683, 0.0086186991755237818, 0.0086165290277409722, 0.0086144190039277955, 0.0086123656401874624, 0.0086103644097383133, 0.008608418838796119, 0.0086065244507806237, 0.0086046799906567568], 'loss': [0.010276523586442739, 0.010217386586952225, 0.010156647929579441, 0.010095148284924712, 0.010035271740895734, 0.0099778124185641928, 0.0099230374546736468, 0.0098703965383279014, 0.0098200348573928599, 0.009771906007161409, 0.0097261800453039352, 0.0096829058241829531, 0.0096419006723454919, 0.0096030986444828846, 0.0095663349898034034, 0.0095314328154044135, 0.0094980466956319665, 0.0094658342186079922, 0.0094348668111070358, 0.0094051201322379839, 0.0093758344603330351, 0.0093449871980235411, 0.0093148702076683767, 0.0092861572768225507, 0.0092587361516363424, 0.0092324730588126645, 0.0092072419326502848, 0.0091829587829647865, 0.0091596845876295001, 0.0091373198084675165, 0.0091159616333112512, 0.0090955777028512569, 0.0090761458479467899, 0.0090575642201456471, 0.0090398395407690763, 0.0090229268092490364, 0.0090067718686340191, 0.0089913531937524816, 0.0089766012828684915, 0.0089624827989842459, 0.008948991055123522, 0.0089360767678937515, 0.0089237001434325728, 0.008911810268103601, 0.0089004501842360733, 0.0088895549596995395, 0.008879091181364724, 0.0088690507060263744, 0.0088594015956740112, 0.0088501413477001991, 0.0088412343165490924, 0.008832676598908679, 0.0088244476387095219, 0.0088165261431814128, 0.0088089052467539997, 0.008801555218084612, 0.0087944770085304231, 0.0087876609385187602, 0.0087810927434162113, 0.0087747548385703564, 0.0087686316198918382, 0.0087627151176177722, 0.0087569923773774278, 0.0087514670792401533, 0.0087461187426955619, 0.0087409427706621589, 0.0087359453898928404, 0.0087310805397031489, 0.0087263327934530219, 0.0087216436209245265, 0.0087169308630954505, 0.0087123275571345336, 0.0087078391862248968, 0.0087034695231674557, 0.0086992456226826602, 0.0086951528589419222, 0.0086911950825948846, 0.0086873632757830041, 0.0086836521951659147, 0.0086800643456407169, 0.0086765864528555326, 0.0086732123518785086, 0.0086699389344849463, 0.0086667667725195009, 0.0086636769533221455, 0.0086606888360382227, 0.0086577814776443527, 0.0086549651026542589, 0.0086522263056325564, 0.0086495599588671205, 0.0086469722135517953, 0.0086444572195841195, 0.0086419890579191097, 0.0086395918278878783, 0.0086372554904398328, 0.0086349832362277272, 0.0086327687240152478, 0.0086306122411557631, 0.0086285195501719283, 0.0086264735884556912, 0.0086244797126859996, 0.0086225414947453793]}
[2017-10-20 01:41:54,832 AE_UNIGRAMA_3L_UNDER_02.py:95]: done!
[2017-10-20 01:41:54,832 AE_UNIGRAMA_3L_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-10-20 01:41:54,832 AE_UNIGRAMA_3L_UNDER_02.py:100]: =======================================
[2017-10-20 01:41:54,833 AE_UNIGRAMA_3L_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f87e4f55898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:41:54,868 AE_UNIGRAMA_3L_UNDER_02.py:113]: training ... 
[2017-10-20 01:42:45,703 AE_UNIGRAMA_3L_UNDER_02.py:125]: trained!
[2017-10-20 01:42:45,704 AE_UNIGRAMA_3L_UNDER_02.py:128]: Training history: 
{'val_loss': [0.010251403723923025, 0.010190397348656531, 0.010127720433429271, 0.010065654448500131, 0.010005729300658942, 0.0099486267768871383, 0.0098939163534171523, 0.0098414456637984753, 0.0097911641050171683, 0.0097431428799731132, 0.0096976915824479766, 0.0096545961675092197, 0.0096137994540280575, 0.0095751614908802015, 0.0095384842456495006, 0.009503552340469618, 0.009469906030894433, 0.0094374333643337163, 0.0094063129469918495, 0.0093762514884254741, 0.0093455263223069743, 0.0093143819363919328, 0.0092846921343896476, 0.0092563460542920799, 0.0092292526134438672, 0.0092032816898091584, 0.0091783025866325908, 0.0091543242778476721, 0.0091313222270860556, 0.0091092517724101433, 0.009088178719203489, 0.0090681061522557387, 0.0090489215754166411, 0.0090306122340677395, 0.009013136606455736, 0.0089964549053723492, 0.0089805372419410473, 0.0089653259087838656, 0.008950769994754108, 0.0089368615507193216, 0.0089235650548593701, 0.0089108219446413575, 0.0088985838674590489, 0.0088869118578316555, 0.008875719368540886, 0.0088649786849502744, 0.0088546794690330232, 0.0088447864101611103, 0.0088353002561623283, 0.0088261786128176183, 0.0088174273727330138, 0.0088090171559703397, 0.0088009212623076805, 0.0087931472669636, 0.0087856538974607299, 0.0087784409010609726, 0.0087714955820026898, 0.0087648188439111291, 0.0087583771799465988, 0.0087521577108526753, 0.0087461680776290737, 0.0087403691543411592, 0.0087347783037499422, 0.0087293756668729416, 0.0087241476027772775, 0.0087191034419995261, 0.0087142124924407122, 0.0087094446921160227, 0.0087047702594760627, 0.0087001048042317751, 0.0086954863375004344, 0.0086909866403635985, 0.0086866085067889946, 0.008682380998195547, 0.0086782921770359057, 0.0086743412989444442, 0.0086705203074615676, 0.0086668164271958264, 0.0086632413637294653, 0.008659780087801161, 0.0086564282959389425, 0.0086531811411108221, 0.0086500336620333462, 0.0086469722212358033, 0.0086440150193233031, 0.0086411419307266032, 0.0086383528273455707, 0.0086356489763328576, 0.0086330209121274239, 0.0086304689947945042, 0.0086279900391416486, 0.0086255722564946326, 0.0086232205527422591, 0.0086209284328616683, 0.0086186991755237818, 0.0086165290277409722, 0.0086144190039277955, 0.0086123656401874624, 0.0086103644097383133, 0.008608418838796119, 0.0086065244507806237, 0.0086046799906567568], 'loss': [0.010276523586442739, 0.010217386586952225, 0.010156647929579441, 0.010095148284924712, 0.010035271740895734, 0.0099778124185641928, 0.0099230374546736468, 0.0098703965383279014, 0.0098200348573928599, 0.009771906007161409, 0.0097261800453039352, 0.0096829058241829531, 0.0096419006723454919, 0.0096030986444828846, 0.0095663349898034034, 0.0095314328154044135, 0.0094980466956319665, 0.0094658342186079922, 0.0094348668111070358, 0.0094051201322379839, 0.0093758344603330351, 0.0093449871980235411, 0.0093148702076683767, 0.0092861572768225507, 0.0092587361516363424, 0.0092324730588126645, 0.0092072419326502848, 0.0091829587829647865, 0.0091596845876295001, 0.0091373198084675165, 0.0091159616333112512, 0.0090955777028512569, 0.0090761458479467899, 0.0090575642201456471, 0.0090398395407690763, 0.0090229268092490364, 0.0090067718686340191, 0.0089913531937524816, 0.0089766012828684915, 0.0089624827989842459, 0.008948991055123522, 0.0089360767678937515, 0.0089237001434325728, 0.008911810268103601, 0.0089004501842360733, 0.0088895549596995395, 0.008879091181364724, 0.0088690507060263744, 0.0088594015956740112, 0.0088501413477001991, 0.0088412343165490924, 0.008832676598908679, 0.0088244476387095219, 0.0088165261431814128, 0.0088089052467539997, 0.008801555218084612, 0.0087944770085304231, 0.0087876609385187602, 0.0087810927434162113, 0.0087747548385703564, 0.0087686316198918382, 0.0087627151176177722, 0.0087569923773774278, 0.0087514670792401533, 0.0087461187426955619, 0.0087409427706621589, 0.0087359453898928404, 0.0087310805397031489, 0.0087263327934530219, 0.0087216436209245265, 0.0087169308630954505, 0.0087123275571345336, 0.0087078391862248968, 0.0087034695231674557, 0.0086992456226826602, 0.0086951528589419222, 0.0086911950825948846, 0.0086873632757830041, 0.0086836521951659147, 0.0086800643456407169, 0.0086765864528555326, 0.0086732123518785086, 0.0086699389344849463, 0.0086667667725195009, 0.0086636769533221455, 0.0086606888360382227, 0.0086577814776443527, 0.0086549651026542589, 0.0086522263056325564, 0.0086495599588671205, 0.0086469722135517953, 0.0086444572195841195, 0.0086419890579191097, 0.0086395918278878783, 0.0086372554904398328, 0.0086349832362277272, 0.0086327687240152478, 0.0086306122411557631, 0.0086285195501719283, 0.0086264735884556912, 0.0086244797126859996, 0.0086225414947453793]}
[2017-10-20 01:42:45,704 AE_UNIGRAMA_3L_UNDER_02.py:132]: evaluating model ... 
[2017-10-20 01:42:45,752 AE_UNIGRAMA_3L_UNDER_02.py:136]: evaluated! 
[2017-10-20 01:42:45,752 AE_UNIGRAMA_3L_UNDER_02.py:138]: generating reports ... 
[2017-10-20 01:42:46,371 AE_UNIGRAMA_3L_UNDER_02.py:141]: done!
[2017-10-20 01:42:46,372 AE_UNIGRAMA_3L_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_3L_UNDER_02 finished!
