[2017-11-13 15:59:40,997 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_FULLDS_UNDER_02
[2017-11-13 15:59:40,997 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-13 15:59:40,997 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_FULLDS_UNDER_02
	layers = 96,76,69,63
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fde907ffeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fde90804400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 15:59:40,998 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-13 15:59:43,489 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 15:59:43,489 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-13 15:59:43,489 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:60]: =======================================
[2017-11-13 15:59:43,489 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fde907ffeb8>, 'discard_decoder_function': True}
[2017-11-13 15:59:43,573 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-13 16:02:26,321 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-13 16:02:26,322 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0087773793519709715, 0.0081331084414944192, 0.007606284068407917, 0.0071969033449611674, 0.0068863154577556143, 0.0066475608243714117, 0.0064617590419126644, 0.0063157240495302028, 0.0061989451357420539, 0.0061036747796765611, 0.0060247477420901103, 0.0059579415142451278, 0.0059003509632087571, 0.0058505034374702241, 0.0058067399866054796, 0.0057675667680924551, 0.0057270071848827177, 0.0056870690749212692, 0.0056528711712206222, 0.0056232866039277168, 0.0055974419689088653, 0.0055746654265391472, 0.0055541907587232054, 0.0055358077672223579, 0.0055194058938472859, 0.0055047822425649175, 0.0054916536286767625, 0.0054797987363450788, 0.005469017586808067, 0.0054591241635269907, 0.0054500171794388029, 0.0054415863114095969, 0.005433758900534034, 0.0054264769686446918, 0.0054196866590444795, 0.0054132727123502589, 0.005407195056791019, 0.0054013876512082615, 0.005395814128413807, 0.0053904465228888712, 0.0053852539052943764, 0.0053802102240119425, 0.0053753132214143361, 0.0053705381539618426, 0.0053658424481305951, 0.0053611988155872932, 0.0053565598755954428, 0.0053519452109149785, 0.0053473803381928788, 0.0053428493405752861, 0.0053383350069916994, 0.0053338420926293756, 0.0053293696429768016, 0.0053249077002241662, 0.0053204678916993582, 0.005316057802838209, 0.0053116674239766732, 0.005307334884833469, 0.0053030368028285967, 0.0052987625797610155, 0.0052945069104976591, 0.0052902591061353603, 0.0052860151614907555, 0.0052817905950128963, 0.005277574099056102, 0.0052733610748514964, 0.0052691534770298743, 0.0052649411319788215, 0.0052607231648506723, 0.0052565054666628809, 0.0052522823443168758, 0.0052480482425641996, 0.0052438046916181589, 0.0052395534232903638, 0.0052352783447134933, 0.0052309941616969016, 0.0052267000693020102, 0.0052223980392732249, 0.0052180847703954649, 0.0052137508921979627, 0.0052094025648096679, 0.0052050497534848099, 0.0052006785213284659, 0.0051962795066833774, 0.005191849035001095, 0.005187383867274506, 0.0051828843083825456, 0.0051783358458996377, 0.0051737355502327106, 0.005169066030190534, 0.0051643112548570482, 0.0051592088228989037, 0.0051536103864554669, 0.0051477587729992285, 0.0051416518106421364, 0.005135433424489408, 0.0051291330400217725, 0.0051226803904740863, 0.0051159112553705362, 0.0051090086528600819, 0.0051020070117580316], 'val_acc': [0.60271958838662254, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0091328969573033023, 0.0084537915599432849, 0.0078701465985059511, 0.007406151226885288, 0.007050978692633247, 0.006780367040083249, 0.0065712373654219884, 0.0064078482208338866, 0.006278545158394289, 0.006174188141089298, 0.0060883746206933254, 0.0060166447119092527, 0.0059553225406064779, 0.0059022461204767057, 0.0058560029162743072, 0.0058151252248944156, 0.0057764998189025829, 0.0057343627054464224, 0.0056967846898340778, 0.0056644332980639008, 0.0056363062843807496, 0.0056116793390303555, 0.0055897106285404397, 0.0055699372475817516, 0.0055522187562080721, 0.005536433687641425, 0.0055222951051918214, 0.0055095741443100064, 0.0054980293986284321, 0.0054874718744237798, 0.0054777740315448782, 0.0054688258494391198, 0.0054605347308422491, 0.0054528067662705636, 0.0054456265936456451, 0.0054388864166948665, 0.0054325140497451865, 0.0054264430995681684, 0.0054206368263055938, 0.0054150448461720863, 0.0054096518643063224, 0.0054044291031036702, 0.0053993560061360796, 0.0053944237116068999, 0.0053895934099886843, 0.0053848356533348855, 0.0053801081132231069, 0.0053754059336754874, 0.0053707432205080839, 0.0053661349860532224, 0.0053615593299982086, 0.005357011106520035, 0.005352487200026324, 0.0053479864455922305, 0.0053435019303739208, 0.0053390370578655652, 0.0053346023558875277, 0.0053302048662307259, 0.0053258615908192038, 0.0053215487954452884, 0.0053172560060165642, 0.0053129770793706611, 0.0053087109516370082, 0.0053044578077197733, 0.0053002179737590468, 0.0052959830752821171, 0.0052917566729659892, 0.00528752981824909, 0.0052832979715197303, 0.0052790700086924368, 0.0052748381260682344, 0.0052706012365706491, 0.0052663526655307054, 0.0052620951263242025, 0.005257827811317165, 0.0052535422340083907, 0.0052492559843571934, 0.0052449597456512261, 0.0052406531049283174, 0.0052363361472386703, 0.0052320009765169607, 0.005227656641464515, 0.0052232976802350974, 0.0052189232983409339, 0.0052145234678030684, 0.0052100907194647514, 0.005205625208908409, 0.0052011185587463029, 0.0051965568124003299, 0.0051919387619061286, 0.0051872550687172289, 0.0051824068405398075, 0.0051770411172637771, 0.0051713576434609734, 0.0051654018800076024, 0.005159234939189016, 0.0051529580889889525, 0.0051465864129578492, 0.0051399683152836785, 0.0051331029303177114, 0.0051261575630672457], 'acc': [0.41647232109247517, 0.59359273349959318, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268059583, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182]}
[2017-11-13 16:02:26,322 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:95]: done!
[2017-11-13 16:02:26,322 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-13 16:02:26,322 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:100]: =======================================
[2017-11-13 16:02:26,322 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fde90804400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 16:02:26,358 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:113]: training ... 
[2017-11-13 16:06:36,844 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:125]: trained!
[2017-11-13 16:06:36,845 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0087773793519709715, 0.0081331084414944192, 0.007606284068407917, 0.0071969033449611674, 0.0068863154577556143, 0.0066475608243714117, 0.0064617590419126644, 0.0063157240495302028, 0.0061989451357420539, 0.0061036747796765611, 0.0060247477420901103, 0.0059579415142451278, 0.0059003509632087571, 0.0058505034374702241, 0.0058067399866054796, 0.0057675667680924551, 0.0057270071848827177, 0.0056870690749212692, 0.0056528711712206222, 0.0056232866039277168, 0.0055974419689088653, 0.0055746654265391472, 0.0055541907587232054, 0.0055358077672223579, 0.0055194058938472859, 0.0055047822425649175, 0.0054916536286767625, 0.0054797987363450788, 0.005469017586808067, 0.0054591241635269907, 0.0054500171794388029, 0.0054415863114095969, 0.005433758900534034, 0.0054264769686446918, 0.0054196866590444795, 0.0054132727123502589, 0.005407195056791019, 0.0054013876512082615, 0.005395814128413807, 0.0053904465228888712, 0.0053852539052943764, 0.0053802102240119425, 0.0053753132214143361, 0.0053705381539618426, 0.0053658424481305951, 0.0053611988155872932, 0.0053565598755954428, 0.0053519452109149785, 0.0053473803381928788, 0.0053428493405752861, 0.0053383350069916994, 0.0053338420926293756, 0.0053293696429768016, 0.0053249077002241662, 0.0053204678916993582, 0.005316057802838209, 0.0053116674239766732, 0.005307334884833469, 0.0053030368028285967, 0.0052987625797610155, 0.0052945069104976591, 0.0052902591061353603, 0.0052860151614907555, 0.0052817905950128963, 0.005277574099056102, 0.0052733610748514964, 0.0052691534770298743, 0.0052649411319788215, 0.0052607231648506723, 0.0052565054666628809, 0.0052522823443168758, 0.0052480482425641996, 0.0052438046916181589, 0.0052395534232903638, 0.0052352783447134933, 0.0052309941616969016, 0.0052267000693020102, 0.0052223980392732249, 0.0052180847703954649, 0.0052137508921979627, 0.0052094025648096679, 0.0052050497534848099, 0.0052006785213284659, 0.0051962795066833774, 0.005191849035001095, 0.005187383867274506, 0.0051828843083825456, 0.0051783358458996377, 0.0051737355502327106, 0.005169066030190534, 0.0051643112548570482, 0.0051592088228989037, 0.0051536103864554669, 0.0051477587729992285, 0.0051416518106421364, 0.005135433424489408, 0.0051291330400217725, 0.0051226803904740863, 0.0051159112553705362, 0.0051090086528600819, 0.0051020070117580316], 'val_acc': [0.60271958838662254, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0091328969573033023, 0.0084537915599432849, 0.0078701465985059511, 0.007406151226885288, 0.007050978692633247, 0.006780367040083249, 0.0065712373654219884, 0.0064078482208338866, 0.006278545158394289, 0.006174188141089298, 0.0060883746206933254, 0.0060166447119092527, 0.0059553225406064779, 0.0059022461204767057, 0.0058560029162743072, 0.0058151252248944156, 0.0057764998189025829, 0.0057343627054464224, 0.0056967846898340778, 0.0056644332980639008, 0.0056363062843807496, 0.0056116793390303555, 0.0055897106285404397, 0.0055699372475817516, 0.0055522187562080721, 0.005536433687641425, 0.0055222951051918214, 0.0055095741443100064, 0.0054980293986284321, 0.0054874718744237798, 0.0054777740315448782, 0.0054688258494391198, 0.0054605347308422491, 0.0054528067662705636, 0.0054456265936456451, 0.0054388864166948665, 0.0054325140497451865, 0.0054264430995681684, 0.0054206368263055938, 0.0054150448461720863, 0.0054096518643063224, 0.0054044291031036702, 0.0053993560061360796, 0.0053944237116068999, 0.0053895934099886843, 0.0053848356533348855, 0.0053801081132231069, 0.0053754059336754874, 0.0053707432205080839, 0.0053661349860532224, 0.0053615593299982086, 0.005357011106520035, 0.005352487200026324, 0.0053479864455922305, 0.0053435019303739208, 0.0053390370578655652, 0.0053346023558875277, 0.0053302048662307259, 0.0053258615908192038, 0.0053215487954452884, 0.0053172560060165642, 0.0053129770793706611, 0.0053087109516370082, 0.0053044578077197733, 0.0053002179737590468, 0.0052959830752821171, 0.0052917566729659892, 0.00528752981824909, 0.0052832979715197303, 0.0052790700086924368, 0.0052748381260682344, 0.0052706012365706491, 0.0052663526655307054, 0.0052620951263242025, 0.005257827811317165, 0.0052535422340083907, 0.0052492559843571934, 0.0052449597456512261, 0.0052406531049283174, 0.0052363361472386703, 0.0052320009765169607, 0.005227656641464515, 0.0052232976802350974, 0.0052189232983409339, 0.0052145234678030684, 0.0052100907194647514, 0.005205625208908409, 0.0052011185587463029, 0.0051965568124003299, 0.0051919387619061286, 0.0051872550687172289, 0.0051824068405398075, 0.0051770411172637771, 0.0051713576434609734, 0.0051654018800076024, 0.005159234939189016, 0.0051529580889889525, 0.0051465864129578492, 0.0051399683152836785, 0.0051331029303177114, 0.0051261575630672457], 'acc': [0.41647232109247517, 0.59359273349959318, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268059583, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182]}
[2017-11-13 16:06:36,845 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-13 16:06:37,000 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-13 16:06:37,000 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-13 16:06:38,163 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:141]: done!
[2017-11-13 16:06:38,164 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_3L_FULLDS_UNDER_02 finished!
[2017-11-14 07:04:12,092 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_3L_FULLDS_UNDER_02 was already executed!
[2017-11-18 14:56:01,016 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_3L_FULLDS_UNDER_02 was already executed!
[2017-11-18 16:22:30,992 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_3L_FULLDS_UNDER_02 was already executed!
[2017-11-18 17:26:08,402 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_FULLDS_UNDER_02
[2017-11-18 17:26:08,402 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 17:26:08,402 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_FULLDS_UNDER_02
	layers = 96,76,69,63
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fcccfba2be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fcccfba2470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:26:08,402 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 17:26:10,671 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:26:10,671 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:26:10,671 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 17:26:10,672 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fcccfba2be0>, 'discard_decoder_function': True}
[2017-11-18 17:26:10,751 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 17:27:41,048 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 17:27:41,049 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0095326971277753386, 0.0089872574032541369, 0.0085184032173443256, 0.0081232146165569515, 0.0077914269918282217, 0.0075103025108189739, 0.0072701465165963377, 0.0070653855648317547, 0.0068908473083154542, 0.0067412253792333669, 0.0066120062435496953, 0.006500236923645159, 0.0064041128264687398, 0.0063209883180384971, 0.0062490376655473748, 0.0061865092377708548, 0.006132017800366066, 0.0060845121405183594, 0.0060429006644847393, 0.0060062723243537192, 0.005973785528136182, 0.0059441281771797309, 0.0059169239551273888, 0.0058919730547812819, 0.0058688833596453873, 0.0058470711544825558, 0.0058260280265000838, 0.0058043807200253697, 0.0057847155914366385, 0.0057670215345153814, 0.0057510457016857605, 0.0057364908240917622, 0.005723206460964002, 0.005710980091319282, 0.0056992112608432758, 0.0056883727744713192, 0.005678454704941392, 0.0056693595478969029, 0.0056609539769470786, 0.0056531121560708863, 0.0056457180766514049, 0.0056385551984033432, 0.0056315196358189068, 0.0056244893587724561, 0.005616967134706153, 0.0056097661999000518, 0.0056030860608659253, 0.005596871059357118, 0.0055910537171854242, 0.0055855721080739383, 0.0055803800340076494, 0.0055754333334909574, 0.0055706772155093166, 0.0055659792252680381, 0.0055612555969587274, 0.0055565682286208371, 0.0055518180316054657, 0.0055468340881116816, 0.0055416391508531226, 0.005536162699355399, 0.0055300183468441812, 0.00552195036133155, 0.0055137254285411511, 0.0055054540374377542, 0.0054977264218319865, 0.0054904436111588477, 0.005483504331447198, 0.0054768297901888439, 0.0054704687465358774, 0.0054644169861766366, 0.0054586461699166937, 0.0054531219231053083, 0.0054478138074784029, 0.0054426972403641806, 0.0054377380239810464, 0.0054329061643341994, 0.0054281743953380297, 0.0054235190777939795, 0.0054188842209379811, 0.0054139572820184325, 0.0053995759697861691, 0.0053769780776591119, 0.0053571604301099474, 0.0053401165053991824, 0.0053252436512261792, 0.0053121405267743654, 0.0053004568689309396, 0.0052899239767576923, 0.0052803337512567269, 0.0052715186857115598, 0.005263361713370854, 0.0052557358716247282, 0.0052485574353951792, 0.0052417636490798324, 0.0052352733631987631, 0.005229056211365048, 0.005223049418381232, 0.0052172234181782932, 0.0052115504357119072, 0.0052059972275408564, 0.0052005557389741639], 'val_acc': [0.57148107313487684, 0.60345461227489894, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.009833750343817874, 0.0092578270467213366, 0.0087516885261095141, 0.0083216134608761292, 0.0079601851208619036, 0.0076557925081641174, 0.0073972313198563556, 0.0071766375210463116, 0.0069887927922324062, 0.00682855361470834, 0.0066905122716608544, 0.0065713822512417702, 0.00646861592197716, 0.0063801835201007578, 0.0063036721278285157, 0.0062373645065348432, 0.0061797667453638233, 0.0061295693089797538, 0.0060857745644578038, 0.0060473715671447541, 0.0060135069166837012, 0.0059831211219604713, 0.0059552095933666773, 0.0059296141404416667, 0.0059061074105635648, 0.0058840933523119244, 0.005863192369430943, 0.0058419703473010622, 0.0058215694838424457, 0.0058032329744330483, 0.005786709636790472, 0.0057717867834511582, 0.0057581750830589477, 0.0057457546228882441, 0.0057340613775535079, 0.0057229782557895728, 0.0057128736528892507, 0.0057036170793798519, 0.0056950934618808409, 0.0056871926717549778, 0.0056797954584450732, 0.005672756119637975, 0.0056658777058727211, 0.0056590795049077346, 0.0056520013804078227, 0.005644724396475476, 0.005637949326879132, 0.005631649206417959, 0.0056257596923850227, 0.0056202350952173829, 0.0056150143129180194, 0.0056100515395515393, 0.0056053158629704386, 0.0056007086510613526, 0.0055960871534618886, 0.0055914693233094417, 0.0055868684840496624, 0.0055821066743650689, 0.0055771204015363307, 0.0055719009491752057, 0.0055662617937294644, 0.0055592378650701517, 0.0055511857769222836, 0.005543044220820313, 0.0055351576401940208, 0.0055278045419323288, 0.0055208568587214232, 0.0055142018285686181, 0.005507823591325965, 0.0055017679067456832, 0.0054960081682895881, 0.0054905062214539646, 0.0054852392158559185, 0.005480164669319664, 0.0054752664694045165, 0.0054705010188510952, 0.0054658431014176622, 0.0054612748569047445, 0.0054567564882766042, 0.005452174547880456, 0.0054438638959157255, 0.0054236437864276961, 0.0054021185186600247, 0.005383560836600485, 0.0053674951793583198, 0.0053534012135130595, 0.0053409063114383528, 0.0053297070053256197, 0.0053195737519387094, 0.0053103112848161211, 0.0053017644042578325, 0.0052938302516469934, 0.0052863938364241334, 0.0052793747762601533, 0.0052727160880341444, 0.0052663459855460913, 0.005260238357583785, 0.0052543327026743619, 0.0052486053188754963, 0.0052430086799571344, 0.0052375397045927551], 'acc': [0.22818215294704855, 0.59064686392017041, 0.59371547808277836, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822267327968, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.59383822262206665, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822267327968, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353]}
[2017-11-18 17:27:41,049 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:95]: done!
[2017-11-18 17:27:41,049 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 17:27:41,049 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 17:27:41,049 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fcccfba2470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:27:41,087 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 17:31:39,847 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 17:31:39,848 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0095326971277753386, 0.0089872574032541369, 0.0085184032173443256, 0.0081232146165569515, 0.0077914269918282217, 0.0075103025108189739, 0.0072701465165963377, 0.0070653855648317547, 0.0068908473083154542, 0.0067412253792333669, 0.0066120062435496953, 0.006500236923645159, 0.0064041128264687398, 0.0063209883180384971, 0.0062490376655473748, 0.0061865092377708548, 0.006132017800366066, 0.0060845121405183594, 0.0060429006644847393, 0.0060062723243537192, 0.005973785528136182, 0.0059441281771797309, 0.0059169239551273888, 0.0058919730547812819, 0.0058688833596453873, 0.0058470711544825558, 0.0058260280265000838, 0.0058043807200253697, 0.0057847155914366385, 0.0057670215345153814, 0.0057510457016857605, 0.0057364908240917622, 0.005723206460964002, 0.005710980091319282, 0.0056992112608432758, 0.0056883727744713192, 0.005678454704941392, 0.0056693595478969029, 0.0056609539769470786, 0.0056531121560708863, 0.0056457180766514049, 0.0056385551984033432, 0.0056315196358189068, 0.0056244893587724561, 0.005616967134706153, 0.0056097661999000518, 0.0056030860608659253, 0.005596871059357118, 0.0055910537171854242, 0.0055855721080739383, 0.0055803800340076494, 0.0055754333334909574, 0.0055706772155093166, 0.0055659792252680381, 0.0055612555969587274, 0.0055565682286208371, 0.0055518180316054657, 0.0055468340881116816, 0.0055416391508531226, 0.005536162699355399, 0.0055300183468441812, 0.00552195036133155, 0.0055137254285411511, 0.0055054540374377542, 0.0054977264218319865, 0.0054904436111588477, 0.005483504331447198, 0.0054768297901888439, 0.0054704687465358774, 0.0054644169861766366, 0.0054586461699166937, 0.0054531219231053083, 0.0054478138074784029, 0.0054426972403641806, 0.0054377380239810464, 0.0054329061643341994, 0.0054281743953380297, 0.0054235190777939795, 0.0054188842209379811, 0.0054139572820184325, 0.0053995759697861691, 0.0053769780776591119, 0.0053571604301099474, 0.0053401165053991824, 0.0053252436512261792, 0.0053121405267743654, 0.0053004568689309396, 0.0052899239767576923, 0.0052803337512567269, 0.0052715186857115598, 0.005263361713370854, 0.0052557358716247282, 0.0052485574353951792, 0.0052417636490798324, 0.0052352733631987631, 0.005229056211365048, 0.005223049418381232, 0.0052172234181782932, 0.0052115504357119072, 0.0052059972275408564, 0.0052005557389741639], 'val_acc': [0.57148107313487684, 0.60345461227489894, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.009833750343817874, 0.0092578270467213366, 0.0087516885261095141, 0.0083216134608761292, 0.0079601851208619036, 0.0076557925081641174, 0.0073972313198563556, 0.0071766375210463116, 0.0069887927922324062, 0.00682855361470834, 0.0066905122716608544, 0.0065713822512417702, 0.00646861592197716, 0.0063801835201007578, 0.0063036721278285157, 0.0062373645065348432, 0.0061797667453638233, 0.0061295693089797538, 0.0060857745644578038, 0.0060473715671447541, 0.0060135069166837012, 0.0059831211219604713, 0.0059552095933666773, 0.0059296141404416667, 0.0059061074105635648, 0.0058840933523119244, 0.005863192369430943, 0.0058419703473010622, 0.0058215694838424457, 0.0058032329744330483, 0.005786709636790472, 0.0057717867834511582, 0.0057581750830589477, 0.0057457546228882441, 0.0057340613775535079, 0.0057229782557895728, 0.0057128736528892507, 0.0057036170793798519, 0.0056950934618808409, 0.0056871926717549778, 0.0056797954584450732, 0.005672756119637975, 0.0056658777058727211, 0.0056590795049077346, 0.0056520013804078227, 0.005644724396475476, 0.005637949326879132, 0.005631649206417959, 0.0056257596923850227, 0.0056202350952173829, 0.0056150143129180194, 0.0056100515395515393, 0.0056053158629704386, 0.0056007086510613526, 0.0055960871534618886, 0.0055914693233094417, 0.0055868684840496624, 0.0055821066743650689, 0.0055771204015363307, 0.0055719009491752057, 0.0055662617937294644, 0.0055592378650701517, 0.0055511857769222836, 0.005543044220820313, 0.0055351576401940208, 0.0055278045419323288, 0.0055208568587214232, 0.0055142018285686181, 0.005507823591325965, 0.0055017679067456832, 0.0054960081682895881, 0.0054905062214539646, 0.0054852392158559185, 0.005480164669319664, 0.0054752664694045165, 0.0054705010188510952, 0.0054658431014176622, 0.0054612748569047445, 0.0054567564882766042, 0.005452174547880456, 0.0054438638959157255, 0.0054236437864276961, 0.0054021185186600247, 0.005383560836600485, 0.0053674951793583198, 0.0053534012135130595, 0.0053409063114383528, 0.0053297070053256197, 0.0053195737519387094, 0.0053103112848161211, 0.0053017644042578325, 0.0052938302516469934, 0.0052863938364241334, 0.0052793747762601533, 0.0052727160880341444, 0.0052663459855460913, 0.005260238357583785, 0.0052543327026743619, 0.0052486053188754963, 0.0052430086799571344, 0.0052375397045927551], 'acc': [0.22818215294704855, 0.59064686392017041, 0.59371547808277836, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822267327968, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.59383822262206665, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822267327968, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353]}
[2017-11-18 17:31:39,848 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 17:31:39,924 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 17:31:39,924 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 17:31:40,883 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:141]: done!
[2017-11-18 17:31:40,883 AE_UNIGRAMA_3L_FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_3L_FULLDS_UNDER_02 finished!
