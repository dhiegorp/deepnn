[2017-10-20 01:36:20,877 AE_UNIGRAMA_3L_UNDER_03.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_3L_UNDER_03
[2017-10-20 01:36:20,877 AE_UNIGRAMA_3L_UNDER_03.py:148]: >> Printing header log
[2017-10-20 01:36:20,877 AE_UNIGRAMA_3L_UNDER_03.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_UNDER_03
	layers = 96,86,78,71,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f7dad591b00>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f7dad591c88>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:36:20,877 AE_UNIGRAMA_3L_UNDER_03.py:150]: >> Loading dataset... 
[2017-10-20 01:36:21,476 AE_UNIGRAMA_3L_UNDER_03.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:36:21,476 AE_UNIGRAMA_3L_UNDER_03.py:152]: >> Executing autoencoder part ... 
[2017-10-20 01:36:21,476 AE_UNIGRAMA_3L_UNDER_03.py:59]: =======================================
[2017-10-20 01:36:21,476 AE_UNIGRAMA_3L_UNDER_03.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f7dad591b00>, 'discard_decoder_function': True}
[2017-10-20 01:36:21,584 AE_UNIGRAMA_3L_UNDER_03.py:75]: training and evaluate autoencoder
[2017-10-20 01:36:51,610 AE_UNIGRAMA_3L_UNDER_03.py:87]: trained and evaluated!
[2017-10-20 01:36:51,611 AE_UNIGRAMA_3L_UNDER_03.py:90]: Training history: 
{'val_loss': [0.01031038846446679, 0.010215831155365949, 0.010062268152694499, 0.0099088415870491452, 0.0097571682863519093, 0.0096093658807940192, 0.0094657231530790881, 0.0093200273853363165, 0.0091789506278849003, 0.0090434308298846158, 0.0089135093988372931, 0.0087887173393900505, 0.0086688984593992786, 0.0085540285825618581, 0.0084438723162315148, 0.0083382410623936403, 0.0082367713386573751, 0.0081393297200807856, 0.0080456805145402606, 0.0079556193088482531, 0.0078689309172886232, 0.0077853904548880115, 0.0077048835940105101, 0.0076271863723499185, 0.0075520558982090438, 0.0074794072706293882, 0.0074093159007732534, 0.0073418364510438698, 0.0072768569636577568, 0.0072143065819315969, 0.0071541430310910516, 0.0070960898658599999, 0.0070401382802199701, 0.0069861504418920854, 0.006934066884718198, 0.0068838730987618403, 0.0068354597159394764, 0.0067887833293485819, 0.0067437306967421977, 0.0067002729211542685, 0.0066583465930199091, 0.0066179039534943031, 0.0065788589244826137, 0.0065411815946042314, 0.0065047561163325074, 0.0064696099844563848, 0.0064356538664452649, 0.0064028339740927554, 0.0063710802002744163, 0.0063403945997855919, 0.0063107188489828188, 0.006282006430207686, 0.0062541646785951015, 0.0062271465640861305, 0.0062009670276568724, 0.0061755865313749773, 0.0061510515565461167, 0.0061272976739976046, 0.0061042719229806534, 0.0060819879790497975, 0.0060603983551402296, 0.0060395000270502056, 0.0060192639627892064, 0.0059996474219216065, 0.005980652308638543, 0.005962288178517362, 0.0059444687214981222, 0.0059272060447742945, 0.0059104800591293768, 0.0058942702373829033, 0.0058785574476071896, 0.0058633212647556596, 0.0058485555763747614, 0.0058342120160095974, 0.0058202978143932433, 0.005806801830276459, 0.0057937130955182927, 0.0057810134095136337, 0.0057686802231772458, 0.0057567093888346152, 0.0057450947040158795, 0.0057337914929347852, 0.0057228256231623958, 0.0057121728318414505, 0.0057018129068485647, 0.0056917561723618705, 0.0056819853244771748, 0.0056724907539535633, 0.0056632702034589968, 0.0056543065629705621, 0.00564559493006162, 0.0056371277364379415, 0.0056288842350715376, 0.0056208702874089482, 0.0056130882321431073, 0.0056055135986868114, 0.0055981462208561077, 0.0055909696637503944, 0.0055840037240331725, 0.0055772219126746332, 0.0055706243525816606, 0.0055641941206882881], 'loss': [0.010329833826635172, 0.010269235338175415, 0.010134263096930208, 0.009979250799056278, 0.0098252336723019026, 0.0096740695002781301, 0.0095273520976085196, 0.009382006964121373, 0.0092371321914656874, 0.0090980608212019153, 0.0089645339937373478, 0.0088363539361118459, 0.0087132545917328694, 0.0085951356508053006, 0.0084819295068661281, 0.0083733361463973182, 0.0082691024803426567, 0.0081689446739802059, 0.0080727412936076777, 0.0079802424791735518, 0.0078912146862300907, 0.0078054961291059953, 0.0077228857159669512, 0.0076432163871769793, 0.0075662252659203641, 0.0074917322617727112, 0.0074197947226244936, 0.0073504318410476882, 0.0072836846730842978, 0.0072193779812618564, 0.0071574563730666075, 0.0070978663003125947, 0.0070403394548047265, 0.0069848752203360244, 0.0069313325562022658, 0.0068796741591277636, 0.0068298839710964222, 0.0067818557543619399, 0.0067355193517708344, 0.0066907917760133965, 0.0066476431755393686, 0.0066059943375572075, 0.0065657958762116901, 0.0065269768716035882, 0.0064894963197808511, 0.006453251410916805, 0.0064182710225940591, 0.0063844538358462022, 0.0063517535581598637, 0.0063201065945708646, 0.0062895225596825404, 0.0062599191344821095, 0.0062312429725606341, 0.0062034320757113574, 0.006176453722571037, 0.0061503138159045099, 0.0061249673617265309, 0.006100456334522295, 0.006076709142661142, 0.0060536980024494856, 0.0060314130491377314, 0.0060098250920311326, 0.0059889222646375964, 0.0059686740279339652, 0.0059490275921869036, 0.0059300073389291358, 0.005911591719806231, 0.0058937354031068714, 0.0058764187380392161, 0.0058596351873141054, 0.0058433654931040174, 0.0058275807932816042, 0.0058122620647103416, 0.0057974144245126384, 0.0057829899075724405, 0.0057689958843319565, 0.0057554011752333246, 0.0057422259345091993, 0.0057294271624754121, 0.0057170049527221541, 0.0057049401816537063, 0.0056932241347925792, 0.005681822698084797, 0.0056707500125216829, 0.0056599913240532309, 0.005649515572184332, 0.0056393598143375393, 0.0056294675148822046, 0.0056198685528446026, 0.0056105314604548784, 0.0056014598642613852, 0.0055926328389856736, 0.0055840525289020913, 0.0055756949294145557, 0.0055675677423947566, 0.0055596723499437128, 0.0055519707867853945, 0.0055445072355038488, 0.0055372054507176281, 0.0055301237205122433, 0.0055232265859398106, 0.0055165058021910476]}
[2017-10-20 01:36:51,611 AE_UNIGRAMA_3L_UNDER_03.py:94]: done!
[2017-10-20 01:36:51,611 AE_UNIGRAMA_3L_UNDER_03.py:154]: >> Executing classifier part ... 
[2017-10-20 01:36:51,611 AE_UNIGRAMA_3L_UNDER_03.py:99]: =======================================
[2017-10-20 01:36:51,611 AE_UNIGRAMA_3L_UNDER_03.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f7dad591c88>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:36:51,645 AE_UNIGRAMA_3L_UNDER_03.py:112]: training ... 
[2017-10-20 01:37:46,570 AE_UNIGRAMA_3L_UNDER_03.py:124]: trained!
[2017-10-20 01:37:46,570 AE_UNIGRAMA_3L_UNDER_03.py:127]: Training history: 
{'val_loss': [0.01031038846446679, 0.010215831155365949, 0.010062268152694499, 0.0099088415870491452, 0.0097571682863519093, 0.0096093658807940192, 0.0094657231530790881, 0.0093200273853363165, 0.0091789506278849003, 0.0090434308298846158, 0.0089135093988372931, 0.0087887173393900505, 0.0086688984593992786, 0.0085540285825618581, 0.0084438723162315148, 0.0083382410623936403, 0.0082367713386573751, 0.0081393297200807856, 0.0080456805145402606, 0.0079556193088482531, 0.0078689309172886232, 0.0077853904548880115, 0.0077048835940105101, 0.0076271863723499185, 0.0075520558982090438, 0.0074794072706293882, 0.0074093159007732534, 0.0073418364510438698, 0.0072768569636577568, 0.0072143065819315969, 0.0071541430310910516, 0.0070960898658599999, 0.0070401382802199701, 0.0069861504418920854, 0.006934066884718198, 0.0068838730987618403, 0.0068354597159394764, 0.0067887833293485819, 0.0067437306967421977, 0.0067002729211542685, 0.0066583465930199091, 0.0066179039534943031, 0.0065788589244826137, 0.0065411815946042314, 0.0065047561163325074, 0.0064696099844563848, 0.0064356538664452649, 0.0064028339740927554, 0.0063710802002744163, 0.0063403945997855919, 0.0063107188489828188, 0.006282006430207686, 0.0062541646785951015, 0.0062271465640861305, 0.0062009670276568724, 0.0061755865313749773, 0.0061510515565461167, 0.0061272976739976046, 0.0061042719229806534, 0.0060819879790497975, 0.0060603983551402296, 0.0060395000270502056, 0.0060192639627892064, 0.0059996474219216065, 0.005980652308638543, 0.005962288178517362, 0.0059444687214981222, 0.0059272060447742945, 0.0059104800591293768, 0.0058942702373829033, 0.0058785574476071896, 0.0058633212647556596, 0.0058485555763747614, 0.0058342120160095974, 0.0058202978143932433, 0.005806801830276459, 0.0057937130955182927, 0.0057810134095136337, 0.0057686802231772458, 0.0057567093888346152, 0.0057450947040158795, 0.0057337914929347852, 0.0057228256231623958, 0.0057121728318414505, 0.0057018129068485647, 0.0056917561723618705, 0.0056819853244771748, 0.0056724907539535633, 0.0056632702034589968, 0.0056543065629705621, 0.00564559493006162, 0.0056371277364379415, 0.0056288842350715376, 0.0056208702874089482, 0.0056130882321431073, 0.0056055135986868114, 0.0055981462208561077, 0.0055909696637503944, 0.0055840037240331725, 0.0055772219126746332, 0.0055706243525816606, 0.0055641941206882881], 'loss': [0.010329833826635172, 0.010269235338175415, 0.010134263096930208, 0.009979250799056278, 0.0098252336723019026, 0.0096740695002781301, 0.0095273520976085196, 0.009382006964121373, 0.0092371321914656874, 0.0090980608212019153, 0.0089645339937373478, 0.0088363539361118459, 0.0087132545917328694, 0.0085951356508053006, 0.0084819295068661281, 0.0083733361463973182, 0.0082691024803426567, 0.0081689446739802059, 0.0080727412936076777, 0.0079802424791735518, 0.0078912146862300907, 0.0078054961291059953, 0.0077228857159669512, 0.0076432163871769793, 0.0075662252659203641, 0.0074917322617727112, 0.0074197947226244936, 0.0073504318410476882, 0.0072836846730842978, 0.0072193779812618564, 0.0071574563730666075, 0.0070978663003125947, 0.0070403394548047265, 0.0069848752203360244, 0.0069313325562022658, 0.0068796741591277636, 0.0068298839710964222, 0.0067818557543619399, 0.0067355193517708344, 0.0066907917760133965, 0.0066476431755393686, 0.0066059943375572075, 0.0065657958762116901, 0.0065269768716035882, 0.0064894963197808511, 0.006453251410916805, 0.0064182710225940591, 0.0063844538358462022, 0.0063517535581598637, 0.0063201065945708646, 0.0062895225596825404, 0.0062599191344821095, 0.0062312429725606341, 0.0062034320757113574, 0.006176453722571037, 0.0061503138159045099, 0.0061249673617265309, 0.006100456334522295, 0.006076709142661142, 0.0060536980024494856, 0.0060314130491377314, 0.0060098250920311326, 0.0059889222646375964, 0.0059686740279339652, 0.0059490275921869036, 0.0059300073389291358, 0.005911591719806231, 0.0058937354031068714, 0.0058764187380392161, 0.0058596351873141054, 0.0058433654931040174, 0.0058275807932816042, 0.0058122620647103416, 0.0057974144245126384, 0.0057829899075724405, 0.0057689958843319565, 0.0057554011752333246, 0.0057422259345091993, 0.0057294271624754121, 0.0057170049527221541, 0.0057049401816537063, 0.0056932241347925792, 0.005681822698084797, 0.0056707500125216829, 0.0056599913240532309, 0.005649515572184332, 0.0056393598143375393, 0.0056294675148822046, 0.0056198685528446026, 0.0056105314604548784, 0.0056014598642613852, 0.0055926328389856736, 0.0055840525289020913, 0.0055756949294145557, 0.0055675677423947566, 0.0055596723499437128, 0.0055519707867853945, 0.0055445072355038488, 0.0055372054507176281, 0.0055301237205122433, 0.0055232265859398106, 0.0055165058021910476]}
[2017-10-20 01:37:46,570 AE_UNIGRAMA_3L_UNDER_03.py:131]: evaluating model ... 
[2017-10-20 01:37:46,624 AE_UNIGRAMA_3L_UNDER_03.py:135]: evaluated! 
[2017-10-20 01:37:46,624 AE_UNIGRAMA_3L_UNDER_03.py:137]: generating reports ... 
[2017-10-20 01:37:47,224 AE_UNIGRAMA_3L_UNDER_03.py:140]: done!
[2017-10-20 01:37:47,224 AE_UNIGRAMA_3L_UNDER_03.py:156]: >> experiment AE_UNIGRAMA_3L_UNDER_03 finished!
[2017-10-21 17:37:59,323 AE_UNIGRAMA_3L_UNDER_03.py:145]: The experiment AE_UNIGRAMA_3L_UNDER_03 was already executed!
