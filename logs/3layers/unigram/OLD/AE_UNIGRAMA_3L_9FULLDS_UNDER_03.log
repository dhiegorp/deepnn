[2017-11-18 21:02:14,575 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_3L_9FULLDS_UNDER_03
[2017-11-18 21:02:14,575 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:148]: >> Printing header log
[2017-11-18 21:02:14,576 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_9FULLDS_UNDER_03
	layers = 96,86,78,71,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbd1d333eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbd1d338400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 21:02:14,576 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:150]: >> Loading dataset... 
[2017-11-18 21:02:16,795 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 21:02:16,795 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:152]: >> Executing autoencoder part ... 
[2017-11-18 21:02:16,795 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:59]: =======================================
[2017-11-18 21:02:16,796 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbd1d333eb8>, 'discard_decoder_function': True}
[2017-11-18 21:02:16,891 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:75]: training and evaluate autoencoder
[2017-11-18 21:04:03,067 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:87]: trained and evaluated!
[2017-11-18 21:04:03,069 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:90]: Training history: 
{'val_loss': [0.0094676556110858522, 0.0088302392224366717, 0.0083063491163190041, 0.0078793921085531134, 0.007536577002632403, 0.0072586942689670591, 0.007031020590811639, 0.0068406822385443716, 0.006681384512752798, 0.0065493614742110013, 0.0064374778496059737, 0.0063407944767944341, 0.0062566281242233809, 0.0061839084736167709, 0.0061201325692003677, 0.0060646868790392048, 0.006015470421379134, 0.005971851241656773, 0.0059315823297502691, 0.0058953526829605878, 0.005864670442144131, 0.005838283709531396, 0.0058150634433812671, 0.0057928383917517298, 0.0057707128319677099, 0.0057483994736049005, 0.0057284462560708909, 0.0057114245105111747, 0.0056967374626362274, 0.0056838553449503858, 0.0056719023320866346, 0.0056611694928117642, 0.0056518238571426948, 0.0056436214113771612, 0.0056363723270057018, 0.0056298883616080929, 0.0056240736622053915, 0.0056188061329557016, 0.0056140111531351733, 0.0056096166123296189, 0.0056055784252845645, 0.0056018591340759941, 0.0055984163814960528, 0.0055951358862898941, 0.0055919801463803929, 0.005588980095641731, 0.0055861840984150523, 0.0055835794542636484, 0.0055810605322627934, 0.0055768902901113743, 0.005570999678078517, 0.005565800997645939, 0.0055612408454560405, 0.0055571703091558122, 0.005553476985880078, 0.0055500901448281978, 0.0055469545559360019, 0.0055440193489166532, 0.0055412595848785967, 0.0055386503017413368, 0.0055361706482842752, 0.005533800715647668, 0.0055315254928865213, 0.0055293374538636581, 0.0055272213776501079, 0.0055251642395062828, 0.0055231658226883298, 0.0055212046322472685, 0.0055192705012449923, 0.0055173771456397385, 0.0055155112582318091, 0.0055136572365443335, 0.0055118139913816998, 0.0055099931657307455, 0.0055081745804222808, 0.005506361212111799, 0.005504555715718955, 0.0055027498899747158, 0.0055009458423344003, 0.0054991153071920953, 0.0054971972912192637, 0.005494893270191141, 0.0054906778604350776, 0.0054855933231505258, 0.0054788978686347431, 0.0054712741998034897, 0.0054646023559065393, 0.0054587160415286171, 0.0054534659767164024, 0.0054487406839375295, 0.0054444335675731615, 0.0054404804204446523, 0.005436822107076804, 0.0054334073315673356, 0.0054302050861968452, 0.0054271680343819483, 0.0054242732900939951, 0.0054214899360590044, 0.0054187977799303073, 0.0054161936815318784, 0.0054136568438932602], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098187539772678911, 0.0091423911965146116, 0.0085641436402965898, 0.0080916577434217343, 0.0077094678439284976, 0.0074027151500272821, 0.0071523488078888715, 0.0069461550279615904, 0.0067727140785868592, 0.0066288292309221522, 0.006508422350448996, 0.0064055458909467395, 0.0063164172978387905, 0.0062389156672080686, 0.0061716499947705589, 0.0061129254700618973, 0.0060613232912712705, 0.0060157189753267341, 0.00597480803126122, 0.0059367635336957077, 0.0059040708789046123, 0.0058761331375870758, 0.0058519295208147876, 0.0058297197068343538, 0.005808151060834434, 0.0057862007015831588, 0.0057651975668365019, 0.005747068426223698, 0.0057315237139861164, 0.005717998812583505, 0.0057058642572975164, 0.0056945830880219261, 0.0056847094906153596, 0.0056760864727504528, 0.0056684848397940022, 0.005661734936941094, 0.0056556860540906747, 0.0056502453176224907, 0.0056452985475260713, 0.00564078192968606, 0.0056366367411676381, 0.005632825275295272, 0.0056293011613042024, 0.0056260119862072567, 0.0056228319309195507, 0.0056198041831105822, 0.0056169620466789971, 0.0056142999154561403, 0.005611797415688991, 0.0056088211673205688, 0.0056034572395869077, 0.0055978927850253201, 0.0055930305305949323, 0.005588717333918955, 0.0055848344254196677, 0.0055812971701435597, 0.0055780363604321214, 0.0055750013571207405, 0.005572150945270209, 0.0055694642035025157, 0.0055669109743192282, 0.0055644883622982481, 0.0055621596311822737, 0.0055599201488217955, 0.0055577585362656997, 0.005555674569514159, 0.0055536393757954806, 0.0055516585853987417, 0.005549706660228919, 0.0055477879335595094, 0.0055458966067157538, 0.0055440265271043112, 0.0055421781901083128, 0.0055403416317079289, 0.0055385173722069126, 0.0055366976111642608, 0.0055348836434235731, 0.0055330706008896186, 0.0055312584478961835, 0.0055294321970887255, 0.0055275582873031666, 0.0055255104397377037, 0.0055221763934573832, 0.0055174306415138475, 0.0055114974607752961, 0.005504035283400429, 0.005496769254825752, 0.0054904484328710621, 0.0054848268386916222, 0.00547980795031073, 0.0054752674916073475, 0.0054711200522879148, 0.0054673060299939534, 0.0054637716897449288, 0.0054604708210454151, 0.0054573615055201578, 0.0054544077720207291, 0.0054515836311944815, 0.0054488647139865672, 0.0054462401245973209, 0.0054436989121273488], 'acc': [0.42199582671027569, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822262206665, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822262938279, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822264767316, 0.59383822262206665, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539]}
[2017-11-18 21:04:03,069 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:94]: done!
[2017-11-18 21:04:03,069 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:154]: >> Executing classifier part ... 
[2017-11-18 21:04:03,069 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:99]: =======================================
[2017-11-18 21:04:03,069 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbd1d338400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 21:04:03,115 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:112]: training ... 
[2017-11-18 21:08:15,030 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:124]: trained!
[2017-11-18 21:08:15,031 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:127]: Training history: 
{'val_loss': [0.0094676556110858522, 0.0088302392224366717, 0.0083063491163190041, 0.0078793921085531134, 0.007536577002632403, 0.0072586942689670591, 0.007031020590811639, 0.0068406822385443716, 0.006681384512752798, 0.0065493614742110013, 0.0064374778496059737, 0.0063407944767944341, 0.0062566281242233809, 0.0061839084736167709, 0.0061201325692003677, 0.0060646868790392048, 0.006015470421379134, 0.005971851241656773, 0.0059315823297502691, 0.0058953526829605878, 0.005864670442144131, 0.005838283709531396, 0.0058150634433812671, 0.0057928383917517298, 0.0057707128319677099, 0.0057483994736049005, 0.0057284462560708909, 0.0057114245105111747, 0.0056967374626362274, 0.0056838553449503858, 0.0056719023320866346, 0.0056611694928117642, 0.0056518238571426948, 0.0056436214113771612, 0.0056363723270057018, 0.0056298883616080929, 0.0056240736622053915, 0.0056188061329557016, 0.0056140111531351733, 0.0056096166123296189, 0.0056055784252845645, 0.0056018591340759941, 0.0055984163814960528, 0.0055951358862898941, 0.0055919801463803929, 0.005588980095641731, 0.0055861840984150523, 0.0055835794542636484, 0.0055810605322627934, 0.0055768902901113743, 0.005570999678078517, 0.005565800997645939, 0.0055612408454560405, 0.0055571703091558122, 0.005553476985880078, 0.0055500901448281978, 0.0055469545559360019, 0.0055440193489166532, 0.0055412595848785967, 0.0055386503017413368, 0.0055361706482842752, 0.005533800715647668, 0.0055315254928865213, 0.0055293374538636581, 0.0055272213776501079, 0.0055251642395062828, 0.0055231658226883298, 0.0055212046322472685, 0.0055192705012449923, 0.0055173771456397385, 0.0055155112582318091, 0.0055136572365443335, 0.0055118139913816998, 0.0055099931657307455, 0.0055081745804222808, 0.005506361212111799, 0.005504555715718955, 0.0055027498899747158, 0.0055009458423344003, 0.0054991153071920953, 0.0054971972912192637, 0.005494893270191141, 0.0054906778604350776, 0.0054855933231505258, 0.0054788978686347431, 0.0054712741998034897, 0.0054646023559065393, 0.0054587160415286171, 0.0054534659767164024, 0.0054487406839375295, 0.0054444335675731615, 0.0054404804204446523, 0.005436822107076804, 0.0054334073315673356, 0.0054302050861968452, 0.0054271680343819483, 0.0054242732900939951, 0.0054214899360590044, 0.0054187977799303073, 0.0054161936815318784, 0.0054136568438932602], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098187539772678911, 0.0091423911965146116, 0.0085641436402965898, 0.0080916577434217343, 0.0077094678439284976, 0.0074027151500272821, 0.0071523488078888715, 0.0069461550279615904, 0.0067727140785868592, 0.0066288292309221522, 0.006508422350448996, 0.0064055458909467395, 0.0063164172978387905, 0.0062389156672080686, 0.0061716499947705589, 0.0061129254700618973, 0.0060613232912712705, 0.0060157189753267341, 0.00597480803126122, 0.0059367635336957077, 0.0059040708789046123, 0.0058761331375870758, 0.0058519295208147876, 0.0058297197068343538, 0.005808151060834434, 0.0057862007015831588, 0.0057651975668365019, 0.005747068426223698, 0.0057315237139861164, 0.005717998812583505, 0.0057058642572975164, 0.0056945830880219261, 0.0056847094906153596, 0.0056760864727504528, 0.0056684848397940022, 0.005661734936941094, 0.0056556860540906747, 0.0056502453176224907, 0.0056452985475260713, 0.00564078192968606, 0.0056366367411676381, 0.005632825275295272, 0.0056293011613042024, 0.0056260119862072567, 0.0056228319309195507, 0.0056198041831105822, 0.0056169620466789971, 0.0056142999154561403, 0.005611797415688991, 0.0056088211673205688, 0.0056034572395869077, 0.0055978927850253201, 0.0055930305305949323, 0.005588717333918955, 0.0055848344254196677, 0.0055812971701435597, 0.0055780363604321214, 0.0055750013571207405, 0.005572150945270209, 0.0055694642035025157, 0.0055669109743192282, 0.0055644883622982481, 0.0055621596311822737, 0.0055599201488217955, 0.0055577585362656997, 0.005555674569514159, 0.0055536393757954806, 0.0055516585853987417, 0.005549706660228919, 0.0055477879335595094, 0.0055458966067157538, 0.0055440265271043112, 0.0055421781901083128, 0.0055403416317079289, 0.0055385173722069126, 0.0055366976111642608, 0.0055348836434235731, 0.0055330706008896186, 0.0055312584478961835, 0.0055294321970887255, 0.0055275582873031666, 0.0055255104397377037, 0.0055221763934573832, 0.0055174306415138475, 0.0055114974607752961, 0.005504035283400429, 0.005496769254825752, 0.0054904484328710621, 0.0054848268386916222, 0.00547980795031073, 0.0054752674916073475, 0.0054711200522879148, 0.0054673060299939534, 0.0054637716897449288, 0.0054604708210454151, 0.0054573615055201578, 0.0054544077720207291, 0.0054515836311944815, 0.0054488647139865672, 0.0054462401245973209, 0.0054436989121273488], 'acc': [0.42199582671027569, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822262206665, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822262938279, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822264767316, 0.59383822262206665, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539]}
[2017-11-18 21:08:15,031 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:131]: evaluating model ... 
[2017-11-18 21:08:15,117 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:135]: evaluated! 
[2017-11-18 21:08:15,118 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:137]: generating reports ... 
[2017-11-18 21:08:15,960 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:140]: done!
[2017-11-18 21:08:15,961 AE_UNIGRAMA_3L_9FULLDS_UNDER_03.py:156]: >> experiment AE_UNIGRAMA_3L_9FULLDS_UNDER_03 finished!
