[2017-11-13 17:09:41,780 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_3L_FULLDS_UNDER_03
[2017-11-13 17:09:41,780 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:148]: >> Printing header log
[2017-11-13 17:09:41,780 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_FULLDS_UNDER_03
	layers = 96,86,78,71
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbee172eeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbee1733400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 17:09:41,781 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:150]: >> Loading dataset... 
[2017-11-13 17:09:44,275 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 17:09:44,275 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:152]: >> Executing autoencoder part ... 
[2017-11-13 17:09:44,275 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:59]: =======================================
[2017-11-13 17:09:44,276 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbee172eeb8>, 'discard_decoder_function': True}
[2017-11-13 17:09:44,368 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:75]: training and evaluate autoencoder
[2017-11-13 17:12:24,402 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:87]: trained and evaluated!
[2017-11-13 17:12:24,403 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:90]: Training history: 
{'val_loss': [0.0090417462058477605, 0.0083991316082459161, 0.0078776281769224847, 0.0074518808320805418, 0.0071044167285002641, 0.0068116644607875351, 0.0065739443635199051, 0.0063810503876636964, 0.0062240066211458429, 0.006096245046192968, 0.005991618728620445, 0.0059051354754906457, 0.0058333379496641946, 0.0057731794229496742, 0.0057225270057832964, 0.0056802365039494091, 0.0056450893753849981, 0.0056156493722194535, 0.005590744668176998, 0.0055694523602361264, 0.0055508735287285596, 0.0055344217465947447, 0.0055197163151104092, 0.0055055176966386553, 0.0054928604180547068, 0.0054816857304797809, 0.0054717726805423635, 0.0054629321317217535, 0.0054549287079817361, 0.0054472700424200741, 0.0054390833993606304, 0.0054315174949478295, 0.0054246366766063396, 0.00541836972973381, 0.005412616276085371, 0.0054072799053774224, 0.0054022627376952301, 0.0053975089059205492, 0.0053929902588519402, 0.0053886680738697186, 0.0053844899372962668, 0.0053804253135766398, 0.0053764567072121638, 0.0053725759032429172, 0.0053687524153155815, 0.0053649693798514765, 0.0053612353711962992, 0.005357520222593371, 0.0053538201889006074, 0.005350133492441924, 0.0053464519769570781, 0.0053427604798745067, 0.0053390519754589428, 0.0053353325510209302, 0.0053316136731060056, 0.0053279122700678576, 0.0053242213499705964, 0.0053205315686984129, 0.0053168333828475262, 0.005313130451820843, 0.0053093862167577707, 0.0053054287865208936, 0.0053010837855046828, 0.0052964991624804211, 0.0052914621430979365, 0.0052861689539603655, 0.0052806020700480573, 0.005275019684201329, 0.0052696882959493586, 0.0052645747795925556, 0.0052596567004736961, 0.0052549098307716575, 0.0052503096699599659, 0.00524581174575989, 0.0052414012216996757, 0.0052370659056167881, 0.0052327932101954699, 0.0052285698502270101, 0.0052243930574140977, 0.0052202597135716953, 0.005216152687892126, 0.0052120714910117551, 0.0052080080057749336, 0.0052039573233997674, 0.0051999122489829715, 0.005195875943750307, 0.0051918496864306026, 0.0051878233094012054, 0.0051837920709090421, 0.0051797569515638787, 0.0051757049919145424, 0.0051716360575336387, 0.0051675442102557213, 0.0051634132665113429, 0.0051592193754921769, 0.0051549329849912241, 0.0051505195480237072, 0.0051459522678447321, 0.0051411832579251037, 0.005136151078014399, 0.0051308005949970399], 'val_acc': [0.60271958838662254, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0094188370188505888, 0.0087171827061246973, 0.0081397713783534446, 0.0076712242877370338, 0.0072893272554134941, 0.0069715755929221834, 0.0067089976740234416, 0.0064956160546642246, 0.0063226419355598192, 0.0061817820009831357, 0.0060671948958350621, 0.0059726479370341328, 0.0058944435244099418, 0.0058291678819190366, 0.0057743892949396877, 0.0057282833575336345, 0.0056899272812967307, 0.0056579285889989256, 0.0056309623249827159, 0.0056080437475447093, 0.0055882548631573693, 0.0055708439031400252, 0.0055553882856187653, 0.0055409717646533654, 0.0055275508230047945, 0.0055156785263610758, 0.0055051723089765536, 0.0054958062728278669, 0.0054873877179919687, 0.0054796184898972897, 0.0054715581051822384, 0.0054636119946158855, 0.0054563473077538713, 0.005449737221945904, 0.005443682886966005, 0.0054380935392734269, 0.0054328770374341279, 0.0054279525215118274, 0.0054232757958663901, 0.0054188154571968251, 0.0054145335890599649, 0.0054103772925736312, 0.0054063185839350785, 0.0054023540529055626, 0.0053984637833913145, 0.0053946397781012663, 0.0053908569775192525, 0.0053871094125271671, 0.0053833787869289381, 0.0053796714333065399, 0.0053759683715185278, 0.0053722688989290591, 0.0053685616992886808, 0.0053648367441611758, 0.0053611025818348906, 0.0053573783074519462, 0.0053536754007319429, 0.0053499754512783384, 0.0053462783075097229, 0.0053425662465186865, 0.0053388404330585986, 0.0053350255496884998, 0.0053308663480633118, 0.005326427612145049, 0.0053217041444404223, 0.005316579187369129, 0.005311250211896195, 0.005305694682118705, 0.0053002763549498079, 0.0052950690323021665, 0.0052900642730575502, 0.0052852453014637204, 0.0052805904054272811, 0.0052760556665786109, 0.005271623600756733, 0.0052672654432745873, 0.0052629694540606434, 0.0052587336918211783, 0.005254544074117508, 0.0052503980362402147, 0.0052462896806894053, 0.0052422094882440861, 0.0052381454144696067, 0.0052340936737174607, 0.0052300579107431777, 0.0052260329142213785, 0.0052220128936508112, 0.0052179956959124514, 0.0052139774137840173, 0.005209953251017121, 0.0052059137531500974, 0.0052018651783459933, 0.0051977869063319498, 0.0051936847204645418, 0.0051895198109305363, 0.0051852755405272172, 0.0051809336463812744, 0.0051764573876628139, 0.0051718022005237674, 0.0051668976948334644, 0.005161683515813492], 'acc': [0.34969927583631011, 0.59371547811570102, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822264767316, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539]}
[2017-11-13 17:12:24,403 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:94]: done!
[2017-11-13 17:12:24,403 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:154]: >> Executing classifier part ... 
[2017-11-13 17:12:24,403 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:99]: =======================================
[2017-11-13 17:12:24,403 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbee1733400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 17:12:24,439 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:112]: training ... 
[2017-11-13 17:16:11,573 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:124]: trained!
[2017-11-13 17:16:11,574 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:127]: Training history: 
{'val_loss': [0.0090417462058477605, 0.0083991316082459161, 0.0078776281769224847, 0.0074518808320805418, 0.0071044167285002641, 0.0068116644607875351, 0.0065739443635199051, 0.0063810503876636964, 0.0062240066211458429, 0.006096245046192968, 0.005991618728620445, 0.0059051354754906457, 0.0058333379496641946, 0.0057731794229496742, 0.0057225270057832964, 0.0056802365039494091, 0.0056450893753849981, 0.0056156493722194535, 0.005590744668176998, 0.0055694523602361264, 0.0055508735287285596, 0.0055344217465947447, 0.0055197163151104092, 0.0055055176966386553, 0.0054928604180547068, 0.0054816857304797809, 0.0054717726805423635, 0.0054629321317217535, 0.0054549287079817361, 0.0054472700424200741, 0.0054390833993606304, 0.0054315174949478295, 0.0054246366766063396, 0.00541836972973381, 0.005412616276085371, 0.0054072799053774224, 0.0054022627376952301, 0.0053975089059205492, 0.0053929902588519402, 0.0053886680738697186, 0.0053844899372962668, 0.0053804253135766398, 0.0053764567072121638, 0.0053725759032429172, 0.0053687524153155815, 0.0053649693798514765, 0.0053612353711962992, 0.005357520222593371, 0.0053538201889006074, 0.005350133492441924, 0.0053464519769570781, 0.0053427604798745067, 0.0053390519754589428, 0.0053353325510209302, 0.0053316136731060056, 0.0053279122700678576, 0.0053242213499705964, 0.0053205315686984129, 0.0053168333828475262, 0.005313130451820843, 0.0053093862167577707, 0.0053054287865208936, 0.0053010837855046828, 0.0052964991624804211, 0.0052914621430979365, 0.0052861689539603655, 0.0052806020700480573, 0.005275019684201329, 0.0052696882959493586, 0.0052645747795925556, 0.0052596567004736961, 0.0052549098307716575, 0.0052503096699599659, 0.00524581174575989, 0.0052414012216996757, 0.0052370659056167881, 0.0052327932101954699, 0.0052285698502270101, 0.0052243930574140977, 0.0052202597135716953, 0.005216152687892126, 0.0052120714910117551, 0.0052080080057749336, 0.0052039573233997674, 0.0051999122489829715, 0.005195875943750307, 0.0051918496864306026, 0.0051878233094012054, 0.0051837920709090421, 0.0051797569515638787, 0.0051757049919145424, 0.0051716360575336387, 0.0051675442102557213, 0.0051634132665113429, 0.0051592193754921769, 0.0051549329849912241, 0.0051505195480237072, 0.0051459522678447321, 0.0051411832579251037, 0.005136151078014399, 0.0051308005949970399], 'val_acc': [0.60271958838662254, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0094188370188505888, 0.0087171827061246973, 0.0081397713783534446, 0.0076712242877370338, 0.0072893272554134941, 0.0069715755929221834, 0.0067089976740234416, 0.0064956160546642246, 0.0063226419355598192, 0.0061817820009831357, 0.0060671948958350621, 0.0059726479370341328, 0.0058944435244099418, 0.0058291678819190366, 0.0057743892949396877, 0.0057282833575336345, 0.0056899272812967307, 0.0056579285889989256, 0.0056309623249827159, 0.0056080437475447093, 0.0055882548631573693, 0.0055708439031400252, 0.0055553882856187653, 0.0055409717646533654, 0.0055275508230047945, 0.0055156785263610758, 0.0055051723089765536, 0.0054958062728278669, 0.0054873877179919687, 0.0054796184898972897, 0.0054715581051822384, 0.0054636119946158855, 0.0054563473077538713, 0.005449737221945904, 0.005443682886966005, 0.0054380935392734269, 0.0054328770374341279, 0.0054279525215118274, 0.0054232757958663901, 0.0054188154571968251, 0.0054145335890599649, 0.0054103772925736312, 0.0054063185839350785, 0.0054023540529055626, 0.0053984637833913145, 0.0053946397781012663, 0.0053908569775192525, 0.0053871094125271671, 0.0053833787869289381, 0.0053796714333065399, 0.0053759683715185278, 0.0053722688989290591, 0.0053685616992886808, 0.0053648367441611758, 0.0053611025818348906, 0.0053573783074519462, 0.0053536754007319429, 0.0053499754512783384, 0.0053462783075097229, 0.0053425662465186865, 0.0053388404330585986, 0.0053350255496884998, 0.0053308663480633118, 0.005326427612145049, 0.0053217041444404223, 0.005316579187369129, 0.005311250211896195, 0.005305694682118705, 0.0053002763549498079, 0.0052950690323021665, 0.0052900642730575502, 0.0052852453014637204, 0.0052805904054272811, 0.0052760556665786109, 0.005271623600756733, 0.0052672654432745873, 0.0052629694540606434, 0.0052587336918211783, 0.005254544074117508, 0.0052503980362402147, 0.0052462896806894053, 0.0052422094882440861, 0.0052381454144696067, 0.0052340936737174607, 0.0052300579107431777, 0.0052260329142213785, 0.0052220128936508112, 0.0052179956959124514, 0.0052139774137840173, 0.005209953251017121, 0.0052059137531500974, 0.0052018651783459933, 0.0051977869063319498, 0.0051936847204645418, 0.0051895198109305363, 0.0051852755405272172, 0.0051809336463812744, 0.0051764573876628139, 0.0051718022005237674, 0.0051668976948334644, 0.005161683515813492], 'acc': [0.34969927583631011, 0.59371547811570102, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822264767316, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539]}
[2017-11-13 17:16:11,574 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:131]: evaluating model ... 
[2017-11-13 17:16:11,701 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:135]: evaluated! 
[2017-11-13 17:16:11,702 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:137]: generating reports ... 
[2017-11-13 17:16:12,670 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:140]: done!
[2017-11-13 17:16:12,670 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:156]: >> experiment AE_UNIGRAMA_3L_FULLDS_UNDER_03 finished!
[2017-11-14 07:04:43,068 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:145]: The experiment AE_UNIGRAMA_3L_FULLDS_UNDER_03 was already executed!
[2017-11-18 14:56:30,663 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:145]: The experiment AE_UNIGRAMA_3L_FULLDS_UNDER_03 was already executed!
[2017-11-18 16:23:00,441 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:145]: The experiment AE_UNIGRAMA_3L_FULLDS_UNDER_03 was already executed!
[2017-11-18 18:14:47,456 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_3L_FULLDS_UNDER_03
[2017-11-18 18:14:47,456 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:148]: >> Printing header log
[2017-11-18 18:14:47,456 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_FULLDS_UNDER_03
	layers = 96,86,78,71
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f80f4cc2eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f80f4cc7400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:14:47,456 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:150]: >> Loading dataset... 
[2017-11-18 18:14:49,685 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:14:49,685 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:152]: >> Executing autoencoder part ... 
[2017-11-18 18:14:49,685 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:59]: =======================================
[2017-11-18 18:14:49,686 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f80f4cc2eb8>, 'discard_decoder_function': True}
[2017-11-18 18:14:49,766 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:75]: training and evaluate autoencoder
[2017-11-18 18:16:23,654 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:87]: trained and evaluated!
[2017-11-18 18:16:23,655 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:90]: Training history: 
{'val_loss': [0.0096209948349885097, 0.0094259133862276065, 0.0092589864308799692, 0.0091187327998207366, 0.0090028631905807767, 0.0089069889041703664, 0.0088255613801322495, 0.008753622363868091, 0.0086886942902089093, 0.0086299432646955512, 0.0085772642898635145, 0.0085298333560739174, 0.0084857848647109779, 0.0084441614873605984, 0.0084065137696628708, 0.0083734770225020773, 0.0083443807898029732, 0.0083180833929647896, 0.0082937035725364049, 0.0082714558109772511, 0.0082509570540459844, 0.0082322489035557798, 0.0082153140035694412, 0.00820002721595889, 0.0081857877336127573, 0.0081717553163458655, 0.0081577127537895804, 0.0081432053691973504, 0.0081286674922620358, 0.0081146688189238404, 0.0081020384484088107, 0.008090819794861261, 0.0080808092559694986, 0.0080717077152923332, 0.0080627229657518392, 0.0080536381652642382, 0.0080449506565134395, 0.0080370671827399483, 0.0080300284062198354, 0.0080237190058754012, 0.0080178824011393878, 0.0080120625810883184, 0.0080062403360389254, 0.008000760380957702, 0.0079956666598262841, 0.0079908356041767624, 0.007985716455988107, 0.0079805090416254307, 0.0079758145577058289, 0.0079715728026618637, 0.0079677098980724531, 0.007964172698995485, 0.0079609030236115971, 0.007957865228039273, 0.0079550287877618499, 0.0079523620497913144, 0.0079498306695113107, 0.00794742334269888, 0.0079451197852784105, 0.0079429066322062088, 0.0079407735653454353, 0.0079387085599902131, 0.0079367016813485375, 0.0079347456212250332, 0.0079328396355200018, 0.0079309736052990097, 0.0079291396079881372, 0.0079273345449974286, 0.0079255583122761451, 0.0079238077896711841, 0.0079220719638909316, 0.0079203548816192543, 0.0079186528418671766, 0.0079169686687223743, 0.0079152904223624681, 0.0079136158256507098, 0.0079119467371249839, 0.0079102873236066885, 0.0079086349574723734, 0.0079069892122509162, 0.0079053445455290645, 0.0079037035975943418, 0.0079020628365402221, 0.0079004255406495538, 0.0078987881591908414, 0.0078971489565019138, 0.0078955120470365243, 0.007893870100351608, 0.0078922156881142611, 0.0078905422301420135, 0.0078888474917398668, 0.0078871254591857936, 0.0078853720289787481, 0.0078836031711959128, 0.0078818148935746943, 0.0078800131078400146, 0.0078782046529321005, 0.0078763863436661415, 0.0078745685498620693, 0.0078727542147182753, 0.0078709433505565578], 'val_acc': [0.002205071664829107, 0.0033076074972436605, 0.0033076074972436605, 0.0033076074972436605, 0.0029400955531054761, 0.0069827269386255053, 0.011025358324145534, 0.012495406100698273, 0.012862918044836457, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.009727014120902747, 0.0095175423576963295, 0.0093356781480604112, 0.0091816577332203362, 0.0090530912756619907, 0.0089470227098642757, 0.0088583877758499421, 0.008781516366872931, 0.0087128693749573723, 0.00865072267509771, 0.0085946487828017348, 0.0085446070892272429, 0.0084987802138798765, 0.0084559190818292093, 0.0084161291821896692, 0.00838083197533393, 0.0083499652020563725, 0.0083224863839124596, 0.0082973408479276901, 0.0082741687528133327, 0.0082529333224733853, 0.0082334332499386514, 0.008215724097740176, 0.0081996687692391726, 0.008185040880060019, 0.0081708900965645048, 0.0081569237262559286, 0.0081425225211286152, 0.0081279992155764563, 0.0081136347865451482, 0.0081003379698363093, 0.0080884928826841229, 0.008077962060527662, 0.0080685264383956769, 0.0080596813667994042, 0.0080506966049904444, 0.0080418274780762588, 0.0080336530364106054, 0.0080262625192608576, 0.0080196677934736421, 0.0080136809045613742, 0.0080079773919478764, 0.0080022514275671502, 0.0079966967639528066, 0.0079915240525648794, 0.0079866857947517612, 0.007981932373143338, 0.0079767723345784518, 0.0079719288892174285, 0.0079675687514030591, 0.0079636241349240623, 0.0079600280820655792, 0.0079567188893633345, 0.0079536531034802623, 0.0079507994721252102, 0.0079481233987279132, 0.0079455955765205862, 0.0079431969804360739, 0.0079409022808323692, 0.0079387079796769712, 0.0079365940738825563, 0.0079345474522860334, 0.0079325672280332812, 0.0079306334958904341, 0.0079287466750498185, 0.0079269074248791305, 0.0079251051648017296, 0.007923334278703573, 0.0079215873006287275, 0.0079198650687903709, 0.0079181620376066846, 0.0079164751647039112, 0.007914800751255625, 0.0079131381908790367, 0.0079114875046652246, 0.0079098414089903372, 0.0079082041228130846, 0.007906567041259303, 0.0079049374215461234, 0.0079033128436294935, 0.0079016894929964249, 0.0079000654145782601, 0.0078984439531685283, 0.0078968184629627375, 0.0078951951965796664, 0.0078935738349095851, 0.0078919505662973771, 0.0078903238932764783, 0.0078886878671339724, 0.0078870349426366174, 0.0078853594349100279, 0.007883658836916595, 0.0078819230269963972, 0.0078801678824445952, 0.0078783964032241652, 0.0078766103884783875, 0.007874820393634652, 0.007873019806782797, 0.0078712180675235693, 0.0078694111784974735, 0.0078676055806569042], 'acc': [0.0024548913710568309, 0.0028231250776298736, 0.0030686142138210385, 0.0035595924880324047, 0.0035595924880324047, 0.0038050816260526061, 0.0062599729961949182, 0.0092058426414631158, 0.010187799189885847, 0.01043328832699153, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-18 18:16:23,655 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:94]: done!
[2017-11-18 18:16:23,655 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:154]: >> Executing classifier part ... 
[2017-11-18 18:16:23,655 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:99]: =======================================
[2017-11-18 18:16:23,655 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f80f4cc7400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:16:23,686 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:112]: training ... 
[2017-11-18 18:20:01,318 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:124]: trained!
[2017-11-18 18:20:01,319 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:127]: Training history: 
{'val_loss': [0.0096209948349885097, 0.0094259133862276065, 0.0092589864308799692, 0.0091187327998207366, 0.0090028631905807767, 0.0089069889041703664, 0.0088255613801322495, 0.008753622363868091, 0.0086886942902089093, 0.0086299432646955512, 0.0085772642898635145, 0.0085298333560739174, 0.0084857848647109779, 0.0084441614873605984, 0.0084065137696628708, 0.0083734770225020773, 0.0083443807898029732, 0.0083180833929647896, 0.0082937035725364049, 0.0082714558109772511, 0.0082509570540459844, 0.0082322489035557798, 0.0082153140035694412, 0.00820002721595889, 0.0081857877336127573, 0.0081717553163458655, 0.0081577127537895804, 0.0081432053691973504, 0.0081286674922620358, 0.0081146688189238404, 0.0081020384484088107, 0.008090819794861261, 0.0080808092559694986, 0.0080717077152923332, 0.0080627229657518392, 0.0080536381652642382, 0.0080449506565134395, 0.0080370671827399483, 0.0080300284062198354, 0.0080237190058754012, 0.0080178824011393878, 0.0080120625810883184, 0.0080062403360389254, 0.008000760380957702, 0.0079956666598262841, 0.0079908356041767624, 0.007985716455988107, 0.0079805090416254307, 0.0079758145577058289, 0.0079715728026618637, 0.0079677098980724531, 0.007964172698995485, 0.0079609030236115971, 0.007957865228039273, 0.0079550287877618499, 0.0079523620497913144, 0.0079498306695113107, 0.00794742334269888, 0.0079451197852784105, 0.0079429066322062088, 0.0079407735653454353, 0.0079387085599902131, 0.0079367016813485375, 0.0079347456212250332, 0.0079328396355200018, 0.0079309736052990097, 0.0079291396079881372, 0.0079273345449974286, 0.0079255583122761451, 0.0079238077896711841, 0.0079220719638909316, 0.0079203548816192543, 0.0079186528418671766, 0.0079169686687223743, 0.0079152904223624681, 0.0079136158256507098, 0.0079119467371249839, 0.0079102873236066885, 0.0079086349574723734, 0.0079069892122509162, 0.0079053445455290645, 0.0079037035975943418, 0.0079020628365402221, 0.0079004255406495538, 0.0078987881591908414, 0.0078971489565019138, 0.0078955120470365243, 0.007893870100351608, 0.0078922156881142611, 0.0078905422301420135, 0.0078888474917398668, 0.0078871254591857936, 0.0078853720289787481, 0.0078836031711959128, 0.0078818148935746943, 0.0078800131078400146, 0.0078782046529321005, 0.0078763863436661415, 0.0078745685498620693, 0.0078727542147182753, 0.0078709433505565578], 'val_acc': [0.002205071664829107, 0.0033076074972436605, 0.0033076074972436605, 0.0033076074972436605, 0.0029400955531054761, 0.0069827269386255053, 0.011025358324145534, 0.012495406100698273, 0.012862918044836457, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.009727014120902747, 0.0095175423576963295, 0.0093356781480604112, 0.0091816577332203362, 0.0090530912756619907, 0.0089470227098642757, 0.0088583877758499421, 0.008781516366872931, 0.0087128693749573723, 0.00865072267509771, 0.0085946487828017348, 0.0085446070892272429, 0.0084987802138798765, 0.0084559190818292093, 0.0084161291821896692, 0.00838083197533393, 0.0083499652020563725, 0.0083224863839124596, 0.0082973408479276901, 0.0082741687528133327, 0.0082529333224733853, 0.0082334332499386514, 0.008215724097740176, 0.0081996687692391726, 0.008185040880060019, 0.0081708900965645048, 0.0081569237262559286, 0.0081425225211286152, 0.0081279992155764563, 0.0081136347865451482, 0.0081003379698363093, 0.0080884928826841229, 0.008077962060527662, 0.0080685264383956769, 0.0080596813667994042, 0.0080506966049904444, 0.0080418274780762588, 0.0080336530364106054, 0.0080262625192608576, 0.0080196677934736421, 0.0080136809045613742, 0.0080079773919478764, 0.0080022514275671502, 0.0079966967639528066, 0.0079915240525648794, 0.0079866857947517612, 0.007981932373143338, 0.0079767723345784518, 0.0079719288892174285, 0.0079675687514030591, 0.0079636241349240623, 0.0079600280820655792, 0.0079567188893633345, 0.0079536531034802623, 0.0079507994721252102, 0.0079481233987279132, 0.0079455955765205862, 0.0079431969804360739, 0.0079409022808323692, 0.0079387079796769712, 0.0079365940738825563, 0.0079345474522860334, 0.0079325672280332812, 0.0079306334958904341, 0.0079287466750498185, 0.0079269074248791305, 0.0079251051648017296, 0.007923334278703573, 0.0079215873006287275, 0.0079198650687903709, 0.0079181620376066846, 0.0079164751647039112, 0.007914800751255625, 0.0079131381908790367, 0.0079114875046652246, 0.0079098414089903372, 0.0079082041228130846, 0.007906567041259303, 0.0079049374215461234, 0.0079033128436294935, 0.0079016894929964249, 0.0079000654145782601, 0.0078984439531685283, 0.0078968184629627375, 0.0078951951965796664, 0.0078935738349095851, 0.0078919505662973771, 0.0078903238932764783, 0.0078886878671339724, 0.0078870349426366174, 0.0078853594349100279, 0.007883658836916595, 0.0078819230269963972, 0.0078801678824445952, 0.0078783964032241652, 0.0078766103884783875, 0.007874820393634652, 0.007873019806782797, 0.0078712180675235693, 0.0078694111784974735, 0.0078676055806569042], 'acc': [0.0024548913710568309, 0.0028231250776298736, 0.0030686142138210385, 0.0035595924880324047, 0.0035595924880324047, 0.0038050816260526061, 0.0062599729961949182, 0.0092058426414631158, 0.010187799189885847, 0.01043328832699153, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-18 18:20:01,319 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:131]: evaluating model ... 
[2017-11-18 18:20:01,395 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:135]: evaluated! 
[2017-11-18 18:20:01,395 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:137]: generating reports ... 
[2017-11-18 18:20:02,228 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:140]: done!
[2017-11-18 18:20:02,228 AE_UNIGRAMA_3L_FULLDS_UNDER_03.py:156]: >> experiment AE_UNIGRAMA_3L_FULLDS_UNDER_03 finished!
