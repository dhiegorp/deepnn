[2017-10-15 11:17:47,639 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_3L_UNDER_96_76_66_56_9
[2017-10-15 11:17:47,639 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:148]: >> Printing header log
[2017-10-15 11:17:47,639 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_UNDER_96_76_66_56_9
	layers = 96,76,66,56,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f04a7f5e860>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0493e41ac8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 11:17:47,639 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:150]: >> Loading dataset... 
[2017-10-15 11:17:48,156 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 11:17:48,156 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:152]: >> Executing autoencoder part ... 
[2017-10-15 11:17:48,156 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:60]: =======================================
[2017-10-15 11:17:48,156 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f04a7f5e860>, 'discard_decoder_function': True}
[2017-10-15 11:17:48,238 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:76]: training and evaluate autoencoder
[2017-10-15 11:18:23,329 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:87]: trained and evaluated!
[2017-10-15 11:18:23,331 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:90]: Training history: 
{'val_loss': [0.010098359367522829, 0.010025558591609108, 0.0099576067276382092, 0.0098945436182130662, 0.0098356510682176927, 0.0097809089693936709, 0.0097304493756653204, 0.0096836096735248775, 0.0096401242352329667, 0.009599904630153153, 0.0095623179051512672, 0.0095263931927960163, 0.0094920422078619213, 0.009459486715911047, 0.0094288148636822357, 0.0094000374531324916, 0.0093729466089085573, 0.0093473555263976632, 0.0093232989969029741, 0.009300474859912599, 0.0092787198154567346, 0.0092578176409006119, 0.0092374567551794552, 0.0092176900463365706, 0.0091987612646862484, 0.0091807361671417172, 0.0091634894960099435, 0.0091470158468502597, 0.0091312174723383217, 0.0091159428507920533, 0.0091012140535178237, 0.0090871031108731223, 0.0090735853029948188, 0.0090606411655873176, 0.0090482516982852302, 0.0090364072520327399, 0.0090250863302429804, 0.009014292564727782, 0.0090039612095262917, 0.0089940412496268534, 0.0089845033604859428, 0.0089753891400245044, 0.008966675339799831, 0.0089583248003874127, 0.0089502971910189518, 0.0089425776555414095, 0.0089351573481214093, 0.0089280156204026868, 0.0089211180238364801, 0.0089144607777378367, 0.0089080264397159385, 0.0089017988241461132, 0.0088957577569887987, 0.008889908372635735, 0.0088842299846468367, 0.0088787129751257739, 0.0088733599129994997, 0.0088681494782516055, 0.0088631011974966666, 0.0088582047742538743, 0.0088534506356350556, 0.0088488332352507516, 0.0088443482696289911, 0.0088399966285463601, 0.0088357642244506051, 0.0088316414463697306, 0.0088276249671624934, 0.0088237175115533032, 0.0088199038183157333, 0.0088161894476879044, 0.0088125573865875436, 0.0088090087879158299, 0.0088055554334226602, 0.0088021734376268323, 0.0087988756001549581, 0.0087956686099111819, 0.008792527276177832, 0.0087894613899595232, 0.0087864695802386365, 0.0087835388396586191, 0.0087806774704928293, 0.0087778876019731777, 0.0087751582278748873, 0.0087724877313665739, 0.0087698752226716518, 0.0087672954799129614, 0.0087647128877918964, 0.0087621054373210692, 0.0087594989701053026, 0.00875691457765807, 0.0087543534821238663, 0.0087518100886429112, 0.0087493160448719135, 0.0087468724310065735, 0.0087444818471333358, 0.0087421488390757689, 0.0087398657900693254, 0.008737631329096383, 0.0087354448398914483, 0.0087333045221283535, 0.0087312099395742207, 0.008729159111870265], 'loss': [0.010137516753914061, 0.010064311912277578, 0.0099951148991368269, 0.0099308719359379495, 0.0098710780701134638, 0.0098152775803985008, 0.0097637342806555193, 0.0097161198267283876, 0.0096718151947757028, 0.0096307659164510707, 0.0095925952228313946, 0.009556534874110444, 0.0095218852873303148, 0.009488863036489846, 0.0094575685636124947, 0.0094281547595806911, 0.0094004944522110105, 0.0093744273549924619, 0.0093497709430108503, 0.0093265179288244422, 0.0093043457388136009, 0.0092831236718436579, 0.0092625844349011957, 0.0092425421693149937, 0.0092232622796945499, 0.0092048144063007348, 0.0091872163501596181, 0.0091703775314214628, 0.0091542563737171453, 0.0091387378887605938, 0.0091237086177641587, 0.0091092380830707833, 0.0090953874434375956, 0.0090821151230678875, 0.009069413961024099, 0.0090572542505774969, 0.0090456377479036527, 0.0090345132170953704, 0.0090238992182037625, 0.0090137201091749723, 0.0090039483996791642, 0.0089945528941307983, 0.0089855779663012229, 0.0089769843615449575, 0.0089687336128624062, 0.0089607846521908112, 0.0089531379168568109, 0.0089457847112726779, 0.008938693861032309, 0.0089318477362623303, 0.0089252260047083774, 0.0089188238706602307, 0.0089126183200895458, 0.0089065915645634239, 0.0089007483980748352, 0.0088950712663094615, 0.0088895404746855561, 0.0088841632808791624, 0.0088789360076830144, 0.0088738643197364513, 0.0088689280147237794, 0.0088641276192687087, 0.0088594623199665778, 0.0088549358386731843, 0.0088505266782654239, 0.0088462421061504311, 0.0088420562370558342, 0.0088379849927624678, 0.0088340102213525888, 0.0088301457558571383, 0.0088263733207162853, 0.0088226821418959222, 0.0088190771547760338, 0.0088155662987813976, 0.0088121295032522473, 0.0088087722004265897, 0.0088055087671315806, 0.0088023091514709915, 0.0087991926232931002, 0.0087961452803045018, 0.0087931682971050269, 0.0087902589953552015, 0.0087874164202633494, 0.0087846363966193539, 0.0087819055710777819, 0.0087792319448844521, 0.0087765739313667365, 0.0087738934373133882, 0.0087711902085712296, 0.008768520026039001, 0.0087658662718767093, 0.0087632528502212467, 0.008760654329726978, 0.0087581197831369875, 0.0087556388336746116, 0.0087532111550621197, 0.0087508476049065146, 0.0087485296517775413, 0.0087462566333886445, 0.0087440413524200386, 0.0087418831763508582, 0.0087397562313570737]}
[2017-10-15 11:18:23,331 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:94]: done!
[2017-10-15 11:18:23,331 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:154]: >> Executing classifier part ... 
[2017-10-15 11:18:23,331 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:99]: =======================================
[2017-10-15 11:18:23,331 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0493e41ac8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 11:18:23,384 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:112]: training ... 
[2017-10-15 11:19:27,081 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:124]: trained!
[2017-10-15 11:19:27,082 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:127]: Training history: 
{'val_loss': [0.010098359367522829, 0.010025558591609108, 0.0099576067276382092, 0.0098945436182130662, 0.0098356510682176927, 0.0097809089693936709, 0.0097304493756653204, 0.0096836096735248775, 0.0096401242352329667, 0.009599904630153153, 0.0095623179051512672, 0.0095263931927960163, 0.0094920422078619213, 0.009459486715911047, 0.0094288148636822357, 0.0094000374531324916, 0.0093729466089085573, 0.0093473555263976632, 0.0093232989969029741, 0.009300474859912599, 0.0092787198154567346, 0.0092578176409006119, 0.0092374567551794552, 0.0092176900463365706, 0.0091987612646862484, 0.0091807361671417172, 0.0091634894960099435, 0.0091470158468502597, 0.0091312174723383217, 0.0091159428507920533, 0.0091012140535178237, 0.0090871031108731223, 0.0090735853029948188, 0.0090606411655873176, 0.0090482516982852302, 0.0090364072520327399, 0.0090250863302429804, 0.009014292564727782, 0.0090039612095262917, 0.0089940412496268534, 0.0089845033604859428, 0.0089753891400245044, 0.008966675339799831, 0.0089583248003874127, 0.0089502971910189518, 0.0089425776555414095, 0.0089351573481214093, 0.0089280156204026868, 0.0089211180238364801, 0.0089144607777378367, 0.0089080264397159385, 0.0089017988241461132, 0.0088957577569887987, 0.008889908372635735, 0.0088842299846468367, 0.0088787129751257739, 0.0088733599129994997, 0.0088681494782516055, 0.0088631011974966666, 0.0088582047742538743, 0.0088534506356350556, 0.0088488332352507516, 0.0088443482696289911, 0.0088399966285463601, 0.0088357642244506051, 0.0088316414463697306, 0.0088276249671624934, 0.0088237175115533032, 0.0088199038183157333, 0.0088161894476879044, 0.0088125573865875436, 0.0088090087879158299, 0.0088055554334226602, 0.0088021734376268323, 0.0087988756001549581, 0.0087956686099111819, 0.008792527276177832, 0.0087894613899595232, 0.0087864695802386365, 0.0087835388396586191, 0.0087806774704928293, 0.0087778876019731777, 0.0087751582278748873, 0.0087724877313665739, 0.0087698752226716518, 0.0087672954799129614, 0.0087647128877918964, 0.0087621054373210692, 0.0087594989701053026, 0.00875691457765807, 0.0087543534821238663, 0.0087518100886429112, 0.0087493160448719135, 0.0087468724310065735, 0.0087444818471333358, 0.0087421488390757689, 0.0087398657900693254, 0.008737631329096383, 0.0087354448398914483, 0.0087333045221283535, 0.0087312099395742207, 0.008729159111870265], 'loss': [0.010137516753914061, 0.010064311912277578, 0.0099951148991368269, 0.0099308719359379495, 0.0098710780701134638, 0.0098152775803985008, 0.0097637342806555193, 0.0097161198267283876, 0.0096718151947757028, 0.0096307659164510707, 0.0095925952228313946, 0.009556534874110444, 0.0095218852873303148, 0.009488863036489846, 0.0094575685636124947, 0.0094281547595806911, 0.0094004944522110105, 0.0093744273549924619, 0.0093497709430108503, 0.0093265179288244422, 0.0093043457388136009, 0.0092831236718436579, 0.0092625844349011957, 0.0092425421693149937, 0.0092232622796945499, 0.0092048144063007348, 0.0091872163501596181, 0.0091703775314214628, 0.0091542563737171453, 0.0091387378887605938, 0.0091237086177641587, 0.0091092380830707833, 0.0090953874434375956, 0.0090821151230678875, 0.009069413961024099, 0.0090572542505774969, 0.0090456377479036527, 0.0090345132170953704, 0.0090238992182037625, 0.0090137201091749723, 0.0090039483996791642, 0.0089945528941307983, 0.0089855779663012229, 0.0089769843615449575, 0.0089687336128624062, 0.0089607846521908112, 0.0089531379168568109, 0.0089457847112726779, 0.008938693861032309, 0.0089318477362623303, 0.0089252260047083774, 0.0089188238706602307, 0.0089126183200895458, 0.0089065915645634239, 0.0089007483980748352, 0.0088950712663094615, 0.0088895404746855561, 0.0088841632808791624, 0.0088789360076830144, 0.0088738643197364513, 0.0088689280147237794, 0.0088641276192687087, 0.0088594623199665778, 0.0088549358386731843, 0.0088505266782654239, 0.0088462421061504311, 0.0088420562370558342, 0.0088379849927624678, 0.0088340102213525888, 0.0088301457558571383, 0.0088263733207162853, 0.0088226821418959222, 0.0088190771547760338, 0.0088155662987813976, 0.0088121295032522473, 0.0088087722004265897, 0.0088055087671315806, 0.0088023091514709915, 0.0087991926232931002, 0.0087961452803045018, 0.0087931682971050269, 0.0087902589953552015, 0.0087874164202633494, 0.0087846363966193539, 0.0087819055710777819, 0.0087792319448844521, 0.0087765739313667365, 0.0087738934373133882, 0.0087711902085712296, 0.008768520026039001, 0.0087658662718767093, 0.0087632528502212467, 0.008760654329726978, 0.0087581197831369875, 0.0087556388336746116, 0.0087532111550621197, 0.0087508476049065146, 0.0087485296517775413, 0.0087462566333886445, 0.0087440413524200386, 0.0087418831763508582, 0.0087397562313570737]}
[2017-10-15 11:19:27,082 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:131]: evaluating model ... 
[2017-10-15 11:19:27,127 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:135]: evaluated! 
[2017-10-15 11:19:27,127 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:137]: generating reports ... 
[2017-10-15 11:19:27,681 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:140]: done!
[2017-10-15 11:19:27,681 AE_UNIGRAMA_3L_UNDER_96_76_66_56_9.py:156]: >> experiment AE_UNIGRAMA_3L_UNDER_96_76_66_56_9 finished!
