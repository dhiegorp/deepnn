[2017-11-13 17:53:26,456 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_FULLDS_OVER_04
[2017-11-13 17:53:26,456 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-13 17:53:26,456 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_FULLDS_OVER_04
	layers = 96,134,122,109
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f282a9e6e48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f282a9ea390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 17:53:26,456 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-13 17:53:29,286 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 17:53:29,286 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-13 17:53:29,287 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-13 17:53:29,287 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f282a9e6e48>, 'discard_decoder_function': True}
[2017-11-13 17:53:29,371 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-13 17:56:59,010 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-13 17:56:59,011 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0091181644281315612, 0.008469328849354963, 0.0079073987729047883, 0.0074412460317058258, 0.0070607290940016276, 0.0067549596134352796, 0.0065088701870488208, 0.0063095157543311591, 0.0061468146174929791, 0.0060125668283287697, 0.0059015387222540487, 0.0058095302449546835, 0.0057331410435859072, 0.0056690704584045036, 0.0056136745058659992, 0.0055657067438481438, 0.0055213712712182351, 0.0054801169467815439, 0.0054445322778401773, 0.0054140399263720605, 0.0053877686762183533, 0.0053648324673896113, 0.0053445128604183737, 0.0053264183806545021, 0.0053100887490405632, 0.0052949994882395528, 0.0052810826206881687, 0.0052681868168217693, 0.0052561625258641803, 0.0052449873589370801, 0.0052345623346083262, 0.0052248014613591716, 0.0052156175669174519, 0.0052069208833044316, 0.0051986468716797331, 0.0051907446869135241, 0.0051831362727250479, 0.0051757553423755209, 0.0051684643424128743, 0.0051611637951958838, 0.0051538653397752614, 0.0051465775821568803, 0.0051392476853580156, 0.0051318048124736563, 0.0051241683081793233, 0.0051165488097633244, 0.005108988359543121, 0.0051014657960283937, 0.0050940199733569055, 0.0050867001731592157, 0.0050794879277981202, 0.0050723448214153675, 0.0050652741089337282, 0.0050582706992258067, 0.0050513287092319795, 0.005044450482404224, 0.0050376405873914683, 0.0050308756421271195, 0.0050241451916510421, 0.0050174426839326514, 0.0050107882213866074, 0.0050041807771108301, 0.0049976128330971063, 0.0049910769433855126, 0.0049845116881763879, 0.0049778675450507012, 0.0049708317612728757, 0.0049637965360832311, 0.0049569312641715435, 0.0049501785700261118, 0.0049435137083102942, 0.0049369128542284466, 0.0049303692305348989, 0.0049238693741249801, 0.0049173771347255004, 0.0049108933339608047, 0.0049044083425167978, 0.0048979079528468378, 0.004891382850698363, 0.0048848082528280858, 0.0048781393354437571, 0.0048713140446865208, 0.0048643524543057412, 0.0048573129340282028, 0.0048500972952096781, 0.0048426395824308433, 0.0048344479956777438, 0.004825820662652836, 0.0048174457358438026, 0.0048092933610740206, 0.0048012788640591905, 0.0047933748272582701, 0.0047853977147500736, 0.0047771306957458091, 0.0047688535230664842, 0.0047605742473813793, 0.0047522678391823808, 0.0047436706771069878, 0.004734444289233088, 0.0047247288454267877, 0.0047149233132750016], 'val_acc': [0.60235207644248434, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0094775757488863334, 0.0087965575894024227, 0.0081910623681717924, 0.0076814095381196037, 0.0072613959576775904, 0.006921853382372228, 0.0066492832286942517, 0.0064294078971239973, 0.0062509124168178025, 0.0061044972619137593, 0.0059836183323001219, 0.0058834863760558551, 0.0058006398390433979, 0.0057315564835774459, 0.0056727191168557461, 0.0056219169578173309, 0.0055767507546109095, 0.0055341383192390554, 0.0054961636281129081, 0.005463569675910245, 0.0054355544152203091, 0.0054112924619543418, 0.0053899310131073621, 0.0053709579450611587, 0.0053539824417921551, 0.0053384950027492561, 0.0053241193145687291, 0.0053108449812351603, 0.0052984891527591742, 0.0052869981648639344, 0.0052762917637101626, 0.0052662753995370319, 0.0052568571123852272, 0.0052479410390170117, 0.0052394684181449542, 0.0052313970375476408, 0.0052236518491097497, 0.0052161669737336002, 0.0052088566333749614, 0.0052015401261336341, 0.0051942254404984461, 0.0051869406506379855, 0.0051796426415298014, 0.0051722632932205892, 0.0051647062964734671, 0.0051570545276804136, 0.0051494548914032007, 0.0051419052081160882, 0.0051344139024188211, 0.0051270395330330247, 0.0051197763197457806, 0.005112594824441612, 0.0051054805202259412, 0.0050984482602477515, 0.0050914683611863474, 0.0050845457253742401, 0.0050776972726574556, 0.0050709120874027139, 0.0050641746153684388, 0.005057477586019825, 0.0050508301651736986, 0.0050442299928012708, 0.0050376778304676555, 0.0050311538172931273, 0.0050246386326782246, 0.0050180788770134216, 0.0050112955000471476, 0.0050042658570773899, 0.0049973752731883748, 0.0049906316254120144, 0.0049839773219583139, 0.0049773992712691664, 0.0049708854616611073, 0.0049644183423847958, 0.0049579783077682692, 0.0049515513684822363, 0.004945121900838889, 0.0049386856847363691, 0.0049322365967887664, 0.0049257368794504638, 0.0049191559217362677, 0.0049124323746720586, 0.0049055515864743502, 0.0048985608556295617, 0.0048914681046097336, 0.0048841723250971662, 0.0048764496124326104, 0.0048679347583052163, 0.004859466625431721, 0.0048512402608463911, 0.004843216358209711, 0.0048353080697196701, 0.004827442172868103, 0.0048193441477800943, 0.0048111149540752433, 0.0048028756447691511, 0.0047946406165232771, 0.0047863083788115685, 0.0047775210225224178, 0.0047681826174010436, 0.0047585470976868813], 'acc': [0.27408862158581132, 0.59359273353617392, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894]}
[2017-11-13 17:56:59,011 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:95]: done!
[2017-11-13 17:56:59,011 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-13 17:56:59,012 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-13 17:56:59,012 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f282a9ea390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 17:56:59,053 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-13 18:01:36,943 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:125]: trained!
[2017-11-13 18:01:36,944 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0091181644281315612, 0.008469328849354963, 0.0079073987729047883, 0.0074412460317058258, 0.0070607290940016276, 0.0067549596134352796, 0.0065088701870488208, 0.0063095157543311591, 0.0061468146174929791, 0.0060125668283287697, 0.0059015387222540487, 0.0058095302449546835, 0.0057331410435859072, 0.0056690704584045036, 0.0056136745058659992, 0.0055657067438481438, 0.0055213712712182351, 0.0054801169467815439, 0.0054445322778401773, 0.0054140399263720605, 0.0053877686762183533, 0.0053648324673896113, 0.0053445128604183737, 0.0053264183806545021, 0.0053100887490405632, 0.0052949994882395528, 0.0052810826206881687, 0.0052681868168217693, 0.0052561625258641803, 0.0052449873589370801, 0.0052345623346083262, 0.0052248014613591716, 0.0052156175669174519, 0.0052069208833044316, 0.0051986468716797331, 0.0051907446869135241, 0.0051831362727250479, 0.0051757553423755209, 0.0051684643424128743, 0.0051611637951958838, 0.0051538653397752614, 0.0051465775821568803, 0.0051392476853580156, 0.0051318048124736563, 0.0051241683081793233, 0.0051165488097633244, 0.005108988359543121, 0.0051014657960283937, 0.0050940199733569055, 0.0050867001731592157, 0.0050794879277981202, 0.0050723448214153675, 0.0050652741089337282, 0.0050582706992258067, 0.0050513287092319795, 0.005044450482404224, 0.0050376405873914683, 0.0050308756421271195, 0.0050241451916510421, 0.0050174426839326514, 0.0050107882213866074, 0.0050041807771108301, 0.0049976128330971063, 0.0049910769433855126, 0.0049845116881763879, 0.0049778675450507012, 0.0049708317612728757, 0.0049637965360832311, 0.0049569312641715435, 0.0049501785700261118, 0.0049435137083102942, 0.0049369128542284466, 0.0049303692305348989, 0.0049238693741249801, 0.0049173771347255004, 0.0049108933339608047, 0.0049044083425167978, 0.0048979079528468378, 0.004891382850698363, 0.0048848082528280858, 0.0048781393354437571, 0.0048713140446865208, 0.0048643524543057412, 0.0048573129340282028, 0.0048500972952096781, 0.0048426395824308433, 0.0048344479956777438, 0.004825820662652836, 0.0048174457358438026, 0.0048092933610740206, 0.0048012788640591905, 0.0047933748272582701, 0.0047853977147500736, 0.0047771306957458091, 0.0047688535230664842, 0.0047605742473813793, 0.0047522678391823808, 0.0047436706771069878, 0.004734444289233088, 0.0047247288454267877, 0.0047149233132750016], 'val_acc': [0.60235207644248434, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0094775757488863334, 0.0087965575894024227, 0.0081910623681717924, 0.0076814095381196037, 0.0072613959576775904, 0.006921853382372228, 0.0066492832286942517, 0.0064294078971239973, 0.0062509124168178025, 0.0061044972619137593, 0.0059836183323001219, 0.0058834863760558551, 0.0058006398390433979, 0.0057315564835774459, 0.0056727191168557461, 0.0056219169578173309, 0.0055767507546109095, 0.0055341383192390554, 0.0054961636281129081, 0.005463569675910245, 0.0054355544152203091, 0.0054112924619543418, 0.0053899310131073621, 0.0053709579450611587, 0.0053539824417921551, 0.0053384950027492561, 0.0053241193145687291, 0.0053108449812351603, 0.0052984891527591742, 0.0052869981648639344, 0.0052762917637101626, 0.0052662753995370319, 0.0052568571123852272, 0.0052479410390170117, 0.0052394684181449542, 0.0052313970375476408, 0.0052236518491097497, 0.0052161669737336002, 0.0052088566333749614, 0.0052015401261336341, 0.0051942254404984461, 0.0051869406506379855, 0.0051796426415298014, 0.0051722632932205892, 0.0051647062964734671, 0.0051570545276804136, 0.0051494548914032007, 0.0051419052081160882, 0.0051344139024188211, 0.0051270395330330247, 0.0051197763197457806, 0.005112594824441612, 0.0051054805202259412, 0.0050984482602477515, 0.0050914683611863474, 0.0050845457253742401, 0.0050776972726574556, 0.0050709120874027139, 0.0050641746153684388, 0.005057477586019825, 0.0050508301651736986, 0.0050442299928012708, 0.0050376778304676555, 0.0050311538172931273, 0.0050246386326782246, 0.0050180788770134216, 0.0050112955000471476, 0.0050042658570773899, 0.0049973752731883748, 0.0049906316254120144, 0.0049839773219583139, 0.0049773992712691664, 0.0049708854616611073, 0.0049644183423847958, 0.0049579783077682692, 0.0049515513684822363, 0.004945121900838889, 0.0049386856847363691, 0.0049322365967887664, 0.0049257368794504638, 0.0049191559217362677, 0.0049124323746720586, 0.0049055515864743502, 0.0048985608556295617, 0.0048914681046097336, 0.0048841723250971662, 0.0048764496124326104, 0.0048679347583052163, 0.004859466625431721, 0.0048512402608463911, 0.004843216358209711, 0.0048353080697196701, 0.004827442172868103, 0.0048193441477800943, 0.0048111149540752433, 0.0048028756447691511, 0.0047946406165232771, 0.0047863083788115685, 0.0047775210225224178, 0.0047681826174010436, 0.0047585470976868813], 'acc': [0.27408862158581132, 0.59359273353617392, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894]}
[2017-11-13 18:01:36,944 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-13 18:01:37,120 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-13 18:01:37,120 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-13 18:01:38,112 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:141]: done!
[2017-11-13 18:01:38,112 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_3L_FULLDS_OVER_04 finished!
[2017-11-14 07:05:05,368 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_3L_FULLDS_OVER_04 was already executed!
[2017-11-18 14:56:52,660 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_3L_FULLDS_OVER_04 was already executed!
[2017-11-18 16:23:23,367 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_3L_FULLDS_OVER_04 was already executed!
[2017-11-18 18:48:25,640 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_FULLDS_OVER_04
[2017-11-18 18:48:25,640 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 18:48:25,640 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_FULLDS_OVER_04
	layers = 96,134,122,109
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc28b130eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc28b135400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:48:25,640 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 18:48:28,008 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:48:28,008 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:48:28,008 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 18:48:28,009 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc28b130eb8>, 'discard_decoder_function': True}
[2017-11-18 18:48:28,088 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 18:50:53,473 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 18:50:53,474 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0096984422368294222, 0.0095279430364727836, 0.0093891855006854753, 0.0092760104010376539, 0.0091821997330956313, 0.0091051939318352922, 0.0090411692287516877, 0.0089868436612322994, 0.0089393582291564314, 0.0088967615779583752, 0.0088581257619207415, 0.0088231179223850088, 0.0087925201385955915, 0.0087649123886930774, 0.0087388043700197485, 0.0087144861719305796, 0.0086910736585191304, 0.008668124507352824, 0.0086473339000762671, 0.0086290545413152172, 0.0086129073208305422, 0.0085984563365310313, 0.0085853982452564672, 0.0085733972769812469, 0.0085622332925137812, 0.0085516695712872046, 0.0085413010910054821, 0.0085305666882313381, 0.0085200729746698727, 0.0085100202493640659, 0.0085004137572926523, 0.0084912176522912684, 0.0084822977780446944, 0.0084728538477981587, 0.0084637535759239275, 0.0084552301952354574, 0.0084472231512826967, 0.008439629984549283, 0.0084322257640332427, 0.008424256543551176, 0.0084160437214625353, 0.0084079868211186758, 0.008399771955665181, 0.008391774713018281, 0.0083842282989519297, 0.0083769642772239961, 0.0083698826205041519, 0.0083630836378127196, 0.0083565128346284236, 0.0083494953313504941, 0.0083425013630492473, 0.008335879709173195, 0.0083296763129157205, 0.0083238527152067112, 0.0083183545341324345, 0.0083131197732501903, 0.0083081157051796244, 0.0083033124755729822, 0.0082986640091198237, 0.0082941578881858199, 0.0082897787936954577, 0.0082855098061085583, 0.0082813304630257063, 0.0082772267891319303, 0.0082732087127160656, 0.008269280816460195, 0.0082654240679780333, 0.0082616309841731291, 0.0082578836101319854, 0.0082541803183504344, 0.0082505178456056087, 0.0082468867465547019, 0.0082432975518855704, 0.0082397336323048343, 0.0082361720521543797, 0.0082326112137077172, 0.0082290476935586044, 0.0082254747000003684, 0.0082218902841352751, 0.0082182713699736221, 0.0082143328625959369, 0.0082092303645792623, 0.0082043664754450161, 0.0081997286639245107, 0.008195258841638681, 0.0081909215467948111, 0.0081867216892871769, 0.0081826244750960661, 0.0081786170443715039, 0.0081746763382373987, 0.0081708029878436311, 0.0081669748023163301, 0.0081631857070090224, 0.0081594079217433002, 0.0081556353106059729, 0.008151845904515535, 0.008148035984342588, 0.0081441991988847415, 0.0081402628758880467, 0.0081360060714790374, 0.0081299588567509198], 'val_acc': [0.0051451672179345827, 0.004410143329658214, 0.0036751194413818448, 0.0033076074972436605, 0.002205071664829107, 0.002205071664829107, 0.0025725836089672913, 0.0029400955531054761, 0.0033076074972436605, 0.0036751194413818448, 0.0040426313855200296, 0.027930907754502021, 0.037486218302094816, 0.037486218302094816, 0.037486218302094816, 0.037486218302094816, 0.037486218302094816, 0.038588754134509372, 0.038956266078647557, 0.038956266078647557, 0.039691289966923927, 0.039691289966923927, 0.040058801911062113, 0.040426313855200291, 0.040426313855200291, 0.041161337743476661, 0.041161337743476661, 0.041161337743476661, 0.041528849687614847, 0.041528849687614847, 0.042263873575891217, 0.042998897464167588, 0.043366409408305773, 0.043366409408305773, 0.043366409408305773, 0.043366409408305773, 0.043733921352443951, 0.044836457184858507, 0.045203969128996692, 0.045203969128996692, 0.045203969128996692, 0.045203969128996692, 0.045571481073134877, 0.045938993017273062, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248], 'loss': [0.0097929650978922003, 0.00961103531032091, 0.0094552465359109585, 0.0093292712705051861, 0.009225457472212515, 0.0091398477824561446, 0.0090693333582309941, 0.0090100630999847883, 0.0089590810800600634, 0.0089138678293453413, 0.0088731295597098553, 0.008835965441248381, 0.0088030387432195233, 0.0087740048583232512, 0.0087470636648545822, 0.0087217768601413823, 0.0086979632280383776, 0.0086745282961347148, 0.0086524809507315427, 0.0086329317905124939, 0.0086157441603796486, 0.0086004774418719059, 0.0085867518530290919, 0.0085742602815728798, 0.008562717505020679, 0.0085519049250342098, 0.0085415700412815702, 0.0085310630072322063, 0.0085204673262946999, 0.0085102223209434086, 0.0085003991288133997, 0.0084910134891075743, 0.0084819972424340258, 0.0084728604292114533, 0.0084635069417971047, 0.0084547180747808794, 0.0084464855422840251, 0.0084387176218933598, 0.0084312718161679567, 0.0084236171811030765, 0.0084154555899627996, 0.0084072965296376062, 0.0083991490577453778, 0.0083909118839538329, 0.0083830750955338935, 0.0083756233555563938, 0.0083683987791812672, 0.0083614214725506158, 0.0083547349418149376, 0.0083479333024897712, 0.0083408390093062997, 0.0083339973051630017, 0.0083275626164203594, 0.0083215297962836911, 0.0083158415866478666, 0.0083104554413779754, 0.0083053061423444402, 0.0083003679124200157, 0.0082956042102541143, 0.0082909964547210543, 0.00828652036696036, 0.0082821615040988162, 0.0082779035870247826, 0.0082737281082884591, 0.0082696386067327276, 0.0082656431298900029, 0.0082617203557661043, 0.0082578689844875781, 0.0082540694685686918, 0.0082503144321907172, 0.0082465967858934737, 0.0082429234813878229, 0.008239286522525844, 0.008235676894271916, 0.0082320831969839459, 0.0082284877012957381, 0.0082248965036720717, 0.0082212979819571205, 0.0082176789718885739, 0.0082140482243205793, 0.0082103059909130315, 0.0082056929399760663, 0.0082006802253367511, 0.008195926515655063, 0.0081913750815317647, 0.0081869672659345121, 0.0081827027326635167, 0.0081785524919458993, 0.0081744990000055216, 0.008170523484696695, 0.0081666124655624048, 0.0081627631837295662, 0.0081589540466208959, 0.008155170363871667, 0.0081513973637250235, 0.0081476210146123641, 0.0081438227540984749, 0.0081400000729737691, 0.0081361234232662609, 0.0081320821836991328, 0.0081272520723007224], 'acc': [0.0046642936050079785, 0.0039278261936909293, 0.0039278261936909293, 0.0034368479194795631, 0.0031913587823738801, 0.0034368479194795631, 0.0035595924880324047, 0.0035595924889469228, 0.003682337056585246, 0.0039278261936909293, 0.0040505707622437706, 0.012519945993304355, 0.035595924881238562, 0.040260218486246543, 0.040751196760457908, 0.040996685897563591, 0.041610408740327801, 0.041855897876518965, 0.042101387013624647, 0.042837854425856213, 0.043697066405726105, 0.04381981097427895, 0.044065300110470114, 0.044433533817043153, 0.044433533817043153, 0.045170001228360207, 0.045415490364551371, 0.045783724073867965, 0.046520191483355976, 0.047379403461396831, 0.047747637167969877, 0.047993126304161041, 0.048729593716392607, 0.048975082852583771, 0.049834294833368181, 0.049957039401921026, 0.05020252853811219, 0.05057076224377071, 0.051061740518896601, 0.051184485087449438, 0.051307229656002283, 0.051552718793107966, 0.051429974223640602, 0.051429974209008314, 0.05179820792929913, 0.051920952497851967, 0.052043697066404812, 0.052043697066404812, 0.052043697068233849, 0.052043697066404812, 0.052043697067319331, 0.052166441635872168, 0.052166441636786687, 0.052166441635872168, 0.05216644163495765, 0.052411930773892376, 0.052411930772063339, 0.052411930773892376, 0.052411930773892376, 0.052411930772063339, 0.052411930772977858, 0.052411930772063339, 0.052411930772063339, 0.052411930772063339, 0.052411930772977858, 0.052411930772977858, 0.052411930772977858, 0.052411930772977858, 0.052534675340616177, 0.052534675342445214, 0.052534675340616177, 0.052534675340616177, 0.052534675341530696, 0.052534675341530696, 0.052534675341530696, 0.052534675340616177, 0.052534675340616177, 0.052534675341530696, 0.052534675340616177, 0.052534675341530696, 0.052534675341530696, 0.052534675340616177, 0.052534675342445214, 0.05265741991008354, 0.052657419910998059, 0.052657419909169022, 0.052657419910998059, 0.052657419909169022, 0.052657419909169022, 0.052657419910998059, 0.05265741991008354, 0.052657419909169022, 0.052657419909169022, 0.052657419909169022, 0.052657419909169022, 0.052657419909169022, 0.052657419910998059, 0.052657419909169022, 0.052657419909169022, 0.052657419910998059, 0.052657419910998059]}
[2017-11-18 18:50:53,474 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:95]: done!
[2017-11-18 18:50:53,474 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 18:50:53,475 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 18:50:53,475 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc28b135400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:50:53,523 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 18:55:30,719 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:125]: trained!
[2017-11-18 18:55:30,721 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0096984422368294222, 0.0095279430364727836, 0.0093891855006854753, 0.0092760104010376539, 0.0091821997330956313, 0.0091051939318352922, 0.0090411692287516877, 0.0089868436612322994, 0.0089393582291564314, 0.0088967615779583752, 0.0088581257619207415, 0.0088231179223850088, 0.0087925201385955915, 0.0087649123886930774, 0.0087388043700197485, 0.0087144861719305796, 0.0086910736585191304, 0.008668124507352824, 0.0086473339000762671, 0.0086290545413152172, 0.0086129073208305422, 0.0085984563365310313, 0.0085853982452564672, 0.0085733972769812469, 0.0085622332925137812, 0.0085516695712872046, 0.0085413010910054821, 0.0085305666882313381, 0.0085200729746698727, 0.0085100202493640659, 0.0085004137572926523, 0.0084912176522912684, 0.0084822977780446944, 0.0084728538477981587, 0.0084637535759239275, 0.0084552301952354574, 0.0084472231512826967, 0.008439629984549283, 0.0084322257640332427, 0.008424256543551176, 0.0084160437214625353, 0.0084079868211186758, 0.008399771955665181, 0.008391774713018281, 0.0083842282989519297, 0.0083769642772239961, 0.0083698826205041519, 0.0083630836378127196, 0.0083565128346284236, 0.0083494953313504941, 0.0083425013630492473, 0.008335879709173195, 0.0083296763129157205, 0.0083238527152067112, 0.0083183545341324345, 0.0083131197732501903, 0.0083081157051796244, 0.0083033124755729822, 0.0082986640091198237, 0.0082941578881858199, 0.0082897787936954577, 0.0082855098061085583, 0.0082813304630257063, 0.0082772267891319303, 0.0082732087127160656, 0.008269280816460195, 0.0082654240679780333, 0.0082616309841731291, 0.0082578836101319854, 0.0082541803183504344, 0.0082505178456056087, 0.0082468867465547019, 0.0082432975518855704, 0.0082397336323048343, 0.0082361720521543797, 0.0082326112137077172, 0.0082290476935586044, 0.0082254747000003684, 0.0082218902841352751, 0.0082182713699736221, 0.0082143328625959369, 0.0082092303645792623, 0.0082043664754450161, 0.0081997286639245107, 0.008195258841638681, 0.0081909215467948111, 0.0081867216892871769, 0.0081826244750960661, 0.0081786170443715039, 0.0081746763382373987, 0.0081708029878436311, 0.0081669748023163301, 0.0081631857070090224, 0.0081594079217433002, 0.0081556353106059729, 0.008151845904515535, 0.008148035984342588, 0.0081441991988847415, 0.0081402628758880467, 0.0081360060714790374, 0.0081299588567509198], 'val_acc': [0.0051451672179345827, 0.004410143329658214, 0.0036751194413818448, 0.0033076074972436605, 0.002205071664829107, 0.002205071664829107, 0.0025725836089672913, 0.0029400955531054761, 0.0033076074972436605, 0.0036751194413818448, 0.0040426313855200296, 0.027930907754502021, 0.037486218302094816, 0.037486218302094816, 0.037486218302094816, 0.037486218302094816, 0.037486218302094816, 0.038588754134509372, 0.038956266078647557, 0.038956266078647557, 0.039691289966923927, 0.039691289966923927, 0.040058801911062113, 0.040426313855200291, 0.040426313855200291, 0.041161337743476661, 0.041161337743476661, 0.041161337743476661, 0.041528849687614847, 0.041528849687614847, 0.042263873575891217, 0.042998897464167588, 0.043366409408305773, 0.043366409408305773, 0.043366409408305773, 0.043366409408305773, 0.043733921352443951, 0.044836457184858507, 0.045203969128996692, 0.045203969128996692, 0.045203969128996692, 0.045203969128996692, 0.045571481073134877, 0.045938993017273062, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248], 'loss': [0.0097929650978922003, 0.00961103531032091, 0.0094552465359109585, 0.0093292712705051861, 0.009225457472212515, 0.0091398477824561446, 0.0090693333582309941, 0.0090100630999847883, 0.0089590810800600634, 0.0089138678293453413, 0.0088731295597098553, 0.008835965441248381, 0.0088030387432195233, 0.0087740048583232512, 0.0087470636648545822, 0.0087217768601413823, 0.0086979632280383776, 0.0086745282961347148, 0.0086524809507315427, 0.0086329317905124939, 0.0086157441603796486, 0.0086004774418719059, 0.0085867518530290919, 0.0085742602815728798, 0.008562717505020679, 0.0085519049250342098, 0.0085415700412815702, 0.0085310630072322063, 0.0085204673262946999, 0.0085102223209434086, 0.0085003991288133997, 0.0084910134891075743, 0.0084819972424340258, 0.0084728604292114533, 0.0084635069417971047, 0.0084547180747808794, 0.0084464855422840251, 0.0084387176218933598, 0.0084312718161679567, 0.0084236171811030765, 0.0084154555899627996, 0.0084072965296376062, 0.0083991490577453778, 0.0083909118839538329, 0.0083830750955338935, 0.0083756233555563938, 0.0083683987791812672, 0.0083614214725506158, 0.0083547349418149376, 0.0083479333024897712, 0.0083408390093062997, 0.0083339973051630017, 0.0083275626164203594, 0.0083215297962836911, 0.0083158415866478666, 0.0083104554413779754, 0.0083053061423444402, 0.0083003679124200157, 0.0082956042102541143, 0.0082909964547210543, 0.00828652036696036, 0.0082821615040988162, 0.0082779035870247826, 0.0082737281082884591, 0.0082696386067327276, 0.0082656431298900029, 0.0082617203557661043, 0.0082578689844875781, 0.0082540694685686918, 0.0082503144321907172, 0.0082465967858934737, 0.0082429234813878229, 0.008239286522525844, 0.008235676894271916, 0.0082320831969839459, 0.0082284877012957381, 0.0082248965036720717, 0.0082212979819571205, 0.0082176789718885739, 0.0082140482243205793, 0.0082103059909130315, 0.0082056929399760663, 0.0082006802253367511, 0.008195926515655063, 0.0081913750815317647, 0.0081869672659345121, 0.0081827027326635167, 0.0081785524919458993, 0.0081744990000055216, 0.008170523484696695, 0.0081666124655624048, 0.0081627631837295662, 0.0081589540466208959, 0.008155170363871667, 0.0081513973637250235, 0.0081476210146123641, 0.0081438227540984749, 0.0081400000729737691, 0.0081361234232662609, 0.0081320821836991328, 0.0081272520723007224], 'acc': [0.0046642936050079785, 0.0039278261936909293, 0.0039278261936909293, 0.0034368479194795631, 0.0031913587823738801, 0.0034368479194795631, 0.0035595924880324047, 0.0035595924889469228, 0.003682337056585246, 0.0039278261936909293, 0.0040505707622437706, 0.012519945993304355, 0.035595924881238562, 0.040260218486246543, 0.040751196760457908, 0.040996685897563591, 0.041610408740327801, 0.041855897876518965, 0.042101387013624647, 0.042837854425856213, 0.043697066405726105, 0.04381981097427895, 0.044065300110470114, 0.044433533817043153, 0.044433533817043153, 0.045170001228360207, 0.045415490364551371, 0.045783724073867965, 0.046520191483355976, 0.047379403461396831, 0.047747637167969877, 0.047993126304161041, 0.048729593716392607, 0.048975082852583771, 0.049834294833368181, 0.049957039401921026, 0.05020252853811219, 0.05057076224377071, 0.051061740518896601, 0.051184485087449438, 0.051307229656002283, 0.051552718793107966, 0.051429974223640602, 0.051429974209008314, 0.05179820792929913, 0.051920952497851967, 0.052043697066404812, 0.052043697066404812, 0.052043697068233849, 0.052043697066404812, 0.052043697067319331, 0.052166441635872168, 0.052166441636786687, 0.052166441635872168, 0.05216644163495765, 0.052411930773892376, 0.052411930772063339, 0.052411930773892376, 0.052411930773892376, 0.052411930772063339, 0.052411930772977858, 0.052411930772063339, 0.052411930772063339, 0.052411930772063339, 0.052411930772977858, 0.052411930772977858, 0.052411930772977858, 0.052411930772977858, 0.052534675340616177, 0.052534675342445214, 0.052534675340616177, 0.052534675340616177, 0.052534675341530696, 0.052534675341530696, 0.052534675341530696, 0.052534675340616177, 0.052534675340616177, 0.052534675341530696, 0.052534675340616177, 0.052534675341530696, 0.052534675341530696, 0.052534675340616177, 0.052534675342445214, 0.05265741991008354, 0.052657419910998059, 0.052657419909169022, 0.052657419910998059, 0.052657419909169022, 0.052657419909169022, 0.052657419910998059, 0.05265741991008354, 0.052657419909169022, 0.052657419909169022, 0.052657419909169022, 0.052657419909169022, 0.052657419909169022, 0.052657419910998059, 0.052657419909169022, 0.052657419909169022, 0.052657419910998059, 0.052657419910998059]}
[2017-11-18 18:55:30,721 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 18:55:30,845 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 18:55:30,845 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 18:55:31,679 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:141]: done!
[2017-11-18 18:55:31,679 AE_UNIGRAMA_3L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_3L_FULLDS_OVER_04 finished!
