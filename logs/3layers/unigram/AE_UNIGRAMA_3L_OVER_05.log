[2017-10-21 17:33:16,132 AE_UNIGRAMA_3L_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_OVER_05
[2017-10-21 17:33:16,132 AE_UNIGRAMA_3L_OVER_05.py:149]: >> Printing header log
[2017-10-21 17:33:16,132 AE_UNIGRAMA_3L_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_OVER_05
	layers = 96,172,156,139,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3387bbf780>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f3387bbf860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 17:33:16,132 AE_UNIGRAMA_3L_OVER_05.py:151]: >> Loading dataset... 
[2017-10-21 17:33:16,644 AE_UNIGRAMA_3L_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 17:33:16,644 AE_UNIGRAMA_3L_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-10-21 17:33:16,644 AE_UNIGRAMA_3L_OVER_05.py:60]: =======================================
[2017-10-21 17:33:16,644 AE_UNIGRAMA_3L_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3387bbf780>, 'discard_decoder_function': True}
[2017-10-21 17:33:16,726 AE_UNIGRAMA_3L_OVER_05.py:76]: training and evaluate autoencoder
[2017-10-21 17:34:16,542 AE_UNIGRAMA_3L_OVER_05.py:88]: trained and evaluated!
[2017-10-21 17:34:16,543 AE_UNIGRAMA_3L_OVER_05.py:91]: Training history: 
{'val_loss': [0.010190192492311772, 0.010125087085958972, 0.01000698119554267, 0.0098416068726201924, 0.0096832709317701462, 0.0095324353713085209, 0.0093892079892267076, 0.0092517819401001407, 0.0091183766390311224, 0.0089879810955500079, 0.0088603677068833531, 0.0087328250433377167, 0.0086102498639859682, 0.0084931920022880275, 0.008381593245389736, 0.0082751559457121954, 0.0081736178719005841, 0.0080766046928678076, 0.0079838227944580148, 0.0078950042137010609, 0.0078098701493170622, 0.0077274272730747124, 0.0076482593632375886, 0.0075725058048658877, 0.0074999280322384657, 0.0074306158937486131, 0.0073643218445484304, 0.0073010052907450272, 0.0072403934431092666, 0.0071823956067483445, 0.0071268558370634972, 0.0070736093470847522, 0.0070223999486675268, 0.0069732128185493571, 0.0069260288819282916, 0.0068808264050591169, 0.0068374747812027827, 0.0067959329611916083, 0.0067560272672140907, 0.0067177542890370116, 0.0066810078333827865, 0.0066456734843302837, 0.0066117342443769746, 0.0065791092944577278, 0.0065477365250508806, 0.0065175150832694484, 0.0064880999400657793, 0.0064595373845953482, 0.0064318914859656066, 0.0064050042967149319, 0.0063787034252263796, 0.0063532228637001994, 0.0063286767320423539, 0.0063050587100693502, 0.006282333777975083, 0.0062604737208401401, 0.00623945330986303, 0.0062192218623999991, 0.0061997573815812407, 0.006181033885584223, 0.0061629998539210916, 0.0061456388430358305, 0.0061289545072443427, 0.0061128469076713885, 0.0060973440376577764, 0.0060823975290175266, 0.0060680031423287319, 0.0060541383077331633, 0.0060407366503210094, 0.0060278382758197956, 0.0060154015118720145, 0.0060034023258544256, 0.0059918150215731679, 0.0059806145744945262, 0.0059698061917157199, 0.0059593567351177061, 0.0059492570282302822, 0.0059394755843874469, 0.005930022847212048, 0.0059208863321345536, 0.0059120577559235148, 0.0059035230794969992, 0.0058952660272140267, 0.0058872716113592613, 0.0058793257818069156, 0.0058713524020709736, 0.0058633770073545912, 0.0058556101007947916, 0.005848094793278932, 0.0058408278009428414, 0.0058338026478055686, 0.0058270163079342874, 0.0058204546712726686, 0.0058141223303835188, 0.005807990641038879, 0.0058020680180324944, 0.005796346771894334, 0.0057908031902514871, 0.0057854278092739969, 0.0057802287737066865, 0.0057752001667083636, 0.0057703266266497981], 'loss': [0.01022150513636476, 0.010158005110992746, 0.010080629114242477, 0.0099256022203056526, 0.0097631262002836807, 0.0096077614205705656, 0.0094601379961608816, 0.0093195455294210038, 0.0091838782931407247, 0.0090515323626661707, 0.0089222467020749312, 0.0087938532135927311, 0.0086674561000531555, 0.0085466388325632237, 0.0084313861493389881, 0.0083214558246554084, 0.0082165776501789221, 0.0081164686108888412, 0.0080207186535266404, 0.0079290720753797585, 0.0078412479982604335, 0.0077566727025625559, 0.0076749510633786107, 0.0075966771022309611, 0.007521745074510611, 0.0074500113599158058, 0.0073814804327445816, 0.0073159047085894864, 0.0072532318218782336, 0.00719322089578661, 0.0071357614784338351, 0.0070807091326789947, 0.0070278545130060249, 0.006976983953294812, 0.0069281809168198613, 0.0068813600318681518, 0.0068365039055469801, 0.0067934557058823824, 0.006752165993211932, 0.0067124838451955056, 0.0066744055339669293, 0.0066378134821977221, 0.006602633746195477, 0.0065688256394134097, 0.0065363112255500443, 0.0065049897197040959, 0.0064746430009195938, 0.0064451429508076939, 0.0064165290360944033, 0.0063887558300471702, 0.0063616953061500902, 0.006335263907538467, 0.006309793727414038, 0.0062852621658922121, 0.0062616266995398229, 0.0062388911526753228, 0.0062170023136939936, 0.0061959525617211603, 0.0061756699519448293, 0.0061561465380712199, 0.0061373495566644362, 0.0061192412061597317, 0.0061017909578374545, 0.0060850106990829192, 0.006068794400795845, 0.0060531875002984995, 0.0060381262958709202, 0.0060236165400184621, 0.0060096397319351815, 0.005996092062926615, 0.0059830547741441982, 0.0059704887992676663, 0.0059583518478376011, 0.005946609089420061, 0.0059352744019807264, 0.0059243104310125827, 0.0059137131498477429, 0.0059034643421715469, 0.0058935346693194347, 0.0058839516196177825, 0.0058746673281235276, 0.0058657070221156153, 0.0058570163319895951, 0.0058486126082793067, 0.0058404078106633452, 0.0058321421819990333, 0.0058238599117394233, 0.0058156845841577393, 0.0058077562476732134, 0.005800076715989335, 0.0057926589314560807, 0.0057854925899937541, 0.0057785624973636209, 0.0057718468361752269, 0.0057653644275018684, 0.0057590854767487869, 0.0057530124370093428, 0.0057471414167060758, 0.0057414407731957171, 0.0057359226992480875, 0.0057305790047197346, 0.0057254177309256724]}
[2017-10-21 17:34:16,543 AE_UNIGRAMA_3L_OVER_05.py:95]: done!
[2017-10-21 17:34:16,543 AE_UNIGRAMA_3L_OVER_05.py:155]: >> Executing classifier part ... 
[2017-10-21 17:34:16,543 AE_UNIGRAMA_3L_OVER_05.py:100]: =======================================
[2017-10-21 17:34:16,543 AE_UNIGRAMA_3L_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f3387bbf860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-21 17:34:16,602 AE_UNIGRAMA_3L_OVER_05.py:113]: training ... 
[2017-10-21 17:35:46,546 AE_UNIGRAMA_3L_OVER_05.py:125]: trained!
[2017-10-21 17:35:46,547 AE_UNIGRAMA_3L_OVER_05.py:128]: Training history: 
{'val_loss': [0.010190192492311772, 0.010125087085958972, 0.01000698119554267, 0.0098416068726201924, 0.0096832709317701462, 0.0095324353713085209, 0.0093892079892267076, 0.0092517819401001407, 0.0091183766390311224, 0.0089879810955500079, 0.0088603677068833531, 0.0087328250433377167, 0.0086102498639859682, 0.0084931920022880275, 0.008381593245389736, 0.0082751559457121954, 0.0081736178719005841, 0.0080766046928678076, 0.0079838227944580148, 0.0078950042137010609, 0.0078098701493170622, 0.0077274272730747124, 0.0076482593632375886, 0.0075725058048658877, 0.0074999280322384657, 0.0074306158937486131, 0.0073643218445484304, 0.0073010052907450272, 0.0072403934431092666, 0.0071823956067483445, 0.0071268558370634972, 0.0070736093470847522, 0.0070223999486675268, 0.0069732128185493571, 0.0069260288819282916, 0.0068808264050591169, 0.0068374747812027827, 0.0067959329611916083, 0.0067560272672140907, 0.0067177542890370116, 0.0066810078333827865, 0.0066456734843302837, 0.0066117342443769746, 0.0065791092944577278, 0.0065477365250508806, 0.0065175150832694484, 0.0064880999400657793, 0.0064595373845953482, 0.0064318914859656066, 0.0064050042967149319, 0.0063787034252263796, 0.0063532228637001994, 0.0063286767320423539, 0.0063050587100693502, 0.006282333777975083, 0.0062604737208401401, 0.00623945330986303, 0.0062192218623999991, 0.0061997573815812407, 0.006181033885584223, 0.0061629998539210916, 0.0061456388430358305, 0.0061289545072443427, 0.0061128469076713885, 0.0060973440376577764, 0.0060823975290175266, 0.0060680031423287319, 0.0060541383077331633, 0.0060407366503210094, 0.0060278382758197956, 0.0060154015118720145, 0.0060034023258544256, 0.0059918150215731679, 0.0059806145744945262, 0.0059698061917157199, 0.0059593567351177061, 0.0059492570282302822, 0.0059394755843874469, 0.005930022847212048, 0.0059208863321345536, 0.0059120577559235148, 0.0059035230794969992, 0.0058952660272140267, 0.0058872716113592613, 0.0058793257818069156, 0.0058713524020709736, 0.0058633770073545912, 0.0058556101007947916, 0.005848094793278932, 0.0058408278009428414, 0.0058338026478055686, 0.0058270163079342874, 0.0058204546712726686, 0.0058141223303835188, 0.005807990641038879, 0.0058020680180324944, 0.005796346771894334, 0.0057908031902514871, 0.0057854278092739969, 0.0057802287737066865, 0.0057752001667083636, 0.0057703266266497981], 'loss': [0.01022150513636476, 0.010158005110992746, 0.010080629114242477, 0.0099256022203056526, 0.0097631262002836807, 0.0096077614205705656, 0.0094601379961608816, 0.0093195455294210038, 0.0091838782931407247, 0.0090515323626661707, 0.0089222467020749312, 0.0087938532135927311, 0.0086674561000531555, 0.0085466388325632237, 0.0084313861493389881, 0.0083214558246554084, 0.0082165776501789221, 0.0081164686108888412, 0.0080207186535266404, 0.0079290720753797585, 0.0078412479982604335, 0.0077566727025625559, 0.0076749510633786107, 0.0075966771022309611, 0.007521745074510611, 0.0074500113599158058, 0.0073814804327445816, 0.0073159047085894864, 0.0072532318218782336, 0.00719322089578661, 0.0071357614784338351, 0.0070807091326789947, 0.0070278545130060249, 0.006976983953294812, 0.0069281809168198613, 0.0068813600318681518, 0.0068365039055469801, 0.0067934557058823824, 0.006752165993211932, 0.0067124838451955056, 0.0066744055339669293, 0.0066378134821977221, 0.006602633746195477, 0.0065688256394134097, 0.0065363112255500443, 0.0065049897197040959, 0.0064746430009195938, 0.0064451429508076939, 0.0064165290360944033, 0.0063887558300471702, 0.0063616953061500902, 0.006335263907538467, 0.006309793727414038, 0.0062852621658922121, 0.0062616266995398229, 0.0062388911526753228, 0.0062170023136939936, 0.0061959525617211603, 0.0061756699519448293, 0.0061561465380712199, 0.0061373495566644362, 0.0061192412061597317, 0.0061017909578374545, 0.0060850106990829192, 0.006068794400795845, 0.0060531875002984995, 0.0060381262958709202, 0.0060236165400184621, 0.0060096397319351815, 0.005996092062926615, 0.0059830547741441982, 0.0059704887992676663, 0.0059583518478376011, 0.005946609089420061, 0.0059352744019807264, 0.0059243104310125827, 0.0059137131498477429, 0.0059034643421715469, 0.0058935346693194347, 0.0058839516196177825, 0.0058746673281235276, 0.0058657070221156153, 0.0058570163319895951, 0.0058486126082793067, 0.0058404078106633452, 0.0058321421819990333, 0.0058238599117394233, 0.0058156845841577393, 0.0058077562476732134, 0.005800076715989335, 0.0057926589314560807, 0.0057854925899937541, 0.0057785624973636209, 0.0057718468361752269, 0.0057653644275018684, 0.0057590854767487869, 0.0057530124370093428, 0.0057471414167060758, 0.0057414407731957171, 0.0057359226992480875, 0.0057305790047197346, 0.0057254177309256724]}
[2017-10-21 17:35:46,547 AE_UNIGRAMA_3L_OVER_05.py:132]: evaluating model ... 
[2017-10-21 17:35:46,605 AE_UNIGRAMA_3L_OVER_05.py:136]: evaluated! 
[2017-10-21 17:35:46,605 AE_UNIGRAMA_3L_OVER_05.py:138]: generating reports ... 
[2017-10-21 17:35:47,160 AE_UNIGRAMA_3L_OVER_05.py:141]: done!
[2017-10-21 17:35:47,160 AE_UNIGRAMA_3L_OVER_05.py:157]: >> experiment AE_UNIGRAMA_3L_OVER_05 finished!
