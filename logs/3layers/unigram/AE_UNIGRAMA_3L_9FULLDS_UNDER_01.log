[2017-11-18 18:16:55,400 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:146]: >> Initializing execution of experiment AE_UNIGRAMA_3L_9FULLDS_UNDER_01
[2017-11-18 18:16:55,400 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:147]: >> Printing header log
[2017-11-18 18:16:55,400 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:36]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_9FULLDS_UNDER_01
	layers = 96,28,26,24,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc56d75aeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc56d75f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:16:55,400 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:149]: >> Loading dataset... 
[2017-11-18 18:16:57,574 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:53]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:16:57,574 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:151]: >> Executing autoencoder part ... 
[2017-11-18 18:16:57,574 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:58]: =======================================
[2017-11-18 18:16:57,574 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:63]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc56d75aeb8>, 'discard_decoder_function': True}
[2017-11-18 18:16:57,669 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:74]: training and evaluate autoencoder
[2017-11-18 18:18:11,090 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:86]: trained and evaluated!
[2017-11-18 18:18:11,091 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:89]: Training history: 
{'val_loss': [0.0096411810515640815, 0.0091079109088572155, 0.0086552571633317938, 0.0082661228345824109, 0.0079273987653535518, 0.0076420154952701186, 0.0073979701225614005, 0.007186384270400992, 0.0070049610770677477, 0.0068496946233110104, 0.0067156318351640088, 0.0065981494081410273, 0.0064931932902829543, 0.0064007315878133065, 0.0063185697395418856, 0.0062453105896150022, 0.0061804519308055316, 0.0061234537603108378, 0.0060730128025705214, 0.0060282107372451625, 0.0059881392717142396, 0.0059516933895182034, 0.0059178466570639944, 0.0058856038523865993, 0.0058550226273824954, 0.0058258258522334494, 0.0057977307284095463, 0.0057726261376765051, 0.0057505301878579135, 0.0057310060891796839, 0.0057135356927461014, 0.0056974805582784326, 0.0056831284638532587, 0.0056703376354603797, 0.0056589093811102199, 0.0056487070354614205, 0.0056395600209315881, 0.005631330219661842, 0.0056239398358405484, 0.0056172607141248788, 0.0056112529760420334, 0.0056057955285220059, 0.0056008424706420271, 0.0055963332061948461, 0.0055922030933161608, 0.0055884221839612074, 0.0055849656016175326, 0.0055817930087397882, 0.0055788790139526083, 0.0055761988915144327, 0.0055737206074883234, 0.0055714252787186615, 0.0055692945746482463, 0.0055673121150722673, 0.0055654546832415944, 0.005563710614349536, 0.0055620800057725244, 0.0055605405059399047, 0.005559084719205765, 0.0055577030316582557, 0.0055563899998863535, 0.0055551340597969553, 0.0055539279498292684, 0.0055527612816806621, 0.0055516356572704595, 0.0055505443991253267, 0.0055494850644487882, 0.005548456159650661, 0.0055474500469274704, 0.0055464674214339956, 0.0055455017968559089, 0.0055445490571992316, 0.0055436025455269586, 0.0055426615722462373, 0.0055417273128052676, 0.0055408033494245791, 0.0055398847732367118, 0.0055389562554113928, 0.00553793183711687, 0.0055368821919943283, 0.0055358288372404398, 0.0055347831271354685, 0.0055337425688256328, 0.0055326996744226682, 0.005531641855327298, 0.005530580584844934, 0.0055295221305779844, 0.0055284777216206673, 0.0055274477045235554, 0.0055264286083045724, 0.005525411626300783, 0.0055244049386459155, 0.005523397466417666, 0.0055223957898840716, 0.0055213965060896498, 0.0055204056154078132, 0.0055194202521648182, 0.0055184378678020873, 0.0055174546214268949, 0.0055164678907210132, 0.005515473375890304], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.009941273676173203, 0.0093745170564659246, 0.0088843872246648081, 0.0084688140914334284, 0.0081062033124646663, 0.007797208518965911, 0.0075357760468135948, 0.0073103855580765476, 0.0071157810255488224, 0.0069494831062669521, 0.0068066429725867688, 0.0066826425646974164, 0.0065727050197715992, 0.0064752578817772527, 0.0063892372954045575, 0.0063124714077787449, 0.0062443384663143, 0.0061843159821854312, 0.006131414913852328, 0.0060845563079367547, 0.0060428700971572481, 0.0060053345087924346, 0.0059708494067624643, 0.0059383604828141629, 0.0059077094892723272, 0.0058782375742303739, 0.0058501586201414966, 0.0058239225692095029, 0.0058008102297497565, 0.005780453971692634, 0.0057623850212449477, 0.0057459860544332121, 0.0057311089315243745, 0.0057178660827696074, 0.0057060726918508756, 0.0056955323979712138, 0.0056861141944406762, 0.0056776739306550377, 0.0056700811599524961, 0.005663261962961943, 0.005657103654738857, 0.0056515577273463687, 0.0056465197275906553, 0.0056419479773289899, 0.0056377696407801338, 0.0056339557971601855, 0.0056304700841355122, 0.0056272740488408045, 0.0056243412143708454, 0.0056216486898181487, 0.0056191691867568212, 0.0056168759391223913, 0.005614751675893803, 0.005612776643247129, 0.0056109401494917567, 0.005609218307123881, 0.0056076020449793195, 0.0056060860977189533, 0.0056046517887642575, 0.0056032953990550879, 0.0056020046023136857, 0.0056007769386001351, 0.0055995982938105556, 0.0055984641655998811, 0.0055973658492399769, 0.0055963061767653945, 0.0055952798111044847, 0.0055942788499617696, 0.0055933001532815045, 0.0055923431830982992, 0.0055914080818483796, 0.0055904851360899276, 0.0055895696516005053, 0.0055886594257056272, 0.0055877530087794728, 0.0055868533894106905, 0.0055859577209324404, 0.0055850629837767649, 0.0055841053974940115, 0.0055830722807446911, 0.0055820295163988704, 0.0055809911531152145, 0.0055799520966266876, 0.0055789189086020968, 0.0055778718653394614, 0.0055768062339207874, 0.0055757386126246049, 0.0055746816611849112, 0.0055736411805056025, 0.0055726204710832266, 0.0055716100958891224, 0.0055705988735652847, 0.0055695990390519584, 0.0055685986037001083, 0.0055676041087161961, 0.0055666142157026893, 0.0055656306494982592, 0.0055646468529495317, 0.0055636655551505902, 0.0055626869870173037, 0.0055617007803699095], 'acc': [0.38836381489387445, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822264767316, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182]}
[2017-11-18 18:18:11,091 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:93]: done!
[2017-11-18 18:18:11,091 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:153]: >> Executing classifier part ... 
[2017-11-18 18:18:11,091 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:98]: =======================================
[2017-11-18 18:18:11,091 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:102]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc56d75f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:18:11,124 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:111]: training ... 
[2017-11-18 18:21:33,084 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:123]: trained!
[2017-11-18 18:21:33,085 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:126]: Training history: 
{'val_loss': [0.0096411810515640815, 0.0091079109088572155, 0.0086552571633317938, 0.0082661228345824109, 0.0079273987653535518, 0.0076420154952701186, 0.0073979701225614005, 0.007186384270400992, 0.0070049610770677477, 0.0068496946233110104, 0.0067156318351640088, 0.0065981494081410273, 0.0064931932902829543, 0.0064007315878133065, 0.0063185697395418856, 0.0062453105896150022, 0.0061804519308055316, 0.0061234537603108378, 0.0060730128025705214, 0.0060282107372451625, 0.0059881392717142396, 0.0059516933895182034, 0.0059178466570639944, 0.0058856038523865993, 0.0058550226273824954, 0.0058258258522334494, 0.0057977307284095463, 0.0057726261376765051, 0.0057505301878579135, 0.0057310060891796839, 0.0057135356927461014, 0.0056974805582784326, 0.0056831284638532587, 0.0056703376354603797, 0.0056589093811102199, 0.0056487070354614205, 0.0056395600209315881, 0.005631330219661842, 0.0056239398358405484, 0.0056172607141248788, 0.0056112529760420334, 0.0056057955285220059, 0.0056008424706420271, 0.0055963332061948461, 0.0055922030933161608, 0.0055884221839612074, 0.0055849656016175326, 0.0055817930087397882, 0.0055788790139526083, 0.0055761988915144327, 0.0055737206074883234, 0.0055714252787186615, 0.0055692945746482463, 0.0055673121150722673, 0.0055654546832415944, 0.005563710614349536, 0.0055620800057725244, 0.0055605405059399047, 0.005559084719205765, 0.0055577030316582557, 0.0055563899998863535, 0.0055551340597969553, 0.0055539279498292684, 0.0055527612816806621, 0.0055516356572704595, 0.0055505443991253267, 0.0055494850644487882, 0.005548456159650661, 0.0055474500469274704, 0.0055464674214339956, 0.0055455017968559089, 0.0055445490571992316, 0.0055436025455269586, 0.0055426615722462373, 0.0055417273128052676, 0.0055408033494245791, 0.0055398847732367118, 0.0055389562554113928, 0.00553793183711687, 0.0055368821919943283, 0.0055358288372404398, 0.0055347831271354685, 0.0055337425688256328, 0.0055326996744226682, 0.005531641855327298, 0.005530580584844934, 0.0055295221305779844, 0.0055284777216206673, 0.0055274477045235554, 0.0055264286083045724, 0.005525411626300783, 0.0055244049386459155, 0.005523397466417666, 0.0055223957898840716, 0.0055213965060896498, 0.0055204056154078132, 0.0055194202521648182, 0.0055184378678020873, 0.0055174546214268949, 0.0055164678907210132, 0.005515473375890304], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.009941273676173203, 0.0093745170564659246, 0.0088843872246648081, 0.0084688140914334284, 0.0081062033124646663, 0.007797208518965911, 0.0075357760468135948, 0.0073103855580765476, 0.0071157810255488224, 0.0069494831062669521, 0.0068066429725867688, 0.0066826425646974164, 0.0065727050197715992, 0.0064752578817772527, 0.0063892372954045575, 0.0063124714077787449, 0.0062443384663143, 0.0061843159821854312, 0.006131414913852328, 0.0060845563079367547, 0.0060428700971572481, 0.0060053345087924346, 0.0059708494067624643, 0.0059383604828141629, 0.0059077094892723272, 0.0058782375742303739, 0.0058501586201414966, 0.0058239225692095029, 0.0058008102297497565, 0.005780453971692634, 0.0057623850212449477, 0.0057459860544332121, 0.0057311089315243745, 0.0057178660827696074, 0.0057060726918508756, 0.0056955323979712138, 0.0056861141944406762, 0.0056776739306550377, 0.0056700811599524961, 0.005663261962961943, 0.005657103654738857, 0.0056515577273463687, 0.0056465197275906553, 0.0056419479773289899, 0.0056377696407801338, 0.0056339557971601855, 0.0056304700841355122, 0.0056272740488408045, 0.0056243412143708454, 0.0056216486898181487, 0.0056191691867568212, 0.0056168759391223913, 0.005614751675893803, 0.005612776643247129, 0.0056109401494917567, 0.005609218307123881, 0.0056076020449793195, 0.0056060860977189533, 0.0056046517887642575, 0.0056032953990550879, 0.0056020046023136857, 0.0056007769386001351, 0.0055995982938105556, 0.0055984641655998811, 0.0055973658492399769, 0.0055963061767653945, 0.0055952798111044847, 0.0055942788499617696, 0.0055933001532815045, 0.0055923431830982992, 0.0055914080818483796, 0.0055904851360899276, 0.0055895696516005053, 0.0055886594257056272, 0.0055877530087794728, 0.0055868533894106905, 0.0055859577209324404, 0.0055850629837767649, 0.0055841053974940115, 0.0055830722807446911, 0.0055820295163988704, 0.0055809911531152145, 0.0055799520966266876, 0.0055789189086020968, 0.0055778718653394614, 0.0055768062339207874, 0.0055757386126246049, 0.0055746816611849112, 0.0055736411805056025, 0.0055726204710832266, 0.0055716100958891224, 0.0055705988735652847, 0.0055695990390519584, 0.0055685986037001083, 0.0055676041087161961, 0.0055666142157026893, 0.0055656306494982592, 0.0055646468529495317, 0.0055636655551505902, 0.0055626869870173037, 0.0055617007803699095], 'acc': [0.38836381489387445, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822264767316, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182]}
[2017-11-18 18:21:33,085 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:130]: evaluating model ... 
[2017-11-18 18:21:33,158 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:134]: evaluated! 
[2017-11-18 18:21:33,158 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:136]: generating reports ... 
[2017-11-18 18:21:33,972 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:139]: done!
[2017-11-18 18:21:33,972 AE_UNIGRAMA_3L_9FULLDS_UNDER_01.py:155]: >> experiment AE_UNIGRAMA_3L_9FULLDS_UNDER_01 finished!
