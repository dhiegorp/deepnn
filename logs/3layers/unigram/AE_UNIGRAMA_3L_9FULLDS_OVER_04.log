[2017-11-18 18:50:22,356 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_3L_9FULLDS_OVER_04
[2017-11-18 18:50:22,356 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 18:50:22,357 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_3L_9FULLDS_OVER_04
	layers = 96,134,122,109,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/3layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/3layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/3layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/3layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/3layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efc8e573ef0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efc8e5d8438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:50:22,357 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 18:50:24,471 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:50:24,472 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:50:24,472 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 18:50:24,472 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efc8e573ef0>, 'discard_decoder_function': True}
[2017-11-18 18:50:24,567 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 18:52:46,919 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 18:52:46,919 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0095348181250925809, 0.008794151778096379, 0.0082001473618762335, 0.007718950108882041, 0.0073317232973345147, 0.0070167743032390865, 0.0067612681278082015, 0.0065541536708453784, 0.0063864483081491627, 0.0062500574712965667, 0.0061381352731313876, 0.0060453554240590349, 0.0059676711193913266, 0.0059031919079590746, 0.0058494419813907754, 0.0058046375637999283, 0.005766889603739383, 0.0057350899596335433, 0.0057081803939593098, 0.0056851696747894928, 0.005665426349588415, 0.0056484139055316225, 0.0056337136135206243, 0.0056209466525362732, 0.00560971439743496, 0.0055998297981015629, 0.0055912664679188158, 0.0055836771280449657, 0.0055769743297375031, 0.0055709830562295564, 0.0055656145911736335, 0.0055607799974566911, 0.005556389181085755, 0.0055523372428284293, 0.0055485235315633581, 0.0055449186115416474, 0.0055415432939380513, 0.005538388456514695, 0.0055354204397985371, 0.0055326197476245021, 0.0055300022099093174, 0.0055275244757434496, 0.0055251510218963249, 0.0055228841609298602, 0.0055207232177121998, 0.0055186365691185799, 0.005516603149922728, 0.0055146174041060779, 0.0055126615439550879, 0.0055107385646935196, 0.0055088402754916391, 0.0055069531660112154, 0.0055050657478868635, 0.0055031838331567329, 0.005501306565028014, 0.0054994137250557844, 0.0054974208695616183, 0.0054953283237896442, 0.0054924284649286552, 0.0054876244224256092, 0.0054831041604313331, 0.0054788518595539695, 0.0054747168184694443, 0.0054706549173537938, 0.0054666203819249528, 0.0054628087651088578, 0.0054591696089710687, 0.0054555717274342632, 0.005451862416967739, 0.0054481451738302659, 0.005444530822670047, 0.0054411548995014136, 0.0054378006747625674, 0.0054344521683648648, 0.0054311148849860496, 0.0054277945448497622, 0.0054244824658801387, 0.0054211826637854139, 0.0054178831704201858, 0.0054145923581040058, 0.0054112956553693482, 0.0054080340042142131, 0.0054048298304823173, 0.0054016628273369496, 0.0053985168949797751, 0.0053954001235269429, 0.0053923376585168301, 0.0053893043244622428, 0.005386281643885652, 0.005383267745499536, 0.0053802505518025347, 0.0053772291022933707, 0.0053741814364473449, 0.0053711212385625182, 0.0053680498961246994, 0.0053649550405300492, 0.0053618384525350995, 0.0053586980186092013, 0.0053555245104956739, 0.0053523387238814555, 0.0053491151031861079], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099323314003124177, 0.0091557414022302788, 0.0084917374582609336, 0.0079580426179087504, 0.0075269773765612863, 0.0071788168435350901, 0.0068956787792394877, 0.0066663912152573127, 0.0064809764379310112, 0.0063305060174355032, 0.0062078570286197262, 0.0061068683177369007, 0.0060225972439122083, 0.0059524451939056908, 0.0058941469039428237, 0.005845562036421159, 0.0058049697726045863, 0.0057707472847930326, 0.0057418977638140252, 0.0057174161693731252, 0.0056964438636671203, 0.0056784654363561836, 0.0056629512726879237, 0.0056495431166339307, 0.0056378456215326498, 0.0056275298943091745, 0.0056185461288679045, 0.0056107004937408665, 0.0056037277022013823, 0.0055975584698857205, 0.0055920456301654584, 0.0055870930761980457, 0.0055826231348576928, 0.0055785270669462452, 0.0055747089022273252, 0.0055710952183705203, 0.0055676911557688844, 0.0055645228516412425, 0.0055615373318291294, 0.0055587270571008313, 0.005556089784200113, 0.0055536088977012257, 0.0055512504656029232, 0.0055489802781761794, 0.0055468198554083931, 0.0055447449633647941, 0.0055427292982127545, 0.0055407692742403319, 0.0055388388116718824, 0.0055369415021065595, 0.0055350716582693669, 0.0055332174407492218, 0.0055313732371473148, 0.0055295259940295197, 0.0055276928412381294, 0.005525847791078062, 0.0055239559949149461, 0.0055219737833567678, 0.0055197450131492494, 0.0055159477690081369, 0.0055114496487296948, 0.0055072749137253805, 0.0055032785114472928, 0.0054993435117569609, 0.0054954235096523456, 0.0054916137728482995, 0.0054880046415779109, 0.0054845068769739111, 0.0054809733606487184, 0.0054773769547290137, 0.0054738216694388171, 0.0054704482189083673, 0.0054672038306876405, 0.0054639635604856653, 0.0054607272684954571, 0.0054575010875338968, 0.0054542828491066214, 0.0054510873183402286, 0.0054478844301597907, 0.0054446859717916874, 0.0054414941128162727, 0.0054383051385459439, 0.0054351610392313785, 0.0054320475356695631, 0.0054289683577519654, 0.0054259134662396243, 0.0054228948891630194, 0.0054199066967283299, 0.0054169450559607276, 0.0054139867227200322, 0.0054110316261882334, 0.0054080655522360105, 0.005405083026042398, 0.0054020758043109044, 0.0053990608934238529, 0.0053960235569476571, 0.0053929649426599424, 0.0053898822667098447, 0.0053867726154992138, 0.005383637156753605, 0.0053804826198987788], 'acc': [0.5145452314027763, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822263669894, 0.5938382226842539, 0.59383822267327968, 0.59383822262206665, 0.59383822272449271, 0.59383822264767316, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822264767316, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182]}
[2017-11-18 18:52:46,919 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 18:52:46,919 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 18:52:46,920 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 18:52:46,920 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efc8e5d8438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:52:46,953 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 18:57:40,794 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:125]: trained!
[2017-11-18 18:57:40,795 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0095348181250925809, 0.008794151778096379, 0.0082001473618762335, 0.007718950108882041, 0.0073317232973345147, 0.0070167743032390865, 0.0067612681278082015, 0.0065541536708453784, 0.0063864483081491627, 0.0062500574712965667, 0.0061381352731313876, 0.0060453554240590349, 0.0059676711193913266, 0.0059031919079590746, 0.0058494419813907754, 0.0058046375637999283, 0.005766889603739383, 0.0057350899596335433, 0.0057081803939593098, 0.0056851696747894928, 0.005665426349588415, 0.0056484139055316225, 0.0056337136135206243, 0.0056209466525362732, 0.00560971439743496, 0.0055998297981015629, 0.0055912664679188158, 0.0055836771280449657, 0.0055769743297375031, 0.0055709830562295564, 0.0055656145911736335, 0.0055607799974566911, 0.005556389181085755, 0.0055523372428284293, 0.0055485235315633581, 0.0055449186115416474, 0.0055415432939380513, 0.005538388456514695, 0.0055354204397985371, 0.0055326197476245021, 0.0055300022099093174, 0.0055275244757434496, 0.0055251510218963249, 0.0055228841609298602, 0.0055207232177121998, 0.0055186365691185799, 0.005516603149922728, 0.0055146174041060779, 0.0055126615439550879, 0.0055107385646935196, 0.0055088402754916391, 0.0055069531660112154, 0.0055050657478868635, 0.0055031838331567329, 0.005501306565028014, 0.0054994137250557844, 0.0054974208695616183, 0.0054953283237896442, 0.0054924284649286552, 0.0054876244224256092, 0.0054831041604313331, 0.0054788518595539695, 0.0054747168184694443, 0.0054706549173537938, 0.0054666203819249528, 0.0054628087651088578, 0.0054591696089710687, 0.0054555717274342632, 0.005451862416967739, 0.0054481451738302659, 0.005444530822670047, 0.0054411548995014136, 0.0054378006747625674, 0.0054344521683648648, 0.0054311148849860496, 0.0054277945448497622, 0.0054244824658801387, 0.0054211826637854139, 0.0054178831704201858, 0.0054145923581040058, 0.0054112956553693482, 0.0054080340042142131, 0.0054048298304823173, 0.0054016628273369496, 0.0053985168949797751, 0.0053954001235269429, 0.0053923376585168301, 0.0053893043244622428, 0.005386281643885652, 0.005383267745499536, 0.0053802505518025347, 0.0053772291022933707, 0.0053741814364473449, 0.0053711212385625182, 0.0053680498961246994, 0.0053649550405300492, 0.0053618384525350995, 0.0053586980186092013, 0.0053555245104956739, 0.0053523387238814555, 0.0053491151031861079], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099323314003124177, 0.0091557414022302788, 0.0084917374582609336, 0.0079580426179087504, 0.0075269773765612863, 0.0071788168435350901, 0.0068956787792394877, 0.0066663912152573127, 0.0064809764379310112, 0.0063305060174355032, 0.0062078570286197262, 0.0061068683177369007, 0.0060225972439122083, 0.0059524451939056908, 0.0058941469039428237, 0.005845562036421159, 0.0058049697726045863, 0.0057707472847930326, 0.0057418977638140252, 0.0057174161693731252, 0.0056964438636671203, 0.0056784654363561836, 0.0056629512726879237, 0.0056495431166339307, 0.0056378456215326498, 0.0056275298943091745, 0.0056185461288679045, 0.0056107004937408665, 0.0056037277022013823, 0.0055975584698857205, 0.0055920456301654584, 0.0055870930761980457, 0.0055826231348576928, 0.0055785270669462452, 0.0055747089022273252, 0.0055710952183705203, 0.0055676911557688844, 0.0055645228516412425, 0.0055615373318291294, 0.0055587270571008313, 0.005556089784200113, 0.0055536088977012257, 0.0055512504656029232, 0.0055489802781761794, 0.0055468198554083931, 0.0055447449633647941, 0.0055427292982127545, 0.0055407692742403319, 0.0055388388116718824, 0.0055369415021065595, 0.0055350716582693669, 0.0055332174407492218, 0.0055313732371473148, 0.0055295259940295197, 0.0055276928412381294, 0.005525847791078062, 0.0055239559949149461, 0.0055219737833567678, 0.0055197450131492494, 0.0055159477690081369, 0.0055114496487296948, 0.0055072749137253805, 0.0055032785114472928, 0.0054993435117569609, 0.0054954235096523456, 0.0054916137728482995, 0.0054880046415779109, 0.0054845068769739111, 0.0054809733606487184, 0.0054773769547290137, 0.0054738216694388171, 0.0054704482189083673, 0.0054672038306876405, 0.0054639635604856653, 0.0054607272684954571, 0.0054575010875338968, 0.0054542828491066214, 0.0054510873183402286, 0.0054478844301597907, 0.0054446859717916874, 0.0054414941128162727, 0.0054383051385459439, 0.0054351610392313785, 0.0054320475356695631, 0.0054289683577519654, 0.0054259134662396243, 0.0054228948891630194, 0.0054199066967283299, 0.0054169450559607276, 0.0054139867227200322, 0.0054110316261882334, 0.0054080655522360105, 0.005405083026042398, 0.0054020758043109044, 0.0053990608934238529, 0.0053960235569476571, 0.0053929649426599424, 0.0053898822667098447, 0.0053867726154992138, 0.005383637156753605, 0.0053804826198987788], 'acc': [0.5145452314027763, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822263669894, 0.5938382226842539, 0.59383822267327968, 0.59383822262206665, 0.59383822272449271, 0.59383822264767316, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822264767316, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182]}
[2017-11-18 18:57:40,795 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 18:57:40,880 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 18:57:40,881 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 18:57:41,738 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:141]: done!
[2017-11-18 18:57:41,738 AE_UNIGRAMA_3L_9FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_3L_9FULLDS_OVER_04 finished!
