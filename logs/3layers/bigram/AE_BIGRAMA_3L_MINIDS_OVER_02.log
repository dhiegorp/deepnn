[2018-06-03 00:54:28,376 AE_BIGRAMA_3L_MINIDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_3L_MINIDS_OVER_02
[2018-06-03 00:54:28,376 AE_BIGRAMA_3L_MINIDS_OVER_02.py:146]: >> Printing header log
[2018-06-03 00:54:28,376 AE_BIGRAMA_3L_MINIDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_3L_MINIDS_OVER_02
	layers = 9216,14746,13272,11799
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/3layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/3layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/3layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/3layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/3layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/3layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa13cf980b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa13cf98630>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,376 AE_BIGRAMA_3L_MINIDS_OVER_02.py:148]: >> Loading dataset... 
[2018-06-03 00:54:54,540 AE_BIGRAMA_3L_MINIDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-06-03 00:54:54,540 AE_BIGRAMA_3L_MINIDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-06-03 00:54:54,541 AE_BIGRAMA_3L_MINIDS_OVER_02.py:57]: =======================================
[2018-06-03 00:54:54,541 AE_BIGRAMA_3L_MINIDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa13cf980b8>, 'discard_decoder_function': True}
[2018-06-03 00:54:54,666 AE_BIGRAMA_3L_MINIDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-06-06 21:36:30,799 AE_BIGRAMA_3L_MINIDS_OVER_02.py:85]: trained and evaluated!
[2018-06-06 21:36:30,800 AE_BIGRAMA_3L_MINIDS_OVER_02.py:88]: Training history: 
{'val_loss': [0.00010628952750311455, 0.00010628851664556346, 0.00010628749720703041, 0.00010628647278080161, 0.00010628543618030466, 0.00010628439074854713, 0.00010628332987102206, 0.00010628225932201526, 0.0001062811729160689, 0.00010628008790453209, 0.00010627900362595417, 0.0001062779224579822, 0.00010627683058165984, 0.00010627572161488175, 0.00010627460063472893, 0.00010627348260428866, 0.00010627235500962893, 0.00010627122316023229, 0.00010627007497121586, 0.0001062689112470467, 0.00010626773729720737, 0.00010626654929601009, 0.0001062653353015883, 0.00010626411043792272, 0.00010626286269163859, 0.00010626161633976403, 0.0001062603407231656, 0.00010625903559156468, 0.00010625770496729652, 0.00010625633152750382, 0.00010625491280515429, 0.0001062534792091027, 0.00010625203195498817, 0.00010625054016915271, 0.00010624900644376796, 0.00010624742523694974, 0.00010624577922584072, 0.00010624404028984798, 0.00010624223236633574, 0.00010624035366759944, 0.00010623838604843765, 0.00010623631912228681, 0.00010623417684438819, 0.00010623194269635154, 0.00010622963148037072, 0.00010622724555621578, 0.00010622476736862779, 0.00010622215703391774, 0.0001062194443709979, 0.00010621656620238865, 0.00010621350087898759, 0.00010621033253017195, 0.00010620705611461485, 0.00010620363796983916, 0.00010620006713721585, 0.00010619630005038447, 0.00010619242096386154, 0.0001061884017391771, 0.00010618426806564586, 0.00010617994950770765, 0.0001061754782619218, 0.00010617085824336133, 0.0001061661562227921, 0.00010616128449542768, 0.00010615625923999451, 0.00010615103655046823, 0.0001061456105453008, 0.00010614008389236588, 0.00010613444050232232, 0.00010612870563543573, 0.00010612286590179886, 0.00010611698276269494, 0.00010611104052207783, 0.0001061050513720927, 0.00010609900966359312, 0.00010609294185460676, 0.00010608684190269216, 0.00010608071154192278, 0.00010607457708730992, 0.0001060683908965267, 0.00010606220168452275, 0.00010605596465142146, 0.00010604969917594041, 0.00010604343402224618, 0.00010603715383395649, 0.00010603093601867937, 0.00010602465084269391, 0.00010601840106325902, 0.00010601215357208597, 0.00010600590649208498, 0.0001059996551573471, 0.00010599337128638598, 0.00010598712576168797, 0.0001059808859576446, 0.00010597459277274266, 0.00010596831569505892, 0.00010596205733464207, 0.0001059558283998425, 0.00010594958099805469, 0.00010594333817279058, 0.00010593710074639429], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00010647512375584163, 0.00010647408549802025, 0.00010647303821042738, 0.00010647197492520783, 0.0001064709096728727, 0.00010646983403985537, 0.00010646874774175359, 0.00010646763968687954, 0.00010646652456934955, 0.00010646540269726608, 0.00010646427499493645, 0.00010646314165196215, 0.0001064620078349841, 0.00010646086228641314, 0.00010645969370125978, 0.00010645851390591765, 0.00010645733363657177, 0.00010645613748810014, 0.00010645493550938236, 0.0001064537251881985, 0.00010645250988997526, 0.00010645127584490355, 0.00010645002201017513, 0.00010644875317322794, 0.00010644747234398578, 0.00010644617392920438, 0.00010644487150909124, 0.00010644354553099158, 0.00010644219784352, 0.00010644081702318606, 0.00010643939989416463, 0.00010643794754666431, 0.00010643646457852152, 0.00010643494662890175, 0.00010643335196177448, 0.0001064317146580096, 0.00010643004860591707, 0.00010642832806709311, 0.00010642652611812449, 0.0001064246389906814, 0.00010642268054937361, 0.00010642063453587239, 0.00010641849111459986, 0.00010641630311327431, 0.00010641404097776174, 0.0001064117270810393, 0.00010640933352798612, 0.0001064068423775601, 0.0001064042501458337, 0.00010640151343776325, 0.00010639864227852818, 0.00010639564351748268, 0.00010639249843147854, 0.00010638920789742265, 0.00010638576319364601, 0.0001063821338891076, 0.00010637832379953766, 0.00010637435546381466, 0.00010637024928780017, 0.00010636598609804239, 0.00010636150050572353, 0.00010635687193017247, 0.00010635211011216633, 0.00010634727152925233, 0.00010634224569115558, 0.00010633699695279379, 0.00010633156792710442, 0.0001063259598464972, 0.00010632025068458958, 0.0001063144084698284, 0.00010630849806962729, 0.0001063025057615776, 0.00010629646546064788, 0.00010629038778452221, 0.0001062842767385323, 0.00010627811921647437, 0.00010627193744912446, 0.00010626572262001275, 0.00010625946953879816, 0.00010625321908830437, 0.000106246928655594, 0.00010624065358060524, 0.00010623433008613308, 0.0001062279831758755, 0.00010622163657372034, 0.00010621527338143384, 0.00010620897271024239, 0.00010620260326110634, 0.00010619626559392195, 0.00010618993423098747, 0.00010618360173044399, 0.00010617727349593428, 0.00010617090198488191, 0.00010616457467467952, 0.00010615825542254094, 0.00010615187573492381, 0.00010614551477045495, 0.0001061391854457366, 0.00010613288351843522, 0.00010612656327088876, 0.00010612024830848416], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-06-06 21:36:30,801 AE_BIGRAMA_3L_MINIDS_OVER_02.py:92]: done!
[2018-06-06 21:36:30,802 AE_BIGRAMA_3L_MINIDS_OVER_02.py:152]: >> Executing classifier part ... 
[2018-06-06 21:36:30,802 AE_BIGRAMA_3L_MINIDS_OVER_02.py:97]: =======================================
[2018-06-06 21:36:30,802 AE_BIGRAMA_3L_MINIDS_OVER_02.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa13cf98630>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-06 21:36:30,964 AE_BIGRAMA_3L_MINIDS_OVER_02.py:110]: training ... 
[2018-06-14 18:08:16,232 AE_BIGRAMA_3L_MINIDS_OVER_02.py:122]: trained!
[2018-06-14 18:08:16,233 AE_BIGRAMA_3L_MINIDS_OVER_02.py:125]: Training history: 
{'val_loss': [0.00010628952750311455, 0.00010628851664556346, 0.00010628749720703041, 0.00010628647278080161, 0.00010628543618030466, 0.00010628439074854713, 0.00010628332987102206, 0.00010628225932201526, 0.0001062811729160689, 0.00010628008790453209, 0.00010627900362595417, 0.0001062779224579822, 0.00010627683058165984, 0.00010627572161488175, 0.00010627460063472893, 0.00010627348260428866, 0.00010627235500962893, 0.00010627122316023229, 0.00010627007497121586, 0.0001062689112470467, 0.00010626773729720737, 0.00010626654929601009, 0.0001062653353015883, 0.00010626411043792272, 0.00010626286269163859, 0.00010626161633976403, 0.0001062603407231656, 0.00010625903559156468, 0.00010625770496729652, 0.00010625633152750382, 0.00010625491280515429, 0.0001062534792091027, 0.00010625203195498817, 0.00010625054016915271, 0.00010624900644376796, 0.00010624742523694974, 0.00010624577922584072, 0.00010624404028984798, 0.00010624223236633574, 0.00010624035366759944, 0.00010623838604843765, 0.00010623631912228681, 0.00010623417684438819, 0.00010623194269635154, 0.00010622963148037072, 0.00010622724555621578, 0.00010622476736862779, 0.00010622215703391774, 0.0001062194443709979, 0.00010621656620238865, 0.00010621350087898759, 0.00010621033253017195, 0.00010620705611461485, 0.00010620363796983916, 0.00010620006713721585, 0.00010619630005038447, 0.00010619242096386154, 0.0001061884017391771, 0.00010618426806564586, 0.00010617994950770765, 0.0001061754782619218, 0.00010617085824336133, 0.0001061661562227921, 0.00010616128449542768, 0.00010615625923999451, 0.00010615103655046823, 0.0001061456105453008, 0.00010614008389236588, 0.00010613444050232232, 0.00010612870563543573, 0.00010612286590179886, 0.00010611698276269494, 0.00010611104052207783, 0.0001061050513720927, 0.00010609900966359312, 0.00010609294185460676, 0.00010608684190269216, 0.00010608071154192278, 0.00010607457708730992, 0.0001060683908965267, 0.00010606220168452275, 0.00010605596465142146, 0.00010604969917594041, 0.00010604343402224618, 0.00010603715383395649, 0.00010603093601867937, 0.00010602465084269391, 0.00010601840106325902, 0.00010601215357208597, 0.00010600590649208498, 0.0001059996551573471, 0.00010599337128638598, 0.00010598712576168797, 0.0001059808859576446, 0.00010597459277274266, 0.00010596831569505892, 0.00010596205733464207, 0.0001059558283998425, 0.00010594958099805469, 0.00010594333817279058, 0.00010593710074639429], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00010647512375584163, 0.00010647408549802025, 0.00010647303821042738, 0.00010647197492520783, 0.0001064709096728727, 0.00010646983403985537, 0.00010646874774175359, 0.00010646763968687954, 0.00010646652456934955, 0.00010646540269726608, 0.00010646427499493645, 0.00010646314165196215, 0.0001064620078349841, 0.00010646086228641314, 0.00010645969370125978, 0.00010645851390591765, 0.00010645733363657177, 0.00010645613748810014, 0.00010645493550938236, 0.0001064537251881985, 0.00010645250988997526, 0.00010645127584490355, 0.00010645002201017513, 0.00010644875317322794, 0.00010644747234398578, 0.00010644617392920438, 0.00010644487150909124, 0.00010644354553099158, 0.00010644219784352, 0.00010644081702318606, 0.00010643939989416463, 0.00010643794754666431, 0.00010643646457852152, 0.00010643494662890175, 0.00010643335196177448, 0.0001064317146580096, 0.00010643004860591707, 0.00010642832806709311, 0.00010642652611812449, 0.0001064246389906814, 0.00010642268054937361, 0.00010642063453587239, 0.00010641849111459986, 0.00010641630311327431, 0.00010641404097776174, 0.0001064117270810393, 0.00010640933352798612, 0.0001064068423775601, 0.0001064042501458337, 0.00010640151343776325, 0.00010639864227852818, 0.00010639564351748268, 0.00010639249843147854, 0.00010638920789742265, 0.00010638576319364601, 0.0001063821338891076, 0.00010637832379953766, 0.00010637435546381466, 0.00010637024928780017, 0.00010636598609804239, 0.00010636150050572353, 0.00010635687193017247, 0.00010635211011216633, 0.00010634727152925233, 0.00010634224569115558, 0.00010633699695279379, 0.00010633156792710442, 0.0001063259598464972, 0.00010632025068458958, 0.0001063144084698284, 0.00010630849806962729, 0.0001063025057615776, 0.00010629646546064788, 0.00010629038778452221, 0.0001062842767385323, 0.00010627811921647437, 0.00010627193744912446, 0.00010626572262001275, 0.00010625946953879816, 0.00010625321908830437, 0.000106246928655594, 0.00010624065358060524, 0.00010623433008613308, 0.0001062279831758755, 0.00010622163657372034, 0.00010621527338143384, 0.00010620897271024239, 0.00010620260326110634, 0.00010619626559392195, 0.00010618993423098747, 0.00010618360173044399, 0.00010617727349593428, 0.00010617090198488191, 0.00010616457467467952, 0.00010615825542254094, 0.00010615187573492381, 0.00010614551477045495, 0.0001061391854457366, 0.00010613288351843522, 0.00010612656327088876, 0.00010612024830848416], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-06-14 18:08:16,233 AE_BIGRAMA_3L_MINIDS_OVER_02.py:129]: evaluating model ... 
[2018-06-14 18:08:59,258 AE_BIGRAMA_3L_MINIDS_OVER_02.py:133]: evaluated! 
[2018-06-14 18:08:59,258 AE_BIGRAMA_3L_MINIDS_OVER_02.py:135]: generating reports ... 
[2018-06-14 18:09:02,018 AE_BIGRAMA_3L_MINIDS_OVER_02.py:138]: done!
[2018-06-14 18:09:02,019 AE_BIGRAMA_3L_MINIDS_OVER_02.py:154]: >> experiment AE_BIGRAMA_3L_MINIDS_OVER_02 finished!
