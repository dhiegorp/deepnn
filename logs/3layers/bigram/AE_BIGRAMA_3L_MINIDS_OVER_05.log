[2018-06-03 00:54:29,093 AE_BIGRAMA_3L_MINIDS_OVER_05.py:145]: >> Initializing execution of experiment AE_BIGRAMA_3L_MINIDS_OVER_05
[2018-06-03 00:54:29,094 AE_BIGRAMA_3L_MINIDS_OVER_05.py:146]: >> Printing header log
[2018-06-03 00:54:29,094 AE_BIGRAMA_3L_MINIDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_3L_MINIDS_OVER_05
	layers = 9216,18432,16590,14747
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/3layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/3layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/3layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/3layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/3layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/3layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fda1dd55630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fda1dd55e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:29,094 AE_BIGRAMA_3L_MINIDS_OVER_05.py:148]: >> Loading dataset... 
[2018-06-03 00:55:00,935 AE_BIGRAMA_3L_MINIDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-06-03 00:55:00,936 AE_BIGRAMA_3L_MINIDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-06-03 00:55:00,936 AE_BIGRAMA_3L_MINIDS_OVER_05.py:57]: =======================================
[2018-06-03 00:55:00,936 AE_BIGRAMA_3L_MINIDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fda1dd55630>, 'discard_decoder_function': True}
[2018-06-03 00:55:01,143 AE_BIGRAMA_3L_MINIDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-06-24 02:50:49,440 AE_BIGRAMA_3L_MINIDS_OVER_05.py:85]: trained and evaluated!
[2018-06-24 02:50:49,440 AE_BIGRAMA_3L_MINIDS_OVER_05.py:88]: Training history: 
{'val_loss': [0.00010626939190717538, 0.00010626822836177667, 0.00010626704912033179, 0.00010626587772690999, 0.00010626469594692464, 0.00010626352782500221, 0.00010626235560923632, 0.00010626118176665926, 0.00010626000881793449, 0.00010625883726361929, 0.00010625766447578792, 0.00010625648612819534, 0.0001062553151459456, 0.00010625413247210795, 0.00010625295412451537, 0.0001062517775825044, 0.00010625060129077208, 0.00010624942449848247, 0.00010624824271849712, 0.00010624705906142195, 0.00010624587295519151, 0.00010624469968467993, 0.00010624351152258923, 0.00010624233326438187, 0.0001062411557391334, 0.00010623997061614048, 0.00010623877895014882, 0.00010623760314109674, 0.00010623641907284952, 0.00010623523042807858, 0.0001062340546190265, 0.00010623287121222997, 0.00010623169238195715, 0.0001062305044701451, 0.00010622932621193775, 0.00010622814010570732, 0.00010622696299163089, 0.00010622577304183563, 0.0001062245835747206, 0.00010622339076459801, 0.00010622220850193241, 0.00010622101864152238, 0.00010621983056881691, 0.00010621865263239639, 0.00010621746595410049, 0.00010621628286909078, 0.00010621509758520446, 0.00010621391653817798, 0.00010621272928781661, 0.00010621153320619465, 0.00010621034023517867, 0.00010620914292004056, 0.00010620795706408877, 0.00010620675983833588, 0.00010620556522263168, 0.00010620437028514066, 0.00010620318262360725, 0.00010620199610620476, 0.00010620080599551609, 0.00010619961465131126, 0.00010619842552386009, 0.00010619722486571443, 0.00010619603196620662, 0.00010619483693933036, 0.00010619364305658504, 0.00010619244354257031, 0.00010619124991010362, 0.00010619006240946362, 0.00010618887614233977, 0.00010618768136574217, 0.00010618649509861831, 0.00010618529819465227, 0.00010618411053311886, 0.00010618292017215154, 0.00010618172784470919, 0.00010618053331839021, 0.00010617934238535744, 0.00010617814932495621, 0.00010617695512042406, 0.00010617575919969552, 0.00010617456417281926, 0.00010617337406213058, 0.00010617217944642639, 0.00010617099080165546, 0.00010616979405858282, 0.00010616860353672208, 0.00010616740647186263, 0.00010616621750530488, 0.00010616502869964053, 0.00010616382696887213, 0.00010616262320012051, 0.0001061614328391532, 0.000106160241745227, 0.00010615904051501587, 0.00010615785170935154, 0.00010615665382214797, 0.00010615545586343621, 0.00010615426010360108, 0.00010615306573817552, 0.0001061518770934046, 0.00010615068526651953], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.0001064508632957368, 0.00010644968300269074, 0.00010644850531666531, 0.00010644731810316443, 0.00010644613726501404, 0.00010644494903240511, 0.00010644377115677817, 0.00010644259190654036, 0.00010644140746596145, 0.00010644022409189098, 0.00010643904178432896, 0.0001064378581969568, 0.0001064366702724503, 0.00010643549168581775, 0.00010643429987448046, 0.00010643312055314208, 0.00010643193367144384, 0.00010643074145720337, 0.00010642955602121657, 0.0001064283688314159, 0.00010642717765998368, 0.00010642598468733721, 0.00010642480233237481, 0.00010642360921752721, 0.00010642242093751789, 0.00010642123445872284, 0.00010642004281328688, 0.0001064188475417222, 0.00010641766203463484, 0.00010641647185861051, 0.00010641527954956929, 0.00010641409167246316, 0.0001064129044589623, 0.00010641171532574622, 0.00010641052100218906, 0.00010640933362278687, 0.00010640813903852763, 0.0001064069523464309, 0.0001064057567193634, 0.00010640456004948765, 0.00010640335650655747, 0.00010640216490852189, 0.00010640096525242249, 0.0001063997705733625, 0.0001063985847581727, 0.00010639738939180727, 0.00010639619478384785, 0.00010639500114759612, 0.0001063938104027673, 0.0001063926186151302, 0.00010639141485889834, 0.00010639021205067398, 0.00010638900732273442, 0.00010638781318877875, 0.0001063866086504407, 0.00010638540939724449, 0.00010638420763182839, 0.00010638301172035864, 0.00010638181742050166, 0.00010638061686379513, 0.00010637941424517228, 0.00010637821525267814, 0.0001063770079888185, 0.00010637580916222568, 0.00010637460467128798, 0.00010637340122315857, 0.00010637219173148128, 0.00010637099060597026, 0.00010636979457599957, 0.00010636859728991895, 0.00010636739554820303, 0.0001063661971008132, 0.00010636498974215282, 0.00010636379477869059, 0.00010636259562029512, 0.00010636139373637809, 0.00010636018680432108, 0.00010635898909163707, 0.00010635778732622097, 0.00010635658475499849, 0.00010635538261037938, 0.00010635417842754415, 0.00010635297701763086, 0.00010635177674532659, 0.00010635057753953075, 0.00010634937302489288, 0.00010634817358209518, 0.00010634696238400439, 0.00010634576490832225, 0.00010634456648463262, 0.00010634335801206342, 0.00010634214484685705, 0.00010634094575956215, 0.00010633974477625224, 0.00010633853355446127, 0.00010633733167054423, 0.00010633612461998628, 0.00010633491534161068, 0.00010633371153797845, 0.0001063325077580464, 0.00010633130570822806], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-06-24 02:50:49,440 AE_BIGRAMA_3L_MINIDS_OVER_05.py:92]: done!
[2018-06-24 02:50:49,441 AE_BIGRAMA_3L_MINIDS_OVER_05.py:152]: >> Executing classifier part ... 
[2018-06-24 02:50:49,441 AE_BIGRAMA_3L_MINIDS_OVER_05.py:97]: =======================================
[2018-06-24 02:50:49,441 AE_BIGRAMA_3L_MINIDS_OVER_05.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fda1dd55e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-24 02:50:49,477 AE_BIGRAMA_3L_MINIDS_OVER_05.py:110]: training ... 
[2018-06-24 10:25:32,203 AE_BIGRAMA_3L_MINIDS_OVER_05.py:122]: trained!
[2018-06-24 10:25:32,204 AE_BIGRAMA_3L_MINIDS_OVER_05.py:125]: Training history: 
{'val_loss': [0.00010626939190717538, 0.00010626822836177667, 0.00010626704912033179, 0.00010626587772690999, 0.00010626469594692464, 0.00010626352782500221, 0.00010626235560923632, 0.00010626118176665926, 0.00010626000881793449, 0.00010625883726361929, 0.00010625766447578792, 0.00010625648612819534, 0.0001062553151459456, 0.00010625413247210795, 0.00010625295412451537, 0.0001062517775825044, 0.00010625060129077208, 0.00010624942449848247, 0.00010624824271849712, 0.00010624705906142195, 0.00010624587295519151, 0.00010624469968467993, 0.00010624351152258923, 0.00010624233326438187, 0.0001062411557391334, 0.00010623997061614048, 0.00010623877895014882, 0.00010623760314109674, 0.00010623641907284952, 0.00010623523042807858, 0.0001062340546190265, 0.00010623287121222997, 0.00010623169238195715, 0.0001062305044701451, 0.00010622932621193775, 0.00010622814010570732, 0.00010622696299163089, 0.00010622577304183563, 0.0001062245835747206, 0.00010622339076459801, 0.00010622220850193241, 0.00010622101864152238, 0.00010621983056881691, 0.00010621865263239639, 0.00010621746595410049, 0.00010621628286909078, 0.00010621509758520446, 0.00010621391653817798, 0.00010621272928781661, 0.00010621153320619465, 0.00010621034023517867, 0.00010620914292004056, 0.00010620795706408877, 0.00010620675983833588, 0.00010620556522263168, 0.00010620437028514066, 0.00010620318262360725, 0.00010620199610620476, 0.00010620080599551609, 0.00010619961465131126, 0.00010619842552386009, 0.00010619722486571443, 0.00010619603196620662, 0.00010619483693933036, 0.00010619364305658504, 0.00010619244354257031, 0.00010619124991010362, 0.00010619006240946362, 0.00010618887614233977, 0.00010618768136574217, 0.00010618649509861831, 0.00010618529819465227, 0.00010618411053311886, 0.00010618292017215154, 0.00010618172784470919, 0.00010618053331839021, 0.00010617934238535744, 0.00010617814932495621, 0.00010617695512042406, 0.00010617575919969552, 0.00010617456417281926, 0.00010617337406213058, 0.00010617217944642639, 0.00010617099080165546, 0.00010616979405858282, 0.00010616860353672208, 0.00010616740647186263, 0.00010616621750530488, 0.00010616502869964053, 0.00010616382696887213, 0.00010616262320012051, 0.0001061614328391532, 0.000106160241745227, 0.00010615904051501587, 0.00010615785170935154, 0.00010615665382214797, 0.00010615545586343621, 0.00010615426010360108, 0.00010615306573817552, 0.0001061518770934046, 0.00010615068526651953], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.0001064508632957368, 0.00010644968300269074, 0.00010644850531666531, 0.00010644731810316443, 0.00010644613726501404, 0.00010644494903240511, 0.00010644377115677817, 0.00010644259190654036, 0.00010644140746596145, 0.00010644022409189098, 0.00010643904178432896, 0.0001064378581969568, 0.0001064366702724503, 0.00010643549168581775, 0.00010643429987448046, 0.00010643312055314208, 0.00010643193367144384, 0.00010643074145720337, 0.00010642955602121657, 0.0001064283688314159, 0.00010642717765998368, 0.00010642598468733721, 0.00010642480233237481, 0.00010642360921752721, 0.00010642242093751789, 0.00010642123445872284, 0.00010642004281328688, 0.0001064188475417222, 0.00010641766203463484, 0.00010641647185861051, 0.00010641527954956929, 0.00010641409167246316, 0.0001064129044589623, 0.00010641171532574622, 0.00010641052100218906, 0.00010640933362278687, 0.00010640813903852763, 0.0001064069523464309, 0.0001064057567193634, 0.00010640456004948765, 0.00010640335650655747, 0.00010640216490852189, 0.00010640096525242249, 0.0001063997705733625, 0.0001063985847581727, 0.00010639738939180727, 0.00010639619478384785, 0.00010639500114759612, 0.0001063938104027673, 0.0001063926186151302, 0.00010639141485889834, 0.00010639021205067398, 0.00010638900732273442, 0.00010638781318877875, 0.0001063866086504407, 0.00010638540939724449, 0.00010638420763182839, 0.00010638301172035864, 0.00010638181742050166, 0.00010638061686379513, 0.00010637941424517228, 0.00010637821525267814, 0.0001063770079888185, 0.00010637580916222568, 0.00010637460467128798, 0.00010637340122315857, 0.00010637219173148128, 0.00010637099060597026, 0.00010636979457599957, 0.00010636859728991895, 0.00010636739554820303, 0.0001063661971008132, 0.00010636498974215282, 0.00010636379477869059, 0.00010636259562029512, 0.00010636139373637809, 0.00010636018680432108, 0.00010635898909163707, 0.00010635778732622097, 0.00010635658475499849, 0.00010635538261037938, 0.00010635417842754415, 0.00010635297701763086, 0.00010635177674532659, 0.00010635057753953075, 0.00010634937302489288, 0.00010634817358209518, 0.00010634696238400439, 0.00010634576490832225, 0.00010634456648463262, 0.00010634335801206342, 0.00010634214484685705, 0.00010634094575956215, 0.00010633974477625224, 0.00010633853355446127, 0.00010633733167054423, 0.00010633612461998628, 0.00010633491534161068, 0.00010633371153797845, 0.0001063325077580464, 0.00010633130570822806], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-06-24 10:25:32,205 AE_BIGRAMA_3L_MINIDS_OVER_05.py:129]: evaluating model ... 
[2018-06-24 10:25:36,006 AE_BIGRAMA_3L_MINIDS_OVER_05.py:133]: evaluated! 
[2018-06-24 10:25:36,006 AE_BIGRAMA_3L_MINIDS_OVER_05.py:135]: generating reports ... 
[2018-06-24 10:25:36,665 AE_BIGRAMA_3L_MINIDS_OVER_05.py:138]: done!
[2018-06-24 10:25:36,665 AE_BIGRAMA_3L_MINIDS_OVER_05.py:154]: >> experiment AE_BIGRAMA_3L_MINIDS_OVER_05 finished!
