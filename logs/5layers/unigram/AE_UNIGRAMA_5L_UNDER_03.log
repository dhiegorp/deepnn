[2017-10-20 01:39:49,704 AE_UNIGRAMA_5L_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_UNDER_03
[2017-10-20 01:39:49,704 AE_UNIGRAMA_5L_UNDER_03.py:149]: >> Printing header log
[2017-10-20 01:39:49,704 AE_UNIGRAMA_5L_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_UNDER_03
	layers = 96,86,78,71,63,55,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f71a4dda7b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f71a4dda898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:39:49,704 AE_UNIGRAMA_5L_UNDER_03.py:151]: >> Loading dataset... 
[2017-10-20 01:39:50,320 AE_UNIGRAMA_5L_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:39:50,320 AE_UNIGRAMA_5L_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:39:50,320 AE_UNIGRAMA_5L_UNDER_03.py:60]: =======================================
[2017-10-20 01:39:50,320 AE_UNIGRAMA_5L_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f71a4dda7b8>, 'discard_decoder_function': True}
[2017-10-20 01:39:50,452 AE_UNIGRAMA_5L_UNDER_03.py:76]: training and evaluate autoencoder
[2017-10-20 01:40:26,474 AE_UNIGRAMA_5L_UNDER_03.py:88]: trained and evaluated!
[2017-10-20 01:40:26,475 AE_UNIGRAMA_5L_UNDER_03.py:91]: Training history: 
{'val_loss': [0.010132816526692597, 0.0098989268100117666, 0.0096682416600587205, 0.0094485995896354483, 0.0092445523010698388, 0.0090549395637773665, 0.0088781754877487531, 0.0087128523079380675, 0.0085581476215037706, 0.0084133082481454291, 0.0082775940028015794, 0.0081503959026423094, 0.0080312304094876941, 0.0079195969132187204, 0.0078148413103309271, 0.0077166287522749165, 0.0076242691238296518, 0.00753750448845687, 0.0074558013091106179, 0.0073789380591182683, 0.0073064660227625568, 0.0072381558886912677, 0.0071736161811727355, 0.0071125869157976822, 0.0070547424101004147, 0.0069995225635686104, 0.006946845082254547, 0.0068965461572500627, 0.0068487309639560243, 0.0068033788245877589, 0.0067602929704195947, 0.0067193638325623861, 0.0066804602122467471, 0.0066434318532121667, 0.0066082088318289876, 0.0065746654178185536, 0.0065427032700950995, 0.0065122272673869665, 0.006483160610203406, 0.006455413926198912, 0.0064289266240114837, 0.0064036248331425577, 0.0063794678610275225, 0.0063563606521758673, 0.0063342737141290342, 0.0063131502258234754, 0.0062929355248559585, 0.006273606393943267, 0.0062551086830826943, 0.0062373696608281929, 0.0062203988619841163, 0.0062041209463625591, 0.0061885106938174448, 0.006173547360782951, 0.0061591810210985323, 0.0061453998341574768, 0.0061321795873039275, 0.006119475864414056, 0.00610728114393287, 0.0060955612612091916, 0.0060842993520338739, 0.0060734791321105227, 0.0060630627270774106, 0.0060529368340996783, 0.0060432292884527311, 0.0060339881398033032, 0.0060251594026015593, 0.0060166672779226387, 0.0060084986164611956, 0.0060006314455825823, 0.005993062121357395, 0.0059857695591964905, 0.0059787708448876238, 0.0059720190989760663, 0.0059655176589895583, 0.0059592789315989023, 0.0059532494955872733, 0.0059474445983324353, 0.0059418552832117087, 0.0059364708884858067, 0.0059312765441530257, 0.0059262639133183482, 0.0059214336053229396, 0.0059167926016239431, 0.0059123021190411315, 0.0059079855219997656, 0.0059038193058568748, 0.0058997896479158814, 0.0058959022745988625, 0.0058921574905763992, 0.0058885344830393567, 0.0058850413309514083, 0.0058816644799338175, 0.0058784044735466015, 0.0058752533626573013, 0.0058722036897609891, 0.0058692567999090407, 0.005866411091849817, 0.0058636619834070087, 0.0058610010372827934, 0.0058584287052897933, 0.0058559377930476764], 'loss': [0.01024828686080667, 0.010011360009750964, 0.0097793830563236983, 0.0095528746355776056, 0.0093403965184383764, 0.0091432787795089187, 0.0089597253692144628, 0.0087882387368827045, 0.0086277715218400549, 0.0084775397267831416, 0.0083367128712803443, 0.0082047598404419442, 0.0080810290032605047, 0.0079650755756441333, 0.0078563570115342055, 0.0077542296250722271, 0.0076583919779940769, 0.0075682050092849874, 0.0074833978457489701, 0.0074034548088674646, 0.0073281770094670469, 0.0072571298499038124, 0.0071900788252141738, 0.0071266535683875629, 0.0070665866384407496, 0.007009429185689595, 0.0069548102812961744, 0.0069026696153978813, 0.0068529206405370307, 0.0068056586547110736, 0.00676075645883298, 0.0067180729812880051, 0.0066774840736859003, 0.0066388434771684213, 0.006602032064587867, 0.0065669787334439646, 0.0065335522453886241, 0.0065016671293944613, 0.0064712375163180225, 0.0064421781964403178, 0.0064144095708744868, 0.0063878626398943686, 0.0063624777796792154, 0.0063382123374296027, 0.0063149808601492856, 0.0062927399188412907, 0.0062714474107989993, 0.0062510331210548081, 0.0062315057019789524, 0.0062127854070009704, 0.0061948193133005572, 0.0061776121819567004, 0.0061610753309684586, 0.0061452139043618398, 0.0061299722036661621, 0.006115336281939489, 0.006101274171405653, 0.00608775723003167, 0.0060747583716141531, 0.0060622671615623153, 0.0060502443689859822, 0.0060386792507615642, 0.0060275583287567065, 0.0060167754705498467, 0.006006342194031079, 0.0059963901204955162, 0.0059868684911455897, 0.005977727679710906, 0.0059689382247434452, 0.0059604747381150616, 0.0059522932613429915, 0.0059444319560423209, 0.0059368342957410733, 0.0059295381300870304, 0.0059224947472460701, 0.0059157100004689524, 0.0059091747720103616, 0.0059028568279201913, 0.0058967707888752715, 0.0058908928984223183, 0.0058852269267863702, 0.0058797616119477631, 0.0058744677308701851, 0.0058693567610883278, 0.0058644520211564152, 0.0058596861647749942, 0.0058551212565512035, 0.0058506876948623294, 0.0058463986747804859, 0.0058422610587277289, 0.0058382562085180171, 0.0058343830480072564, 0.0058306373725058513, 0.0058270195749781217, 0.0058235123896079521, 0.0058201255451958821, 0.0058168453177564264, 0.0058136586873770929, 0.0058105762649531293, 0.0058076019489309979, 0.0058047202308149923, 0.0058019244880258081]}
[2017-10-20 01:40:26,475 AE_UNIGRAMA_5L_UNDER_03.py:95]: done!
[2017-10-20 01:40:26,475 AE_UNIGRAMA_5L_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-10-20 01:40:26,475 AE_UNIGRAMA_5L_UNDER_03.py:100]: =======================================
[2017-10-20 01:40:26,475 AE_UNIGRAMA_5L_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f71a4dda898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:40:26,508 AE_UNIGRAMA_5L_UNDER_03.py:113]: training ... 
[2017-10-20 01:41:29,825 AE_UNIGRAMA_5L_UNDER_03.py:125]: trained!
[2017-10-20 01:41:29,825 AE_UNIGRAMA_5L_UNDER_03.py:128]: Training history: 
{'val_loss': [0.010132816526692597, 0.0098989268100117666, 0.0096682416600587205, 0.0094485995896354483, 0.0092445523010698388, 0.0090549395637773665, 0.0088781754877487531, 0.0087128523079380675, 0.0085581476215037706, 0.0084133082481454291, 0.0082775940028015794, 0.0081503959026423094, 0.0080312304094876941, 0.0079195969132187204, 0.0078148413103309271, 0.0077166287522749165, 0.0076242691238296518, 0.00753750448845687, 0.0074558013091106179, 0.0073789380591182683, 0.0073064660227625568, 0.0072381558886912677, 0.0071736161811727355, 0.0071125869157976822, 0.0070547424101004147, 0.0069995225635686104, 0.006946845082254547, 0.0068965461572500627, 0.0068487309639560243, 0.0068033788245877589, 0.0067602929704195947, 0.0067193638325623861, 0.0066804602122467471, 0.0066434318532121667, 0.0066082088318289876, 0.0065746654178185536, 0.0065427032700950995, 0.0065122272673869665, 0.006483160610203406, 0.006455413926198912, 0.0064289266240114837, 0.0064036248331425577, 0.0063794678610275225, 0.0063563606521758673, 0.0063342737141290342, 0.0063131502258234754, 0.0062929355248559585, 0.006273606393943267, 0.0062551086830826943, 0.0062373696608281929, 0.0062203988619841163, 0.0062041209463625591, 0.0061885106938174448, 0.006173547360782951, 0.0061591810210985323, 0.0061453998341574768, 0.0061321795873039275, 0.006119475864414056, 0.00610728114393287, 0.0060955612612091916, 0.0060842993520338739, 0.0060734791321105227, 0.0060630627270774106, 0.0060529368340996783, 0.0060432292884527311, 0.0060339881398033032, 0.0060251594026015593, 0.0060166672779226387, 0.0060084986164611956, 0.0060006314455825823, 0.005993062121357395, 0.0059857695591964905, 0.0059787708448876238, 0.0059720190989760663, 0.0059655176589895583, 0.0059592789315989023, 0.0059532494955872733, 0.0059474445983324353, 0.0059418552832117087, 0.0059364708884858067, 0.0059312765441530257, 0.0059262639133183482, 0.0059214336053229396, 0.0059167926016239431, 0.0059123021190411315, 0.0059079855219997656, 0.0059038193058568748, 0.0058997896479158814, 0.0058959022745988625, 0.0058921574905763992, 0.0058885344830393567, 0.0058850413309514083, 0.0058816644799338175, 0.0058784044735466015, 0.0058752533626573013, 0.0058722036897609891, 0.0058692567999090407, 0.005866411091849817, 0.0058636619834070087, 0.0058610010372827934, 0.0058584287052897933, 0.0058559377930476764], 'loss': [0.01024828686080667, 0.010011360009750964, 0.0097793830563236983, 0.0095528746355776056, 0.0093403965184383764, 0.0091432787795089187, 0.0089597253692144628, 0.0087882387368827045, 0.0086277715218400549, 0.0084775397267831416, 0.0083367128712803443, 0.0082047598404419442, 0.0080810290032605047, 0.0079650755756441333, 0.0078563570115342055, 0.0077542296250722271, 0.0076583919779940769, 0.0075682050092849874, 0.0074833978457489701, 0.0074034548088674646, 0.0073281770094670469, 0.0072571298499038124, 0.0071900788252141738, 0.0071266535683875629, 0.0070665866384407496, 0.007009429185689595, 0.0069548102812961744, 0.0069026696153978813, 0.0068529206405370307, 0.0068056586547110736, 0.00676075645883298, 0.0067180729812880051, 0.0066774840736859003, 0.0066388434771684213, 0.006602032064587867, 0.0065669787334439646, 0.0065335522453886241, 0.0065016671293944613, 0.0064712375163180225, 0.0064421781964403178, 0.0064144095708744868, 0.0063878626398943686, 0.0063624777796792154, 0.0063382123374296027, 0.0063149808601492856, 0.0062927399188412907, 0.0062714474107989993, 0.0062510331210548081, 0.0062315057019789524, 0.0062127854070009704, 0.0061948193133005572, 0.0061776121819567004, 0.0061610753309684586, 0.0061452139043618398, 0.0061299722036661621, 0.006115336281939489, 0.006101274171405653, 0.00608775723003167, 0.0060747583716141531, 0.0060622671615623153, 0.0060502443689859822, 0.0060386792507615642, 0.0060275583287567065, 0.0060167754705498467, 0.006006342194031079, 0.0059963901204955162, 0.0059868684911455897, 0.005977727679710906, 0.0059689382247434452, 0.0059604747381150616, 0.0059522932613429915, 0.0059444319560423209, 0.0059368342957410733, 0.0059295381300870304, 0.0059224947472460701, 0.0059157100004689524, 0.0059091747720103616, 0.0059028568279201913, 0.0058967707888752715, 0.0058908928984223183, 0.0058852269267863702, 0.0058797616119477631, 0.0058744677308701851, 0.0058693567610883278, 0.0058644520211564152, 0.0058596861647749942, 0.0058551212565512035, 0.0058506876948623294, 0.0058463986747804859, 0.0058422610587277289, 0.0058382562085180171, 0.0058343830480072564, 0.0058306373725058513, 0.0058270195749781217, 0.0058235123896079521, 0.0058201255451958821, 0.0058168453177564264, 0.0058136586873770929, 0.0058105762649531293, 0.0058076019489309979, 0.0058047202308149923, 0.0058019244880258081]}
[2017-10-20 01:41:29,826 AE_UNIGRAMA_5L_UNDER_03.py:132]: evaluating model ... 
[2017-10-20 01:41:29,882 AE_UNIGRAMA_5L_UNDER_03.py:136]: evaluated! 
[2017-10-20 01:41:29,882 AE_UNIGRAMA_5L_UNDER_03.py:138]: generating reports ... 
[2017-10-20 01:41:30,533 AE_UNIGRAMA_5L_UNDER_03.py:141]: done!
[2017-10-20 01:41:30,533 AE_UNIGRAMA_5L_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_5L_UNDER_03 finished!
