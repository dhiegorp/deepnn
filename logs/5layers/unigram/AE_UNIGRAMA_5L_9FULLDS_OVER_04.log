[2017-11-18 19:25:22,139 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_9FULLDS_OVER_04
[2017-11-18 19:25:22,139 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 19:25:22,139 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_9FULLDS_OVER_04
	layers = 96,134,122,109,97,84,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efe680502b0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efe680507b8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:25:22,139 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 19:25:24,617 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:25:24,617 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:25:24,617 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 19:25:24,617 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efe680502b0>, 'discard_decoder_function': True}
[2017-11-18 19:25:24,767 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 19:27:38,889 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 19:27:38,890 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0094001606508585644, 0.0086258993549453815, 0.0080203906465588747, 0.0075546820093191358, 0.0071924926033014218, 0.0069093407619127082, 0.0066851048164880151, 0.0065060760175555295, 0.0063608470538857667, 0.0062425418784968533, 0.006145292439199204, 0.006064858310847368, 0.0059978231263662883, 0.0059419483177771864, 0.0058951037751085638, 0.0058556275925873199, 0.0058222581967519779, 0.0057939113562194876, 0.0057697764975872768, 0.0057491954310445641, 0.0057315022455482513, 0.0057162517583828031, 0.0057030617955453264, 0.0056916006307847706, 0.0056816228206424488, 0.0056729109961065798, 0.0056652761212844802, 0.0056585937628720346, 0.0056526795712815445, 0.0056474382326983054, 0.0056427980354552057, 0.0056386893225449748, 0.0056350601942972232, 0.0056318220147984193, 0.0056289026448835136, 0.0056262262198404547, 0.0056237811425468723, 0.0056215840501684074, 0.0056195639338082843, 0.005617669653469195, 0.0056159501530446358, 0.0056143393082039696, 0.0056128318791025455, 0.0056114054403244868, 0.0056100582139370072, 0.0056087853306906492, 0.0056075663080775084, 0.0056063503355372425, 0.005605135332739603, 0.005603959096885892, 0.0056027721014498119, 0.0056015577057574335, 0.0056003517519514247, 0.0055991460318317397, 0.0055979571706700612, 0.0055968700929516458, 0.0055958622449085536, 0.0055948896250574247, 0.0055939495656433975, 0.0055930244809790806, 0.0055921103464571633, 0.0055912057158921582, 0.0055903108972434508, 0.0055894194895936226, 0.0055885284294356144, 0.005587630271579617, 0.0055867302364463354, 0.0055858377063149247, 0.0055849538156464941, 0.005584063025198956, 0.0055831736473086636, 0.0055822944087180002, 0.0055814078275336094, 0.0055805304313940362, 0.0055796501392040652, 0.0055787590137576408, 0.005577875318783323, 0.0055769954344962111, 0.0055760926775290645, 0.0055752050545537562, 0.0055743046525047078, 0.0055733978568115235, 0.0055724884502662267, 0.0055715711708620424, 0.0055706365160111482, 0.0055696613886741016, 0.0055686756811053036, 0.0055676961408531681, 0.0055667456785899417, 0.0055658065155011595, 0.0055648189070382978, 0.0055637607262468119, 0.0055626807518738761, 0.0055615718912700165, 0.0055604267517842003, 0.0055592605748817255, 0.0055580671749343681, 0.0055568784784911715, 0.0055556827587086143, 0.0055544786244214614, 0.0055532669829932348], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098841401646733353, 0.0090006968426941444, 0.0083162168939843115, 0.0077856486102851228, 0.0073754101699236218, 0.0070559962118659277, 0.0068048337571404308, 0.0066051695762083026, 0.0064445834019765157, 0.0063141651838085977, 0.0062075207628697485, 0.0061195830621234085, 0.0060466549486037089, 0.0059857994272968394, 0.005935019571930847, 0.005892351916686525, 0.0058563391252669933, 0.0058258532690382949, 0.0057999034902272715, 0.0057778450368561893, 0.005758958029726158, 0.0057427248298734098, 0.0057286943656640341, 0.0057165371210075302, 0.0057059666433941919, 0.0056967591388786413, 0.005688705363501665, 0.0056816600376290386, 0.0056754614416168296, 0.0056699715499042899, 0.0056651078705972314, 0.0056608064753798249, 0.0056570044972347275, 0.0056536344712323702, 0.0056506124669412749, 0.0056478567223671727, 0.0056453376886235604, 0.0056430580323314876, 0.0056410054244696401, 0.0056390833665530046, 0.0056373143061191648, 0.005635680113814481, 0.005634151223490918, 0.0056327067592105932, 0.005631342829869608, 0.0056300535787784482, 0.0056288372051934241, 0.0056276389761659041, 0.0056264341221391838, 0.0056252530062068408, 0.0056240951103514155, 0.0056229042514268825, 0.0056217128093826183, 0.0056205154969882227, 0.0056193243344436145, 0.0056181880794063154, 0.005617160112938278, 0.0056161894873964346, 0.0056152512732976908, 0.0056143332127816872, 0.0056134337956929214, 0.0056125441879560801, 0.0056116625924283875, 0.0056107866802889905, 0.0056099108267930794, 0.0056090292855077535, 0.00560814579972789, 0.0056072684784301058, 0.0056063894484120348, 0.0056055153810846796, 0.0056046427756719858, 0.0056037707253147433, 0.0056029015810680309, 0.0056020264467836062, 0.0056011517053991058, 0.0056002849323268759, 0.0055994112999672883, 0.0055985244507034291, 0.0055976525955386868, 0.0055967692460792079, 0.005595885269374489, 0.0055949890965393961, 0.0055940909202233354, 0.0055931884247516547, 0.005592268733992465, 0.0055913143628131129, 0.0055903446506464227, 0.0055893566857804378, 0.0055884074050957357, 0.005587470818839568, 0.0055865169720793039, 0.0055855132817853497, 0.0055844678340713615, 0.005583391591668316, 0.0055822872512048928, 0.0055811504195066473, 0.0055799809877459033, 0.0055788167540500233, 0.0055776382541544373, 0.0055764559895871086, 0.0055752634778993768], 'acc': [0.57481281452198274, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270986042, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822262938279, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 19:27:38,890 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 19:27:38,890 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 19:27:38,890 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 19:27:38,890 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efe680507b8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:27:38,921 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 19:33:19,934 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:125]: trained!
[2017-11-18 19:33:19,935 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0094001606508585644, 0.0086258993549453815, 0.0080203906465588747, 0.0075546820093191358, 0.0071924926033014218, 0.0069093407619127082, 0.0066851048164880151, 0.0065060760175555295, 0.0063608470538857667, 0.0062425418784968533, 0.006145292439199204, 0.006064858310847368, 0.0059978231263662883, 0.0059419483177771864, 0.0058951037751085638, 0.0058556275925873199, 0.0058222581967519779, 0.0057939113562194876, 0.0057697764975872768, 0.0057491954310445641, 0.0057315022455482513, 0.0057162517583828031, 0.0057030617955453264, 0.0056916006307847706, 0.0056816228206424488, 0.0056729109961065798, 0.0056652761212844802, 0.0056585937628720346, 0.0056526795712815445, 0.0056474382326983054, 0.0056427980354552057, 0.0056386893225449748, 0.0056350601942972232, 0.0056318220147984193, 0.0056289026448835136, 0.0056262262198404547, 0.0056237811425468723, 0.0056215840501684074, 0.0056195639338082843, 0.005617669653469195, 0.0056159501530446358, 0.0056143393082039696, 0.0056128318791025455, 0.0056114054403244868, 0.0056100582139370072, 0.0056087853306906492, 0.0056075663080775084, 0.0056063503355372425, 0.005605135332739603, 0.005603959096885892, 0.0056027721014498119, 0.0056015577057574335, 0.0056003517519514247, 0.0055991460318317397, 0.0055979571706700612, 0.0055968700929516458, 0.0055958622449085536, 0.0055948896250574247, 0.0055939495656433975, 0.0055930244809790806, 0.0055921103464571633, 0.0055912057158921582, 0.0055903108972434508, 0.0055894194895936226, 0.0055885284294356144, 0.005587630271579617, 0.0055867302364463354, 0.0055858377063149247, 0.0055849538156464941, 0.005584063025198956, 0.0055831736473086636, 0.0055822944087180002, 0.0055814078275336094, 0.0055805304313940362, 0.0055796501392040652, 0.0055787590137576408, 0.005577875318783323, 0.0055769954344962111, 0.0055760926775290645, 0.0055752050545537562, 0.0055743046525047078, 0.0055733978568115235, 0.0055724884502662267, 0.0055715711708620424, 0.0055706365160111482, 0.0055696613886741016, 0.0055686756811053036, 0.0055676961408531681, 0.0055667456785899417, 0.0055658065155011595, 0.0055648189070382978, 0.0055637607262468119, 0.0055626807518738761, 0.0055615718912700165, 0.0055604267517842003, 0.0055592605748817255, 0.0055580671749343681, 0.0055568784784911715, 0.0055556827587086143, 0.0055544786244214614, 0.0055532669829932348], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098841401646733353, 0.0090006968426941444, 0.0083162168939843115, 0.0077856486102851228, 0.0073754101699236218, 0.0070559962118659277, 0.0068048337571404308, 0.0066051695762083026, 0.0064445834019765157, 0.0063141651838085977, 0.0062075207628697485, 0.0061195830621234085, 0.0060466549486037089, 0.0059857994272968394, 0.005935019571930847, 0.005892351916686525, 0.0058563391252669933, 0.0058258532690382949, 0.0057999034902272715, 0.0057778450368561893, 0.005758958029726158, 0.0057427248298734098, 0.0057286943656640341, 0.0057165371210075302, 0.0057059666433941919, 0.0056967591388786413, 0.005688705363501665, 0.0056816600376290386, 0.0056754614416168296, 0.0056699715499042899, 0.0056651078705972314, 0.0056608064753798249, 0.0056570044972347275, 0.0056536344712323702, 0.0056506124669412749, 0.0056478567223671727, 0.0056453376886235604, 0.0056430580323314876, 0.0056410054244696401, 0.0056390833665530046, 0.0056373143061191648, 0.005635680113814481, 0.005634151223490918, 0.0056327067592105932, 0.005631342829869608, 0.0056300535787784482, 0.0056288372051934241, 0.0056276389761659041, 0.0056264341221391838, 0.0056252530062068408, 0.0056240951103514155, 0.0056229042514268825, 0.0056217128093826183, 0.0056205154969882227, 0.0056193243344436145, 0.0056181880794063154, 0.005617160112938278, 0.0056161894873964346, 0.0056152512732976908, 0.0056143332127816872, 0.0056134337956929214, 0.0056125441879560801, 0.0056116625924283875, 0.0056107866802889905, 0.0056099108267930794, 0.0056090292855077535, 0.00560814579972789, 0.0056072684784301058, 0.0056063894484120348, 0.0056055153810846796, 0.0056046427756719858, 0.0056037707253147433, 0.0056029015810680309, 0.0056020264467836062, 0.0056011517053991058, 0.0056002849323268759, 0.0055994112999672883, 0.0055985244507034291, 0.0055976525955386868, 0.0055967692460792079, 0.005595885269374489, 0.0055949890965393961, 0.0055940909202233354, 0.0055931884247516547, 0.005592268733992465, 0.0055913143628131129, 0.0055903446506464227, 0.0055893566857804378, 0.0055884074050957357, 0.005587470818839568, 0.0055865169720793039, 0.0055855132817853497, 0.0055844678340713615, 0.005583391591668316, 0.0055822872512048928, 0.0055811504195066473, 0.0055799809877459033, 0.0055788167540500233, 0.0055776382541544373, 0.0055764559895871086, 0.0055752634778993768], 'acc': [0.57481281452198274, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270986042, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822262938279, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 19:33:19,935 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 19:33:20,087 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 19:33:20,087 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 19:33:20,948 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:141]: done!
[2017-11-18 19:33:20,948 AE_UNIGRAMA_5L_9FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_5L_9FULLDS_OVER_04 finished!
