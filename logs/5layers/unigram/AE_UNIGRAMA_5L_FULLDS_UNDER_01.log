[2017-11-13 18:01:43,327 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_UNDER_01
[2017-11-13 18:01:43,327 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-13 18:01:43,327 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_UNDER_01
	layers = 96,28,26,24,22,20
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f545f1f2eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f545f1f7400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 18:01:43,327 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-13 18:01:45,646 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 18:01:45,646 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-13 18:01:45,646 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-13 18:01:45,646 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f545f1f2eb8>, 'discard_decoder_function': True}
[2017-11-13 18:01:45,766 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-13 18:04:19,929 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-13 18:04:19,930 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0094530276487999349, 0.0087916852512048786, 0.0082898375034696457, 0.0079053075252000192, 0.0076045363385727283, 0.0073654370614146432, 0.0071711344278196079, 0.0070100326723570071, 0.0068748020734713273, 0.0067595606151241256, 0.0066603482783029666, 0.0065741576444328879, 0.0064988324984439879, 0.0064327215254909196, 0.0063745549382646701, 0.0063230884887787381, 0.0062775038497968113, 0.0062371503867384203, 0.0062013098886883446, 0.0061694369148237111, 0.0061411502136506941, 0.0061159320668519659, 0.0060935436661715614, 0.0060735529609358581, 0.0060546752724294078, 0.0060369494077275503, 0.0060211410144435018, 0.0060071412502839009, 0.0059947124632737381, 0.0059836705942432509, 0.0059738729243399144, 0.0059651494328581542, 0.0059573817008148604, 0.0059504465157051807, 0.0059442727028014728, 0.0059387547826344469, 0.0059338322603949799, 0.0059294145815628925, 0.0059254463831012747, 0.0059218984450638374, 0.0059187145080884258, 0.0059158477863931443, 0.0059132671699192113, 0.0059109494005881308, 0.0059088573161134748, 0.0059069724543343921, 0.0059052602005817845, 0.0059037189146018462, 0.0059023278736971795, 0.0059010621655023205, 0.0058999087315638717, 0.0058988514648102165, 0.0058978811475951104, 0.0058969919306583064, 0.0058961745669181536, 0.0058954299100014446, 0.0058947417293618767, 0.0058941024516287127, 0.0058935123044129454, 0.0058929670197517504, 0.0058924513302527123, 0.0058919723771679536, 0.0058915191845990951, 0.0058910905704236301, 0.0058906925630812885, 0.0058903147462031191, 0.0058899530351130469, 0.0058896110567836883, 0.0058892855061494012, 0.0058889715068585809, 0.0058886724287518753, 0.0058883832215178497, 0.0058881042590032814, 0.0058878323463541658, 0.0058875716604033634, 0.0058873143975165338, 0.0058870640748824952, 0.0058868197931811212, 0.0058865818642223587, 0.00588634954390651, 0.0058861227850000161, 0.005885896814688602, 0.0058856251344422909, 0.0058853127352738645, 0.0058850667885895196, 0.0058848469452066525, 0.0058846350884026013, 0.0058844276408342123, 0.0058842221351469793, 0.0058840176975200531, 0.0058838161926522154, 0.005883615655901211, 0.0058834202110477117, 0.0058832230597963093, 0.005883028560298543, 0.005882834607238297, 0.0058826412813918023, 0.005882449186356031, 0.0058822580261511243, 0.0058820645167611783, 0.0058818729557555604], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098601236896676513, 0.0091122097044367429, 0.0085364051016416382, 0.0080987208391279913, 0.0077601517051091636, 0.0074935299028852011, 0.0072795420783803161, 0.0071041255777698764, 0.0069577610865509685, 0.0068341291894695212, 0.0067282577777562393, 0.0066367567376141839, 0.006557064629886338, 0.0064873025781525652, 0.0064259719042873602, 0.0063719757627048778, 0.0063241630461905113, 0.0062818481862143543, 0.0062443555746654125, 0.0062110859552510127, 0.0061814872078950547, 0.0061552490477409152, 0.006131870753213085, 0.006111127085198639, 0.0060922118884420865, 0.0060741439547672789, 0.0060577235079783227, 0.0060431543520794769, 0.0060302716353159416, 0.0060188301259472762, 0.0060086906728693329, 0.0059996921463024841, 0.0059916944458725859, 0.0059845805066068751, 0.0059782365768895462, 0.0059725983238447383, 0.0059675647882529532, 0.005963079647161181, 0.0059590543385600117, 0.0059554484261082549, 0.0059522386955018899, 0.0059493522167071372, 0.0059467629306393308, 0.0059444295784052241, 0.0059423452646511455, 0.0059404607011846414, 0.0059387660256117253, 0.0059372308218539147, 0.0059358501081299246, 0.0059346013439642489, 0.0059334704328574831, 0.0059324371021680375, 0.0059314907665752089, 0.0059306263989718968, 0.0059298334001481523, 0.0059291102139939298, 0.0059284437602111295, 0.0059278292643854891, 0.005927260285793246, 0.0059267321363278029, 0.0059262442529888311, 0.005925784099959564, 0.0059253533857888179, 0.0059249484757236048, 0.0059245656623067343, 0.0059242031940070303, 0.0059238610327576689, 0.0059235313891490221, 0.0059232220424167018, 0.0059229199036889991, 0.0059226341987980045, 0.0059223553524513223, 0.0059220893765779469, 0.0059218247518482035, 0.005921568531770274, 0.0059213222817137033, 0.005921081821472495, 0.005920841761333044, 0.0059206120493682677, 0.0059203849499536478, 0.0059201588187852792, 0.0059199379698174582, 0.0059197022839905123, 0.0059194006983749091, 0.005919120298375948, 0.0059188886611786767, 0.0059186748143345413, 0.0059184645556029595, 0.0059182561053313168, 0.0059180534841421668, 0.0059178517456346495, 0.0059176543150799028, 0.0059174531431164723, 0.0059172581994227725, 0.0059170633123148929, 0.0059168662551122419, 0.0059166690310671587, 0.0059164761349799347, 0.0059162791229887832, 0.005916083124341066, 0.0059158897010911987], 'acc': [0.57824966239390729, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822263669894, 0.59383822266596353, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.5938382226842539, 0.59383822272449271, 0.59383822264767316, 0.59383822265133124, 0.59383822267327968, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822262938279, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822262938279, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822262206665, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198]}
[2017-11-13 18:04:19,930 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:95]: done!
[2017-11-13 18:04:19,930 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-13 18:04:19,930 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-13 18:04:19,931 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f545f1f7400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 18:04:19,983 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-13 18:08:12,727 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-13 18:08:12,728 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0094530276487999349, 0.0087916852512048786, 0.0082898375034696457, 0.0079053075252000192, 0.0076045363385727283, 0.0073654370614146432, 0.0071711344278196079, 0.0070100326723570071, 0.0068748020734713273, 0.0067595606151241256, 0.0066603482783029666, 0.0065741576444328879, 0.0064988324984439879, 0.0064327215254909196, 0.0063745549382646701, 0.0063230884887787381, 0.0062775038497968113, 0.0062371503867384203, 0.0062013098886883446, 0.0061694369148237111, 0.0061411502136506941, 0.0061159320668519659, 0.0060935436661715614, 0.0060735529609358581, 0.0060546752724294078, 0.0060369494077275503, 0.0060211410144435018, 0.0060071412502839009, 0.0059947124632737381, 0.0059836705942432509, 0.0059738729243399144, 0.0059651494328581542, 0.0059573817008148604, 0.0059504465157051807, 0.0059442727028014728, 0.0059387547826344469, 0.0059338322603949799, 0.0059294145815628925, 0.0059254463831012747, 0.0059218984450638374, 0.0059187145080884258, 0.0059158477863931443, 0.0059132671699192113, 0.0059109494005881308, 0.0059088573161134748, 0.0059069724543343921, 0.0059052602005817845, 0.0059037189146018462, 0.0059023278736971795, 0.0059010621655023205, 0.0058999087315638717, 0.0058988514648102165, 0.0058978811475951104, 0.0058969919306583064, 0.0058961745669181536, 0.0058954299100014446, 0.0058947417293618767, 0.0058941024516287127, 0.0058935123044129454, 0.0058929670197517504, 0.0058924513302527123, 0.0058919723771679536, 0.0058915191845990951, 0.0058910905704236301, 0.0058906925630812885, 0.0058903147462031191, 0.0058899530351130469, 0.0058896110567836883, 0.0058892855061494012, 0.0058889715068585809, 0.0058886724287518753, 0.0058883832215178497, 0.0058881042590032814, 0.0058878323463541658, 0.0058875716604033634, 0.0058873143975165338, 0.0058870640748824952, 0.0058868197931811212, 0.0058865818642223587, 0.00588634954390651, 0.0058861227850000161, 0.005885896814688602, 0.0058856251344422909, 0.0058853127352738645, 0.0058850667885895196, 0.0058848469452066525, 0.0058846350884026013, 0.0058844276408342123, 0.0058842221351469793, 0.0058840176975200531, 0.0058838161926522154, 0.005883615655901211, 0.0058834202110477117, 0.0058832230597963093, 0.005883028560298543, 0.005882834607238297, 0.0058826412813918023, 0.005882449186356031, 0.0058822580261511243, 0.0058820645167611783, 0.0058818729557555604], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098601236896676513, 0.0091122097044367429, 0.0085364051016416382, 0.0080987208391279913, 0.0077601517051091636, 0.0074935299028852011, 0.0072795420783803161, 0.0071041255777698764, 0.0069577610865509685, 0.0068341291894695212, 0.0067282577777562393, 0.0066367567376141839, 0.006557064629886338, 0.0064873025781525652, 0.0064259719042873602, 0.0063719757627048778, 0.0063241630461905113, 0.0062818481862143543, 0.0062443555746654125, 0.0062110859552510127, 0.0061814872078950547, 0.0061552490477409152, 0.006131870753213085, 0.006111127085198639, 0.0060922118884420865, 0.0060741439547672789, 0.0060577235079783227, 0.0060431543520794769, 0.0060302716353159416, 0.0060188301259472762, 0.0060086906728693329, 0.0059996921463024841, 0.0059916944458725859, 0.0059845805066068751, 0.0059782365768895462, 0.0059725983238447383, 0.0059675647882529532, 0.005963079647161181, 0.0059590543385600117, 0.0059554484261082549, 0.0059522386955018899, 0.0059493522167071372, 0.0059467629306393308, 0.0059444295784052241, 0.0059423452646511455, 0.0059404607011846414, 0.0059387660256117253, 0.0059372308218539147, 0.0059358501081299246, 0.0059346013439642489, 0.0059334704328574831, 0.0059324371021680375, 0.0059314907665752089, 0.0059306263989718968, 0.0059298334001481523, 0.0059291102139939298, 0.0059284437602111295, 0.0059278292643854891, 0.005927260285793246, 0.0059267321363278029, 0.0059262442529888311, 0.005925784099959564, 0.0059253533857888179, 0.0059249484757236048, 0.0059245656623067343, 0.0059242031940070303, 0.0059238610327576689, 0.0059235313891490221, 0.0059232220424167018, 0.0059229199036889991, 0.0059226341987980045, 0.0059223553524513223, 0.0059220893765779469, 0.0059218247518482035, 0.005921568531770274, 0.0059213222817137033, 0.005921081821472495, 0.005920841761333044, 0.0059206120493682677, 0.0059203849499536478, 0.0059201588187852792, 0.0059199379698174582, 0.0059197022839905123, 0.0059194006983749091, 0.005919120298375948, 0.0059188886611786767, 0.0059186748143345413, 0.0059184645556029595, 0.0059182561053313168, 0.0059180534841421668, 0.0059178517456346495, 0.0059176543150799028, 0.0059174531431164723, 0.0059172581994227725, 0.0059170633123148929, 0.0059168662551122419, 0.0059166690310671587, 0.0059164761349799347, 0.0059162791229887832, 0.005916083124341066, 0.0059158897010911987], 'acc': [0.57824966239390729, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822263669894, 0.59383822266596353, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.5938382226842539, 0.59383822272449271, 0.59383822264767316, 0.59383822265133124, 0.59383822267327968, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822262938279, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822262938279, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822262206665, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198]}
[2017-11-13 18:08:12,728 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-13 18:08:12,850 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-13 18:08:12,850 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-13 18:08:13,714 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:141]: done!
[2017-11-13 18:08:13,714 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_5L_FULLDS_UNDER_01 finished!
[2017-11-14 07:05:09,115 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_5L_FULLDS_UNDER_01 was already executed!
[2017-11-18 14:56:56,508 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_5L_FULLDS_UNDER_01 was already executed!
[2017-11-18 16:23:26,991 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_5L_FULLDS_UNDER_01 was already executed!
[2017-11-18 18:55:36,044 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_UNDER_01
[2017-11-18 18:55:36,044 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 18:55:36,044 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_UNDER_01
	layers = 96,28,26,24,22,20
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc8262b3eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc8262b8400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:55:36,044 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 18:55:38,266 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:55:38,267 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:55:38,267 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 18:55:38,267 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc8262b3eb8>, 'discard_decoder_function': True}
[2017-11-18 18:55:38,380 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 18:56:56,858 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 18:56:56,859 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0096205963466682014, 0.0089999787767514588, 0.0085032091923372931, 0.0081025026889243405, 0.0077773695645627292, 0.0075115097343691657, 0.0072917871970241124, 0.0071088928367856316, 0.0069552610107368627, 0.0068250917163853782, 0.0067141447989807462, 0.0066189918564738643, 0.0065369809820607317, 0.0064658331648829621, 0.0064040327960476744, 0.0063500426097327037, 0.0063027732263537225, 0.0062613078818828669, 0.0062248018261857087, 0.0061926223580321266, 0.0061642308469597512, 0.0061391528159481269, 0.0061169533492488673, 0.006097279221383538, 0.0060798684905191769, 0.0060643887177940755, 0.0060506168381029993, 0.0060383675450363973, 0.0060275118552950632, 0.0060178252858257295, 0.0060092076140317967, 0.0060014948249718899, 0.005994624810023606, 0.0059884777747831203, 0.0059830236263389708, 0.0059781381228027567, 0.0059737880880753099, 0.0059699036796378412, 0.0059664348774931524, 0.0059633479113575891, 0.0059605789466157626, 0.0059581007007530008, 0.0059558923661884077, 0.0059539167422155044, 0.0059521460827119659, 0.0059505653567098766, 0.0059491417099314771, 0.0059478562445890119, 0.0059466885412382273, 0.0059456337278914863, 0.005944684486427522, 0.0059438293028105348, 0.0059430395574396212, 0.0059423323438147916, 0.0059416899940177648, 0.0059410980590288856, 0.0059405503292608757, 0.0059400257630186758, 0.0059395232338845753, 0.0059386999383110118, 0.0059290855168202365, 0.0059194232448244117, 0.0059111706151133104, 0.005904058445856326, 0.0058978998201677782, 0.005892543630189824, 0.0058878704218227433, 0.0058837821922760949, 0.0058801829892264398, 0.0058770076241152543, 0.005874200270982519, 0.005871712738847944, 0.005869503232942417, 0.0058675346318810342, 0.0058657805045511475, 0.0058642170748453301, 0.0058628132128530144, 0.0058615572801224668, 0.0058604276562619576, 0.0058594129594383114, 0.0058585016846003741, 0.0058576785923364801, 0.0058569377322449526, 0.0058562668352375863, 0.0058556600116660158, 0.0058551089045273683, 0.0058546065905113256, 0.0058541469997632255, 0.0058537270975268715, 0.0058533424963864529, 0.0058529903881699508, 0.005852664051507625, 0.0058523631236765458, 0.0058520761623469314, 0.0058518005415211264, 0.0058515425890414419, 0.0058513019451798265, 0.0058510732401137744, 0.0058508614692200376, 0.0058506520927768335, 0.0058504543192746256], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099892050240015535, 0.0093048457869062094, 0.0087506669632129337, 0.0083064234816566766, 0.0079474289514256079, 0.0076551417768371023, 0.0074151182828197399, 0.0072160544253088285, 0.0070497799692514291, 0.0069095617451932411, 0.0067904417084561318, 0.0066886748365803635, 0.0066011924071074429, 0.0065256183687723256, 0.0064599416138677677, 0.0064028069732235855, 0.0063528389885666777, 0.0063090420477718715, 0.0062705908315097338, 0.0062367281820147231, 0.006206857630560259, 0.0061804928568906176, 0.0061571948253472475, 0.0061365695799651416, 0.0061182876869032895, 0.0061021095087583242, 0.0060877141626639771, 0.0060749084383959866, 0.0060635287656111668, 0.0060534345801602817, 0.00604443612383987, 0.0060364239597886279, 0.0060292616051810244, 0.0060228745843901935, 0.0060171822048367034, 0.0060121182516803436, 0.0060075949272775306, 0.0060035653687955026, 0.0059999752982584842, 0.0059967691243281059, 0.0059939106934095389, 0.0059913535582042732, 0.0059890663257568099, 0.0059870263836876419, 0.0059852038525118993, 0.0059835774908844818, 0.0059821204269425816, 0.0059808064021793844, 0.0059796184620543227, 0.0059785428915935983, 0.0059775741797956135, 0.005976701093574923, 0.0059759117782594226, 0.0059751909967167578, 0.005974539795441651, 0.0059739449499850552, 0.0059734002693438617, 0.0059728901177128939, 0.0059724021366919363, 0.0059718729948026643, 0.0059670631166072446, 0.0059567601053606397, 0.0059477885154159259, 0.0059400921042405443, 0.0059334375571248738, 0.0059276648802924874, 0.0059226352243159641, 0.0059182477848723439, 0.005914397265067514, 0.0059110046508060697, 0.0059080142532962846, 0.0059053615217783103, 0.0059030070138208794, 0.0059009169327714512, 0.0058990530956619294, 0.0058973921986226587, 0.0058959107460209246, 0.00589458335294352, 0.0058933903000324261, 0.0058923213486836903, 0.0058913577715630208, 0.0058904949013119543, 0.0058897126516791612, 0.0058890086436595955, 0.0058883672696266771, 0.0058877888916153377, 0.0058872637709773499, 0.0058867831486850569, 0.0058863462001858963, 0.0058859455233687408, 0.0058855761262211308, 0.0058852348765178857, 0.0058849235469955741, 0.0058846264252581122, 0.005884339055658023, 0.0058840674902487927, 0.0058838166304484123, 0.0058835773069534523, 0.0058833536169202146, 0.0058831385859463518, 0.0058829338348440792], 'acc': [0.55345525964865938, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822272449271, 0.59383822262938279, 0.59383822264767316, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822262206665, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427]}
[2017-11-18 18:56:56,859 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:95]: done!
[2017-11-18 18:56:56,860 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 18:56:56,860 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 18:56:56,860 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc8262b8400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:56:56,921 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 19:00:10,411 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 19:00:10,412 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0096205963466682014, 0.0089999787767514588, 0.0085032091923372931, 0.0081025026889243405, 0.0077773695645627292, 0.0075115097343691657, 0.0072917871970241124, 0.0071088928367856316, 0.0069552610107368627, 0.0068250917163853782, 0.0067141447989807462, 0.0066189918564738643, 0.0065369809820607317, 0.0064658331648829621, 0.0064040327960476744, 0.0063500426097327037, 0.0063027732263537225, 0.0062613078818828669, 0.0062248018261857087, 0.0061926223580321266, 0.0061642308469597512, 0.0061391528159481269, 0.0061169533492488673, 0.006097279221383538, 0.0060798684905191769, 0.0060643887177940755, 0.0060506168381029993, 0.0060383675450363973, 0.0060275118552950632, 0.0060178252858257295, 0.0060092076140317967, 0.0060014948249718899, 0.005994624810023606, 0.0059884777747831203, 0.0059830236263389708, 0.0059781381228027567, 0.0059737880880753099, 0.0059699036796378412, 0.0059664348774931524, 0.0059633479113575891, 0.0059605789466157626, 0.0059581007007530008, 0.0059558923661884077, 0.0059539167422155044, 0.0059521460827119659, 0.0059505653567098766, 0.0059491417099314771, 0.0059478562445890119, 0.0059466885412382273, 0.0059456337278914863, 0.005944684486427522, 0.0059438293028105348, 0.0059430395574396212, 0.0059423323438147916, 0.0059416899940177648, 0.0059410980590288856, 0.0059405503292608757, 0.0059400257630186758, 0.0059395232338845753, 0.0059386999383110118, 0.0059290855168202365, 0.0059194232448244117, 0.0059111706151133104, 0.005904058445856326, 0.0058978998201677782, 0.005892543630189824, 0.0058878704218227433, 0.0058837821922760949, 0.0058801829892264398, 0.0058770076241152543, 0.005874200270982519, 0.005871712738847944, 0.005869503232942417, 0.0058675346318810342, 0.0058657805045511475, 0.0058642170748453301, 0.0058628132128530144, 0.0058615572801224668, 0.0058604276562619576, 0.0058594129594383114, 0.0058585016846003741, 0.0058576785923364801, 0.0058569377322449526, 0.0058562668352375863, 0.0058556600116660158, 0.0058551089045273683, 0.0058546065905113256, 0.0058541469997632255, 0.0058537270975268715, 0.0058533424963864529, 0.0058529903881699508, 0.005852664051507625, 0.0058523631236765458, 0.0058520761623469314, 0.0058518005415211264, 0.0058515425890414419, 0.0058513019451798265, 0.0058510732401137744, 0.0058508614692200376, 0.0058506520927768335, 0.0058504543192746256], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099892050240015535, 0.0093048457869062094, 0.0087506669632129337, 0.0083064234816566766, 0.0079474289514256079, 0.0076551417768371023, 0.0074151182828197399, 0.0072160544253088285, 0.0070497799692514291, 0.0069095617451932411, 0.0067904417084561318, 0.0066886748365803635, 0.0066011924071074429, 0.0065256183687723256, 0.0064599416138677677, 0.0064028069732235855, 0.0063528389885666777, 0.0063090420477718715, 0.0062705908315097338, 0.0062367281820147231, 0.006206857630560259, 0.0061804928568906176, 0.0061571948253472475, 0.0061365695799651416, 0.0061182876869032895, 0.0061021095087583242, 0.0060877141626639771, 0.0060749084383959866, 0.0060635287656111668, 0.0060534345801602817, 0.00604443612383987, 0.0060364239597886279, 0.0060292616051810244, 0.0060228745843901935, 0.0060171822048367034, 0.0060121182516803436, 0.0060075949272775306, 0.0060035653687955026, 0.0059999752982584842, 0.0059967691243281059, 0.0059939106934095389, 0.0059913535582042732, 0.0059890663257568099, 0.0059870263836876419, 0.0059852038525118993, 0.0059835774908844818, 0.0059821204269425816, 0.0059808064021793844, 0.0059796184620543227, 0.0059785428915935983, 0.0059775741797956135, 0.005976701093574923, 0.0059759117782594226, 0.0059751909967167578, 0.005974539795441651, 0.0059739449499850552, 0.0059734002693438617, 0.0059728901177128939, 0.0059724021366919363, 0.0059718729948026643, 0.0059670631166072446, 0.0059567601053606397, 0.0059477885154159259, 0.0059400921042405443, 0.0059334375571248738, 0.0059276648802924874, 0.0059226352243159641, 0.0059182477848723439, 0.005914397265067514, 0.0059110046508060697, 0.0059080142532962846, 0.0059053615217783103, 0.0059030070138208794, 0.0059009169327714512, 0.0058990530956619294, 0.0058973921986226587, 0.0058959107460209246, 0.00589458335294352, 0.0058933903000324261, 0.0058923213486836903, 0.0058913577715630208, 0.0058904949013119543, 0.0058897126516791612, 0.0058890086436595955, 0.0058883672696266771, 0.0058877888916153377, 0.0058872637709773499, 0.0058867831486850569, 0.0058863462001858963, 0.0058859455233687408, 0.0058855761262211308, 0.0058852348765178857, 0.0058849235469955741, 0.0058846264252581122, 0.005884339055658023, 0.0058840674902487927, 0.0058838166304484123, 0.0058835773069534523, 0.0058833536169202146, 0.0058831385859463518, 0.0058829338348440792], 'acc': [0.55345525964865938, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822272449271, 0.59383822262938279, 0.59383822264767316, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822262206665, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427]}
[2017-11-18 19:00:10,412 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 19:00:10,501 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 19:00:10,502 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 19:00:11,342 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:141]: done!
[2017-11-18 19:00:11,342 AE_UNIGRAMA_5L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_5L_FULLDS_UNDER_01 finished!
