[2017-11-18 20:06:24,798 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_9FULLDS_UNDER_02
[2017-11-18 20:06:24,798 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 20:06:24,799 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_9FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4cdc792eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4cdc797400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:06:24,799 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 20:06:27,070 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:06:27,071 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:06:27,071 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 20:06:27,071 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4cdc792eb8>, 'discard_decoder_function': True}
[2017-11-18 20:06:27,197 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 20:08:01,381 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 20:08:01,381 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0094857059233643612, 0.0087366879437473354, 0.0081385431488793115, 0.0076616507814906178, 0.0072820790812649716, 0.0069747724456015051, 0.0067219346156224026, 0.0065157473368316239, 0.0063468684308512907, 0.0062074984922849026, 0.0060916310640032108, 0.0059948641990298776, 0.0059135098320742445, 0.0058447310055145026, 0.0057862001342527114, 0.0057362474497539111, 0.0056933543627903016, 0.0056564051698816641, 0.0056244671829585608, 0.0055967086240873752, 0.0055725606912572466, 0.0055515217365137755, 0.0055330707122582378, 0.0055169194023056761, 0.0055027377186052141, 0.0054902959255092951, 0.005479351895919856, 0.0054697272699266034, 0.005461247951132531, 0.0054537499448758893, 0.005447122995364824, 0.0054412366862921198, 0.0054360100476996062, 0.0054313637677666374, 0.0054272194455443814, 0.0054235055797775466, 0.0054201681238935573, 0.0054171717244288374, 0.0054144758240137359, 0.0054120457255771304, 0.0054098544153735693, 0.0054078809608072483, 0.0054060833102337899, 0.0054044557162189156, 0.005402960471835608, 0.0054015967258529782, 0.0054003458856189132, 0.0053992011570308364, 0.005398147534192271, 0.0053971699309439142, 0.0053962609192095652, 0.0053954129160348656, 0.0053946173245697192, 0.0053938731851685311, 0.0053931742306567321, 0.0053925151295462969, 0.0053918951067618978, 0.0053913108218127219, 0.0053907338928914561, 0.0053901714054598602, 0.0053896116068328634, 0.0053890702161165788, 0.0053885395871218636, 0.0053880171456197274, 0.0053875069300795041, 0.0053869946553443378, 0.0053863533738643223, 0.0053854223157805267, 0.005384687131417259, 0.0053840165707778678, 0.0053833914341905433, 0.0053828024495877697, 0.0053822459677492366, 0.0053817218765808087, 0.0053812447367684391, 0.0053807881283233243, 0.0053803393229991418, 0.0053798998541752128, 0.0053794685174813391, 0.0053790378833866621, 0.0053785916516924936, 0.0053781370512726318, 0.0053776732883123474, 0.0053771704258907208, 0.0053765302097328344, 0.0053753845215847289, 0.0053741329457222022, 0.0053731918225262704, 0.0053725851469018449, 0.0053720736665803853, 0.0053715882302617507, 0.0053711139844461473, 0.0053706454917978805, 0.0053701795833900664, 0.0053697164383166166, 0.0053692556910308539, 0.0053687925016331576, 0.0053683287952333491, 0.0053678657411187283, 0.0053674056953197779, 0.0053669464318694404], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099294964701707299, 0.0091041391940607508, 0.0084364388574281034, 0.0079040847333703458, 0.0074802995666269842, 0.007141518984888468, 0.0068640400140808156, 0.0066370523488531999, 0.0064519225103373441, 0.0062997653009032742, 0.0061738517008949542, 0.0060690053647430462, 0.005981230632472535, 0.0059072101586219962, 0.0058445511314923282, 0.0057911232979887027, 0.0057454523377804554, 0.0057061682882207409, 0.0056723051081336434, 0.0056429595031014315, 0.0056174461154478213, 0.0055952403178602932, 0.0055758608822353353, 0.0055588662804519238, 0.0055439873000421016, 0.0055309120650017156, 0.0055194422752977449, 0.0055093585144409714, 0.0055004889994852381, 0.0054926620517966318, 0.0054857435307453031, 0.0054796243938559676, 0.0054741982082313111, 0.0054693701455825246, 0.0054650758670322201, 0.0054612478332890574, 0.0054578040843083955, 0.0054547092944774124, 0.0054519353207528624, 0.0054494337896892221, 0.0054471843808613207, 0.0054451534538277752, 0.0054433159324967766, 0.0054416405461153337, 0.0054401220974187861, 0.0054387291378946451, 0.0054374530243161369, 0.0054362841555557215, 0.0054352088679669383, 0.0054342172174207289, 0.0054332965444688847, 0.0054324376901534639, 0.0054316330682593755, 0.005430886715413241, 0.0054301790724692166, 0.0054295177366737724, 0.0054288856034481817, 0.0054282924045817877, 0.0054277286902998283, 0.0054271656351569343, 0.0054266169050287052, 0.0054260734477843686, 0.0054255471000914501, 0.0054250280715171231, 0.0054245177036597349, 0.0054240114260426043, 0.0054234707898014383, 0.0054226372563257871, 0.0054218224613301206, 0.0054211379273490399, 0.0054205043653600769, 0.0054199028812436639, 0.0054193412173117348, 0.0054188102862245653, 0.0054183194183551183, 0.005417853390917546, 0.0054174052954119737, 0.0054169684340778382, 0.0054165344355289295, 0.005416109239447295, 0.0054156758090428804, 0.0054152266952211805, 0.0054147675137532934, 0.0054142944903078768, 0.0054137288161560417, 0.0054128285079835066, 0.005411575167339624, 0.005410434383607699, 0.0054096716380781801, 0.0054091202476162139, 0.0054086272251988076, 0.0054081571783961453, 0.005407695396095368, 0.0054072314298105736, 0.0054067752238422927, 0.0054063162468264035, 0.0054058598716150794, 0.005405400126918234, 0.0054049440551555139, 0.0054044859539623697, 0.0054040255302356859], 'acc': [0.52657419911729675, 0.59383822264767316, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.59383822262938279, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124]}
[2017-11-18 20:08:01,381 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:95]: done!
[2017-11-18 20:08:01,382 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 20:08:01,382 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 20:08:01,382 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4cdc797400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:08:01,412 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 20:11:16,927 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 20:11:16,928 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0094857059233643612, 0.0087366879437473354, 0.0081385431488793115, 0.0076616507814906178, 0.0072820790812649716, 0.0069747724456015051, 0.0067219346156224026, 0.0065157473368316239, 0.0063468684308512907, 0.0062074984922849026, 0.0060916310640032108, 0.0059948641990298776, 0.0059135098320742445, 0.0058447310055145026, 0.0057862001342527114, 0.0057362474497539111, 0.0056933543627903016, 0.0056564051698816641, 0.0056244671829585608, 0.0055967086240873752, 0.0055725606912572466, 0.0055515217365137755, 0.0055330707122582378, 0.0055169194023056761, 0.0055027377186052141, 0.0054902959255092951, 0.005479351895919856, 0.0054697272699266034, 0.005461247951132531, 0.0054537499448758893, 0.005447122995364824, 0.0054412366862921198, 0.0054360100476996062, 0.0054313637677666374, 0.0054272194455443814, 0.0054235055797775466, 0.0054201681238935573, 0.0054171717244288374, 0.0054144758240137359, 0.0054120457255771304, 0.0054098544153735693, 0.0054078809608072483, 0.0054060833102337899, 0.0054044557162189156, 0.005402960471835608, 0.0054015967258529782, 0.0054003458856189132, 0.0053992011570308364, 0.005398147534192271, 0.0053971699309439142, 0.0053962609192095652, 0.0053954129160348656, 0.0053946173245697192, 0.0053938731851685311, 0.0053931742306567321, 0.0053925151295462969, 0.0053918951067618978, 0.0053913108218127219, 0.0053907338928914561, 0.0053901714054598602, 0.0053896116068328634, 0.0053890702161165788, 0.0053885395871218636, 0.0053880171456197274, 0.0053875069300795041, 0.0053869946553443378, 0.0053863533738643223, 0.0053854223157805267, 0.005384687131417259, 0.0053840165707778678, 0.0053833914341905433, 0.0053828024495877697, 0.0053822459677492366, 0.0053817218765808087, 0.0053812447367684391, 0.0053807881283233243, 0.0053803393229991418, 0.0053798998541752128, 0.0053794685174813391, 0.0053790378833866621, 0.0053785916516924936, 0.0053781370512726318, 0.0053776732883123474, 0.0053771704258907208, 0.0053765302097328344, 0.0053753845215847289, 0.0053741329457222022, 0.0053731918225262704, 0.0053725851469018449, 0.0053720736665803853, 0.0053715882302617507, 0.0053711139844461473, 0.0053706454917978805, 0.0053701795833900664, 0.0053697164383166166, 0.0053692556910308539, 0.0053687925016331576, 0.0053683287952333491, 0.0053678657411187283, 0.0053674056953197779, 0.0053669464318694404], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099294964701707299, 0.0091041391940607508, 0.0084364388574281034, 0.0079040847333703458, 0.0074802995666269842, 0.007141518984888468, 0.0068640400140808156, 0.0066370523488531999, 0.0064519225103373441, 0.0062997653009032742, 0.0061738517008949542, 0.0060690053647430462, 0.005981230632472535, 0.0059072101586219962, 0.0058445511314923282, 0.0057911232979887027, 0.0057454523377804554, 0.0057061682882207409, 0.0056723051081336434, 0.0056429595031014315, 0.0056174461154478213, 0.0055952403178602932, 0.0055758608822353353, 0.0055588662804519238, 0.0055439873000421016, 0.0055309120650017156, 0.0055194422752977449, 0.0055093585144409714, 0.0055004889994852381, 0.0054926620517966318, 0.0054857435307453031, 0.0054796243938559676, 0.0054741982082313111, 0.0054693701455825246, 0.0054650758670322201, 0.0054612478332890574, 0.0054578040843083955, 0.0054547092944774124, 0.0054519353207528624, 0.0054494337896892221, 0.0054471843808613207, 0.0054451534538277752, 0.0054433159324967766, 0.0054416405461153337, 0.0054401220974187861, 0.0054387291378946451, 0.0054374530243161369, 0.0054362841555557215, 0.0054352088679669383, 0.0054342172174207289, 0.0054332965444688847, 0.0054324376901534639, 0.0054316330682593755, 0.005430886715413241, 0.0054301790724692166, 0.0054295177366737724, 0.0054288856034481817, 0.0054282924045817877, 0.0054277286902998283, 0.0054271656351569343, 0.0054266169050287052, 0.0054260734477843686, 0.0054255471000914501, 0.0054250280715171231, 0.0054245177036597349, 0.0054240114260426043, 0.0054234707898014383, 0.0054226372563257871, 0.0054218224613301206, 0.0054211379273490399, 0.0054205043653600769, 0.0054199028812436639, 0.0054193412173117348, 0.0054188102862245653, 0.0054183194183551183, 0.005417853390917546, 0.0054174052954119737, 0.0054169684340778382, 0.0054165344355289295, 0.005416109239447295, 0.0054156758090428804, 0.0054152266952211805, 0.0054147675137532934, 0.0054142944903078768, 0.0054137288161560417, 0.0054128285079835066, 0.005411575167339624, 0.005410434383607699, 0.0054096716380781801, 0.0054091202476162139, 0.0054086272251988076, 0.0054081571783961453, 0.005407695396095368, 0.0054072314298105736, 0.0054067752238422927, 0.0054063162468264035, 0.0054058598716150794, 0.005405400126918234, 0.0054049440551555139, 0.0054044859539623697, 0.0054040255302356859], 'acc': [0.52657419911729675, 0.59383822264767316, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.59383822262938279, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124]}
[2017-11-18 20:11:16,929 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 20:11:17,075 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 20:11:17,075 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 20:11:17,901 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:141]: done!
[2017-11-18 20:11:17,901 AE_UNIGRAMA_5L_9FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_5L_9FULLDS_UNDER_02 finished!
