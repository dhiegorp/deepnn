[2017-11-13 15:03:39,480 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_OVER_04
[2017-11-13 15:03:39,480 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-13 15:03:39,480 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4a1bd602e8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4a1bd607f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 15:03:39,480 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-13 15:03:42,238 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 15:03:42,239 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-13 15:03:42,239 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-13 15:03:42,239 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4a1bd602e8>, 'discard_decoder_function': True}
[2017-11-13 15:03:42,379 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-13 15:08:01,524 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-13 15:08:01,524 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0093265869639312816, 0.0085471384970006465, 0.0079324997568592705, 0.0074497107784333959, 0.0070766286518204324, 0.0067862191814922401, 0.0065581329970886516, 0.0063778355353823679, 0.0062347071557464911, 0.0061201262304909155, 0.0060274322569070444, 0.0059488725053397709, 0.0058843485771608904, 0.0058314021476036162, 0.0057874903467390378, 0.005750927646366831, 0.0057206488094124529, 0.0056953071581507123, 0.0056738840763993457, 0.0056556467652609738, 0.0056400512950443545, 0.0056266631351428592, 0.0056150640240873496, 0.0056045494162645605, 0.0055943808804318519, 0.0055837211647823603, 0.0055745512563516193, 0.0055665876881521676, 0.0055595962497556649, 0.0055534143860115426, 0.0055479059637260977, 0.0055428901749729111, 0.0055380946422116922, 0.0055333187505678134, 0.0055286674019262788, 0.0055240443125586219, 0.0055166449640302187, 0.0055097973487418291, 0.0055039942904434704, 0.0054989532355865338, 0.0054944953053761153, 0.0054905071361890578, 0.005486844327504097, 0.0054834628890472843, 0.0054803099123010117, 0.0054773570135754667, 0.005474563538210137, 0.0054718910119037987, 0.0054693233556511517, 0.005466799881088163, 0.0054643157822001579, 0.0054618508295895029, 0.0054593865636623886, 0.005456830460721273, 0.0054543366464377217, 0.005451916890097005, 0.0054495460893726061, 0.0054472082764976818, 0.0054448938557863759, 0.0054425840880085183, 0.0054402559957487896, 0.0054379133013881765, 0.0054355565890141355, 0.0054331441528483191, 0.0054307063253071376, 0.0054282249718697762, 0.005425669761488912, 0.00542311419386147, 0.0054205692565230841, 0.0054180176339246738, 0.0054154395111602038, 0.0054128362290809008, 0.0054101419522338372, 0.0054069557073171829, 0.0054033656755358922, 0.0053996051277811971, 0.005395533752058472, 0.0053911001285629123, 0.0053863572734567239, 0.0053809625341343734, 0.0053758924091607879, 0.0053711466826477971, 0.0053666604489248241, 0.0053623701326476489, 0.0053582226212188812, 0.0053541906494941616, 0.005350234237089151, 0.0053463389467925809, 0.0053424424496443393, 0.0053384725431590251, 0.0053343970706951297, 0.0053303165933564281, 0.0053264726586030641, 0.005322783340339558, 0.0053191267439800507, 0.0053154136577380825, 0.0053116404407790143, 0.0053078239197161311, 0.0053039131736063163, 0.0052996989416943582, 0.005294816479759783], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098074397142613907, 0.0089291514202584753, 0.0082404657176839684, 0.0076959387143648366, 0.0072736425267088244, 0.006946304045232111, 0.0066907492973714263, 0.006489388133536709, 0.0063300887437115951, 0.0062032959056894472, 0.0061013275717764753, 0.006017093184482152, 0.0059464721467423227, 0.005888658431677002, 0.0058410187283073805, 0.0058013397875162258, 0.0057684845158244308, 0.005741137629177097, 0.005718154158892241, 0.0056986484527533016, 0.0056819873845964444, 0.0056677339419062278, 0.0056554299286653894, 0.0056445889459696341, 0.0056344507192607318, 0.0056238915874472209, 0.0056140135479394795, 0.005605492324306436, 0.0055980542128807572, 0.0055915019119976194, 0.00558569873226467, 0.005580490147353144, 0.0055756468380267184, 0.0055708718953449091, 0.0055661808086184912, 0.0055616107577033001, 0.005555844489872324, 0.0055485758278850427, 0.0055423879325943145, 0.005537083784978628, 0.0055324342551069479, 0.0055282978733997628, 0.0055245474952922268, 0.0055211095463009435, 0.005517909445686601, 0.0055149109441728931, 0.0055120872964434815, 0.0055094028385709298, 0.0055068218125467307, 0.0055043145372793293, 0.0055018423538510091, 0.0054993927815447331, 0.0054969456943847828, 0.0054944681838302034, 0.0054919781460896237, 0.0054895511123726594, 0.0054871800233982299, 0.005484851996689976, 0.0054825428228336519, 0.0054802527829864774, 0.0054779569825313679, 0.0054756341082763784, 0.0054732973225404694, 0.0054709317817199414, 0.0054685141150138308, 0.0054660831500113203, 0.0054635782938734535, 0.0054610440143095622, 0.0054585131584164023, 0.0054559856209672125, 0.0054534425469380818, 0.0054508851868184712, 0.0054482712883767914, 0.0054454141790514837, 0.0054420031048951923, 0.0054383793415606193, 0.0054344933742262458, 0.0054303131556558849, 0.0054258231785913377, 0.0054208006877513861, 0.0054156318630090815, 0.0054108292799261472, 0.0054062987394595243, 0.0054020003537503733, 0.005397880133982175, 0.0053938746157856654, 0.0053899623856576723, 0.0053861148573565191, 0.0053822991486908106, 0.0053784538630171613, 0.0053745383251336317, 0.0053705251906000827, 0.0053666304580078979, 0.0053629340338508706, 0.0053593209249402892, 0.0053556978867044143, 0.0053520092739626109, 0.0053482508322614287, 0.0053444169461155568, 0.0053404292187865989, 0.0053359893885900327], 'acc': [0.5226463729272639, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822264767316, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822262206665, 0.59383822266596353, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822262938279, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822262206665, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.5938382226001182]}
[2017-11-13 15:08:01,524 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:95]: done!
[2017-11-13 15:08:01,525 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-13 15:08:01,525 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-13 15:08:01,525 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4a1bd607f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 15:08:01,561 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-13 15:14:26,573 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:125]: trained!
[2017-11-13 15:14:26,574 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0093265869639312816, 0.0085471384970006465, 0.0079324997568592705, 0.0074497107784333959, 0.0070766286518204324, 0.0067862191814922401, 0.0065581329970886516, 0.0063778355353823679, 0.0062347071557464911, 0.0061201262304909155, 0.0060274322569070444, 0.0059488725053397709, 0.0058843485771608904, 0.0058314021476036162, 0.0057874903467390378, 0.005750927646366831, 0.0057206488094124529, 0.0056953071581507123, 0.0056738840763993457, 0.0056556467652609738, 0.0056400512950443545, 0.0056266631351428592, 0.0056150640240873496, 0.0056045494162645605, 0.0055943808804318519, 0.0055837211647823603, 0.0055745512563516193, 0.0055665876881521676, 0.0055595962497556649, 0.0055534143860115426, 0.0055479059637260977, 0.0055428901749729111, 0.0055380946422116922, 0.0055333187505678134, 0.0055286674019262788, 0.0055240443125586219, 0.0055166449640302187, 0.0055097973487418291, 0.0055039942904434704, 0.0054989532355865338, 0.0054944953053761153, 0.0054905071361890578, 0.005486844327504097, 0.0054834628890472843, 0.0054803099123010117, 0.0054773570135754667, 0.005474563538210137, 0.0054718910119037987, 0.0054693233556511517, 0.005466799881088163, 0.0054643157822001579, 0.0054618508295895029, 0.0054593865636623886, 0.005456830460721273, 0.0054543366464377217, 0.005451916890097005, 0.0054495460893726061, 0.0054472082764976818, 0.0054448938557863759, 0.0054425840880085183, 0.0054402559957487896, 0.0054379133013881765, 0.0054355565890141355, 0.0054331441528483191, 0.0054307063253071376, 0.0054282249718697762, 0.005425669761488912, 0.00542311419386147, 0.0054205692565230841, 0.0054180176339246738, 0.0054154395111602038, 0.0054128362290809008, 0.0054101419522338372, 0.0054069557073171829, 0.0054033656755358922, 0.0053996051277811971, 0.005395533752058472, 0.0053911001285629123, 0.0053863572734567239, 0.0053809625341343734, 0.0053758924091607879, 0.0053711466826477971, 0.0053666604489248241, 0.0053623701326476489, 0.0053582226212188812, 0.0053541906494941616, 0.005350234237089151, 0.0053463389467925809, 0.0053424424496443393, 0.0053384725431590251, 0.0053343970706951297, 0.0053303165933564281, 0.0053264726586030641, 0.005322783340339558, 0.0053191267439800507, 0.0053154136577380825, 0.0053116404407790143, 0.0053078239197161311, 0.0053039131736063163, 0.0052996989416943582, 0.005294816479759783], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098074397142613907, 0.0089291514202584753, 0.0082404657176839684, 0.0076959387143648366, 0.0072736425267088244, 0.006946304045232111, 0.0066907492973714263, 0.006489388133536709, 0.0063300887437115951, 0.0062032959056894472, 0.0061013275717764753, 0.006017093184482152, 0.0059464721467423227, 0.005888658431677002, 0.0058410187283073805, 0.0058013397875162258, 0.0057684845158244308, 0.005741137629177097, 0.005718154158892241, 0.0056986484527533016, 0.0056819873845964444, 0.0056677339419062278, 0.0056554299286653894, 0.0056445889459696341, 0.0056344507192607318, 0.0056238915874472209, 0.0056140135479394795, 0.005605492324306436, 0.0055980542128807572, 0.0055915019119976194, 0.00558569873226467, 0.005580490147353144, 0.0055756468380267184, 0.0055708718953449091, 0.0055661808086184912, 0.0055616107577033001, 0.005555844489872324, 0.0055485758278850427, 0.0055423879325943145, 0.005537083784978628, 0.0055324342551069479, 0.0055282978733997628, 0.0055245474952922268, 0.0055211095463009435, 0.005517909445686601, 0.0055149109441728931, 0.0055120872964434815, 0.0055094028385709298, 0.0055068218125467307, 0.0055043145372793293, 0.0055018423538510091, 0.0054993927815447331, 0.0054969456943847828, 0.0054944681838302034, 0.0054919781460896237, 0.0054895511123726594, 0.0054871800233982299, 0.005484851996689976, 0.0054825428228336519, 0.0054802527829864774, 0.0054779569825313679, 0.0054756341082763784, 0.0054732973225404694, 0.0054709317817199414, 0.0054685141150138308, 0.0054660831500113203, 0.0054635782938734535, 0.0054610440143095622, 0.0054585131584164023, 0.0054559856209672125, 0.0054534425469380818, 0.0054508851868184712, 0.0054482712883767914, 0.0054454141790514837, 0.0054420031048951923, 0.0054383793415606193, 0.0054344933742262458, 0.0054303131556558849, 0.0054258231785913377, 0.0054208006877513861, 0.0054156318630090815, 0.0054108292799261472, 0.0054062987394595243, 0.0054020003537503733, 0.005397880133982175, 0.0053938746157856654, 0.0053899623856576723, 0.0053861148573565191, 0.0053822991486908106, 0.0053784538630171613, 0.0053745383251336317, 0.0053705251906000827, 0.0053666304580078979, 0.0053629340338508706, 0.0053593209249402892, 0.0053556978867044143, 0.0053520092739626109, 0.0053482508322614287, 0.0053444169461155568, 0.0053404292187865989, 0.0053359893885900327], 'acc': [0.5226463729272639, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822264767316, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822262206665, 0.59383822266596353, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822262938279, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822262206665, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.5938382226001182]}
[2017-11-13 15:14:26,574 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-13 15:14:26,686 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-13 15:14:26,687 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-13 15:14:27,601 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:141]: done!
[2017-11-13 15:14:27,601 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_5L_FULLDS_OVER_04 finished!
[2017-11-14 07:03:48,717 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_5L_FULLDS_OVER_04 was already executed!
[2017-11-18 14:55:38,887 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_5L_FULLDS_OVER_04 was already executed!
[2017-11-18 16:22:09,301 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_5L_FULLDS_OVER_04 was already executed!
[2017-11-18 16:30:24,332 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_OVER_04
[2017-11-18 16:30:24,332 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 16:30:24,332 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ffad76282e8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ffad76287f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:30:24,333 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 16:30:26,503 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:30:26,504 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:30:26,504 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 16:30:26,504 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ffad76282e8>, 'discard_decoder_function': True}
[2017-11-18 16:30:26,616 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 16:37:49,387 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_OVER_04
[2017-11-18 16:37:49,387 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 16:37:49,387 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2a5bc982e8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2a5bc987f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:37:49,387 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 16:37:51,618 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:37:51,618 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:37:51,619 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 16:37:51,619 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2a5bc982e8>, 'discard_decoder_function': True}
[2017-11-18 16:37:51,732 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 16:40:08,617 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 16:40:08,618 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0096466827488003604, 0.0089197497026298651, 0.0083200085318781841, 0.0078351059363787334, 0.007377843960889645, 0.0070221362206283975, 0.0067435067747019638, 0.006522864712048315, 0.0063458995565700864, 0.0062034704773120362, 0.0060878791411649279, 0.0059931863173609684, 0.0059147827282413782, 0.0058493409519731034, 0.0057943327195301665, 0.0057477044362269506, 0.0057077238862277809, 0.0056731996812044109, 0.0056435335455760115, 0.0056178064878074363, 0.0055953648843409245, 0.0055756107402588247, 0.0055577360409853086, 0.005541709674151258, 0.0055277437137324159, 0.0055154274168668352, 0.0055045559085893231, 0.0054948569276465605, 0.0054861899929614689, 0.0054783631371657987, 0.0054712421052843796, 0.0054646906060793355, 0.0054586166467172608, 0.005452985255710318, 0.0054477487558287456, 0.0054428459897956369, 0.0054382404375982905, 0.0054338720426215315, 0.0054297119530327875, 0.0054257357059555242, 0.0054219098466810264, 0.0054181857480886924, 0.0054145506975055834, 0.005410989209511911, 0.005407462576205696, 0.0054038772182364546, 0.0054003462413252656, 0.0053968071197055198, 0.0053932693262729288, 0.0053897862445333074, 0.0053863547978021181, 0.0053829376703694335, 0.0053795389540990468, 0.0053761337857415508, 0.0053727009349243526, 0.0053692222468470089, 0.0053656881894007221, 0.0053619587675348959, 0.0053579389770200027, 0.0053536484569197511, 0.0053493255494865468, 0.0053451420792003015, 0.0053410237801022687, 0.0053366088474909364, 0.0053318393536840279, 0.0053269373782140637, 0.0053219668137115652, 0.0053168851263562366, 0.0053116240323367514, 0.0053064145479119907, 0.0053012504330324541, 0.0052961419332732788, 0.0052907802853377336, 0.005284399671161062, 0.0052777246624444918, 0.0052709261573083048, 0.0052639992235249643, 0.0052562476806130394, 0.0052484945620511802, 0.0052410338425824682, 0.0052336620779393824, 0.0052265123265991531, 0.0052194691259545394, 0.0052126522970210266, 0.0052060571987591255, 0.0051997704538374661, 0.0051937590547259218, 0.0051879322321285266, 0.0051821298070336827, 0.005176372734627158, 0.0051706694778450623, 0.0051650118694744401, 0.0051593421166882501, 0.0051536035170530146, 0.0051478418321867269, 0.0051420597661251, 0.0051362745232643265, 0.0051304766515872955, 0.0051246793979682365, 0.0051188586228922452, 0.0051129457285988477], 'val_acc': [0.59830944505696437, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010002837485959702, 0.009277315409763745, 0.0086123469615236471, 0.0080777240437078807, 0.0076051183006957922, 0.0072026505149632046, 0.0068892806756871566, 0.0066427564961995551, 0.0064465633461580395, 0.0062887711075848016, 0.0061615877486427013, 0.0060578152962939844, 0.0059724291429317762, 0.0059014889671122816, 0.0058421209720661265, 0.0057920524078862896, 0.0057494207419664474, 0.0057126930336957992, 0.0056811022578278055, 0.0056538396885675041, 0.0056301821123822798, 0.0056094598718174097, 0.0055910867955652251, 0.0055743316710873203, 0.0055596287283628931, 0.0055467426618331372, 0.0055353757009098566, 0.0055253292329090859, 0.005516322332383943, 0.0055082506697720487, 0.0055009237267337604, 0.0054942134050902734, 0.0054880001988480047, 0.0054822391893257867, 0.0054768666373987617, 0.0054718678672773403, 0.0054671872815073115, 0.0054627494459894739, 0.0054585497957914137, 0.0054545353623560904, 0.0054506838095456827, 0.0054469479036330995, 0.0054433104527602753, 0.0054397485186362454, 0.005436244459517096, 0.0054327070871826449, 0.005429173904885262, 0.0054256750700090641, 0.0054221388935216065, 0.0054186433358217392, 0.0054151950558029988, 0.0054117903653273913, 0.0054084021009150876, 0.0054050195827642124, 0.0054016201282488224, 0.0053981882225659431, 0.0053947203185848733, 0.0053911269853323448, 0.0053873096894629675, 0.0053831604926679912, 0.0053788832518222602, 0.0053746380249471131, 0.0053705427883328017, 0.005366333087807245, 0.0053617851339404976, 0.0053570373881755944, 0.005352195595177669, 0.0053472723977621298, 0.0053421914585143225, 0.0053370405339245065, 0.0053319488463431097, 0.0053269242934358618, 0.0053218448062144867, 0.005315977979208613, 0.0053094859349646422, 0.0053027620851948745, 0.0052959810472234699, 0.0052887914175648032, 0.0052810309053439482, 0.0052735178219937536, 0.0052662017581223295, 0.0052590546697401938, 0.0052520654531662391, 0.0052452367073471621, 0.0052386484070226867, 0.0052323242841141896, 0.0052262998282762152, 0.0052205016055182438, 0.005214817092422548, 0.0052091312659071007, 0.0052034947091794256, 0.0051979103278356363, 0.0051923540583271562, 0.0051867388441131698, 0.0051810785373452217, 0.0051754039699789924, 0.0051697083096482552, 0.0051640004597030874, 0.005158284077930903, 0.0051525568100758102, 0.0051467814250689492], 'acc': [0.095004296052583204, 0.59359273358738696, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822262938279, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822262206665, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822267327968, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427]}
[2017-11-18 16:40:08,618 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:95]: done!
[2017-11-18 16:40:08,619 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 16:40:08,619 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 16:40:08,619 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2a5bc987f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:40:08,665 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 16:45:23,460 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:125]: trained!
[2017-11-18 16:45:23,462 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0096466827488003604, 0.0089197497026298651, 0.0083200085318781841, 0.0078351059363787334, 0.007377843960889645, 0.0070221362206283975, 0.0067435067747019638, 0.006522864712048315, 0.0063458995565700864, 0.0062034704773120362, 0.0060878791411649279, 0.0059931863173609684, 0.0059147827282413782, 0.0058493409519731034, 0.0057943327195301665, 0.0057477044362269506, 0.0057077238862277809, 0.0056731996812044109, 0.0056435335455760115, 0.0056178064878074363, 0.0055953648843409245, 0.0055756107402588247, 0.0055577360409853086, 0.005541709674151258, 0.0055277437137324159, 0.0055154274168668352, 0.0055045559085893231, 0.0054948569276465605, 0.0054861899929614689, 0.0054783631371657987, 0.0054712421052843796, 0.0054646906060793355, 0.0054586166467172608, 0.005452985255710318, 0.0054477487558287456, 0.0054428459897956369, 0.0054382404375982905, 0.0054338720426215315, 0.0054297119530327875, 0.0054257357059555242, 0.0054219098466810264, 0.0054181857480886924, 0.0054145506975055834, 0.005410989209511911, 0.005407462576205696, 0.0054038772182364546, 0.0054003462413252656, 0.0053968071197055198, 0.0053932693262729288, 0.0053897862445333074, 0.0053863547978021181, 0.0053829376703694335, 0.0053795389540990468, 0.0053761337857415508, 0.0053727009349243526, 0.0053692222468470089, 0.0053656881894007221, 0.0053619587675348959, 0.0053579389770200027, 0.0053536484569197511, 0.0053493255494865468, 0.0053451420792003015, 0.0053410237801022687, 0.0053366088474909364, 0.0053318393536840279, 0.0053269373782140637, 0.0053219668137115652, 0.0053168851263562366, 0.0053116240323367514, 0.0053064145479119907, 0.0053012504330324541, 0.0052961419332732788, 0.0052907802853377336, 0.005284399671161062, 0.0052777246624444918, 0.0052709261573083048, 0.0052639992235249643, 0.0052562476806130394, 0.0052484945620511802, 0.0052410338425824682, 0.0052336620779393824, 0.0052265123265991531, 0.0052194691259545394, 0.0052126522970210266, 0.0052060571987591255, 0.0051997704538374661, 0.0051937590547259218, 0.0051879322321285266, 0.0051821298070336827, 0.005176372734627158, 0.0051706694778450623, 0.0051650118694744401, 0.0051593421166882501, 0.0051536035170530146, 0.0051478418321867269, 0.0051420597661251, 0.0051362745232643265, 0.0051304766515872955, 0.0051246793979682365, 0.0051188586228922452, 0.0051129457285988477], 'val_acc': [0.59830944505696437, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010002837485959702, 0.009277315409763745, 0.0086123469615236471, 0.0080777240437078807, 0.0076051183006957922, 0.0072026505149632046, 0.0068892806756871566, 0.0066427564961995551, 0.0064465633461580395, 0.0062887711075848016, 0.0061615877486427013, 0.0060578152962939844, 0.0059724291429317762, 0.0059014889671122816, 0.0058421209720661265, 0.0057920524078862896, 0.0057494207419664474, 0.0057126930336957992, 0.0056811022578278055, 0.0056538396885675041, 0.0056301821123822798, 0.0056094598718174097, 0.0055910867955652251, 0.0055743316710873203, 0.0055596287283628931, 0.0055467426618331372, 0.0055353757009098566, 0.0055253292329090859, 0.005516322332383943, 0.0055082506697720487, 0.0055009237267337604, 0.0054942134050902734, 0.0054880001988480047, 0.0054822391893257867, 0.0054768666373987617, 0.0054718678672773403, 0.0054671872815073115, 0.0054627494459894739, 0.0054585497957914137, 0.0054545353623560904, 0.0054506838095456827, 0.0054469479036330995, 0.0054433104527602753, 0.0054397485186362454, 0.005436244459517096, 0.0054327070871826449, 0.005429173904885262, 0.0054256750700090641, 0.0054221388935216065, 0.0054186433358217392, 0.0054151950558029988, 0.0054117903653273913, 0.0054084021009150876, 0.0054050195827642124, 0.0054016201282488224, 0.0053981882225659431, 0.0053947203185848733, 0.0053911269853323448, 0.0053873096894629675, 0.0053831604926679912, 0.0053788832518222602, 0.0053746380249471131, 0.0053705427883328017, 0.005366333087807245, 0.0053617851339404976, 0.0053570373881755944, 0.005352195595177669, 0.0053472723977621298, 0.0053421914585143225, 0.0053370405339245065, 0.0053319488463431097, 0.0053269242934358618, 0.0053218448062144867, 0.005315977979208613, 0.0053094859349646422, 0.0053027620851948745, 0.0052959810472234699, 0.0052887914175648032, 0.0052810309053439482, 0.0052735178219937536, 0.0052662017581223295, 0.0052590546697401938, 0.0052520654531662391, 0.0052452367073471621, 0.0052386484070226867, 0.0052323242841141896, 0.0052262998282762152, 0.0052205016055182438, 0.005214817092422548, 0.0052091312659071007, 0.0052034947091794256, 0.0051979103278356363, 0.0051923540583271562, 0.0051867388441131698, 0.0051810785373452217, 0.0051754039699789924, 0.0051697083096482552, 0.0051640004597030874, 0.005158284077930903, 0.0051525568100758102, 0.0051467814250689492], 'acc': [0.095004296052583204, 0.59359273358738696, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822262938279, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822262206665, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822267327968, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427]}
[2017-11-18 16:45:23,462 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 16:45:23,625 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 16:45:23,625 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 16:45:24,511 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:141]: done!
[2017-11-18 16:45:24,511 AE_UNIGRAMA_5L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_5L_FULLDS_OVER_04 finished!
