[2017-10-20 01:31:52,941 AE_UNIGRAMA_5L_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_UNDER_01
[2017-10-20 01:31:52,941 AE_UNIGRAMA_5L_UNDER_01.py:149]: >> Printing header log
[2017-10-20 01:31:52,942 AE_UNIGRAMA_5L_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_UNDER_01
	layers = 96,28,26,24,22,20,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f45a647b7b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f45a647b898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:31:52,942 AE_UNIGRAMA_5L_UNDER_01.py:151]: >> Loading dataset... 
[2017-10-20 01:31:53,473 AE_UNIGRAMA_5L_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:31:53,473 AE_UNIGRAMA_5L_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:31:53,473 AE_UNIGRAMA_5L_UNDER_01.py:60]: =======================================
[2017-10-20 01:31:53,473 AE_UNIGRAMA_5L_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f45a647b7b8>, 'discard_decoder_function': True}
[2017-10-20 01:31:53,591 AE_UNIGRAMA_5L_UNDER_01.py:76]: training and evaluate autoencoder
[2017-10-20 01:41:46,411 AE_UNIGRAMA_5L_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_UNDER_01
[2017-10-20 01:41:46,411 AE_UNIGRAMA_5L_UNDER_01.py:149]: >> Printing header log
[2017-10-20 01:41:46,411 AE_UNIGRAMA_5L_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_UNDER_01
	layers = 96,28,26,24,22,20,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2a8fa467b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2a8fa46898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:41:46,411 AE_UNIGRAMA_5L_UNDER_01.py:151]: >> Loading dataset... 
[2017-10-20 01:41:46,979 AE_UNIGRAMA_5L_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:41:46,979 AE_UNIGRAMA_5L_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:41:46,979 AE_UNIGRAMA_5L_UNDER_01.py:60]: =======================================
[2017-10-20 01:41:46,979 AE_UNIGRAMA_5L_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2a8fa467b8>, 'discard_decoder_function': True}
[2017-10-20 01:41:47,108 AE_UNIGRAMA_5L_UNDER_01.py:76]: training and evaluate autoencoder
[2017-10-20 01:42:15,855 AE_UNIGRAMA_5L_UNDER_01.py:88]: trained and evaluated!
[2017-10-20 01:42:15,856 AE_UNIGRAMA_5L_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010187947281314317, 0.0099539347200699457, 0.0097210191356426716, 0.0095066293298533416, 0.0093098240644847591, 0.0091294598381370853, 0.0089644180146845748, 0.0088130860315933542, 0.0086739672327130254, 0.0085458849802557864, 0.0084275040103877347, 0.0083180048042513621, 0.0082163959568484126, 0.0081220165494012338, 0.0080340595649326819, 0.0079519382650274986, 0.0078750731091129286, 0.0078029234246195026, 0.0077351832201489725, 0.0076712657572860837, 0.0076109562865475742, 0.0075539133656894629, 0.0074997902865137312, 0.0074484286705191255, 0.0073995798666958027, 0.0073530456954855683, 0.0073086834446869815, 0.0072662900305841271, 0.0072257167531599789, 0.0071868370252498688, 0.0071495031595202405, 0.0071136288372557399, 0.0070791268153427706, 0.0070459189475081223, 0.0070139373216404127, 0.0069830364021420703, 0.0069532338754865978, 0.0069244208963774841, 0.0068965904158453514, 0.0068696499646374726, 0.0068435601294594625, 0.0068183111573905308, 0.0067938270227339628, 0.0067701167686665814, 0.0067470988767657806, 0.0067247921881373263, 0.0067031026945958347, 0.0066820503416779317, 0.0066616081210289528, 0.0066417554241075391, 0.0066224451343006143, 0.0066036981561647026, 0.0065854694417307371, 0.0065677287247461235, 0.0065504821142022491, 0.0065336792338570255, 0.0065173404949083651, 0.0065014443799964114, 0.0064859633025848287, 0.0064709197996412737, 0.0064562608982993768, 0.0064419843637311767, 0.0064280699941997857, 0.0064145219200688885, 0.0064013279752882001, 0.0063884809135448979, 0.006375962061648254, 0.0063637671853696105, 0.0063518927463756172, 0.0063402863569059116, 0.0063289886645169508, 0.0063179869578673491, 0.0063072695434924393, 0.0062968225000239212, 0.0062866234012834421, 0.0062766842505995006, 0.0062669827914398624, 0.0062575441089261418, 0.0062483159226251134, 0.0062393404190258907, 0.0062305843474890444, 0.0062220441454460627, 0.0062137097847339831, 0.0062055834707523587, 0.0061976639744323646, 0.0061899351967034727, 0.0061823913747908682, 0.0061750371791560853, 0.006167846865134944, 0.0061608334781678197, 0.0061540077336575683, 0.0061473360607144333, 0.0061408344476196405, 0.0061344808680749733, 0.0061282805343709024, 0.0061222315353919579, 0.0061163336114757119, 0.0061105676514674736, 0.0061049456569646594, 0.0060994635772333933, 0.0060941056438399734, 0.0060888758192330491], 'loss': [0.010295524026056008, 0.010069329619577089, 0.0098332348563001434, 0.0096092711688782369, 0.0094043062353013265, 0.0092157892597760239, 0.0090433191702676535, 0.0088852603605547118, 0.008740205765365822, 0.0086067248869643818, 0.0084836002623578776, 0.0083696596792680981, 0.0082641193919689767, 0.0081660714814440569, 0.0080748619591861914, 0.0079897159422028258, 0.0079101144559979072, 0.0078354850368483817, 0.007765349436301759, 0.0076993621872038509, 0.0076370412969221056, 0.0075781414481068798, 0.007522353466277336, 0.0074693545182226949, 0.0074189894846408699, 0.0073710172248233775, 0.0073252772911238245, 0.007281615312961654, 0.0072398267147722574, 0.0071998026846497613, 0.0071614052002451573, 0.0071244895871506557, 0.0070889850087537129, 0.0070548050976218116, 0.0070218661492066512, 0.0069901259726493836, 0.0069594155921478837, 0.0069297902545357639, 0.0069011016886225676, 0.0068733888843108817, 0.0068465397457380967, 0.0068205131332893165, 0.0067953081714526306, 0.0067708610780834785, 0.0067471593060858719, 0.0067241394399483838, 0.0067018114405866776, 0.0066800997000057124, 0.0066590014419826947, 0.0066385112168208986, 0.0066185977373480536, 0.0065992274333064038, 0.0065804038307851051, 0.0065620896565603678, 0.0065442587457340811, 0.0065269133086947664, 0.0065100064873809859, 0.0064935652724024736, 0.0064775576916899355, 0.0064619632661640277, 0.006446805253988973, 0.0064320212765868702, 0.0064176113104886193, 0.0064035821671711568, 0.0063898972955148282, 0.0063765726505006538, 0.0063635912974557961, 0.0063509410064033229, 0.0063386007287089046, 0.0063265904148247206, 0.0063148375993254515, 0.0063034007265664682, 0.0062922617751411227, 0.0062813958884105226, 0.0062708028869219151, 0.0062604613156248511, 0.006250377430179292, 0.0062405296404443606, 0.0062309447750357591, 0.0062215699941336597, 0.0062124495762019673, 0.0062035471724704618, 0.0061948664109185382, 0.0061863882074472574, 0.0061781088882838569, 0.0061700467261260796, 0.0061621702981388086, 0.0061544844592774321, 0.0061469837068966471, 0.0061396549495318295, 0.0061325023987415786, 0.0061255311770862641, 0.0061187196892732556, 0.0061120778137901555, 0.0061055851064750625, 0.0060992471418116236, 0.0060930592863698571, 0.0060870290614238676, 0.006081117579819933, 0.0060753783053124908, 0.0060697552194497158, 0.0060642589434303602]}
[2017-10-20 01:42:15,856 AE_UNIGRAMA_5L_UNDER_01.py:95]: done!
[2017-10-20 01:42:15,856 AE_UNIGRAMA_5L_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-10-20 01:42:15,856 AE_UNIGRAMA_5L_UNDER_01.py:100]: =======================================
[2017-10-20 01:42:15,856 AE_UNIGRAMA_5L_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2a8fa46898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:42:15,892 AE_UNIGRAMA_5L_UNDER_01.py:113]: training ... 
[2017-10-20 01:43:08,808 AE_UNIGRAMA_5L_UNDER_01.py:125]: trained!
[2017-10-20 01:43:08,809 AE_UNIGRAMA_5L_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010187947281314317, 0.0099539347200699457, 0.0097210191356426716, 0.0095066293298533416, 0.0093098240644847591, 0.0091294598381370853, 0.0089644180146845748, 0.0088130860315933542, 0.0086739672327130254, 0.0085458849802557864, 0.0084275040103877347, 0.0083180048042513621, 0.0082163959568484126, 0.0081220165494012338, 0.0080340595649326819, 0.0079519382650274986, 0.0078750731091129286, 0.0078029234246195026, 0.0077351832201489725, 0.0076712657572860837, 0.0076109562865475742, 0.0075539133656894629, 0.0074997902865137312, 0.0074484286705191255, 0.0073995798666958027, 0.0073530456954855683, 0.0073086834446869815, 0.0072662900305841271, 0.0072257167531599789, 0.0071868370252498688, 0.0071495031595202405, 0.0071136288372557399, 0.0070791268153427706, 0.0070459189475081223, 0.0070139373216404127, 0.0069830364021420703, 0.0069532338754865978, 0.0069244208963774841, 0.0068965904158453514, 0.0068696499646374726, 0.0068435601294594625, 0.0068183111573905308, 0.0067938270227339628, 0.0067701167686665814, 0.0067470988767657806, 0.0067247921881373263, 0.0067031026945958347, 0.0066820503416779317, 0.0066616081210289528, 0.0066417554241075391, 0.0066224451343006143, 0.0066036981561647026, 0.0065854694417307371, 0.0065677287247461235, 0.0065504821142022491, 0.0065336792338570255, 0.0065173404949083651, 0.0065014443799964114, 0.0064859633025848287, 0.0064709197996412737, 0.0064562608982993768, 0.0064419843637311767, 0.0064280699941997857, 0.0064145219200688885, 0.0064013279752882001, 0.0063884809135448979, 0.006375962061648254, 0.0063637671853696105, 0.0063518927463756172, 0.0063402863569059116, 0.0063289886645169508, 0.0063179869578673491, 0.0063072695434924393, 0.0062968225000239212, 0.0062866234012834421, 0.0062766842505995006, 0.0062669827914398624, 0.0062575441089261418, 0.0062483159226251134, 0.0062393404190258907, 0.0062305843474890444, 0.0062220441454460627, 0.0062137097847339831, 0.0062055834707523587, 0.0061976639744323646, 0.0061899351967034727, 0.0061823913747908682, 0.0061750371791560853, 0.006167846865134944, 0.0061608334781678197, 0.0061540077336575683, 0.0061473360607144333, 0.0061408344476196405, 0.0061344808680749733, 0.0061282805343709024, 0.0061222315353919579, 0.0061163336114757119, 0.0061105676514674736, 0.0061049456569646594, 0.0060994635772333933, 0.0060941056438399734, 0.0060888758192330491], 'loss': [0.010295524026056008, 0.010069329619577089, 0.0098332348563001434, 0.0096092711688782369, 0.0094043062353013265, 0.0092157892597760239, 0.0090433191702676535, 0.0088852603605547118, 0.008740205765365822, 0.0086067248869643818, 0.0084836002623578776, 0.0083696596792680981, 0.0082641193919689767, 0.0081660714814440569, 0.0080748619591861914, 0.0079897159422028258, 0.0079101144559979072, 0.0078354850368483817, 0.007765349436301759, 0.0076993621872038509, 0.0076370412969221056, 0.0075781414481068798, 0.007522353466277336, 0.0074693545182226949, 0.0074189894846408699, 0.0073710172248233775, 0.0073252772911238245, 0.007281615312961654, 0.0072398267147722574, 0.0071998026846497613, 0.0071614052002451573, 0.0071244895871506557, 0.0070889850087537129, 0.0070548050976218116, 0.0070218661492066512, 0.0069901259726493836, 0.0069594155921478837, 0.0069297902545357639, 0.0069011016886225676, 0.0068733888843108817, 0.0068465397457380967, 0.0068205131332893165, 0.0067953081714526306, 0.0067708610780834785, 0.0067471593060858719, 0.0067241394399483838, 0.0067018114405866776, 0.0066800997000057124, 0.0066590014419826947, 0.0066385112168208986, 0.0066185977373480536, 0.0065992274333064038, 0.0065804038307851051, 0.0065620896565603678, 0.0065442587457340811, 0.0065269133086947664, 0.0065100064873809859, 0.0064935652724024736, 0.0064775576916899355, 0.0064619632661640277, 0.006446805253988973, 0.0064320212765868702, 0.0064176113104886193, 0.0064035821671711568, 0.0063898972955148282, 0.0063765726505006538, 0.0063635912974557961, 0.0063509410064033229, 0.0063386007287089046, 0.0063265904148247206, 0.0063148375993254515, 0.0063034007265664682, 0.0062922617751411227, 0.0062813958884105226, 0.0062708028869219151, 0.0062604613156248511, 0.006250377430179292, 0.0062405296404443606, 0.0062309447750357591, 0.0062215699941336597, 0.0062124495762019673, 0.0062035471724704618, 0.0061948664109185382, 0.0061863882074472574, 0.0061781088882838569, 0.0061700467261260796, 0.0061621702981388086, 0.0061544844592774321, 0.0061469837068966471, 0.0061396549495318295, 0.0061325023987415786, 0.0061255311770862641, 0.0061187196892732556, 0.0061120778137901555, 0.0061055851064750625, 0.0060992471418116236, 0.0060930592863698571, 0.0060870290614238676, 0.006081117579819933, 0.0060753783053124908, 0.0060697552194497158, 0.0060642589434303602]}
[2017-10-20 01:43:08,809 AE_UNIGRAMA_5L_UNDER_01.py:132]: evaluating model ... 
[2017-10-20 01:43:08,861 AE_UNIGRAMA_5L_UNDER_01.py:136]: evaluated! 
[2017-10-20 01:43:08,862 AE_UNIGRAMA_5L_UNDER_01.py:138]: generating reports ... 
[2017-10-20 01:43:09,479 AE_UNIGRAMA_5L_UNDER_01.py:141]: done!
[2017-10-20 01:43:09,479 AE_UNIGRAMA_5L_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_5L_UNDER_01 finished!
