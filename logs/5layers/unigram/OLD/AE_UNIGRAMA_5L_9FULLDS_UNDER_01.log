[2017-11-18 17:49:29,228 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_9FULLDS_UNDER_01
[2017-11-18 17:49:29,228 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 17:49:29,228 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_9FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f826c358eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f826c35d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:49:29,228 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 17:49:31,562 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:49:31,563 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:49:31,563 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 17:49:31,563 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f826c358eb8>, 'discard_decoder_function': True}
[2017-11-18 17:49:31,695 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 17:50:49,317 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 17:50:49,319 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0098094959811433104, 0.0093263350759154734, 0.0089195308281339435, 0.0085756011264113245, 0.0082844072788233643, 0.0080365486114803743, 0.0078245995715821824, 0.0076424810858782225, 0.0074855407021559147, 0.00734976518407015, 0.0072320807719714764, 0.0071296939109162846, 0.0070404249417312503, 0.0069623526647133848, 0.0068919172095328581, 0.0068300610775444952, 0.0067757546115503704, 0.0067280101893111679, 0.0066859088256237742, 0.0066488537349036862, 0.0066148850011602672, 0.0065811579127668324, 0.006551619681082351, 0.00652571334953679, 0.0065028784568642306, 0.0064827684374325571, 0.0064649865935183168, 0.0064486880971201636, 0.0064322143029496865, 0.0064177656544865992, 0.0064049866879636128, 0.0063936734693217307, 0.0063836563635961139, 0.0063747608940398067, 0.0063668460701036076, 0.006359808886860446, 0.0063535601391981724, 0.0063480070737546163, 0.0063430699425688214, 0.0063386733111648521, 0.0063347537073079815, 0.0063312519987745947, 0.0063281303131490817, 0.0063253489220449861, 0.0063228643239530207, 0.0063206415349779839, 0.0063186616474062273, 0.0063168910096369707, 0.0063153119698387272, 0.00631390192469966, 0.0063126368369586777, 0.0063115127864014804, 0.0063105038590886686, 0.0063096016552333491, 0.0063087915711944123, 0.0063080653718178793, 0.0063074155208695431, 0.0063068318423410846, 0.006306308020369719, 0.0063058351088166016, 0.0063054093361846917, 0.0063050258270636317, 0.0063046834864391808, 0.0063043709234935214, 0.0063040905574919199, 0.0063038362561150408, 0.0063036080937215137, 0.0063034018093650942, 0.0063032126132890349, 0.0063030410379832638, 0.0063028865399195767, 0.0063027443377268923, 0.0063026171428853433, 0.0063025022139659827, 0.0063023929471695619, 0.0063022933714673643, 0.0063022032592483946, 0.0063021177935452689, 0.0063020397871506812, 0.0063019648368187308, 0.0063018975532122537, 0.0063018353010922427, 0.0063017736772128007, 0.0063017167698438611, 0.0063016628024217258, 0.006301611090915463, 0.0063015647508575003, 0.0063015224749392853, 0.0063014792096833614, 0.0063014370021340117, 0.006301396239657764, 0.0063013592290834756, 0.0063013236385108529, 0.0063012891772652553, 0.0063012565757554926, 0.0063012265995588427, 0.0063011956339389177, 0.0063011670411208106, 0.0063011387577167456, 0.0063011111714355219, 0.0063010857223872972], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010089723103190106, 0.0095626314291717956, 0.0091202555543694955, 0.0087465256562531245, 0.008430765448013515, 0.0081627913211713872, 0.007934280690841438, 0.0077385374229884674, 0.0075701514046469564, 0.0074248242373616546, 0.0072989968126986101, 0.0071898210056174586, 0.007094800927232376, 0.007011869745092391, 0.0069382698116251312, 0.0068727007182732237, 0.0068151566847094334, 0.0067646348217578374, 0.0067202145284849055, 0.0066810460732382136, 0.0066464274363896118, 0.0066124682701763802, 0.0065812710012449057, 0.006553923757020917, 0.0065299164620070925, 0.0065087641766988728, 0.0064901196207735488, 0.0064735594422184826, 0.0064571583829317169, 0.0064418893917888402, 0.0064284510317674532, 0.0064165602894610783, 0.0064060317367960942, 0.0063967063144623054, 0.0063884202980773498, 0.0063810540012589102, 0.0063745075125396762, 0.0063686925689005643, 0.0063635248723308982, 0.006358929628265556, 0.0063548420719474067, 0.0063511943326293833, 0.0063479422939486541, 0.006345043713561857, 0.0063424589931695089, 0.0063401537036725103, 0.0063380925521520663, 0.0063362579580798347, 0.0063346170503529534, 0.0063331568197199642, 0.006331847881221769, 0.006330684074663093, 0.0063296402869141366, 0.0063287107251301941, 0.0063278781824779645, 0.0063271300096832545, 0.0063264606459032206, 0.0063258624817168693, 0.006325325664561285, 0.0063248436930115545, 0.0063244088530486509, 0.0063240188568907309, 0.0063236677705714849, 0.0063233536685154716, 0.0063230680682225086, 0.0063228125020251642, 0.0063225817112145801, 0.0063223698431022612, 0.0063221823773103921, 0.006322009673958723, 0.0063218564909430274, 0.0063217135401868125, 0.0063215851290141191, 0.0063214685707416503, 0.0063213618610882347, 0.00632126299080001, 0.0063211712975370943, 0.0063210895427446567, 0.0063210124746870379, 0.0063209393574627931, 0.0063208709526370388, 0.0063208090439777192, 0.0063207521284168499, 0.0063206952912759247, 0.006320642664234313, 0.0063205946050401409, 0.0063205451364017956, 0.006320504585974448, 0.0063204632917007774, 0.0063204243316207541, 0.0063203849241698102, 0.0063203486970134148, 0.0063203153896853248, 0.0063202806990911471, 0.0063202512822953805, 0.0063202196423056247, 0.0063201924987165668, 0.0063201647053050987, 0.0063201363890177924, 0.0063201108239444798, 0.0063200854720682461], 'acc': [0.55996072176366962, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822266596353, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.59383822262938279, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198]}
[2017-11-18 17:50:49,319 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:95]: done!
[2017-11-18 17:50:49,319 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 17:50:49,319 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 17:50:49,319 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f826c35d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:50:49,386 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 17:53:03,118 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 17:53:03,119 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0098094959811433104, 0.0093263350759154734, 0.0089195308281339435, 0.0085756011264113245, 0.0082844072788233643, 0.0080365486114803743, 0.0078245995715821824, 0.0076424810858782225, 0.0074855407021559147, 0.00734976518407015, 0.0072320807719714764, 0.0071296939109162846, 0.0070404249417312503, 0.0069623526647133848, 0.0068919172095328581, 0.0068300610775444952, 0.0067757546115503704, 0.0067280101893111679, 0.0066859088256237742, 0.0066488537349036862, 0.0066148850011602672, 0.0065811579127668324, 0.006551619681082351, 0.00652571334953679, 0.0065028784568642306, 0.0064827684374325571, 0.0064649865935183168, 0.0064486880971201636, 0.0064322143029496865, 0.0064177656544865992, 0.0064049866879636128, 0.0063936734693217307, 0.0063836563635961139, 0.0063747608940398067, 0.0063668460701036076, 0.006359808886860446, 0.0063535601391981724, 0.0063480070737546163, 0.0063430699425688214, 0.0063386733111648521, 0.0063347537073079815, 0.0063312519987745947, 0.0063281303131490817, 0.0063253489220449861, 0.0063228643239530207, 0.0063206415349779839, 0.0063186616474062273, 0.0063168910096369707, 0.0063153119698387272, 0.00631390192469966, 0.0063126368369586777, 0.0063115127864014804, 0.0063105038590886686, 0.0063096016552333491, 0.0063087915711944123, 0.0063080653718178793, 0.0063074155208695431, 0.0063068318423410846, 0.006306308020369719, 0.0063058351088166016, 0.0063054093361846917, 0.0063050258270636317, 0.0063046834864391808, 0.0063043709234935214, 0.0063040905574919199, 0.0063038362561150408, 0.0063036080937215137, 0.0063034018093650942, 0.0063032126132890349, 0.0063030410379832638, 0.0063028865399195767, 0.0063027443377268923, 0.0063026171428853433, 0.0063025022139659827, 0.0063023929471695619, 0.0063022933714673643, 0.0063022032592483946, 0.0063021177935452689, 0.0063020397871506812, 0.0063019648368187308, 0.0063018975532122537, 0.0063018353010922427, 0.0063017736772128007, 0.0063017167698438611, 0.0063016628024217258, 0.006301611090915463, 0.0063015647508575003, 0.0063015224749392853, 0.0063014792096833614, 0.0063014370021340117, 0.006301396239657764, 0.0063013592290834756, 0.0063013236385108529, 0.0063012891772652553, 0.0063012565757554926, 0.0063012265995588427, 0.0063011956339389177, 0.0063011670411208106, 0.0063011387577167456, 0.0063011111714355219, 0.0063010857223872972], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010089723103190106, 0.0095626314291717956, 0.0091202555543694955, 0.0087465256562531245, 0.008430765448013515, 0.0081627913211713872, 0.007934280690841438, 0.0077385374229884674, 0.0075701514046469564, 0.0074248242373616546, 0.0072989968126986101, 0.0071898210056174586, 0.007094800927232376, 0.007011869745092391, 0.0069382698116251312, 0.0068727007182732237, 0.0068151566847094334, 0.0067646348217578374, 0.0067202145284849055, 0.0066810460732382136, 0.0066464274363896118, 0.0066124682701763802, 0.0065812710012449057, 0.006553923757020917, 0.0065299164620070925, 0.0065087641766988728, 0.0064901196207735488, 0.0064735594422184826, 0.0064571583829317169, 0.0064418893917888402, 0.0064284510317674532, 0.0064165602894610783, 0.0064060317367960942, 0.0063967063144623054, 0.0063884202980773498, 0.0063810540012589102, 0.0063745075125396762, 0.0063686925689005643, 0.0063635248723308982, 0.006358929628265556, 0.0063548420719474067, 0.0063511943326293833, 0.0063479422939486541, 0.006345043713561857, 0.0063424589931695089, 0.0063401537036725103, 0.0063380925521520663, 0.0063362579580798347, 0.0063346170503529534, 0.0063331568197199642, 0.006331847881221769, 0.006330684074663093, 0.0063296402869141366, 0.0063287107251301941, 0.0063278781824779645, 0.0063271300096832545, 0.0063264606459032206, 0.0063258624817168693, 0.006325325664561285, 0.0063248436930115545, 0.0063244088530486509, 0.0063240188568907309, 0.0063236677705714849, 0.0063233536685154716, 0.0063230680682225086, 0.0063228125020251642, 0.0063225817112145801, 0.0063223698431022612, 0.0063221823773103921, 0.006322009673958723, 0.0063218564909430274, 0.0063217135401868125, 0.0063215851290141191, 0.0063214685707416503, 0.0063213618610882347, 0.00632126299080001, 0.0063211712975370943, 0.0063210895427446567, 0.0063210124746870379, 0.0063209393574627931, 0.0063208709526370388, 0.0063208090439777192, 0.0063207521284168499, 0.0063206952912759247, 0.006320642664234313, 0.0063205946050401409, 0.0063205451364017956, 0.006320504585974448, 0.0063204632917007774, 0.0063204243316207541, 0.0063203849241698102, 0.0063203486970134148, 0.0063203153896853248, 0.0063202806990911471, 0.0063202512822953805, 0.0063202196423056247, 0.0063201924987165668, 0.0063201647053050987, 0.0063201363890177924, 0.0063201108239444798, 0.0063200854720682461], 'acc': [0.55996072176366962, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822266596353, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.59383822262938279, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198]}
[2017-11-18 17:53:03,119 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 17:53:03,252 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 17:53:03,252 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 17:53:04,118 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:141]: done!
[2017-11-18 17:53:04,118 AE_UNIGRAMA_5L_9FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_5L_9FULLDS_UNDER_01 finished!
