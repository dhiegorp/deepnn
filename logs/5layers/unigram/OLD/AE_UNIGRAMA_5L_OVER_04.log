[2017-10-20 01:35:36,585 AE_UNIGRAMA_5L_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_OVER_04
[2017-10-20 01:35:36,585 AE_UNIGRAMA_5L_OVER_04.py:149]: >> Printing header log
[2017-10-20 01:35:36,585 AE_UNIGRAMA_5L_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_OVER_04
	layers = 96,134,122,109,97,84,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f74fc23eb38>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f74fc23ec18>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:35:36,585 AE_UNIGRAMA_5L_OVER_04.py:151]: >> Loading dataset... 
[2017-10-20 01:35:37,143 AE_UNIGRAMA_5L_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:35:37,143 AE_UNIGRAMA_5L_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:35:37,144 AE_UNIGRAMA_5L_OVER_04.py:60]: =======================================
[2017-10-20 01:35:37,144 AE_UNIGRAMA_5L_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f74fc23eb38>, 'discard_decoder_function': True}
[2017-10-20 01:35:37,263 AE_UNIGRAMA_5L_OVER_04.py:76]: training and evaluate autoencoder
[2017-10-20 01:36:27,766 AE_UNIGRAMA_5L_OVER_04.py:88]: trained and evaluated!
[2017-10-20 01:36:27,766 AE_UNIGRAMA_5L_OVER_04.py:91]: Training history: 
{'val_loss': [0.010201659919105498, 0.010115909944098013, 0.010030561157928081, 0.0099484856520886764, 0.0098709626933455915, 0.0097977033812815823, 0.009728245250188285, 0.0096629256500298209, 0.0096015392432203962, 0.0095437353608444284, 0.0094892907209112743, 0.0094381128316641302, 0.009389871371335257, 0.0093443949488736001, 0.0093014788360345317, 0.0092609277978317889, 0.0092226402508614226, 0.0091864304291603728, 0.0091521351366238082, 0.0091196547286605742, 0.0090889146683052133, 0.0090598025459616149, 0.0090321963202886872, 0.009005965727301779, 0.0089810441030002443, 0.0089574256517186927, 0.0089349543578839657, 0.0089135957729472998, 0.0088932900222149919, 0.0088739649991619093, 0.0088555607806240309, 0.0088380415297241461, 0.0088213212601148065, 0.0088053530836858709, 0.008790161104034978, 0.0087756245815953354, 0.0087617358026617527, 0.0087484543568361207, 0.0087357738598848808, 0.0087236217655878526, 0.0087119899932502822, 0.0087008540809403786, 0.008690166515627094, 0.0086799362158492821, 0.0086700962423641222, 0.0086606736935425869, 0.0086516126779126196, 0.0086429179109439088, 0.0086345568725139897, 0.0086265247709855272, 0.0086187865328888474, 0.0086113534137246556, 0.0086041835420609183, 0.008597273604605056, 0.0085906133204560076, 0.0085842010329674825, 0.008578013240958679, 0.0085720410224285719, 0.0085662739233678155, 0.0085607116062152554, 0.0085553289269924612, 0.0085501125442438847, 0.008545059778253275, 0.0085401510920195545, 0.0085354037600185121, 0.0085308018510946559, 0.0085263413699087597, 0.0085219983651984802, 0.0085177197481148964, 0.0085132419335963994, 0.0085087917662021399, 0.0085044142315822014, 0.0085001674266081979, 0.0084959683891344239, 0.0084913846236899446, 0.0084868856986160621, 0.0084825523169953579, 0.0084783543147091307, 0.0084742910374080611, 0.0084703413554948499, 0.0084665010970598267, 0.0084628280127580276, 0.0084593107016777899, 0.0084559289793930525, 0.0084526639234371575, 0.0084495074704261739, 0.0084464624801089769, 0.0084435043486049844, 0.0084406415582201737, 0.0084378725959881311, 0.0084351955161717299, 0.0084325976957148122, 0.0084300855777077518, 0.0084276531829903783, 0.0084252942052278606, 0.0084230059473931126, 0.0084207901440311542, 0.008418640805595316, 0.0084165518507915357, 0.0084145195543295168, 0.0084125522859948496, 0.0084106389374288704], 'loss': [0.010241473148008506, 0.010156785531201902, 0.010072767137496583, 0.0099903519632273015, 0.0099119702960835613, 0.0098380234336323657, 0.0097679489245838594, 0.0097018118962627214, 0.0096396318944222594, 0.0095812020189121379, 0.0095262186013313262, 0.0094744556920617808, 0.0094258017207197644, 0.0093799574660124695, 0.0093367509503826523, 0.009295980791780541, 0.0092574847397321781, 0.009221122232074011, 0.0091867557072527733, 0.0091542169788294808, 0.0091234162425795212, 0.0090942683583325815, 0.0090666786082359129, 0.0090405192528407712, 0.0090156786948598164, 0.0089920854995046654, 0.0089697274760089547, 0.008948464822951422, 0.0089282636841519821, 0.0089090610342014397, 0.0088907850685299872, 0.0088733979549485628, 0.0088568379239310283, 0.0088410351898225818, 0.0088259499278503396, 0.0088115967581187133, 0.0087978755660268089, 0.0087847546070411158, 0.0087722318324809367, 0.0087602526829855601, 0.0087487949344622045, 0.0087378124998952252, 0.0087273065338498556, 0.0087172281484737234, 0.0087075803392253626, 0.0086983045352452288, 0.0086894190286932443, 0.0086808824681601938, 0.0086726900682393658, 0.0086648140953236655, 0.0086572456712243236, 0.0086499536347008216, 0.0086429547552836772, 0.0086362031485928883, 0.0086296944281964421, 0.0086234346891913075, 0.0086173989209584034, 0.0086115811383048295, 0.0086059619597609813, 0.0086005403395208683, 0.0085953108756845909, 0.0085902499737928965, 0.0085853400423243579, 0.0085805836308246088, 0.0085759729635801578, 0.0085715078688658811, 0.0085671771084174248, 0.0085629843892077399, 0.0085588861388493764, 0.0085546996091854823, 0.0085504265209017678, 0.0085461931566455356, 0.0085420667536707847, 0.0085380256643087203, 0.0085338148469884991, 0.0085293688715768132, 0.0085250727074437146, 0.0085209320976496767, 0.0085169325422978729, 0.008513044449715396, 0.0085092645473938532, 0.0085056119597875859, 0.0085021401841374328, 0.0084987960065490056, 0.0084955798875318393, 0.0084924760464059109, 0.0084894712299987737, 0.0084865715311177314, 0.0084837600342659181, 0.0084810467252591382, 0.0084784071733367983, 0.0084758680920587696, 0.0084733980654589439, 0.00847101829243113, 0.0084687073210731705, 0.0084664670855823521, 0.0084643006472451664, 0.0084621954678380934, 0.008460161182285271, 0.008458183083474893, 0.0084562567374643263, 0.0084543977111358175]}
[2017-10-20 01:36:27,767 AE_UNIGRAMA_5L_OVER_04.py:95]: done!
[2017-10-20 01:36:27,767 AE_UNIGRAMA_5L_OVER_04.py:155]: >> Executing classifier part ... 
[2017-10-20 01:36:27,767 AE_UNIGRAMA_5L_OVER_04.py:100]: =======================================
[2017-10-20 01:36:27,767 AE_UNIGRAMA_5L_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f74fc23ec18>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:36:27,800 AE_UNIGRAMA_5L_OVER_04.py:113]: training ... 
[2017-10-20 01:37:40,009 AE_UNIGRAMA_5L_OVER_04.py:125]: trained!
[2017-10-20 01:37:40,010 AE_UNIGRAMA_5L_OVER_04.py:128]: Training history: 
{'val_loss': [0.010201659919105498, 0.010115909944098013, 0.010030561157928081, 0.0099484856520886764, 0.0098709626933455915, 0.0097977033812815823, 0.009728245250188285, 0.0096629256500298209, 0.0096015392432203962, 0.0095437353608444284, 0.0094892907209112743, 0.0094381128316641302, 0.009389871371335257, 0.0093443949488736001, 0.0093014788360345317, 0.0092609277978317889, 0.0092226402508614226, 0.0091864304291603728, 0.0091521351366238082, 0.0091196547286605742, 0.0090889146683052133, 0.0090598025459616149, 0.0090321963202886872, 0.009005965727301779, 0.0089810441030002443, 0.0089574256517186927, 0.0089349543578839657, 0.0089135957729472998, 0.0088932900222149919, 0.0088739649991619093, 0.0088555607806240309, 0.0088380415297241461, 0.0088213212601148065, 0.0088053530836858709, 0.008790161104034978, 0.0087756245815953354, 0.0087617358026617527, 0.0087484543568361207, 0.0087357738598848808, 0.0087236217655878526, 0.0087119899932502822, 0.0087008540809403786, 0.008690166515627094, 0.0086799362158492821, 0.0086700962423641222, 0.0086606736935425869, 0.0086516126779126196, 0.0086429179109439088, 0.0086345568725139897, 0.0086265247709855272, 0.0086187865328888474, 0.0086113534137246556, 0.0086041835420609183, 0.008597273604605056, 0.0085906133204560076, 0.0085842010329674825, 0.008578013240958679, 0.0085720410224285719, 0.0085662739233678155, 0.0085607116062152554, 0.0085553289269924612, 0.0085501125442438847, 0.008545059778253275, 0.0085401510920195545, 0.0085354037600185121, 0.0085308018510946559, 0.0085263413699087597, 0.0085219983651984802, 0.0085177197481148964, 0.0085132419335963994, 0.0085087917662021399, 0.0085044142315822014, 0.0085001674266081979, 0.0084959683891344239, 0.0084913846236899446, 0.0084868856986160621, 0.0084825523169953579, 0.0084783543147091307, 0.0084742910374080611, 0.0084703413554948499, 0.0084665010970598267, 0.0084628280127580276, 0.0084593107016777899, 0.0084559289793930525, 0.0084526639234371575, 0.0084495074704261739, 0.0084464624801089769, 0.0084435043486049844, 0.0084406415582201737, 0.0084378725959881311, 0.0084351955161717299, 0.0084325976957148122, 0.0084300855777077518, 0.0084276531829903783, 0.0084252942052278606, 0.0084230059473931126, 0.0084207901440311542, 0.008418640805595316, 0.0084165518507915357, 0.0084145195543295168, 0.0084125522859948496, 0.0084106389374288704], 'loss': [0.010241473148008506, 0.010156785531201902, 0.010072767137496583, 0.0099903519632273015, 0.0099119702960835613, 0.0098380234336323657, 0.0097679489245838594, 0.0097018118962627214, 0.0096396318944222594, 0.0095812020189121379, 0.0095262186013313262, 0.0094744556920617808, 0.0094258017207197644, 0.0093799574660124695, 0.0093367509503826523, 0.009295980791780541, 0.0092574847397321781, 0.009221122232074011, 0.0091867557072527733, 0.0091542169788294808, 0.0091234162425795212, 0.0090942683583325815, 0.0090666786082359129, 0.0090405192528407712, 0.0090156786948598164, 0.0089920854995046654, 0.0089697274760089547, 0.008948464822951422, 0.0089282636841519821, 0.0089090610342014397, 0.0088907850685299872, 0.0088733979549485628, 0.0088568379239310283, 0.0088410351898225818, 0.0088259499278503396, 0.0088115967581187133, 0.0087978755660268089, 0.0087847546070411158, 0.0087722318324809367, 0.0087602526829855601, 0.0087487949344622045, 0.0087378124998952252, 0.0087273065338498556, 0.0087172281484737234, 0.0087075803392253626, 0.0086983045352452288, 0.0086894190286932443, 0.0086808824681601938, 0.0086726900682393658, 0.0086648140953236655, 0.0086572456712243236, 0.0086499536347008216, 0.0086429547552836772, 0.0086362031485928883, 0.0086296944281964421, 0.0086234346891913075, 0.0086173989209584034, 0.0086115811383048295, 0.0086059619597609813, 0.0086005403395208683, 0.0085953108756845909, 0.0085902499737928965, 0.0085853400423243579, 0.0085805836308246088, 0.0085759729635801578, 0.0085715078688658811, 0.0085671771084174248, 0.0085629843892077399, 0.0085588861388493764, 0.0085546996091854823, 0.0085504265209017678, 0.0085461931566455356, 0.0085420667536707847, 0.0085380256643087203, 0.0085338148469884991, 0.0085293688715768132, 0.0085250727074437146, 0.0085209320976496767, 0.0085169325422978729, 0.008513044449715396, 0.0085092645473938532, 0.0085056119597875859, 0.0085021401841374328, 0.0084987960065490056, 0.0084955798875318393, 0.0084924760464059109, 0.0084894712299987737, 0.0084865715311177314, 0.0084837600342659181, 0.0084810467252591382, 0.0084784071733367983, 0.0084758680920587696, 0.0084733980654589439, 0.00847101829243113, 0.0084687073210731705, 0.0084664670855823521, 0.0084643006472451664, 0.0084621954678380934, 0.008460161182285271, 0.008458183083474893, 0.0084562567374643263, 0.0084543977111358175]}
[2017-10-20 01:37:40,010 AE_UNIGRAMA_5L_OVER_04.py:132]: evaluating model ... 
[2017-10-20 01:37:40,074 AE_UNIGRAMA_5L_OVER_04.py:136]: evaluated! 
[2017-10-20 01:37:40,075 AE_UNIGRAMA_5L_OVER_04.py:138]: generating reports ... 
[2017-10-20 01:37:40,682 AE_UNIGRAMA_5L_OVER_04.py:141]: done!
[2017-10-20 01:37:40,683 AE_UNIGRAMA_5L_OVER_04.py:157]: >> experiment AE_UNIGRAMA_5L_OVER_04 finished!
