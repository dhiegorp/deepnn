[2017-11-18 17:24:35,862 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_9FULLDS_UNDER_03
[2017-11-18 17:24:35,862 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 17:24:35,862 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_9FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f72e660deb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f72e6612400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:24:35,862 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 17:24:38,291 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:24:38,292 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:24:38,292 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 17:24:38,292 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f72e660deb8>, 'discard_decoder_function': True}
[2017-11-18 17:24:38,419 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 17:26:31,178 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 17:26:31,179 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0095004475337016111, 0.0087692546204707275, 0.0082078670727918027, 0.0077423645118070037, 0.0073718924699327235, 0.0070661048196770937, 0.0067687804404425733, 0.0065353760889052624, 0.0063482748309628837, 0.0061982062303668891, 0.0060702215168913993, 0.0059592923019745362, 0.0058695575215869837, 0.0057956427854281472, 0.0057341954100963302, 0.0056825607062003566, 0.0056389925414603919, 0.0056019972350779693, 0.0055702424440286485, 0.0055417153225833116, 0.0055152684027785677, 0.0054924474048158867, 0.0054725141147098878, 0.0054548900675073743, 0.0054394487678855437, 0.0054259323199251884, 0.0054139161549367557, 0.0054032178749684598, 0.0053935848499584264, 0.0053847649256031013, 0.0053766794024923186, 0.0053691995713157454, 0.0053622272421456315, 0.0053557596614023685, 0.0053497786830990239, 0.0053442448690959425, 0.0053392059205819393, 0.0053345922842582098, 0.0053303105689383951, 0.0053263551480102929, 0.0053226707540164975, 0.0053191863275750878, 0.0053159060824843167, 0.005312793831933442, 0.0053098156594885912, 0.0053069469061512763, 0.0053041942355328076, 0.0053015063156211907, 0.005298913612147846, 0.0052963942933679778, 0.0052939367838079317, 0.0052915208081200371, 0.00528911908781132, 0.0052866613443082458, 0.0052843229044762735, 0.0052820341994432142, 0.0052797826348767313, 0.0052775448418877135, 0.0052753269258415609, 0.0052731164346200244, 0.005270943989517227, 0.0052687459481036026, 0.0052665670544219858, 0.0052644010234140859, 0.005262229346797878, 0.0052600478888131632, 0.0052576333075420893, 0.005254728445175382, 0.0052519507729439823, 0.0052493244592847904, 0.0052466596787687954, 0.0052439477399932148, 0.0052411973715829297, 0.0052383860346588394, 0.00523554069812874, 0.0052326644043643846, 0.0052297811469871613, 0.0052268801918284105, 0.0052239768853454202, 0.0052210473744195261, 0.0052180920882600275, 0.0052150818048670028, 0.0052120634366630498, 0.0052090332206223642, 0.0052059543042148309, 0.0052028659101197748, 0.0051997828038730402, 0.0051967028213732655, 0.0051936516782131285, 0.0051905874891780956, 0.0051875269547541573, 0.0051844709260010658, 0.0051814153031827671, 0.0051783668551592648, 0.0051753306816147556, 0.0051722980953392925, 0.0051692554477166877, 0.0051661566002017181, 0.0051628342884065953, 0.0051593612201815799, 0.0051558275337583248], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099487675840179805, 0.009125158730407347, 0.0084861593912659104, 0.0079763849391962637, 0.0075600490631217623, 0.0072309348084754086, 0.0069237529473111532, 0.0066616408539129117, 0.0064528823888030601, 0.0062861952879132892, 0.0061491119128456321, 0.0060295475162958955, 0.0059303606868227358, 0.0058493826609656782, 0.0057824608978792628, 0.005726575242599871, 0.005679512303802676, 0.0056397459147710868, 0.0056058566221571585, 0.0055763267333995047, 0.0055488706188011432, 0.0055245685284700998, 0.0055035188874956601, 0.0054849657705971638, 0.0054686671657101591, 0.0054544132316949852, 0.005441889664844342, 0.0054307371394291962, 0.0054207902814476412, 0.0054117477895277944, 0.0054034594319759882, 0.0053958304564655927, 0.0053887674439805, 0.0053821913490458961, 0.0053760963379495402, 0.0053704581508072068, 0.0053652851865549711, 0.005360579694279121, 0.0053562324212794764, 0.0053522079872435893, 0.0053484572899120085, 0.0053449572251230105, 0.0053416591293572995, 0.0053385306975416861, 0.0053355562706650901, 0.005332697600142728, 0.0053299292974033187, 0.0053272691390250666, 0.0053246757919815872, 0.0053221761787199812, 0.0053197451633618074, 0.0053173566467550632, 0.0053149936912206142, 0.0053125773790304214, 0.005310213838261418, 0.0053079416730745345, 0.0053057082105307718, 0.0053035026495974243, 0.005301306470535852, 0.0052991377473141799, 0.0052969662238374704, 0.005294817034097973, 0.0052926674191646232, 0.005290524811556281, 0.0052883796836498166, 0.0052862306443485791, 0.0052840122588964688, 0.0052813687496668276, 0.0052784979129645651, 0.0052758668286091888, 0.0052732502824655554, 0.0052705974323459899, 0.0052678968031606389, 0.0052651489006381239, 0.0052623542349081844, 0.0052595430829282062, 0.0052567007100364832, 0.0052538500576104815, 0.0052509731305592795, 0.0052481052726145953, 0.0052452038878574286, 0.0052422614365416472, 0.0052392790950235744, 0.0052362796185190423, 0.0052332443864066148, 0.0052301872667275913, 0.0052271260284582422, 0.0052240737429229567, 0.0052210197572409925, 0.0052179870771490401, 0.0052149531798903869, 0.005211921447753811, 0.0052088929902786409, 0.0052058626788462452, 0.0052028477516693362, 0.0051998447657008251, 0.0051968340656561316, 0.0051938066512462414, 0.0051906401484338649, 0.0051872664851064371, 0.0051838014349368826], 'acc': [0.49097827424063073, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822262938279, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822263669894, 0.59383822272449271, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822262938279, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.5938382226842539, 0.59383822264767316, 0.59383822266596353, 0.5938382226842539, 0.59383822272449271, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 17:26:31,179 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:95]: done!
[2017-11-18 17:26:31,179 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 17:26:31,179 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 17:26:31,179 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f72e6612400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:26:31,212 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 17:29:18,775 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 17:29:18,776 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0095004475337016111, 0.0087692546204707275, 0.0082078670727918027, 0.0077423645118070037, 0.0073718924699327235, 0.0070661048196770937, 0.0067687804404425733, 0.0065353760889052624, 0.0063482748309628837, 0.0061982062303668891, 0.0060702215168913993, 0.0059592923019745362, 0.0058695575215869837, 0.0057956427854281472, 0.0057341954100963302, 0.0056825607062003566, 0.0056389925414603919, 0.0056019972350779693, 0.0055702424440286485, 0.0055417153225833116, 0.0055152684027785677, 0.0054924474048158867, 0.0054725141147098878, 0.0054548900675073743, 0.0054394487678855437, 0.0054259323199251884, 0.0054139161549367557, 0.0054032178749684598, 0.0053935848499584264, 0.0053847649256031013, 0.0053766794024923186, 0.0053691995713157454, 0.0053622272421456315, 0.0053557596614023685, 0.0053497786830990239, 0.0053442448690959425, 0.0053392059205819393, 0.0053345922842582098, 0.0053303105689383951, 0.0053263551480102929, 0.0053226707540164975, 0.0053191863275750878, 0.0053159060824843167, 0.005312793831933442, 0.0053098156594885912, 0.0053069469061512763, 0.0053041942355328076, 0.0053015063156211907, 0.005298913612147846, 0.0052963942933679778, 0.0052939367838079317, 0.0052915208081200371, 0.00528911908781132, 0.0052866613443082458, 0.0052843229044762735, 0.0052820341994432142, 0.0052797826348767313, 0.0052775448418877135, 0.0052753269258415609, 0.0052731164346200244, 0.005270943989517227, 0.0052687459481036026, 0.0052665670544219858, 0.0052644010234140859, 0.005262229346797878, 0.0052600478888131632, 0.0052576333075420893, 0.005254728445175382, 0.0052519507729439823, 0.0052493244592847904, 0.0052466596787687954, 0.0052439477399932148, 0.0052411973715829297, 0.0052383860346588394, 0.00523554069812874, 0.0052326644043643846, 0.0052297811469871613, 0.0052268801918284105, 0.0052239768853454202, 0.0052210473744195261, 0.0052180920882600275, 0.0052150818048670028, 0.0052120634366630498, 0.0052090332206223642, 0.0052059543042148309, 0.0052028659101197748, 0.0051997828038730402, 0.0051967028213732655, 0.0051936516782131285, 0.0051905874891780956, 0.0051875269547541573, 0.0051844709260010658, 0.0051814153031827671, 0.0051783668551592648, 0.0051753306816147556, 0.0051722980953392925, 0.0051692554477166877, 0.0051661566002017181, 0.0051628342884065953, 0.0051593612201815799, 0.0051558275337583248], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099487675840179805, 0.009125158730407347, 0.0084861593912659104, 0.0079763849391962637, 0.0075600490631217623, 0.0072309348084754086, 0.0069237529473111532, 0.0066616408539129117, 0.0064528823888030601, 0.0062861952879132892, 0.0061491119128456321, 0.0060295475162958955, 0.0059303606868227358, 0.0058493826609656782, 0.0057824608978792628, 0.005726575242599871, 0.005679512303802676, 0.0056397459147710868, 0.0056058566221571585, 0.0055763267333995047, 0.0055488706188011432, 0.0055245685284700998, 0.0055035188874956601, 0.0054849657705971638, 0.0054686671657101591, 0.0054544132316949852, 0.005441889664844342, 0.0054307371394291962, 0.0054207902814476412, 0.0054117477895277944, 0.0054034594319759882, 0.0053958304564655927, 0.0053887674439805, 0.0053821913490458961, 0.0053760963379495402, 0.0053704581508072068, 0.0053652851865549711, 0.005360579694279121, 0.0053562324212794764, 0.0053522079872435893, 0.0053484572899120085, 0.0053449572251230105, 0.0053416591293572995, 0.0053385306975416861, 0.0053355562706650901, 0.005332697600142728, 0.0053299292974033187, 0.0053272691390250666, 0.0053246757919815872, 0.0053221761787199812, 0.0053197451633618074, 0.0053173566467550632, 0.0053149936912206142, 0.0053125773790304214, 0.005310213838261418, 0.0053079416730745345, 0.0053057082105307718, 0.0053035026495974243, 0.005301306470535852, 0.0052991377473141799, 0.0052969662238374704, 0.005294817034097973, 0.0052926674191646232, 0.005290524811556281, 0.0052883796836498166, 0.0052862306443485791, 0.0052840122588964688, 0.0052813687496668276, 0.0052784979129645651, 0.0052758668286091888, 0.0052732502824655554, 0.0052705974323459899, 0.0052678968031606389, 0.0052651489006381239, 0.0052623542349081844, 0.0052595430829282062, 0.0052567007100364832, 0.0052538500576104815, 0.0052509731305592795, 0.0052481052726145953, 0.0052452038878574286, 0.0052422614365416472, 0.0052392790950235744, 0.0052362796185190423, 0.0052332443864066148, 0.0052301872667275913, 0.0052271260284582422, 0.0052240737429229567, 0.0052210197572409925, 0.0052179870771490401, 0.0052149531798903869, 0.005211921447753811, 0.0052088929902786409, 0.0052058626788462452, 0.0052028477516693362, 0.0051998447657008251, 0.0051968340656561316, 0.0051938066512462414, 0.0051906401484338649, 0.0051872664851064371, 0.0051838014349368826], 'acc': [0.49097827424063073, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822262938279, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822263669894, 0.59383822272449271, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822262938279, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.5938382226842539, 0.59383822264767316, 0.59383822266596353, 0.5938382226842539, 0.59383822272449271, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 17:29:18,776 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 17:29:18,914 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 17:29:18,915 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 17:29:19,834 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:141]: done!
[2017-11-18 17:29:19,835 AE_UNIGRAMA_5L_9FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_5L_9FULLDS_UNDER_03 finished!
