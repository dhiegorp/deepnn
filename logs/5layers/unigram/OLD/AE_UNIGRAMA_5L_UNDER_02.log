[2017-10-20 01:37:56,595 AE_UNIGRAMA_5L_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_UNDER_02
[2017-10-20 01:37:56,596 AE_UNIGRAMA_5L_UNDER_02.py:149]: >> Printing header log
[2017-10-20 01:37:56,596 AE_UNIGRAMA_5L_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_UNDER_02
	layers = 96,76,69,63,56,49,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f5d2a7b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f5d2a898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:37:56,596 AE_UNIGRAMA_5L_UNDER_02.py:151]: >> Loading dataset... 
[2017-10-20 01:37:57,188 AE_UNIGRAMA_5L_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:37:57,188 AE_UNIGRAMA_5L_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:37:57,188 AE_UNIGRAMA_5L_UNDER_02.py:60]: =======================================
[2017-10-20 01:37:57,188 AE_UNIGRAMA_5L_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f5d2a7b8>, 'discard_decoder_function': True}
[2017-10-20 01:37:57,327 AE_UNIGRAMA_5L_UNDER_02.py:76]: training and evaluate autoencoder
[2017-10-20 01:38:32,779 AE_UNIGRAMA_5L_UNDER_02.py:88]: trained and evaluated!
[2017-10-20 01:38:32,779 AE_UNIGRAMA_5L_UNDER_02.py:91]: Training history: 
{'val_loss': [0.010263544282283925, 0.010167838503575458, 0.010079261150945075, 0.0099973723423913072, 0.0099211440951352224, 0.0098501495414562382, 0.0097830508589799962, 0.0097200080032242269, 0.0096611150620041289, 0.0096060679013733521, 0.0095544569609776753, 0.0095055622107532833, 0.0094596084629680593, 0.0094164945808374312, 0.0093759409598590717, 0.0093377701501919427, 0.0093018483599045469, 0.0092679650131543764, 0.0092360134440782338, 0.0092058406734222813, 0.0091773630275657631, 0.0091504835381716158, 0.0091250600660268254, 0.0091010272108212279, 0.0090782718774499067, 0.0090567686328435915, 0.0090363743718450389, 0.0090170669677532289, 0.0089987258679583172, 0.0089812874967114629, 0.0089646970167700686, 0.0089489366568375698, 0.0089339242735704521, 0.0089196224097979563, 0.0089059924277508119, 0.0088929830077467791, 0.0088805864914753181, 0.0088687528402554942, 0.0088574433955450477, 0.0088466182835815563, 0.0088362255164847938, 0.0088259225648907487, 0.0088159079424566054, 0.0088062976213469819, 0.0087970829911557715, 0.0087882398167230379, 0.0087797423845440929, 0.0087715806162545675, 0.0087637448212526548, 0.008756193678590667, 0.0087489425187383448, 0.008741944162763627, 0.0087352140865472171, 0.008728722816672467, 0.0087224767581459313, 0.0087164725872885332, 0.0087106794458173473, 0.0087050923620624176, 0.0086996977677963484, 0.0086944987997412682, 0.0086894843685804239, 0.00868464957881151, 0.0086799743948815927, 0.0086754486899559818, 0.0086710781766080949, 0.0086668484816570038, 0.0086627680285518722, 0.0086588182496980214, 0.0086550031681320045, 0.0086513089507707433, 0.0086477378618706122, 0.0086442771087293282, 0.0086409228241078034, 0.00863767722725425, 0.0086345286541324121, 0.0086314770181881457, 0.0086285142162226165, 0.0086256427686924615, 0.008622865166625901, 0.0086201728948263872, 0.0086175633462831427, 0.0086150380408869139, 0.0086125944841473068, 0.0086102179220451745, 0.0086079155195324386, 0.008605684989848655, 0.0086035185569696485, 0.0086014148100628952, 0.0085993730757371635, 0.0085973946124896904, 0.0085954655578089918, 0.0085935927408169188, 0.0085917756110291277, 0.0085900074310711547, 0.0085882930029668337, 0.0085866272858028964, 0.0085850076033252547, 0.0085834303219910011, 0.0085818928607556012, 0.0085803979806962066, 0.0085789430661466267, 0.0085775218661666795], 'loss': [0.010310862608340963, 0.010212440849078639, 0.010120904958075955, 0.010036392270781434, 0.0099580374597294172, 0.0098850767700014198, 0.009816786461494309, 0.0097522356804430523, 0.0096919142372663501, 0.0096355736027823758, 0.0095828827939922999, 0.009533250228156688, 0.009486387866722637, 0.0094424042714497548, 0.0094011304911498506, 0.00936231883465969, 0.0093257768273115448, 0.0092913799443509436, 0.0092589540198701765, 0.0092283801491055747, 0.0091995052442632348, 0.0091722530456512848, 0.0091465291439497779, 0.0091222053286107163, 0.0090992062025747559, 0.0090774573550571596, 0.009056886921956742, 0.0090373933433195008, 0.0090189219338529733, 0.0090013695245387739, 0.0089846897982495955, 0.0089688162092112587, 0.0089537392198105279, 0.0089393747311037382, 0.0089257081556142516, 0.0089126670505272221, 0.0089002274727814027, 0.0088883845167624931, 0.0088770664923840965, 0.0088662522871873831, 0.0088558948473442759, 0.0088458497474484081, 0.0088358909611778533, 0.0088263486970511403, 0.0088171967847321987, 0.0088084129949764899, 0.0087999940547032005, 0.0087918916833944743, 0.0087841204490647692, 0.0087766554240954753, 0.0087694666693565234, 0.0087625542999037447, 0.0087558886153049891, 0.008749480176082805, 0.0087433027907216857, 0.0087373684799801222, 0.0087316638155260484, 0.0087261453331588384, 0.0087208294074412277, 0.0087157070834805572, 0.0087107669106457376, 0.0087059985087256011, 0.0087014048268128988, 0.0086969597123164894, 0.0086926549968447658, 0.0086885066634271868, 0.0086844848324650632, 0.0086806122890199042, 0.0086768618604533502, 0.0086732366195002367, 0.008669725993617261, 0.0086663317607318466, 0.0086630387746882941, 0.0086598554231139442, 0.0086567682450489538, 0.008653776399612647, 0.0086508799692330812, 0.0086480628420869555, 0.0086453375438046223, 0.0086426976221008547, 0.0086401381822372777, 0.008637661800090712, 0.008635267028018383, 0.0086329451916119983, 0.0086306936892359704, 0.0086285039289100592, 0.0086263853686815335, 0.0086243295613916728, 0.0086223338756392029, 0.0086203935048379775, 0.0086185118314004699, 0.0086166849960907874, 0.0086149047074476556, 0.0086131833216659699, 0.0086115063960906114, 0.0086098794877465037, 0.0086082921923809654, 0.0086067525930954552, 0.0086052542490530903, 0.008603797252985438, 0.0086023704937047297, 0.008600987418432798]}
[2017-10-20 01:38:32,779 AE_UNIGRAMA_5L_UNDER_02.py:95]: done!
[2017-10-20 01:38:32,779 AE_UNIGRAMA_5L_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-10-20 01:38:32,779 AE_UNIGRAMA_5L_UNDER_02.py:100]: =======================================
[2017-10-20 01:38:32,780 AE_UNIGRAMA_5L_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f5d2a898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:38:32,815 AE_UNIGRAMA_5L_UNDER_02.py:113]: training ... 
[2017-10-20 01:39:33,054 AE_UNIGRAMA_5L_UNDER_02.py:125]: trained!
[2017-10-20 01:39:33,055 AE_UNIGRAMA_5L_UNDER_02.py:128]: Training history: 
{'val_loss': [0.010263544282283925, 0.010167838503575458, 0.010079261150945075, 0.0099973723423913072, 0.0099211440951352224, 0.0098501495414562382, 0.0097830508589799962, 0.0097200080032242269, 0.0096611150620041289, 0.0096060679013733521, 0.0095544569609776753, 0.0095055622107532833, 0.0094596084629680593, 0.0094164945808374312, 0.0093759409598590717, 0.0093377701501919427, 0.0093018483599045469, 0.0092679650131543764, 0.0092360134440782338, 0.0092058406734222813, 0.0091773630275657631, 0.0091504835381716158, 0.0091250600660268254, 0.0091010272108212279, 0.0090782718774499067, 0.0090567686328435915, 0.0090363743718450389, 0.0090170669677532289, 0.0089987258679583172, 0.0089812874967114629, 0.0089646970167700686, 0.0089489366568375698, 0.0089339242735704521, 0.0089196224097979563, 0.0089059924277508119, 0.0088929830077467791, 0.0088805864914753181, 0.0088687528402554942, 0.0088574433955450477, 0.0088466182835815563, 0.0088362255164847938, 0.0088259225648907487, 0.0088159079424566054, 0.0088062976213469819, 0.0087970829911557715, 0.0087882398167230379, 0.0087797423845440929, 0.0087715806162545675, 0.0087637448212526548, 0.008756193678590667, 0.0087489425187383448, 0.008741944162763627, 0.0087352140865472171, 0.008728722816672467, 0.0087224767581459313, 0.0087164725872885332, 0.0087106794458173473, 0.0087050923620624176, 0.0086996977677963484, 0.0086944987997412682, 0.0086894843685804239, 0.00868464957881151, 0.0086799743948815927, 0.0086754486899559818, 0.0086710781766080949, 0.0086668484816570038, 0.0086627680285518722, 0.0086588182496980214, 0.0086550031681320045, 0.0086513089507707433, 0.0086477378618706122, 0.0086442771087293282, 0.0086409228241078034, 0.00863767722725425, 0.0086345286541324121, 0.0086314770181881457, 0.0086285142162226165, 0.0086256427686924615, 0.008622865166625901, 0.0086201728948263872, 0.0086175633462831427, 0.0086150380408869139, 0.0086125944841473068, 0.0086102179220451745, 0.0086079155195324386, 0.008605684989848655, 0.0086035185569696485, 0.0086014148100628952, 0.0085993730757371635, 0.0085973946124896904, 0.0085954655578089918, 0.0085935927408169188, 0.0085917756110291277, 0.0085900074310711547, 0.0085882930029668337, 0.0085866272858028964, 0.0085850076033252547, 0.0085834303219910011, 0.0085818928607556012, 0.0085803979806962066, 0.0085789430661466267, 0.0085775218661666795], 'loss': [0.010310862608340963, 0.010212440849078639, 0.010120904958075955, 0.010036392270781434, 0.0099580374597294172, 0.0098850767700014198, 0.009816786461494309, 0.0097522356804430523, 0.0096919142372663501, 0.0096355736027823758, 0.0095828827939922999, 0.009533250228156688, 0.009486387866722637, 0.0094424042714497548, 0.0094011304911498506, 0.00936231883465969, 0.0093257768273115448, 0.0092913799443509436, 0.0092589540198701765, 0.0092283801491055747, 0.0091995052442632348, 0.0091722530456512848, 0.0091465291439497779, 0.0091222053286107163, 0.0090992062025747559, 0.0090774573550571596, 0.009056886921956742, 0.0090373933433195008, 0.0090189219338529733, 0.0090013695245387739, 0.0089846897982495955, 0.0089688162092112587, 0.0089537392198105279, 0.0089393747311037382, 0.0089257081556142516, 0.0089126670505272221, 0.0089002274727814027, 0.0088883845167624931, 0.0088770664923840965, 0.0088662522871873831, 0.0088558948473442759, 0.0088458497474484081, 0.0088358909611778533, 0.0088263486970511403, 0.0088171967847321987, 0.0088084129949764899, 0.0087999940547032005, 0.0087918916833944743, 0.0087841204490647692, 0.0087766554240954753, 0.0087694666693565234, 0.0087625542999037447, 0.0087558886153049891, 0.008749480176082805, 0.0087433027907216857, 0.0087373684799801222, 0.0087316638155260484, 0.0087261453331588384, 0.0087208294074412277, 0.0087157070834805572, 0.0087107669106457376, 0.0087059985087256011, 0.0087014048268128988, 0.0086969597123164894, 0.0086926549968447658, 0.0086885066634271868, 0.0086844848324650632, 0.0086806122890199042, 0.0086768618604533502, 0.0086732366195002367, 0.008669725993617261, 0.0086663317607318466, 0.0086630387746882941, 0.0086598554231139442, 0.0086567682450489538, 0.008653776399612647, 0.0086508799692330812, 0.0086480628420869555, 0.0086453375438046223, 0.0086426976221008547, 0.0086401381822372777, 0.008637661800090712, 0.008635267028018383, 0.0086329451916119983, 0.0086306936892359704, 0.0086285039289100592, 0.0086263853686815335, 0.0086243295613916728, 0.0086223338756392029, 0.0086203935048379775, 0.0086185118314004699, 0.0086166849960907874, 0.0086149047074476556, 0.0086131833216659699, 0.0086115063960906114, 0.0086098794877465037, 0.0086082921923809654, 0.0086067525930954552, 0.0086052542490530903, 0.008603797252985438, 0.0086023704937047297, 0.008600987418432798]}
[2017-10-20 01:39:33,055 AE_UNIGRAMA_5L_UNDER_02.py:132]: evaluating model ... 
[2017-10-20 01:39:33,116 AE_UNIGRAMA_5L_UNDER_02.py:136]: evaluated! 
[2017-10-20 01:39:33,116 AE_UNIGRAMA_5L_UNDER_02.py:138]: generating reports ... 
[2017-10-20 01:39:33,754 AE_UNIGRAMA_5L_UNDER_02.py:141]: done!
[2017-10-20 01:39:33,754 AE_UNIGRAMA_5L_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_5L_UNDER_02 finished!
