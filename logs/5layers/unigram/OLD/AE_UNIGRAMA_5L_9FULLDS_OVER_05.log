[2017-11-18 16:57:50,856 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_9FULLDS_OVER_05
[2017-11-18 16:57:50,857 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 16:57:50,857 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_9FULLDS_OVER_05
	layers = 96,172,156,139,123,107,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe54820beb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe548210400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:57:50,857 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 16:57:53,021 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:57:53,021 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:57:53,021 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 16:57:53,022 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe54820beb8>, 'discard_decoder_function': True}
[2017-11-18 16:57:53,149 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 17:01:01,910 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 17:01:01,910 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0095091867840786225, 0.0087463663947775008, 0.0081475127492824252, 0.0076767172373814847, 0.007300371731138928, 0.0069961278953988935, 0.0067494247883602082, 0.0065484537061225815, 0.0063841108452475318, 0.0062489141532121031, 0.0061370668823610705, 0.0060439827413500471, 0.0059661000144888001, 0.0059004733960176057, 0.005845254133956884, 0.0057985183823263658, 0.0057587685948768301, 0.0057249021582416329, 0.0056959307470688513, 0.0056710353290415046, 0.005649626729852468, 0.0056311610964794659, 0.0056151559434178084, 0.0056012891704789562, 0.005581633775083924, 0.0055573266893741632, 0.0055374950013927452, 0.0055212790666894903, 0.005507796914229434, 0.0054964733289336347, 0.0054868661820099921, 0.0054786440213674664, 0.0054713704779700339, 0.0054635719965372576, 0.0054553421103840137, 0.0054484667080717739, 0.0054427520497758539, 0.0054379749197056961, 0.0054339059450222438, 0.0054303609647297635, 0.0054270210564656756, 0.0054221555158682098, 0.005413828190646789, 0.0054057576298783506, 0.0053994330365856984, 0.005394252255789659, 0.0053900044529675856, 0.0053864552713697861, 0.0053834774484703895, 0.005380896298907552, 0.005378656295353724, 0.0053766737940205414, 0.0053749235309434535, 0.0053733482142963073, 0.0053719278357892914, 0.0053706207723027864, 0.0053694247421649383, 0.0053683152445070017, 0.0053672859042531067, 0.0053663416572246473, 0.0053654532443707381, 0.0053646090882496604, 0.0053637766907178482, 0.0053629851425138469, 0.0053622297359406622, 0.00536142573655966, 0.0053606669413208555, 0.0053599723842363287, 0.0053592934853334672, 0.0053586316938782083, 0.0053579928630669302, 0.0053573668328069698, 0.005356739537252366, 0.0053561224336217362, 0.005355498258904778, 0.0053548733865515698, 0.0053542580962788969, 0.0053536346607842575, 0.0053530238841402586, 0.0053524007441120708, 0.0053517885211114497, 0.0053511759541272977, 0.00535056096000562, 0.0053499406734149454, 0.0053493149157747685, 0.0053486837931894637, 0.0053480502004259068, 0.0053474177189345188, 0.0053467921918146488, 0.0053461696534153674, 0.005345537160628998, 0.005344885598234244, 0.0053442493721997473, 0.0053436060699448397, 0.0053429785880230391, 0.0053423490163585045, 0.0053417130205876103, 0.0053410772313779711, 0.0053403944547881273, 0.005339665123450103, 0.0053389029702646069], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099605333378507167, 0.0091169018713807472, 0.0084413876686150555, 0.0079117228342872933, 0.0074921150244722139, 0.0071548186232863655, 0.0068818888268844473, 0.006660175636926044, 0.0064792310463167874, 0.0063310133902454565, 0.0062087709321927932, 0.006107435972678218, 0.0060230338169444484, 0.0059519909680981614, 0.0058924093563806953, 0.0058421348877195365, 0.0057994838767082904, 0.0057632255073459815, 0.0057322836878964528, 0.0057058057420155094, 0.005683051292376751, 0.0056634898493767181, 0.0056466048491250606, 0.0056319849405470175, 0.0056174962437396487, 0.0055934923834279338, 0.0055717203722782252, 0.0055540128559243597, 0.0055394378955778579, 0.0055272851660696769, 0.0055170565973558065, 0.0055083651894689105, 0.0055008697203127637, 0.0054938202799079874, 0.0054856302103248782, 0.005478279932837728, 0.0054721742526850879, 0.0054670898269505728, 0.0054628169284092077, 0.0054591598020752429, 0.0054558837866680171, 0.0054520084716428111, 0.0054459655152710833, 0.0054373344917701284, 0.0054303718959093934, 0.0054248089853976425, 0.0054202629996885935, 0.0054164960543961489, 0.0054133484178105311, 0.0054106727838392774, 0.0054083535388501653, 0.0054063075975981012, 0.0054045081655542306, 0.005402910093521617, 0.0054014670868119908, 0.005400152115922454, 0.0053989458752573601, 0.0053978322065357963, 0.0053967791616896538, 0.0053958293707037398, 0.0053949425169244466, 0.0053941047557450059, 0.0053932910551419576, 0.0053924999234787972, 0.005391743828955093, 0.0053909963643404913, 0.0053902181580788933, 0.0053895164138350665, 0.0053888354242982908, 0.0053881923950444052, 0.005387557847661973, 0.0053869339650490207, 0.0053863152104831257, 0.0053857116317197022, 0.005385099711634856, 0.0053844880649338246, 0.0053838878493114523, 0.0053832771132420187, 0.0053826632584365501, 0.0053820595804478901, 0.0053814564109314058, 0.0053808527504900661, 0.0053802513842893564, 0.0053796493940442211, 0.0053790371552497477, 0.0053784208471917795, 0.0053777902278369216, 0.0053771654952935229, 0.0053765399446563476, 0.0053759245090488385, 0.0053753081114252341, 0.0053746571198034481, 0.0053740110688667818, 0.0053733745530408642, 0.0053727410175729321, 0.0053721113454304045, 0.0053714849613241125, 0.0053708498282498658, 0.0053702092006925103, 0.0053695158239481927, 0.0053687930698467093], 'acc': [0.48655946976907039, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822267327968, 0.59383822262938279, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268059583, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 17:01:01,910 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:95]: done!
[2017-11-18 17:01:01,911 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 17:01:01,911 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 17:01:01,911 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe548210400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:01:01,942 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 17:06:03,379 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:125]: trained!
[2017-11-18 17:06:03,380 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0095091867840786225, 0.0087463663947775008, 0.0081475127492824252, 0.0076767172373814847, 0.007300371731138928, 0.0069961278953988935, 0.0067494247883602082, 0.0065484537061225815, 0.0063841108452475318, 0.0062489141532121031, 0.0061370668823610705, 0.0060439827413500471, 0.0059661000144888001, 0.0059004733960176057, 0.005845254133956884, 0.0057985183823263658, 0.0057587685948768301, 0.0057249021582416329, 0.0056959307470688513, 0.0056710353290415046, 0.005649626729852468, 0.0056311610964794659, 0.0056151559434178084, 0.0056012891704789562, 0.005581633775083924, 0.0055573266893741632, 0.0055374950013927452, 0.0055212790666894903, 0.005507796914229434, 0.0054964733289336347, 0.0054868661820099921, 0.0054786440213674664, 0.0054713704779700339, 0.0054635719965372576, 0.0054553421103840137, 0.0054484667080717739, 0.0054427520497758539, 0.0054379749197056961, 0.0054339059450222438, 0.0054303609647297635, 0.0054270210564656756, 0.0054221555158682098, 0.005413828190646789, 0.0054057576298783506, 0.0053994330365856984, 0.005394252255789659, 0.0053900044529675856, 0.0053864552713697861, 0.0053834774484703895, 0.005380896298907552, 0.005378656295353724, 0.0053766737940205414, 0.0053749235309434535, 0.0053733482142963073, 0.0053719278357892914, 0.0053706207723027864, 0.0053694247421649383, 0.0053683152445070017, 0.0053672859042531067, 0.0053663416572246473, 0.0053654532443707381, 0.0053646090882496604, 0.0053637766907178482, 0.0053629851425138469, 0.0053622297359406622, 0.00536142573655966, 0.0053606669413208555, 0.0053599723842363287, 0.0053592934853334672, 0.0053586316938782083, 0.0053579928630669302, 0.0053573668328069698, 0.005356739537252366, 0.0053561224336217362, 0.005355498258904778, 0.0053548733865515698, 0.0053542580962788969, 0.0053536346607842575, 0.0053530238841402586, 0.0053524007441120708, 0.0053517885211114497, 0.0053511759541272977, 0.00535056096000562, 0.0053499406734149454, 0.0053493149157747685, 0.0053486837931894637, 0.0053480502004259068, 0.0053474177189345188, 0.0053467921918146488, 0.0053461696534153674, 0.005345537160628998, 0.005344885598234244, 0.0053442493721997473, 0.0053436060699448397, 0.0053429785880230391, 0.0053423490163585045, 0.0053417130205876103, 0.0053410772313779711, 0.0053403944547881273, 0.005339665123450103, 0.0053389029702646069], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099605333378507167, 0.0091169018713807472, 0.0084413876686150555, 0.0079117228342872933, 0.0074921150244722139, 0.0071548186232863655, 0.0068818888268844473, 0.006660175636926044, 0.0064792310463167874, 0.0063310133902454565, 0.0062087709321927932, 0.006107435972678218, 0.0060230338169444484, 0.0059519909680981614, 0.0058924093563806953, 0.0058421348877195365, 0.0057994838767082904, 0.0057632255073459815, 0.0057322836878964528, 0.0057058057420155094, 0.005683051292376751, 0.0056634898493767181, 0.0056466048491250606, 0.0056319849405470175, 0.0056174962437396487, 0.0055934923834279338, 0.0055717203722782252, 0.0055540128559243597, 0.0055394378955778579, 0.0055272851660696769, 0.0055170565973558065, 0.0055083651894689105, 0.0055008697203127637, 0.0054938202799079874, 0.0054856302103248782, 0.005478279932837728, 0.0054721742526850879, 0.0054670898269505728, 0.0054628169284092077, 0.0054591598020752429, 0.0054558837866680171, 0.0054520084716428111, 0.0054459655152710833, 0.0054373344917701284, 0.0054303718959093934, 0.0054248089853976425, 0.0054202629996885935, 0.0054164960543961489, 0.0054133484178105311, 0.0054106727838392774, 0.0054083535388501653, 0.0054063075975981012, 0.0054045081655542306, 0.005402910093521617, 0.0054014670868119908, 0.005400152115922454, 0.0053989458752573601, 0.0053978322065357963, 0.0053967791616896538, 0.0053958293707037398, 0.0053949425169244466, 0.0053941047557450059, 0.0053932910551419576, 0.0053924999234787972, 0.005391743828955093, 0.0053909963643404913, 0.0053902181580788933, 0.0053895164138350665, 0.0053888354242982908, 0.0053881923950444052, 0.005387557847661973, 0.0053869339650490207, 0.0053863152104831257, 0.0053857116317197022, 0.005385099711634856, 0.0053844880649338246, 0.0053838878493114523, 0.0053832771132420187, 0.0053826632584365501, 0.0053820595804478901, 0.0053814564109314058, 0.0053808527504900661, 0.0053802513842893564, 0.0053796493940442211, 0.0053790371552497477, 0.0053784208471917795, 0.0053777902278369216, 0.0053771654952935229, 0.0053765399446563476, 0.0053759245090488385, 0.0053753081114252341, 0.0053746571198034481, 0.0053740110688667818, 0.0053733745530408642, 0.0053727410175729321, 0.0053721113454304045, 0.0053714849613241125, 0.0053708498282498658, 0.0053702092006925103, 0.0053695158239481927, 0.0053687930698467093], 'acc': [0.48655946976907039, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822267327968, 0.59383822262938279, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268059583, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 17:06:03,380 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 17:06:03,556 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 17:06:03,556 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 17:06:04,421 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:141]: done!
[2017-11-18 17:06:04,421 AE_UNIGRAMA_5L_9FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_5L_9FULLDS_OVER_05 finished!
