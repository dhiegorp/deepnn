[2018-07-21 00:52:16,458 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_OVER_05
[2018-07-21 00:52:16,459 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:146]: >> Printing header log
[2018-07-21 00:52:16,459 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_OVER_05
	layers = 96,192,174,155,137,119
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f21abbbf668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f21abbbfe48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,459 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,410 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,411 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,411 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:57]: =======================================
[2018-07-21 00:52:18,411 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f21abbbf668>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,551 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-07-21 00:56:43,069 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:85]: trained and evaluated!
[2018-07-21 00:56:43,070 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:88]: Training history: 
{'val_loss': [0.009334477360843954, 0.008561651411342056, 0.007948315376022235, 0.007471195784408034, 0.007103718283973998, 0.0068150796412049805, 0.006587772477159426, 0.006407586536111802, 0.0062643440164083485, 0.00614989515481594, 0.006057257663584542, 0.005981693481557545, 0.0059193955787082055, 0.005867751790309864, 0.005824595567154554, 0.005788239906105606, 0.005757582145707134, 0.0057315467085856334, 0.005709400922912271, 0.005690369067319321, 0.0056740036658677094, 0.0056598220448886224, 0.005647436133200814, 0.005636603498656148, 0.005626965321936549, 0.005618437751836716, 0.005610763672475718, 0.005603822325611297, 0.005597472541771476, 0.005591629134718354, 0.005586065684223753, 0.005580834204020257, 0.0055759013761368876, 0.005571192844426181, 0.005566729707485944, 0.005562528389845234, 0.005558540586033718, 0.005554705868242052, 0.00555099714999195, 0.005547399186737663, 0.005543908213057481, 0.005540507139045251, 0.0055371595335079, 0.005533865672060094, 0.005530613497223395, 0.005527404109916236, 0.005524245196801447, 0.005521123937903762, 0.005517998506023779, 0.005514877144187738, 0.005511730569556838, 0.005508532724865205, 0.005505352979953764, 0.005502147471360405, 0.00549893845901241, 0.005495738672953029, 0.005492538134579419, 0.005489321816260819, 0.005486083872501972, 0.005482837550604948, 0.005479595269744299, 0.005476345087958446, 0.005473071743074622, 0.005469791895190705, 0.005466490042885681, 0.005463164016924106, 0.005459796225628824, 0.005456386195551857, 0.0054529374748576555, 0.005449465667905586, 0.005445958530935584, 0.0054424201470835, 0.0054388476137101965, 0.005435248781170166, 0.005431618384632889, 0.0054279376879486415, 0.005424206832047991, 0.005420454482824152, 0.005416619517740844, 0.005412656717168052, 0.005408357508574331, 0.005403870722081804, 0.005399267924662018, 0.005394642253535383, 0.005390005970773524, 0.0053846569524243475, 0.0053793876478944805, 0.005374237506361853, 0.005368903504006184, 0.005363120791135724, 0.005357002979178681, 0.005350396267023076, 0.005343324867686758, 0.005334945022597778, 0.005325931881751916, 0.005317410831851354, 0.005309266441178915, 0.005301335860828937, 0.005293326348323719, 0.00528536749355432, 0.005277359450509096], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009776822056169084, 0.00894394306605676, 0.008254252072495485, 0.007714083888369648, 0.0072975958749739705, 0.006973768097677852, 0.006719556238892763, 0.006518696526533473, 0.006359612457355894, 0.006233012576007808, 0.006131441445742957, 0.006048973792290759, 0.005981443268151496, 0.005925684560415415, 0.005879319141987801, 0.005840469130129811, 0.005807753280982626, 0.005780079302347019, 0.005756557931602495, 0.005736510608230041, 0.005719258274098376, 0.005704403071735949, 0.005691483624087908, 0.005680191902014172, 0.005670244253488703, 0.005661405883768325, 0.00565353509595857, 0.005646442030458761, 0.005640002784728583, 0.005634088752860103, 0.005628553485321559, 0.005623303646889584, 0.005618355068276067, 0.005613661478570217, 0.005609183817780887, 0.005604950453294092, 0.005600938035800049, 0.0055971231021886, 0.005593441345018924, 0.00558986838260439, 0.005586403205431106, 0.0055830371384927874, 0.005579736773978644, 0.005576480208718112, 0.005573273182685308, 0.005570109306255177, 0.005566988846352748, 0.005563914146374011, 0.005560855710074421, 0.0055578030756504035, 0.005554715882722945, 0.005551583874111942, 0.00554844009293543, 0.005545294189562044, 0.005542117433227636, 0.005538955773532709, 0.005535794225580487, 0.005532618393366821, 0.005529420946913218, 0.005526221956466936, 0.005523022054760324, 0.005519820753612082, 0.0055166011033400235, 0.005513367409553464, 0.005510119975758167, 0.00550685206246867, 0.005503542283045776, 0.005500196717207152, 0.005496810850776148, 0.005493390864410385, 0.005489942424751044, 0.005486464833163299, 0.0054829584820898156, 0.005479429147571025, 0.005475864077963843, 0.005472257141137275, 0.0054685907100940154, 0.0054648951138618375, 0.005461156977496276, 0.0054573018533775886, 0.005453227577351259, 0.005448851495767676, 0.005444356857689137, 0.0054397697789290225, 0.00543522593796544, 0.0054303483698117895, 0.005425006546328404, 0.005419859179557724, 0.005414678309980665, 0.005409156948207302, 0.00540320935923292, 0.0053968821714878105, 0.005389979827807965, 0.005382395995435824, 0.005373380321879464, 0.005364617522235727, 0.005356311461667283, 0.005348331273176856, 0.005340438981783878, 0.0053325231339427185, 0.0053246326632985196], 'acc': [0.4320608813133184, 0.5938382226513312, 0.5938382226476732, 0.5938382226842539, 0.5938382226513312, 0.5938382227025443, 0.5938382226366989, 0.5938382226366989, 0.5938382227244927, 0.593838222687912, 0.5938382227025443, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226366989, 0.5938382226366989, 0.5938382226805958, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382227244927, 0.5938382226659635, 0.593838222687912, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.5938382226366989, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.593838222687912, 0.5938382226842539, 0.5938382227025443, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.593838222687912, 0.5938382226513312, 0.5938382226659635, 0.5938382226659635, 0.5938382226732797, 0.5938382227025443, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.593838222687912, 0.5938382226220666, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226366989, 0.5938382226659635, 0.5938382226001182, 0.5938382226513312, 0.5938382226732797, 0.5938382226659635, 0.5938382226366989, 0.5938382226476732, 0.5938382227025443, 0.5938382227025443, 0.5938382226659635, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226842539, 0.5938382226293828, 0.5938382226513312, 0.5938382226732797, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382226513312, 0.5938382226366989, 0.593838222687912, 0.5938382226513312, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.5938382226513312, 0.5938382226732797, 0.5938382227025443]}
[2018-07-21 00:56:43,071 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:92]: done!
[2018-07-21 00:56:43,071 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:152]: >> Executing classifier part ... 
[2018-07-21 00:56:43,071 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:97]: =======================================
[2018-07-21 00:56:43,071 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f21abbbfe48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 00:56:43,126 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:110]: training ... 
[2018-07-21 01:05:02,678 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:122]: trained!
[2018-07-21 01:05:02,679 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:125]: Training history: 
{'val_loss': [0.009334477360843954, 0.008561651411342056, 0.007948315376022235, 0.007471195784408034, 0.007103718283973998, 0.0068150796412049805, 0.006587772477159426, 0.006407586536111802, 0.0062643440164083485, 0.00614989515481594, 0.006057257663584542, 0.005981693481557545, 0.0059193955787082055, 0.005867751790309864, 0.005824595567154554, 0.005788239906105606, 0.005757582145707134, 0.0057315467085856334, 0.005709400922912271, 0.005690369067319321, 0.0056740036658677094, 0.0056598220448886224, 0.005647436133200814, 0.005636603498656148, 0.005626965321936549, 0.005618437751836716, 0.005610763672475718, 0.005603822325611297, 0.005597472541771476, 0.005591629134718354, 0.005586065684223753, 0.005580834204020257, 0.0055759013761368876, 0.005571192844426181, 0.005566729707485944, 0.005562528389845234, 0.005558540586033718, 0.005554705868242052, 0.00555099714999195, 0.005547399186737663, 0.005543908213057481, 0.005540507139045251, 0.0055371595335079, 0.005533865672060094, 0.005530613497223395, 0.005527404109916236, 0.005524245196801447, 0.005521123937903762, 0.005517998506023779, 0.005514877144187738, 0.005511730569556838, 0.005508532724865205, 0.005505352979953764, 0.005502147471360405, 0.00549893845901241, 0.005495738672953029, 0.005492538134579419, 0.005489321816260819, 0.005486083872501972, 0.005482837550604948, 0.005479595269744299, 0.005476345087958446, 0.005473071743074622, 0.005469791895190705, 0.005466490042885681, 0.005463164016924106, 0.005459796225628824, 0.005456386195551857, 0.0054529374748576555, 0.005449465667905586, 0.005445958530935584, 0.0054424201470835, 0.0054388476137101965, 0.005435248781170166, 0.005431618384632889, 0.0054279376879486415, 0.005424206832047991, 0.005420454482824152, 0.005416619517740844, 0.005412656717168052, 0.005408357508574331, 0.005403870722081804, 0.005399267924662018, 0.005394642253535383, 0.005390005970773524, 0.0053846569524243475, 0.0053793876478944805, 0.005374237506361853, 0.005368903504006184, 0.005363120791135724, 0.005357002979178681, 0.005350396267023076, 0.005343324867686758, 0.005334945022597778, 0.005325931881751916, 0.005317410831851354, 0.005309266441178915, 0.005301335860828937, 0.005293326348323719, 0.00528536749355432, 0.005277359450509096], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009776822056169084, 0.00894394306605676, 0.008254252072495485, 0.007714083888369648, 0.0072975958749739705, 0.006973768097677852, 0.006719556238892763, 0.006518696526533473, 0.006359612457355894, 0.006233012576007808, 0.006131441445742957, 0.006048973792290759, 0.005981443268151496, 0.005925684560415415, 0.005879319141987801, 0.005840469130129811, 0.005807753280982626, 0.005780079302347019, 0.005756557931602495, 0.005736510608230041, 0.005719258274098376, 0.005704403071735949, 0.005691483624087908, 0.005680191902014172, 0.005670244253488703, 0.005661405883768325, 0.00565353509595857, 0.005646442030458761, 0.005640002784728583, 0.005634088752860103, 0.005628553485321559, 0.005623303646889584, 0.005618355068276067, 0.005613661478570217, 0.005609183817780887, 0.005604950453294092, 0.005600938035800049, 0.0055971231021886, 0.005593441345018924, 0.00558986838260439, 0.005586403205431106, 0.0055830371384927874, 0.005579736773978644, 0.005576480208718112, 0.005573273182685308, 0.005570109306255177, 0.005566988846352748, 0.005563914146374011, 0.005560855710074421, 0.0055578030756504035, 0.005554715882722945, 0.005551583874111942, 0.00554844009293543, 0.005545294189562044, 0.005542117433227636, 0.005538955773532709, 0.005535794225580487, 0.005532618393366821, 0.005529420946913218, 0.005526221956466936, 0.005523022054760324, 0.005519820753612082, 0.0055166011033400235, 0.005513367409553464, 0.005510119975758167, 0.00550685206246867, 0.005503542283045776, 0.005500196717207152, 0.005496810850776148, 0.005493390864410385, 0.005489942424751044, 0.005486464833163299, 0.0054829584820898156, 0.005479429147571025, 0.005475864077963843, 0.005472257141137275, 0.0054685907100940154, 0.0054648951138618375, 0.005461156977496276, 0.0054573018533775886, 0.005453227577351259, 0.005448851495767676, 0.005444356857689137, 0.0054397697789290225, 0.00543522593796544, 0.0054303483698117895, 0.005425006546328404, 0.005419859179557724, 0.005414678309980665, 0.005409156948207302, 0.00540320935923292, 0.0053968821714878105, 0.005389979827807965, 0.005382395995435824, 0.005373380321879464, 0.005364617522235727, 0.005356311461667283, 0.005348331273176856, 0.005340438981783878, 0.0053325231339427185, 0.0053246326632985196], 'acc': [0.4320608813133184, 0.5938382226513312, 0.5938382226476732, 0.5938382226842539, 0.5938382226513312, 0.5938382227025443, 0.5938382226366989, 0.5938382226366989, 0.5938382227244927, 0.593838222687912, 0.5938382227025443, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226366989, 0.5938382226366989, 0.5938382226805958, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382227244927, 0.5938382226659635, 0.593838222687912, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.5938382226366989, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.593838222687912, 0.5938382226842539, 0.5938382227025443, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.593838222687912, 0.5938382226513312, 0.5938382226659635, 0.5938382226659635, 0.5938382226732797, 0.5938382227025443, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.593838222687912, 0.5938382226220666, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226366989, 0.5938382226659635, 0.5938382226001182, 0.5938382226513312, 0.5938382226732797, 0.5938382226659635, 0.5938382226366989, 0.5938382226476732, 0.5938382227025443, 0.5938382227025443, 0.5938382226659635, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226842539, 0.5938382226293828, 0.5938382226513312, 0.5938382226732797, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382226513312, 0.5938382226366989, 0.593838222687912, 0.5938382226513312, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.5938382226513312, 0.5938382226732797, 0.5938382227025443]}
[2018-07-21 01:05:02,679 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:129]: evaluating model ... 
[2018-07-21 01:05:02,831 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:133]: evaluated! 
[2018-07-21 01:05:02,832 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:135]: generating reports ... 
[2018-07-21 01:05:03,853 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:138]: done!
[2018-07-21 01:05:03,853 AE_UNIGRAMA_5L_FULLDS_OVER_05.py:154]: >> experiment AE_UNIGRAMA_5L_FULLDS_OVER_05 finished!
