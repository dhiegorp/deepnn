[2017-11-14 07:07:41,777 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_UNDER_03
[2017-11-14 07:07:41,777 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-14 07:07:41,777 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_UNDER_03
	layers = 96,86,78,71,63,55
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff780ae3e48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff780ae7390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 07:07:41,777 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-14 07:07:43,918 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-14 07:07:43,919 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-14 07:07:43,919 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:60]: =======================================
[2017-11-14 07:07:43,919 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff780ae3e48>, 'discard_decoder_function': True}
[2017-11-14 07:07:44,029 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-14 07:10:18,547 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-14 07:10:18,548 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0095145242485172917, 0.0088863801693722464, 0.0083709567438199073, 0.0079526107209621326, 0.0076203635511786372, 0.0073537120699282846, 0.0071351594724259433, 0.0069565059952930754, 0.0068083318685910818, 0.0066846069941096601, 0.0065821563309549367, 0.0064970265606056126, 0.0064258680027560119, 0.0063661219357406445, 0.0063157365244951198, 0.0062730097751318315, 0.0062367487686813888, 0.0062058181876713022, 0.0061793282307350365, 0.0061564840321955833, 0.0061367855142721228, 0.0061196651401628699, 0.0061047658483740471, 0.0060917180060973417, 0.0060803125411695094, 0.0060702658383136711, 0.0060613723981746285, 0.0060534775866355056, 0.0060464417522869667, 0.0060401208990878835, 0.0060343817691019203, 0.0060292115231865701, 0.006024516647279766, 0.0060202501078801297, 0.0060163640704838364, 0.0060128016618635942, 0.0060095251783439723, 0.0060064709413001219, 0.006003601011316655, 0.0060008740440546339, 0.0059982533098596538, 0.0059957585815382719, 0.0059933837963379744, 0.0059910861715210279, 0.0059888069609468284, 0.0059864956855456295, 0.0059842818196060646, 0.0059821496761100386, 0.0059801368251612679, 0.00597824691563779, 0.0059764172190623016, 0.0059746565778651785, 0.005972989082958677, 0.0059713903430011431, 0.0059698181258852007, 0.0059682705903577101, 0.0059667499718837813, 0.0059652648786940599, 0.0059638026237004505, 0.0059623584717386179, 0.0059608925074559338, 0.0059594579290178319, 0.00595804673444325, 0.0059566463928913387, 0.0059552561475127632, 0.0059538635318138414, 0.0059523960545170302, 0.0059506251056223713, 0.0059486434341280642, 0.0059467772400442704, 0.0059450321708617955, 0.0059434016485373706, 0.0059418181108549725, 0.005940224797793831, 0.0059386021400281925, 0.0059369649321870388, 0.0059353226972233882, 0.0059336785718049744, 0.0059320525224644035, 0.005930446812561968, 0.0059288620376512433, 0.0059272959883653721, 0.0059257306945597488, 0.0059241566040170836, 0.0059225784661915753, 0.0059209996529775086, 0.0059194259742738316, 0.0059178460190686694, 0.0059162573848680917, 0.005914663558398695, 0.0059130614902721482, 0.0059114510428094711, 0.0059098315459273233, 0.0059082101111857166, 0.0059065772467784003, 0.0059049353469847726, 0.00590328202034918, 0.0059016167547468893, 0.0058999493274391407, 0.0058982651923721171, 0.0058965641386205933], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098730031424010545, 0.0092000043262228347, 0.0086265569473901998, 0.0081633839497213066, 0.0077919958304392975, 0.0074960634311723087, 0.0072564977184381568, 0.0070602726946903021, 0.0068993972221964876, 0.0067652635768099814, 0.0066539617098718825, 0.0065618186555340989, 0.0064851489964389275, 0.0064209561616207934, 0.0063670179118474664, 0.0063215421121880708, 0.006282965699570855, 0.0062502171930894608, 0.0062222674975887984, 0.0061982990023856646, 0.0061776467817430264, 0.0061598047856444944, 0.0061443154748112632, 0.006130827351448008, 0.0061190165761651084, 0.0061086956957453224, 0.0060995899148722525, 0.0060915466604567542, 0.0060843920048357803, 0.0060780080666575122, 0.0060722432437082937, 0.0060670317149623572, 0.0060623356837784317, 0.0060580801019840362, 0.0060542182653010208, 0.0060506952812544694, 0.0060474540189716097, 0.0060444623269040121, 0.0060416670762253044, 0.0060390169625159666, 0.0060364827946376232, 0.0060340637083133222, 0.0060317575203020935, 0.0060295451868463109, 0.0060274016712356104, 0.0060252119541031948, 0.0060230666860468006, 0.0060210040372312692, 0.0060190198680895104, 0.0060171636353711332, 0.0060153827055757381, 0.0060136553706109479, 0.0060120026554811275, 0.0060104253487296821, 0.0060089003448802678, 0.0060073951153742861, 0.0060059171318834117, 0.0060044623130267828, 0.0060030421121172834, 0.0060016448752195778, 0.0060002320701910503, 0.0059988223776112444, 0.0059974353061560274, 0.0059960656928551717, 0.0059947044293921911, 0.0059933420677070453, 0.0059919459045681394, 0.0059903641096466604, 0.0059884805667254218, 0.0059865834389777692, 0.0059848102043966169, 0.0059831586735108388, 0.0059815971499734884, 0.005980058121300042, 0.005978500822780084, 0.0059769179035726681, 0.0059753261015346821, 0.0059737242952952159, 0.0059721320149641582, 0.0059705563302252344, 0.0059689987147103695, 0.0059674658521194097, 0.0059659345849627831, 0.0059643999151693461, 0.0059628491886636846, 0.0059613072881741442, 0.0059597612451453312, 0.0059582155999891358, 0.0059566669931654234, 0.0059550976135729246, 0.0059535298435326343, 0.0059519590196871084, 0.0059503737121008359, 0.0059487904813856239, 0.0059471905044685466, 0.0059455814779356235, 0.0059439657502698504, 0.0059423387701422747, 0.0059407009189641844, 0.0059390586153965893, 0.005937396580182136], 'acc': [0.43218362584529046, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822263669894, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268059583, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268059583, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894]}
[2017-11-14 07:10:18,548 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:95]: done!
[2017-11-14 07:10:18,549 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-14 07:10:18,549 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:100]: =======================================
[2017-11-14 07:10:18,549 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff780ae7390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 07:10:18,593 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:113]: training ... 
[2017-11-14 07:14:30,214 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:125]: trained!
[2017-11-14 07:14:30,215 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0095145242485172917, 0.0088863801693722464, 0.0083709567438199073, 0.0079526107209621326, 0.0076203635511786372, 0.0073537120699282846, 0.0071351594724259433, 0.0069565059952930754, 0.0068083318685910818, 0.0066846069941096601, 0.0065821563309549367, 0.0064970265606056126, 0.0064258680027560119, 0.0063661219357406445, 0.0063157365244951198, 0.0062730097751318315, 0.0062367487686813888, 0.0062058181876713022, 0.0061793282307350365, 0.0061564840321955833, 0.0061367855142721228, 0.0061196651401628699, 0.0061047658483740471, 0.0060917180060973417, 0.0060803125411695094, 0.0060702658383136711, 0.0060613723981746285, 0.0060534775866355056, 0.0060464417522869667, 0.0060401208990878835, 0.0060343817691019203, 0.0060292115231865701, 0.006024516647279766, 0.0060202501078801297, 0.0060163640704838364, 0.0060128016618635942, 0.0060095251783439723, 0.0060064709413001219, 0.006003601011316655, 0.0060008740440546339, 0.0059982533098596538, 0.0059957585815382719, 0.0059933837963379744, 0.0059910861715210279, 0.0059888069609468284, 0.0059864956855456295, 0.0059842818196060646, 0.0059821496761100386, 0.0059801368251612679, 0.00597824691563779, 0.0059764172190623016, 0.0059746565778651785, 0.005972989082958677, 0.0059713903430011431, 0.0059698181258852007, 0.0059682705903577101, 0.0059667499718837813, 0.0059652648786940599, 0.0059638026237004505, 0.0059623584717386179, 0.0059608925074559338, 0.0059594579290178319, 0.00595804673444325, 0.0059566463928913387, 0.0059552561475127632, 0.0059538635318138414, 0.0059523960545170302, 0.0059506251056223713, 0.0059486434341280642, 0.0059467772400442704, 0.0059450321708617955, 0.0059434016485373706, 0.0059418181108549725, 0.005940224797793831, 0.0059386021400281925, 0.0059369649321870388, 0.0059353226972233882, 0.0059336785718049744, 0.0059320525224644035, 0.005930446812561968, 0.0059288620376512433, 0.0059272959883653721, 0.0059257306945597488, 0.0059241566040170836, 0.0059225784661915753, 0.0059209996529775086, 0.0059194259742738316, 0.0059178460190686694, 0.0059162573848680917, 0.005914663558398695, 0.0059130614902721482, 0.0059114510428094711, 0.0059098315459273233, 0.0059082101111857166, 0.0059065772467784003, 0.0059049353469847726, 0.00590328202034918, 0.0059016167547468893, 0.0058999493274391407, 0.0058982651923721171, 0.0058965641386205933], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098730031424010545, 0.0092000043262228347, 0.0086265569473901998, 0.0081633839497213066, 0.0077919958304392975, 0.0074960634311723087, 0.0072564977184381568, 0.0070602726946903021, 0.0068993972221964876, 0.0067652635768099814, 0.0066539617098718825, 0.0065618186555340989, 0.0064851489964389275, 0.0064209561616207934, 0.0063670179118474664, 0.0063215421121880708, 0.006282965699570855, 0.0062502171930894608, 0.0062222674975887984, 0.0061982990023856646, 0.0061776467817430264, 0.0061598047856444944, 0.0061443154748112632, 0.006130827351448008, 0.0061190165761651084, 0.0061086956957453224, 0.0060995899148722525, 0.0060915466604567542, 0.0060843920048357803, 0.0060780080666575122, 0.0060722432437082937, 0.0060670317149623572, 0.0060623356837784317, 0.0060580801019840362, 0.0060542182653010208, 0.0060506952812544694, 0.0060474540189716097, 0.0060444623269040121, 0.0060416670762253044, 0.0060390169625159666, 0.0060364827946376232, 0.0060340637083133222, 0.0060317575203020935, 0.0060295451868463109, 0.0060274016712356104, 0.0060252119541031948, 0.0060230666860468006, 0.0060210040372312692, 0.0060190198680895104, 0.0060171636353711332, 0.0060153827055757381, 0.0060136553706109479, 0.0060120026554811275, 0.0060104253487296821, 0.0060089003448802678, 0.0060073951153742861, 0.0060059171318834117, 0.0060044623130267828, 0.0060030421121172834, 0.0060016448752195778, 0.0060002320701910503, 0.0059988223776112444, 0.0059974353061560274, 0.0059960656928551717, 0.0059947044293921911, 0.0059933420677070453, 0.0059919459045681394, 0.0059903641096466604, 0.0059884805667254218, 0.0059865834389777692, 0.0059848102043966169, 0.0059831586735108388, 0.0059815971499734884, 0.005980058121300042, 0.005978500822780084, 0.0059769179035726681, 0.0059753261015346821, 0.0059737242952952159, 0.0059721320149641582, 0.0059705563302252344, 0.0059689987147103695, 0.0059674658521194097, 0.0059659345849627831, 0.0059643999151693461, 0.0059628491886636846, 0.0059613072881741442, 0.0059597612451453312, 0.0059582155999891358, 0.0059566669931654234, 0.0059550976135729246, 0.0059535298435326343, 0.0059519590196871084, 0.0059503737121008359, 0.0059487904813856239, 0.0059471905044685466, 0.0059455814779356235, 0.0059439657502698504, 0.0059423387701422747, 0.0059407009189641844, 0.0059390586153965893, 0.005937396580182136], 'acc': [0.43218362584529046, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822263669894, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268059583, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268059583, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822264767316, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894]}
[2017-11-14 07:14:30,215 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-14 07:14:30,356 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-14 07:14:30,357 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-14 07:14:31,247 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:141]: done!
[2017-11-14 07:14:31,247 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_5L_FULLDS_UNDER_03 finished!
[2017-11-18 16:23:35,153 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:146]: The experiment AE_UNIGRAMA_5L_FULLDS_UNDER_03 was already executed!
[2017-11-18 19:02:14,557 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_5L_FULLDS_UNDER_03
[2017-11-18 19:02:14,557 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 19:02:14,557 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_5L_FULLDS_UNDER_03
	layers = 96,86,78,71,63,55
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/5layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/5layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/5layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/5layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/5layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8f8cb4eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff8f8cb9400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:02:14,557 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 19:02:16,774 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:02:16,775 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:02:16,775 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 19:02:16,775 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8f8cb4eb8>, 'discard_decoder_function': True}
[2017-11-18 19:02:16,886 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 19:04:01,893 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 19:04:01,894 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0092637073998200863, 0.008383819773500235, 0.0077301626674179226, 0.007269849370102624, 0.0069278899582978426, 0.0066664063024996223, 0.0064566478429951574, 0.006288927104919656, 0.0061531560781293059, 0.0060415604435529006, 0.0059489014920275779, 0.0058711732033323886, 0.0058054232260349899, 0.0057494683738473426, 0.0057017468082869492, 0.0056608871340160204, 0.0056258369447168503, 0.0055955167908908763, 0.0055691828945763234, 0.0055462898745912426, 0.0055262970935603967, 0.0055087665137853676, 0.005492906164954999, 0.0054763081109268303, 0.0054618870775813965, 0.0054494007809744111, 0.0054384925667448425, 0.0054289239535922134, 0.0054204825131179482, 0.0054130167096239903, 0.0054063854987388398, 0.0054004798739640614, 0.0053951962019608809, 0.0053904946990658894, 0.0053862321469658973, 0.0053823930417584206, 0.0053788978719925707, 0.0053757114928196575, 0.0053727605140698508, 0.0053699929995352086, 0.0053674182887108656, 0.0053650211996013122, 0.0053627962747623669, 0.005360748463535174, 0.0053588433039895933, 0.005357063898490862, 0.0053554018979083684, 0.0053538303481375895, 0.00535232696837264, 0.0053508945759413208, 0.0053495034065990221, 0.005348157563675654, 0.0053468574877610676, 0.0053455900605042352, 0.0053443552388644303, 0.0053431298259443072, 0.0053419320176169684, 0.0053407461640864158, 0.0053395791078011687, 0.0053384171192832385, 0.005337252699862789, 0.0053360928818638256, 0.005334923264612634, 0.0053337569870821411, 0.0053325871434179092, 0.0053314269866550652, 0.0053302679382550757, 0.0053291146549163818, 0.00532796453365913, 0.0053268112237943432, 0.0053256609023078719, 0.0053245182852823805, 0.0053233724138475281, 0.0053222195889824058, 0.0053210691040609746, 0.0053199152642733, 0.0053187549468992398, 0.0053175838299825357, 0.0053163893682213392, 0.0053151076711243301, 0.005313620809072034, 0.0053119459585654616, 0.0053102156419980581, 0.0053084425655395909, 0.0053067422979016735, 0.0053052269368138449, 0.0053037654112022296, 0.0053023128509822682, 0.0053008309761777613, 0.0052993001851182357, 0.0052976987321403475, 0.0052960626550808748, 0.0052943772888608557, 0.0052926688262859402, 0.0052909069772958976, 0.0052889719978009122, 0.0052858214932865232, 0.0052826945908341621, 0.0052798612111544822, 0.0052772492983401403, 0.0052748007332075776], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097523441487230283, 0.0088178776877900125, 0.0080467403657268899, 0.0074991417383541686, 0.0071051883298276801, 0.0068080393422353383, 0.0065753084671552947, 0.0063887008943548009, 0.0062388548263060221, 0.0061167258096188285, 0.0060158462158016882, 0.0059317119796356279, 0.0058608630965771898, 0.0058007722662660527, 0.0057495656379602453, 0.0057058375188972239, 0.005668355810006835, 0.0056360841223932791, 0.0056081351784551866, 0.0055838522039000846, 0.0055627165113261278, 0.005544236173851678, 0.005527868550611454, 0.0055116908348126475, 0.0054962691740989425, 0.0054829536183957049, 0.0054713967908985436, 0.0054612844860965643, 0.005452405977596388, 0.0054445711986017848, 0.0054376262768932038, 0.0054314653801832251, 0.005425978822061364, 0.0054210710338219344, 0.0054166815696347964, 0.0054127162895004771, 0.0054091323168000164, 0.0054058682892416223, 0.0054028737369037245, 0.0054000752985571641, 0.0053974617179677513, 0.0053950324439667359, 0.0053927737162545062, 0.0053906854115425623, 0.0053887570059544011, 0.0053869593017785459, 0.0053852838987643011, 0.0053837051754811651, 0.0053822118524890434, 0.005380781388969488, 0.0053794095440725066, 0.005378081645609426, 0.0053767930648601818, 0.005375536711735858, 0.0053743167627843787, 0.005373119469709183, 0.0053719436080274232, 0.0053707818190675905, 0.0053696348861146112, 0.0053684962597313583, 0.0053673744332779216, 0.0053662431214978263, 0.0053650968776915433, 0.005363959445897821, 0.0053628121091850124, 0.0053616686891826129, 0.0053605283953467109, 0.0053593894816332394, 0.0053582545436737664, 0.0053571312386728664, 0.0053560039879256005, 0.005354880747569713, 0.0053537527561769377, 0.0053526233448230286, 0.0053514951929894495, 0.0053503638333686149, 0.0053492223987854472, 0.0053480736433689658, 0.005346911040373532, 0.005345709736335383, 0.005344356435125988, 0.0053428066914417132, 0.0053411324344903718, 0.0053394121364009617, 0.0053376781896974862, 0.0053360875661306447, 0.0053346149059936426, 0.0053331765408644949, 0.0053317243877715557, 0.0053302460964881155, 0.0053287037607450214, 0.0053271130776201764, 0.0053254833074115795, 0.0053238108075356816, 0.0053221018782805283, 0.0053202943809854486, 0.0053178228292034878, 0.0053145691214697014, 0.0053116213624040173, 0.0053089305704062421, 0.0053064318496573405], 'acc': [0.33558365046736566, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822262938279, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353]}
[2017-11-18 19:04:01,895 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:95]: done!
[2017-11-18 19:04:01,895 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 19:04:01,895 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 19:04:01,895 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff8f8cb9400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:04:01,963 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 19:08:20,157 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 19:08:20,159 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0092637073998200863, 0.008383819773500235, 0.0077301626674179226, 0.007269849370102624, 0.0069278899582978426, 0.0066664063024996223, 0.0064566478429951574, 0.006288927104919656, 0.0061531560781293059, 0.0060415604435529006, 0.0059489014920275779, 0.0058711732033323886, 0.0058054232260349899, 0.0057494683738473426, 0.0057017468082869492, 0.0056608871340160204, 0.0056258369447168503, 0.0055955167908908763, 0.0055691828945763234, 0.0055462898745912426, 0.0055262970935603967, 0.0055087665137853676, 0.005492906164954999, 0.0054763081109268303, 0.0054618870775813965, 0.0054494007809744111, 0.0054384925667448425, 0.0054289239535922134, 0.0054204825131179482, 0.0054130167096239903, 0.0054063854987388398, 0.0054004798739640614, 0.0053951962019608809, 0.0053904946990658894, 0.0053862321469658973, 0.0053823930417584206, 0.0053788978719925707, 0.0053757114928196575, 0.0053727605140698508, 0.0053699929995352086, 0.0053674182887108656, 0.0053650211996013122, 0.0053627962747623669, 0.005360748463535174, 0.0053588433039895933, 0.005357063898490862, 0.0053554018979083684, 0.0053538303481375895, 0.00535232696837264, 0.0053508945759413208, 0.0053495034065990221, 0.005348157563675654, 0.0053468574877610676, 0.0053455900605042352, 0.0053443552388644303, 0.0053431298259443072, 0.0053419320176169684, 0.0053407461640864158, 0.0053395791078011687, 0.0053384171192832385, 0.005337252699862789, 0.0053360928818638256, 0.005334923264612634, 0.0053337569870821411, 0.0053325871434179092, 0.0053314269866550652, 0.0053302679382550757, 0.0053291146549163818, 0.00532796453365913, 0.0053268112237943432, 0.0053256609023078719, 0.0053245182852823805, 0.0053233724138475281, 0.0053222195889824058, 0.0053210691040609746, 0.0053199152642733, 0.0053187549468992398, 0.0053175838299825357, 0.0053163893682213392, 0.0053151076711243301, 0.005313620809072034, 0.0053119459585654616, 0.0053102156419980581, 0.0053084425655395909, 0.0053067422979016735, 0.0053052269368138449, 0.0053037654112022296, 0.0053023128509822682, 0.0053008309761777613, 0.0052993001851182357, 0.0052976987321403475, 0.0052960626550808748, 0.0052943772888608557, 0.0052926688262859402, 0.0052909069772958976, 0.0052889719978009122, 0.0052858214932865232, 0.0052826945908341621, 0.0052798612111544822, 0.0052772492983401403, 0.0052748007332075776], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097523441487230283, 0.0088178776877900125, 0.0080467403657268899, 0.0074991417383541686, 0.0071051883298276801, 0.0068080393422353383, 0.0065753084671552947, 0.0063887008943548009, 0.0062388548263060221, 0.0061167258096188285, 0.0060158462158016882, 0.0059317119796356279, 0.0058608630965771898, 0.0058007722662660527, 0.0057495656379602453, 0.0057058375188972239, 0.005668355810006835, 0.0056360841223932791, 0.0056081351784551866, 0.0055838522039000846, 0.0055627165113261278, 0.005544236173851678, 0.005527868550611454, 0.0055116908348126475, 0.0054962691740989425, 0.0054829536183957049, 0.0054713967908985436, 0.0054612844860965643, 0.005452405977596388, 0.0054445711986017848, 0.0054376262768932038, 0.0054314653801832251, 0.005425978822061364, 0.0054210710338219344, 0.0054166815696347964, 0.0054127162895004771, 0.0054091323168000164, 0.0054058682892416223, 0.0054028737369037245, 0.0054000752985571641, 0.0053974617179677513, 0.0053950324439667359, 0.0053927737162545062, 0.0053906854115425623, 0.0053887570059544011, 0.0053869593017785459, 0.0053852838987643011, 0.0053837051754811651, 0.0053822118524890434, 0.005380781388969488, 0.0053794095440725066, 0.005378081645609426, 0.0053767930648601818, 0.005375536711735858, 0.0053743167627843787, 0.005373119469709183, 0.0053719436080274232, 0.0053707818190675905, 0.0053696348861146112, 0.0053684962597313583, 0.0053673744332779216, 0.0053662431214978263, 0.0053650968776915433, 0.005363959445897821, 0.0053628121091850124, 0.0053616686891826129, 0.0053605283953467109, 0.0053593894816332394, 0.0053582545436737664, 0.0053571312386728664, 0.0053560039879256005, 0.005354880747569713, 0.0053537527561769377, 0.0053526233448230286, 0.0053514951929894495, 0.0053503638333686149, 0.0053492223987854472, 0.0053480736433689658, 0.005346911040373532, 0.005345709736335383, 0.005344356435125988, 0.0053428066914417132, 0.0053411324344903718, 0.0053394121364009617, 0.0053376781896974862, 0.0053360875661306447, 0.0053346149059936426, 0.0053331765408644949, 0.0053317243877715557, 0.0053302460964881155, 0.0053287037607450214, 0.0053271130776201764, 0.0053254833074115795, 0.0053238108075356816, 0.0053221018782805283, 0.0053202943809854486, 0.0053178228292034878, 0.0053145691214697014, 0.0053116213624040173, 0.0053089305704062421, 0.0053064318496573405], 'acc': [0.33558365046736566, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822262938279, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353]}
[2017-11-18 19:08:20,159 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 19:08:20,303 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 19:08:20,303 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 19:08:21,181 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:141]: done!
[2017-11-18 19:08:21,181 AE_UNIGRAMA_5L_FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_5L_FULLDS_UNDER_03 finished!
