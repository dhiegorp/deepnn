[2018-07-21 00:52:16,422 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_9L_FULLDS_OVER_01
[2018-07-21 00:52:16,423 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-07-21 00:52:16,423 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_FULLDS_OVER_01
	layers = 96,144,130,117,103,90,76,63,49,36
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f38a3945668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f38a3945e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,423 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,377 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,377 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,377 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:57]: =======================================
[2018-07-21 00:52:18,378 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f38a3945668>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,742 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-07-21 00:57:10,509 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:85]: trained and evaluated!
[2018-07-21 00:57:10,510 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:88]: Training history: 
{'val_loss': [0.009360723108127139, 0.008593673825343384, 0.008036237675012067, 0.0076199810649379566, 0.007289276817537644, 0.0070319188854909365, 0.006829393103969301, 0.0066682394579920925, 0.006532120135897214, 0.006421435760756498, 0.006330522988402298, 0.006255236005760354, 0.006192441331479358, 0.006139719093273894, 0.00609527787471581, 0.006057598350093163, 0.0060260600824722284, 0.0059992567245368954, 0.005976284454254593, 0.005956523747702609, 0.005939511880032151, 0.005924789128206925, 0.005912054992835039, 0.005901042085763195, 0.005891506194856835, 0.005883161526533423, 0.005875919116298144, 0.005869590099479966, 0.0058640914260471725, 0.005859203556554583, 0.0058549381158486125, 0.0058512006658179025, 0.005847933497235387, 0.005845087006050123, 0.005842579640526816, 0.005840379778567519, 0.005838427410362776, 0.005836718915699844, 0.0058352133293917835, 0.005833887340479045, 0.005832710013033816, 0.005831647690577937, 0.00583070369914122, 0.005829857341867818, 0.005829109830572347, 0.005828436352233842, 0.005827819612524097, 0.005827279721387757, 0.005826766451496257, 0.00582629410862835, 0.005825868452368979, 0.0058254690276775805, 0.00582511168868664, 0.005824765347927338, 0.0058244048339341796, 0.005824114297914022, 0.005823839582911515, 0.005823578111617218, 0.00582333153344072, 0.005823102989499291, 0.005822877224636747, 0.0058226636263518945, 0.00582247319955068, 0.005822294724465802, 0.00582211742500026, 0.005821965945007, 0.005821811606613279, 0.0058216717446209895, 0.005821517799070152, 0.0058213896318333675, 0.005821255546625196, 0.005821125635169433, 0.005821016215634057, 0.0058208882795165555, 0.00582078037504894, 0.005820670219885102, 0.00582056504341225, 0.005820459837589559, 0.005820353795339253, 0.005820250042376356, 0.005820143117406123, 0.005820044655115294, 0.005819940286233627, 0.0058198449760127795, 0.005819750932027825, 0.005819658103622482, 0.005819568576603356, 0.0058194835134123025, 0.005819391074769393, 0.005819297819465086, 0.005819200743119842, 0.005819097142553628, 0.005818992379545558, 0.005818893071928037, 0.00581878013922554, 0.00581867804876414, 0.005818563963545679, 0.005818404520076975, 0.0058181142578745525, 0.0058178553784362635, 0.00581772041641236], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009868008292190858, 0.008959014952270564, 0.00830414590560795, 0.007822765746512039, 0.007452688219863201, 0.007160934244024307, 0.006933116914190711, 0.006752838909740779, 0.00660591252853245, 0.0064833354343442635, 0.006383555356906509, 0.006301278085416411, 0.006233001098688818, 0.00617590789481169, 0.006127934110076208, 0.006087414455983381, 0.0060532466404193035, 0.006024554013571257, 0.006000045924963608, 0.005979032434554657, 0.0059609594097564675, 0.005945398055400635, 0.005931939849531916, 0.005920322390100141, 0.005910267471321539, 0.005901559346440205, 0.005893956260085545, 0.005887367805436105, 0.00588162280638578, 0.0058766038983999016, 0.005872173392460458, 0.005868307619004787, 0.0058649357731681675, 0.005861997170659813, 0.005859441611969783, 0.005857192084768919, 0.005855221578016158, 0.0058534818224639075, 0.005851969606323894, 0.005850643274087719, 0.00584946401062651, 0.005848415110091519, 0.0058474845623425345, 0.005846648827049759, 0.005845905118533292, 0.00584524474349648, 0.005844652111231329, 0.005844114077080517, 0.0058436334106627165, 0.005843184097704656, 0.00584276502466599, 0.005842390895572062, 0.005842032561409495, 0.005841712996935671, 0.00584138494167384, 0.005841086279773245, 0.005840826866311724, 0.005840585413703845, 0.005840355502888497, 0.005840134128529912, 0.005839928889532125, 0.005839721941413949, 0.005839535778410558, 0.0058393559909715, 0.005839196715720672, 0.005839045741323831, 0.005838901653935683, 0.005838764091178352, 0.005838629989758476, 0.0058384976682769995, 0.005838376782732561, 0.005838252141604405, 0.005838131527671902, 0.00583802213882281, 0.005837917951010766, 0.0058378123238612325, 0.005837708333299356, 0.005837607622142948, 0.005837507847167494, 0.005837411532843605, 0.005837310195642263, 0.005837208620323218, 0.005837109170173233, 0.005837014247060309, 0.005836925119535644, 0.005836830705580783, 0.005836744178031648, 0.0058366533496172586, 0.005836572048940314, 0.0058364727579736705, 0.005836377082955231, 0.005836279511683094, 0.005836176018962118, 0.005836070583175538, 0.005835968811749475, 0.005835859032115282, 0.0058357447968336125, 0.005835614129315641, 0.005835401607036949, 0.0058350735733806135, 0.005834889423975048], 'acc': [0.5734626242861918, 0.5938382226476732, 0.5938382226842539, 0.5938382226842539, 0.5938382226513312, 0.593838222687912, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226623055, 0.593838222687912, 0.5938382226842539, 0.5938382226659635, 0.593838222687912, 0.5938382226513312, 0.593838222687912, 0.5938382226366989, 0.5938382226513312, 0.5938382226476732, 0.5938382226366989, 0.593838222687912, 0.593838222687912, 0.593838222687912, 0.5938382226001182, 0.5938382226513312, 0.5938382226001182, 0.593838222687912, 0.5938382226366989, 0.5938382226001182, 0.5938382227025443, 0.5938382226842539, 0.5938382227025443, 0.5938382227025443, 0.5938382227244927, 0.5938382226513312, 0.593838222687912, 0.5938382226366989, 0.5938382226842539, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.5938382226659635, 0.593838222687912, 0.5938382226366989, 0.5938382226513312, 0.5938382226659635, 0.5938382226366989, 0.5938382226476732, 0.5938382226001182, 0.5938382227025443, 0.5938382226476732, 0.5938382226513312, 0.5938382227025443, 0.593838222687912, 0.5938382227025443, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.593838222687912, 0.5938382227025443, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226366989, 0.5938382226513312, 0.5938382226659635, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382227025443, 0.5938382227025443, 0.5938382226842539, 0.5938382226366989, 0.5938382226659635, 0.593838222687912, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.593838222687912, 0.593838222687912, 0.5938382226001182, 0.593838222687912, 0.5938382226001182, 0.5938382226659635]}
[2018-07-21 00:57:10,510 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:92]: done!
[2018-07-21 00:57:10,510 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:152]: >> Executing classifier part ... 
[2018-07-21 00:57:10,510 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:97]: =======================================
[2018-07-21 00:57:10,511 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f38a3945e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 00:57:10,570 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:110]: training ... 
[2018-07-21 01:07:33,837 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:122]: trained!
[2018-07-21 01:07:33,838 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:125]: Training history: 
{'val_loss': [0.009360723108127139, 0.008593673825343384, 0.008036237675012067, 0.0076199810649379566, 0.007289276817537644, 0.0070319188854909365, 0.006829393103969301, 0.0066682394579920925, 0.006532120135897214, 0.006421435760756498, 0.006330522988402298, 0.006255236005760354, 0.006192441331479358, 0.006139719093273894, 0.00609527787471581, 0.006057598350093163, 0.0060260600824722284, 0.0059992567245368954, 0.005976284454254593, 0.005956523747702609, 0.005939511880032151, 0.005924789128206925, 0.005912054992835039, 0.005901042085763195, 0.005891506194856835, 0.005883161526533423, 0.005875919116298144, 0.005869590099479966, 0.0058640914260471725, 0.005859203556554583, 0.0058549381158486125, 0.0058512006658179025, 0.005847933497235387, 0.005845087006050123, 0.005842579640526816, 0.005840379778567519, 0.005838427410362776, 0.005836718915699844, 0.0058352133293917835, 0.005833887340479045, 0.005832710013033816, 0.005831647690577937, 0.00583070369914122, 0.005829857341867818, 0.005829109830572347, 0.005828436352233842, 0.005827819612524097, 0.005827279721387757, 0.005826766451496257, 0.00582629410862835, 0.005825868452368979, 0.0058254690276775805, 0.00582511168868664, 0.005824765347927338, 0.0058244048339341796, 0.005824114297914022, 0.005823839582911515, 0.005823578111617218, 0.00582333153344072, 0.005823102989499291, 0.005822877224636747, 0.0058226636263518945, 0.00582247319955068, 0.005822294724465802, 0.00582211742500026, 0.005821965945007, 0.005821811606613279, 0.0058216717446209895, 0.005821517799070152, 0.0058213896318333675, 0.005821255546625196, 0.005821125635169433, 0.005821016215634057, 0.0058208882795165555, 0.00582078037504894, 0.005820670219885102, 0.00582056504341225, 0.005820459837589559, 0.005820353795339253, 0.005820250042376356, 0.005820143117406123, 0.005820044655115294, 0.005819940286233627, 0.0058198449760127795, 0.005819750932027825, 0.005819658103622482, 0.005819568576603356, 0.0058194835134123025, 0.005819391074769393, 0.005819297819465086, 0.005819200743119842, 0.005819097142553628, 0.005818992379545558, 0.005818893071928037, 0.00581878013922554, 0.00581867804876414, 0.005818563963545679, 0.005818404520076975, 0.0058181142578745525, 0.0058178553784362635, 0.00581772041641236], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009868008292190858, 0.008959014952270564, 0.00830414590560795, 0.007822765746512039, 0.007452688219863201, 0.007160934244024307, 0.006933116914190711, 0.006752838909740779, 0.00660591252853245, 0.0064833354343442635, 0.006383555356906509, 0.006301278085416411, 0.006233001098688818, 0.00617590789481169, 0.006127934110076208, 0.006087414455983381, 0.0060532466404193035, 0.006024554013571257, 0.006000045924963608, 0.005979032434554657, 0.0059609594097564675, 0.005945398055400635, 0.005931939849531916, 0.005920322390100141, 0.005910267471321539, 0.005901559346440205, 0.005893956260085545, 0.005887367805436105, 0.00588162280638578, 0.0058766038983999016, 0.005872173392460458, 0.005868307619004787, 0.0058649357731681675, 0.005861997170659813, 0.005859441611969783, 0.005857192084768919, 0.005855221578016158, 0.0058534818224639075, 0.005851969606323894, 0.005850643274087719, 0.00584946401062651, 0.005848415110091519, 0.0058474845623425345, 0.005846648827049759, 0.005845905118533292, 0.00584524474349648, 0.005844652111231329, 0.005844114077080517, 0.0058436334106627165, 0.005843184097704656, 0.00584276502466599, 0.005842390895572062, 0.005842032561409495, 0.005841712996935671, 0.00584138494167384, 0.005841086279773245, 0.005840826866311724, 0.005840585413703845, 0.005840355502888497, 0.005840134128529912, 0.005839928889532125, 0.005839721941413949, 0.005839535778410558, 0.0058393559909715, 0.005839196715720672, 0.005839045741323831, 0.005838901653935683, 0.005838764091178352, 0.005838629989758476, 0.0058384976682769995, 0.005838376782732561, 0.005838252141604405, 0.005838131527671902, 0.00583802213882281, 0.005837917951010766, 0.0058378123238612325, 0.005837708333299356, 0.005837607622142948, 0.005837507847167494, 0.005837411532843605, 0.005837310195642263, 0.005837208620323218, 0.005837109170173233, 0.005837014247060309, 0.005836925119535644, 0.005836830705580783, 0.005836744178031648, 0.0058366533496172586, 0.005836572048940314, 0.0058364727579736705, 0.005836377082955231, 0.005836279511683094, 0.005836176018962118, 0.005836070583175538, 0.005835968811749475, 0.005835859032115282, 0.0058357447968336125, 0.005835614129315641, 0.005835401607036949, 0.0058350735733806135, 0.005834889423975048], 'acc': [0.5734626242861918, 0.5938382226476732, 0.5938382226842539, 0.5938382226842539, 0.5938382226513312, 0.593838222687912, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226623055, 0.593838222687912, 0.5938382226842539, 0.5938382226659635, 0.593838222687912, 0.5938382226513312, 0.593838222687912, 0.5938382226366989, 0.5938382226513312, 0.5938382226476732, 0.5938382226366989, 0.593838222687912, 0.593838222687912, 0.593838222687912, 0.5938382226001182, 0.5938382226513312, 0.5938382226001182, 0.593838222687912, 0.5938382226366989, 0.5938382226001182, 0.5938382227025443, 0.5938382226842539, 0.5938382227025443, 0.5938382227025443, 0.5938382227244927, 0.5938382226513312, 0.593838222687912, 0.5938382226366989, 0.5938382226842539, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.5938382226659635, 0.593838222687912, 0.5938382226366989, 0.5938382226513312, 0.5938382226659635, 0.5938382226366989, 0.5938382226476732, 0.5938382226001182, 0.5938382227025443, 0.5938382226476732, 0.5938382226513312, 0.5938382227025443, 0.593838222687912, 0.5938382227025443, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.593838222687912, 0.5938382227025443, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226366989, 0.5938382226513312, 0.5938382226659635, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382227025443, 0.5938382227025443, 0.5938382226842539, 0.5938382226366989, 0.5938382226659635, 0.593838222687912, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.593838222687912, 0.593838222687912, 0.5938382226001182, 0.593838222687912, 0.5938382226001182, 0.5938382226659635]}
[2018-07-21 01:07:33,838 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:129]: evaluating model ... 
[2018-07-21 01:07:34,004 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:133]: evaluated! 
[2018-07-21 01:07:34,004 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:135]: generating reports ... 
[2018-07-21 01:07:35,001 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:138]: done!
[2018-07-21 01:07:35,001 AE_UNIGRAMA_9L_FULLDS_OVER_01.py:154]: >> experiment AE_UNIGRAMA_9L_FULLDS_OVER_01 finished!
