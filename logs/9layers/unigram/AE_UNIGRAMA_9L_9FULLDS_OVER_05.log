[2017-11-18 21:08:20,345 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_9FULLDS_OVER_05
[2017-11-18 21:08:20,345 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 21:08:20,345 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_9FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb9d6fb9eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fb9d6fbe400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 21:08:20,345 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 21:08:22,744 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 21:08:22,745 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 21:08:22,745 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 21:08:22,745 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb9d6fb9eb8>, 'discard_decoder_function': True}
[2017-11-18 21:08:22,951 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 21:11:51,492 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 21:11:51,494 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0093015489869780806, 0.0084255394850642259, 0.0077637211119811547, 0.0072670863081866419, 0.0068895070445995936, 0.0065980788767994961, 0.0063703256477463206, 0.0061898699534447023, 0.0060455964528057056, 0.0059290381827183242, 0.0058339617296557728, 0.0057556819304541845, 0.0056908754133870934, 0.005637242776817152, 0.0055921812702137367, 0.0055542692032261717, 0.0055223175792385665, 0.0054951425049130868, 0.0054719724452984885, 0.0054522014173580824, 0.0054353315608924374, 0.0054208641196335835, 0.0054083718805827503, 0.0053975902611916168, 0.0053850439522081343, 0.005374436059645632, 0.0053654352156975909, 0.005357783649630847, 0.0053512371340797352, 0.0053456099015940905, 0.0053407988776800249, 0.0053366849154270896, 0.0053331286477685544, 0.0053300569803433106, 0.0053274187189894795, 0.0053251278409559809, 0.0053231492998829406, 0.0053214334675036603, 0.0053199383665323919, 0.005318671428211354, 0.0053175410836967902, 0.0053165556218794105, 0.0053157043297258604, 0.0053149567682019483, 0.005314311897056982, 0.0053137271884604277, 0.0053132190255264083, 0.0053127752034283163, 0.0053123863124196549, 0.0053120443573648037, 0.0053117461418695352, 0.0053114870808558595, 0.0053112578367111394, 0.0053110508680670838, 0.0053108709047828108, 0.0053107073963186797, 0.0053105614221155457, 0.0053104366094882992, 0.0053103234521696911, 0.0053102186405589724, 0.0053101280964780919, 0.0053100488868256905, 0.0053099581564631819, 0.0053099000946102131, 0.005309828320820705, 0.005309761530856264, 0.0053097077249010249, 0.005309656131307525, 0.005309591208009932, 0.0053095387854332357, 0.0053094842549733807, 0.0053094432711326073, 0.0053093976725217332, 0.0053093580815575551, 0.0053093222501964608, 0.0053093011286664167, 0.0053092527057967314, 0.0053092261420536165, 0.0053091929154693036, 0.0053091517644285749, 0.0053091189930662488, 0.0053090860635741791, 0.0053090591702229647, 0.0053090261065602048, 0.0053089980942356988, 0.0053089611397084784, 0.0053089301630502754, 0.0053088923032131646, 0.0053088616225348212, 0.0053088265001049583, 0.0053087916691198491, 0.0053087516846282434, 0.0053087025336600851, 0.0053086552755425946, 0.0053086047126161664, 0.0053085532366787249, 0.0053085024765179584, 0.0053084413225782051, 0.0053083731741355219, 0.0053083065123520094, 0.0053082426133894524], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098485017853339896, 0.0088514687632450274, 0.0080867004271574262, 0.007514121494451095, 0.0070819791435657638, 0.0067511874157215193, 0.0064944549746275481, 0.006292681241065275, 0.0061320910977669049, 0.0060031193019773081, 0.0058984434367807398, 0.0058127705383772856, 0.0057420088384061325, 0.0056834293829353295, 0.0056347099590209329, 0.0055937009671049327, 0.0055591907771515734, 0.0055300116433717548, 0.0055051745321705427, 0.0054839961603421056, 0.0054659147792472584, 0.0054504605315600979, 0.0054372047432858922, 0.0054257814131692698, 0.0054142367748864391, 0.005402872898519072, 0.0053932818337109863, 0.0053851253291214993, 0.005378184263307861, 0.0053722765468169802, 0.005367202522756462, 0.0053628760515044031, 0.0053591792404489771, 0.0053559811724658733, 0.0053532296757149642, 0.0053508716296005411, 0.0053488318897542322, 0.0053470716987189752, 0.0053455577098423931, 0.0053442359805482981, 0.0053431093198939659, 0.0053421142157265506, 0.0053412595588786587, 0.0053405229402224766, 0.0053398695945162684, 0.0053392985019578157, 0.0053388000873118785, 0.005338366044637461, 0.0053379884981601148, 0.0053376592906623829, 0.0053373743293890817, 0.005337127634019256, 0.0053369077934793344, 0.005336722480177759, 0.0053365512657190398, 0.0053364045144533969, 0.0053362782572570888, 0.005336156838891425, 0.0053360568807836808, 0.0053359652083260567, 0.005335881786766858, 0.0053358065323705021, 0.0053357389371220731, 0.0053356760217495762, 0.0053356184419054769, 0.0053355685402427157, 0.005335516008082377, 0.005335468878724688, 0.0053354268314595114, 0.0053353805610059785, 0.0053353376832438694, 0.0053352934748004763, 0.0053352648792421437, 0.005335223667732379, 0.0053351955512101644, 0.0053351636647577258, 0.0053351398813375351, 0.0053351010056789834, 0.0053350775374246618, 0.0053350523063791589, 0.0053350131122967652, 0.0053349962772151526, 0.0053349601039581794, 0.005334928057064937, 0.0053349069081433413, 0.0053348762325131334, 0.0053348444738646281, 0.0053348131806487805, 0.005334780275137169, 0.005334752091855118, 0.0053347180664586888, 0.0053346842419133419, 0.0053346440667242844, 0.0053345962232992745, 0.0053345437410373406, 0.0053344978393633129, 0.0053344424611077076, 0.0053343822770012738, 0.0053343235429207632, 0.0053342673089332368, 0.0053341929836588954], 'acc': [0.55713759665403162, 0.59383822267327968, 0.59383822264767316, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822262938279, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822272449271, 0.5938382226842539, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822267327968, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.59383822265133124]}
[2017-11-18 21:11:51,494 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:95]: done!
[2017-11-18 21:11:51,494 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 21:11:51,495 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 21:11:51,495 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fb9d6fbe400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 21:11:51,565 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 21:19:29,133 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:125]: trained!
[2017-11-18 21:19:29,135 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0093015489869780806, 0.0084255394850642259, 0.0077637211119811547, 0.0072670863081866419, 0.0068895070445995936, 0.0065980788767994961, 0.0063703256477463206, 0.0061898699534447023, 0.0060455964528057056, 0.0059290381827183242, 0.0058339617296557728, 0.0057556819304541845, 0.0056908754133870934, 0.005637242776817152, 0.0055921812702137367, 0.0055542692032261717, 0.0055223175792385665, 0.0054951425049130868, 0.0054719724452984885, 0.0054522014173580824, 0.0054353315608924374, 0.0054208641196335835, 0.0054083718805827503, 0.0053975902611916168, 0.0053850439522081343, 0.005374436059645632, 0.0053654352156975909, 0.005357783649630847, 0.0053512371340797352, 0.0053456099015940905, 0.0053407988776800249, 0.0053366849154270896, 0.0053331286477685544, 0.0053300569803433106, 0.0053274187189894795, 0.0053251278409559809, 0.0053231492998829406, 0.0053214334675036603, 0.0053199383665323919, 0.005318671428211354, 0.0053175410836967902, 0.0053165556218794105, 0.0053157043297258604, 0.0053149567682019483, 0.005314311897056982, 0.0053137271884604277, 0.0053132190255264083, 0.0053127752034283163, 0.0053123863124196549, 0.0053120443573648037, 0.0053117461418695352, 0.0053114870808558595, 0.0053112578367111394, 0.0053110508680670838, 0.0053108709047828108, 0.0053107073963186797, 0.0053105614221155457, 0.0053104366094882992, 0.0053103234521696911, 0.0053102186405589724, 0.0053101280964780919, 0.0053100488868256905, 0.0053099581564631819, 0.0053099000946102131, 0.005309828320820705, 0.005309761530856264, 0.0053097077249010249, 0.005309656131307525, 0.005309591208009932, 0.0053095387854332357, 0.0053094842549733807, 0.0053094432711326073, 0.0053093976725217332, 0.0053093580815575551, 0.0053093222501964608, 0.0053093011286664167, 0.0053092527057967314, 0.0053092261420536165, 0.0053091929154693036, 0.0053091517644285749, 0.0053091189930662488, 0.0053090860635741791, 0.0053090591702229647, 0.0053090261065602048, 0.0053089980942356988, 0.0053089611397084784, 0.0053089301630502754, 0.0053088923032131646, 0.0053088616225348212, 0.0053088265001049583, 0.0053087916691198491, 0.0053087516846282434, 0.0053087025336600851, 0.0053086552755425946, 0.0053086047126161664, 0.0053085532366787249, 0.0053085024765179584, 0.0053084413225782051, 0.0053083731741355219, 0.0053083065123520094, 0.0053082426133894524], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098485017853339896, 0.0088514687632450274, 0.0080867004271574262, 0.007514121494451095, 0.0070819791435657638, 0.0067511874157215193, 0.0064944549746275481, 0.006292681241065275, 0.0061320910977669049, 0.0060031193019773081, 0.0058984434367807398, 0.0058127705383772856, 0.0057420088384061325, 0.0056834293829353295, 0.0056347099590209329, 0.0055937009671049327, 0.0055591907771515734, 0.0055300116433717548, 0.0055051745321705427, 0.0054839961603421056, 0.0054659147792472584, 0.0054504605315600979, 0.0054372047432858922, 0.0054257814131692698, 0.0054142367748864391, 0.005402872898519072, 0.0053932818337109863, 0.0053851253291214993, 0.005378184263307861, 0.0053722765468169802, 0.005367202522756462, 0.0053628760515044031, 0.0053591792404489771, 0.0053559811724658733, 0.0053532296757149642, 0.0053508716296005411, 0.0053488318897542322, 0.0053470716987189752, 0.0053455577098423931, 0.0053442359805482981, 0.0053431093198939659, 0.0053421142157265506, 0.0053412595588786587, 0.0053405229402224766, 0.0053398695945162684, 0.0053392985019578157, 0.0053388000873118785, 0.005338366044637461, 0.0053379884981601148, 0.0053376592906623829, 0.0053373743293890817, 0.005337127634019256, 0.0053369077934793344, 0.005336722480177759, 0.0053365512657190398, 0.0053364045144533969, 0.0053362782572570888, 0.005336156838891425, 0.0053360568807836808, 0.0053359652083260567, 0.005335881786766858, 0.0053358065323705021, 0.0053357389371220731, 0.0053356760217495762, 0.0053356184419054769, 0.0053355685402427157, 0.005335516008082377, 0.005335468878724688, 0.0053354268314595114, 0.0053353805610059785, 0.0053353376832438694, 0.0053352934748004763, 0.0053352648792421437, 0.005335223667732379, 0.0053351955512101644, 0.0053351636647577258, 0.0053351398813375351, 0.0053351010056789834, 0.0053350775374246618, 0.0053350523063791589, 0.0053350131122967652, 0.0053349962772151526, 0.0053349601039581794, 0.005334928057064937, 0.0053349069081433413, 0.0053348762325131334, 0.0053348444738646281, 0.0053348131806487805, 0.005334780275137169, 0.005334752091855118, 0.0053347180664586888, 0.0053346842419133419, 0.0053346440667242844, 0.0053345962232992745, 0.0053345437410373406, 0.0053344978393633129, 0.0053344424611077076, 0.0053343822770012738, 0.0053343235429207632, 0.0053342673089332368, 0.0053341929836588954], 'acc': [0.55713759665403162, 0.59383822267327968, 0.59383822264767316, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822262938279, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822272449271, 0.5938382226842539, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822264767316, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822267327968, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.59383822265133124]}
[2017-11-18 21:19:29,135 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 21:19:29,342 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 21:19:29,342 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 21:19:30,206 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:141]: done!
[2017-11-18 21:19:30,206 AE_UNIGRAMA_9L_9FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_9L_9FULLDS_OVER_05 finished!
