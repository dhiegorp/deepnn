[2017-11-18 17:44:06,545 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_9FULLDS_UNDER_02
[2017-11-18 17:44:06,545 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 17:44:06,545 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_9FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f60886a7e48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f60886ab390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:44:06,545 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 17:44:08,852 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:44:08,852 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:44:08,853 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 17:44:08,853 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f60886a7e48>, 'discard_decoder_function': True}
[2017-11-18 17:44:09,050 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 17:45:57,786 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 17:45:57,787 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0093540846230171261, 0.008611324872001485, 0.0080784504053356427, 0.0076853812772141291, 0.007387902681434781, 0.0071575912821165823, 0.0069757070389289775, 0.0068298341943932037, 0.0067110923197611933, 0.0066108807244737531, 0.0065260269570971115, 0.006447211283750939, 0.0063814485347386514, 0.0063244263642905328, 0.0062727445783760999, 0.0062276047633229069, 0.006189172862348164, 0.006154081828085153, 0.0061241851280827058, 0.0060957337065453707, 0.0060719618206184515, 0.006052014484432708, 0.0060351260611564966, 0.0060207736703236231, 0.0060084271465470273, 0.005997793750771729, 0.0059886364744088311, 0.0059807222319930489, 0.00597385082673521, 0.0059678948647625, 0.0059627075983366791, 0.0059581933732533697, 0.0059542433354108212, 0.0059508033238319857, 0.0059477670879939416, 0.0059451194379433513, 0.0059428028568101086, 0.0059407633660482333, 0.0059389812026914924, 0.0059374108035541804, 0.0059360245512938758, 0.005934819632861181, 0.0059337481177449284, 0.005932823556928167, 0.0059319872132549386, 0.0059312507149943787, 0.0059306067601975791, 0.0059300361738363278, 0.005929539013241213, 0.0059290834970721611, 0.0059286823481847061, 0.005928323932063247, 0.0059280159474357011, 0.0059277331269148, 0.0059274751676752406, 0.0059272404675409941, 0.0059270389126158517, 0.005926858281644143, 0.0059267026863414462, 0.0059265584110917962, 0.0059264342641839208, 0.0059263051347344985, 0.0059262015522231421, 0.0059261044025460848, 0.0059259885750767094, 0.0059259066493235028, 0.0059258251744283121, 0.0059257512596408123, 0.0059256793250689523, 0.0059256046774767363, 0.0059255430486343475, 0.0059254737898607451, 0.0059254040115179875, 0.0059253022589647883, 0.0059251952419233419, 0.005925025306700242, 0.0059249300057207426, 0.005924866926414466, 0.0059247995343932776, 0.0059247443350480345, 0.0059246995113413532, 0.0059246343935475997, 0.0059245790659358611, 0.0059245277780769767, 0.005924473760939809, 0.0059244318995131905, 0.0059243793267645803, 0.0059243349357754899, 0.0059242916294469069, 0.005924242404120119, 0.0059241967941286947, 0.0059241521464354768, 0.0059241144700562503, 0.0059240765775321483, 0.0059240400470801464, 0.0059240137475711462, 0.0059239811898722222, 0.0059239511142455065, 0.0059239258089515924, 0.0059238983961167916, 0.0059238754462543845], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.009856132846346212, 0.0089649999496160416, 0.0083354987286152881, 0.007878217198676209, 0.0075369464010946758, 0.0072759739813746133, 0.0070720508533350579, 0.0069098611672871743, 0.006778963959928018, 0.0066712794009112786, 0.0065791447635713063, 0.0064980785471707402, 0.0064264933485046211, 0.0063663417191878076, 0.0063124755149947488, 0.0062642035582546945, 0.0062233400912924536, 0.0061867665273677075, 0.0061548983089386227, 0.0061258758209980458, 0.0061001196027289503, 0.0060786035924014084, 0.0060604706405335863, 0.0060451100705568956, 0.0060320155367797517, 0.0060207722440514698, 0.0060111018002551768, 0.0060027619014236117, 0.0059955587249481967, 0.0059893093426482431, 0.0059838985300190656, 0.005979188734877453, 0.0059751009625615119, 0.0059715232946645326, 0.0059684049553585718, 0.0059656750429542835, 0.0059632961440507226, 0.0059612152054407475, 0.005959395949269356, 0.0059577980663705577, 0.0059563976075105631, 0.0059551753754641459, 0.0059541006178387189, 0.005953155469233487, 0.0059523311594751032, 0.0059515977703259847, 0.0059509612116891795, 0.0059503916471764923, 0.0059499002383123136, 0.0059494610829661778, 0.0059490735429757842, 0.0059487268002183652, 0.0059484284960087406, 0.0059481612193473966, 0.0059479171103496405, 0.005947702256106439, 0.005947505438621898, 0.0059473372382440274, 0.0059471838428886139, 0.0059470547957827568, 0.0059469339042367911, 0.0059468306818131296, 0.0059467351157938405, 0.005946649722476027, 0.0059465637502109725, 0.0059464585802062745, 0.0059463883046190205, 0.005946324571152746, 0.0059462631254111591, 0.0059462014449241556, 0.0059461434629777907, 0.0059460827902899542, 0.0059460135973208967, 0.0059459411915918905, 0.0059458531126196151, 0.005945720432646965, 0.0059455873768644507, 0.0059455172461711902, 0.0059454569508364677, 0.0059453998847230237, 0.0059453526565973582, 0.0059453013215986323, 0.0059452540026498678, 0.0059452065746447959, 0.0059451584151393984, 0.0059451134054636584, 0.0059450642386163523, 0.0059450155366301298, 0.0059449719644628432, 0.0059449314917695509, 0.0059448823262940225, 0.0059448462812982409, 0.005944805813863429, 0.0059447725543189198, 0.0059447377985653131, 0.005944710611650951, 0.0059446822881618127, 0.0059446511798501344, 0.0059446307725457238, 0.0059446050077644761, 0.0059445777824403455], 'acc': [0.59150607592198867, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.59383822270254427, 0.59383822272449271]}
[2017-11-18 17:45:57,787 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:95]: done!
[2017-11-18 17:45:57,787 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 17:45:57,787 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 17:45:57,787 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f60886ab390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:45:57,824 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 17:49:23,866 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 17:49:23,867 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0093540846230171261, 0.008611324872001485, 0.0080784504053356427, 0.0076853812772141291, 0.007387902681434781, 0.0071575912821165823, 0.0069757070389289775, 0.0068298341943932037, 0.0067110923197611933, 0.0066108807244737531, 0.0065260269570971115, 0.006447211283750939, 0.0063814485347386514, 0.0063244263642905328, 0.0062727445783760999, 0.0062276047633229069, 0.006189172862348164, 0.006154081828085153, 0.0061241851280827058, 0.0060957337065453707, 0.0060719618206184515, 0.006052014484432708, 0.0060351260611564966, 0.0060207736703236231, 0.0060084271465470273, 0.005997793750771729, 0.0059886364744088311, 0.0059807222319930489, 0.00597385082673521, 0.0059678948647625, 0.0059627075983366791, 0.0059581933732533697, 0.0059542433354108212, 0.0059508033238319857, 0.0059477670879939416, 0.0059451194379433513, 0.0059428028568101086, 0.0059407633660482333, 0.0059389812026914924, 0.0059374108035541804, 0.0059360245512938758, 0.005934819632861181, 0.0059337481177449284, 0.005932823556928167, 0.0059319872132549386, 0.0059312507149943787, 0.0059306067601975791, 0.0059300361738363278, 0.005929539013241213, 0.0059290834970721611, 0.0059286823481847061, 0.005928323932063247, 0.0059280159474357011, 0.0059277331269148, 0.0059274751676752406, 0.0059272404675409941, 0.0059270389126158517, 0.005926858281644143, 0.0059267026863414462, 0.0059265584110917962, 0.0059264342641839208, 0.0059263051347344985, 0.0059262015522231421, 0.0059261044025460848, 0.0059259885750767094, 0.0059259066493235028, 0.0059258251744283121, 0.0059257512596408123, 0.0059256793250689523, 0.0059256046774767363, 0.0059255430486343475, 0.0059254737898607451, 0.0059254040115179875, 0.0059253022589647883, 0.0059251952419233419, 0.005925025306700242, 0.0059249300057207426, 0.005924866926414466, 0.0059247995343932776, 0.0059247443350480345, 0.0059246995113413532, 0.0059246343935475997, 0.0059245790659358611, 0.0059245277780769767, 0.005924473760939809, 0.0059244318995131905, 0.0059243793267645803, 0.0059243349357754899, 0.0059242916294469069, 0.005924242404120119, 0.0059241967941286947, 0.0059241521464354768, 0.0059241144700562503, 0.0059240765775321483, 0.0059240400470801464, 0.0059240137475711462, 0.0059239811898722222, 0.0059239511142455065, 0.0059239258089515924, 0.0059238983961167916, 0.0059238754462543845], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.009856132846346212, 0.0089649999496160416, 0.0083354987286152881, 0.007878217198676209, 0.0075369464010946758, 0.0072759739813746133, 0.0070720508533350579, 0.0069098611672871743, 0.006778963959928018, 0.0066712794009112786, 0.0065791447635713063, 0.0064980785471707402, 0.0064264933485046211, 0.0063663417191878076, 0.0063124755149947488, 0.0062642035582546945, 0.0062233400912924536, 0.0061867665273677075, 0.0061548983089386227, 0.0061258758209980458, 0.0061001196027289503, 0.0060786035924014084, 0.0060604706405335863, 0.0060451100705568956, 0.0060320155367797517, 0.0060207722440514698, 0.0060111018002551768, 0.0060027619014236117, 0.0059955587249481967, 0.0059893093426482431, 0.0059838985300190656, 0.005979188734877453, 0.0059751009625615119, 0.0059715232946645326, 0.0059684049553585718, 0.0059656750429542835, 0.0059632961440507226, 0.0059612152054407475, 0.005959395949269356, 0.0059577980663705577, 0.0059563976075105631, 0.0059551753754641459, 0.0059541006178387189, 0.005953155469233487, 0.0059523311594751032, 0.0059515977703259847, 0.0059509612116891795, 0.0059503916471764923, 0.0059499002383123136, 0.0059494610829661778, 0.0059490735429757842, 0.0059487268002183652, 0.0059484284960087406, 0.0059481612193473966, 0.0059479171103496405, 0.005947702256106439, 0.005947505438621898, 0.0059473372382440274, 0.0059471838428886139, 0.0059470547957827568, 0.0059469339042367911, 0.0059468306818131296, 0.0059467351157938405, 0.005946649722476027, 0.0059465637502109725, 0.0059464585802062745, 0.0059463883046190205, 0.005946324571152746, 0.0059462631254111591, 0.0059462014449241556, 0.0059461434629777907, 0.0059460827902899542, 0.0059460135973208967, 0.0059459411915918905, 0.0059458531126196151, 0.005945720432646965, 0.0059455873768644507, 0.0059455172461711902, 0.0059454569508364677, 0.0059453998847230237, 0.0059453526565973582, 0.0059453013215986323, 0.0059452540026498678, 0.0059452065746447959, 0.0059451584151393984, 0.0059451134054636584, 0.0059450642386163523, 0.0059450155366301298, 0.0059449719644628432, 0.0059449314917695509, 0.0059448823262940225, 0.0059448462812982409, 0.005944805813863429, 0.0059447725543189198, 0.0059447377985653131, 0.005944710611650951, 0.0059446822881618127, 0.0059446511798501344, 0.0059446307725457238, 0.0059446050077644761, 0.0059445777824403455], 'acc': [0.59150607592198867, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.59383822270254427, 0.59383822272449271]}
[2017-11-18 17:49:23,867 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 17:49:24,016 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 17:49:24,016 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 17:49:24,891 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:141]: done!
[2017-11-18 17:49:24,891 AE_UNIGRAMA_9L_9FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_9L_9FULLDS_UNDER_02 finished!
