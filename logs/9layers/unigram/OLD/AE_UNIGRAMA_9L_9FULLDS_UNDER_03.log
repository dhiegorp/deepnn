[2017-11-18 18:07:47,345 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_9FULLDS_UNDER_03
[2017-11-18 18:07:47,345 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 18:07:47,345 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_9FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48,40,32,24,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9c85b17eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9c85b1c400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:07:47,345 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 18:07:49,784 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:07:49,784 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:07:49,785 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 18:07:49,785 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9c85b17eb8>, 'discard_decoder_function': True}
[2017-11-18 18:07:50,034 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 18:09:51,290 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 18:09:51,291 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0094672230187665234, 0.0087081321745492088, 0.0081021606638748307, 0.007614208609194319, 0.0072208244986051761, 0.0069016898747428137, 0.0066419032166853348, 0.0064294109816119783, 0.0062551983310069198, 0.006111793935905426, 0.0059935770398680116, 0.0058955760826368692, 0.005814061880225329, 0.0057461286673526997, 0.0056892855809772174, 0.0056416035114860421, 0.0056014453026355521, 0.0055675518104976998, 0.0055388516447144381, 0.0055144563708687117, 0.0054937038394030028, 0.0054760071169516538, 0.005460862958090478, 0.0054478844492882768, 0.0054367230035390641, 0.0054192978040599636, 0.0054049155184912167, 0.0053929346300406918, 0.0053828982993151253, 0.0053744864414245145, 0.0053673125354238389, 0.0053612204924539325, 0.0053560195330021104, 0.0053515482844681489, 0.0053477104447264522, 0.0053444124624072867, 0.005341576503278966, 0.0053391347011022107, 0.0053370262665426967, 0.0053351968960670187, 0.0053336107251136808, 0.0053322216414924172, 0.005331013816741159, 0.0053299667933378722, 0.0053290479713985857, 0.0053282486934054648, 0.005327563165717487, 0.0053269435960158719, 0.0053264103766198067, 0.0053259268939907182, 0.0053255160261994278, 0.0053251492250943472, 0.0053248322083320754, 0.0053245459253003346, 0.0053243109202871525, 0.005324091640027573, 0.0053239004273694561, 0.0053237281360303057, 0.0053235787818894931, 0.0053234539891996013, 0.0053233377344034218, 0.0053232249040403041, 0.0053231318611158783, 0.0053230495354176415, 0.0053229779599748553, 0.0053229167608551762, 0.0053228550079391255, 0.0053227962526427404, 0.0053227523410913921, 0.0053227123880032583, 0.0053226664341994396, 0.0053226293147826008, 0.005322594492439864, 0.0053225649054066708, 0.0053225214714105679, 0.0053224888237796307, 0.0053224677199621723, 0.0053224391525577737, 0.0053224121438608376, 0.0053223910964327187, 0.0053223686738405893, 0.0053223450844426317, 0.0053223255164859679, 0.0053223038533957824, 0.0053222849902630851, 0.0053222768723373247, 0.0053222536465179797, 0.0053222344144158822, 0.0053222170776459268, 0.0053221986042756627, 0.0053221844191478481, 0.0053221651973994841, 0.0053221474805362837, 0.0053221291987528667, 0.0053221074701175616, 0.0053220866972772908, 0.0053220620151754302, 0.0053220440361317475, 0.0053220237213372091, 0.0053220061756956618, 0.0053219953441505695], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099290468194696297, 0.009076978673725658, 0.0083999737753789241, 0.0078563608388172185, 0.0074189676197523044, 0.0070654376820566593, 0.0067782926932068721, 0.0065442074385288849, 0.0063525684752535954, 0.006195152959119557, 0.006065715853960727, 0.0059587626348862228, 0.0058699973229132752, 0.0057961418497125454, 0.0057345271436103186, 0.0056829414927946275, 0.0056396549550661633, 0.0056031672388605104, 0.0055723553888657037, 0.0055462583952997305, 0.0055240503776047114, 0.0055051710312801726, 0.0054890616859555267, 0.0054752788180308177, 0.0054634713054062716, 0.0054493580052723534, 0.0054336714880556742, 0.0054207366231723304, 0.0054099319137589866, 0.0054008701880903379, 0.0053932330339284624, 0.0053867284933063276, 0.0053811850842686096, 0.0053764500483075789, 0.0053723853630633011, 0.00536889098337732, 0.0053658823347114901, 0.0053632968414368638, 0.0053610618349004225, 0.0053591333206560558, 0.005357457111208142, 0.005356001518326086, 0.0053547374690158453, 0.005353628512807085, 0.0053526713453165564, 0.005351828490727439, 0.0053510959714566974, 0.0053504571483582643, 0.0053498958058223606, 0.005349400723623954, 0.0053489623223553157, 0.0053485829498707092, 0.0053482490388910408, 0.0053479541413192448, 0.0053476970754833594, 0.0053474717195407225, 0.0053472747884272826, 0.0053470979367062858, 0.005346939714923382, 0.005346799878959343, 0.0053466820610522294, 0.0053465686722715617, 0.0053464758681546981, 0.0053463881475021239, 0.0053463102675237271, 0.00534623799251368, 0.0053461820117048295, 0.0053461235829019588, 0.0053460731581347299, 0.0053460232760197983, 0.0053459850151461735, 0.0053459453424849228, 0.0053459041578962901, 0.0053458677869890493, 0.0053458429731925204, 0.0053458109169254656, 0.0053457834754892294, 0.0053457552388793302, 0.0053457325075552866, 0.0053457049824977834, 0.0053456837536129936, 0.0053456644018913309, 0.0053456435264107073, 0.0053456239566335882, 0.0053456026698483587, 0.0053455775321408789, 0.0053455669749416139, 0.0053455467055579945, 0.0053455271393817909, 0.0053455146232271678, 0.0053454929378834318, 0.0053454724085479849, 0.0053454496681930733, 0.0053454375569985859, 0.0053454175252754099, 0.0053454010858372761, 0.0053453766135561753, 0.0053453553179115499, 0.0053453430196409128, 0.0053453199406284426, 0.0053453040952271035], 'acc': [0.58941941816148047, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822267327968, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539]}
[2017-11-18 18:09:51,291 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:95]: done!
[2017-11-18 18:09:51,291 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 18:09:51,291 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 18:09:51,291 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9c85b1c400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:09:51,332 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 18:16:50,052 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 18:16:50,053 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0094672230187665234, 0.0087081321745492088, 0.0081021606638748307, 0.007614208609194319, 0.0072208244986051761, 0.0069016898747428137, 0.0066419032166853348, 0.0064294109816119783, 0.0062551983310069198, 0.006111793935905426, 0.0059935770398680116, 0.0058955760826368692, 0.005814061880225329, 0.0057461286673526997, 0.0056892855809772174, 0.0056416035114860421, 0.0056014453026355521, 0.0055675518104976998, 0.0055388516447144381, 0.0055144563708687117, 0.0054937038394030028, 0.0054760071169516538, 0.005460862958090478, 0.0054478844492882768, 0.0054367230035390641, 0.0054192978040599636, 0.0054049155184912167, 0.0053929346300406918, 0.0053828982993151253, 0.0053744864414245145, 0.0053673125354238389, 0.0053612204924539325, 0.0053560195330021104, 0.0053515482844681489, 0.0053477104447264522, 0.0053444124624072867, 0.005341576503278966, 0.0053391347011022107, 0.0053370262665426967, 0.0053351968960670187, 0.0053336107251136808, 0.0053322216414924172, 0.005331013816741159, 0.0053299667933378722, 0.0053290479713985857, 0.0053282486934054648, 0.005327563165717487, 0.0053269435960158719, 0.0053264103766198067, 0.0053259268939907182, 0.0053255160261994278, 0.0053251492250943472, 0.0053248322083320754, 0.0053245459253003346, 0.0053243109202871525, 0.005324091640027573, 0.0053239004273694561, 0.0053237281360303057, 0.0053235787818894931, 0.0053234539891996013, 0.0053233377344034218, 0.0053232249040403041, 0.0053231318611158783, 0.0053230495354176415, 0.0053229779599748553, 0.0053229167608551762, 0.0053228550079391255, 0.0053227962526427404, 0.0053227523410913921, 0.0053227123880032583, 0.0053226664341994396, 0.0053226293147826008, 0.005322594492439864, 0.0053225649054066708, 0.0053225214714105679, 0.0053224888237796307, 0.0053224677199621723, 0.0053224391525577737, 0.0053224121438608376, 0.0053223910964327187, 0.0053223686738405893, 0.0053223450844426317, 0.0053223255164859679, 0.0053223038533957824, 0.0053222849902630851, 0.0053222768723373247, 0.0053222536465179797, 0.0053222344144158822, 0.0053222170776459268, 0.0053221986042756627, 0.0053221844191478481, 0.0053221651973994841, 0.0053221474805362837, 0.0053221291987528667, 0.0053221074701175616, 0.0053220866972772908, 0.0053220620151754302, 0.0053220440361317475, 0.0053220237213372091, 0.0053220061756956618, 0.0053219953441505695], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099290468194696297, 0.009076978673725658, 0.0083999737753789241, 0.0078563608388172185, 0.0074189676197523044, 0.0070654376820566593, 0.0067782926932068721, 0.0065442074385288849, 0.0063525684752535954, 0.006195152959119557, 0.006065715853960727, 0.0059587626348862228, 0.0058699973229132752, 0.0057961418497125454, 0.0057345271436103186, 0.0056829414927946275, 0.0056396549550661633, 0.0056031672388605104, 0.0055723553888657037, 0.0055462583952997305, 0.0055240503776047114, 0.0055051710312801726, 0.0054890616859555267, 0.0054752788180308177, 0.0054634713054062716, 0.0054493580052723534, 0.0054336714880556742, 0.0054207366231723304, 0.0054099319137589866, 0.0054008701880903379, 0.0053932330339284624, 0.0053867284933063276, 0.0053811850842686096, 0.0053764500483075789, 0.0053723853630633011, 0.00536889098337732, 0.0053658823347114901, 0.0053632968414368638, 0.0053610618349004225, 0.0053591333206560558, 0.005357457111208142, 0.005356001518326086, 0.0053547374690158453, 0.005353628512807085, 0.0053526713453165564, 0.005351828490727439, 0.0053510959714566974, 0.0053504571483582643, 0.0053498958058223606, 0.005349400723623954, 0.0053489623223553157, 0.0053485829498707092, 0.0053482490388910408, 0.0053479541413192448, 0.0053476970754833594, 0.0053474717195407225, 0.0053472747884272826, 0.0053470979367062858, 0.005346939714923382, 0.005346799878959343, 0.0053466820610522294, 0.0053465686722715617, 0.0053464758681546981, 0.0053463881475021239, 0.0053463102675237271, 0.00534623799251368, 0.0053461820117048295, 0.0053461235829019588, 0.0053460731581347299, 0.0053460232760197983, 0.0053459850151461735, 0.0053459453424849228, 0.0053459041578962901, 0.0053458677869890493, 0.0053458429731925204, 0.0053458109169254656, 0.0053457834754892294, 0.0053457552388793302, 0.0053457325075552866, 0.0053457049824977834, 0.0053456837536129936, 0.0053456644018913309, 0.0053456435264107073, 0.0053456239566335882, 0.0053456026698483587, 0.0053455775321408789, 0.0053455669749416139, 0.0053455467055579945, 0.0053455271393817909, 0.0053455146232271678, 0.0053454929378834318, 0.0053454724085479849, 0.0053454496681930733, 0.0053454375569985859, 0.0053454175252754099, 0.0053454010858372761, 0.0053453766135561753, 0.0053453553179115499, 0.0053453430196409128, 0.0053453199406284426, 0.0053453040952271035], 'acc': [0.58941941816148047, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822267327968, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539]}
[2017-11-18 18:16:50,053 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 18:16:50,236 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 18:16:50,236 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 18:16:51,097 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:141]: done!
[2017-11-18 18:16:51,098 AE_UNIGRAMA_9L_9FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_9L_9FULLDS_UNDER_03 finished!
