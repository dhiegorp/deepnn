[2017-10-20 01:48:45,498 AE_UNIGRAMA_9L_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_UNDER_03
[2017-10-20 01:48:45,498 AE_UNIGRAMA_9L_UNDER_03.py:149]: >> Printing header log
[2017-10-20 01:48:45,498 AE_UNIGRAMA_9L_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_UNDER_03
	layers = 96,86,78,71,63,55,48,40,32,24,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f88747037b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8874703898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:48:45,498 AE_UNIGRAMA_9L_UNDER_03.py:151]: >> Loading dataset... 
[2017-10-20 01:48:46,029 AE_UNIGRAMA_9L_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:48:46,029 AE_UNIGRAMA_9L_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:48:46,029 AE_UNIGRAMA_9L_UNDER_03.py:60]: =======================================
[2017-10-20 01:48:46,029 AE_UNIGRAMA_9L_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f88747037b8>, 'discard_decoder_function': True}
[2017-10-20 01:48:46,234 AE_UNIGRAMA_9L_UNDER_03.py:76]: training and evaluate autoencoder
[2017-10-20 01:49:36,075 AE_UNIGRAMA_9L_UNDER_03.py:88]: trained and evaluated!
[2017-10-20 01:49:36,076 AE_UNIGRAMA_9L_UNDER_03.py:91]: Training history: 
{'val_loss': [0.010149107041135154, 0.0098965870715040701, 0.0096627794531586007, 0.0094459921530132846, 0.0092447981113727203, 0.0090579365702089763, 0.0088840602519731533, 0.0087221111638339927, 0.0085712329771882104, 0.0084304197528659187, 0.0082938282934041721, 0.0081648685221584541, 0.0080440300724514135, 0.0079305365605480613, 0.0078238749177260911, 0.0077237553832200821, 0.0076297091313232718, 0.007541263953793005, 0.0074579699214229354, 0.0073793763017842764, 0.0073052286568572088, 0.0072351903117999269, 0.0071689964594063259, 0.0071063538940561079, 0.0070470107708915678, 0.0069907838634481884, 0.0069374297122336013, 0.0068868188201328638, 0.0068387663784717318, 0.0067930049764954913, 0.0067494726570177695, 0.006708001593287106, 0.0066684744680875077, 0.0066307883235352414, 0.0065948639331614, 0.0065604931186732307, 0.006527619197493814, 0.0064961997459756842, 0.0064661088624629829, 0.0064372929734035937, 0.0064096735136022574, 0.006383206324866492, 0.0063578105708203348, 0.0063333955583020655, 0.0063099717465142776, 0.0062874598968704837, 0.0062658051946321604, 0.0062449888973652654, 0.0062249468511392861, 0.0062056694103605689, 0.0061870677583612029, 0.0061691663726527231, 0.0061518766425660773, 0.0061352086222304734, 0.0061191249773820313, 0.0061035819047002542, 0.006088582845577852, 0.0060740996958847165, 0.0060601254274244643, 0.0060466037523070676, 0.0060335589749357732, 0.0060209117615145375, 0.0060086649181286637, 0.0059968320112744672, 0.0059854060871921289, 0.00597434391901174, 0.0059636373048627461, 0.0059532918153697677, 0.0059432789897996257, 0.0059335673362930687, 0.005924164864570456, 0.0059150484162053879, 0.0059062093548255118, 0.0058976212104429318, 0.005889314784214842, 0.0058812918002997634, 0.0058734738891147989, 0.0058659172762309973, 0.0058585831507708061, 0.0058514615815119008, 0.0058445331734020027, 0.0058378245868481223, 0.0058313201278531197, 0.0058250224224696816, 0.005818893807528187, 0.0058129412783344443, 0.0058071552568070284, 0.0058015426343867773, 0.005796098212631883, 0.0057908217059136763, 0.0057856728492450098, 0.0057806877841736744, 0.005775849404138925, 0.0057711491749022972, 0.0057658909951582493, 0.0057606771034378985, 0.0057556509389974815, 0.0057507957362995712, 0.0057460958896322547, 0.0057415605720035649, 0.0057370313148959419, 0.0057323258335539402], 'loss': [0.010278571085671229, 0.010017196349021146, 0.0097734089379817625, 0.0095476061758283607, 0.0093380856953364389, 0.0091434612340158157, 0.0089625377487333995, 0.0087940703004772639, 0.0086370442702578629, 0.008490632940713401, 0.0083518251307313253, 0.0082181607222513112, 0.0080927095262044099, 0.0079750378353414756, 0.0078644275032189927, 0.0077604475719070028, 0.0076629090461749457, 0.0075711360471420446, 0.0074847307904510685, 0.0074032870597551224, 0.0073264108812774184, 0.0072537932302241832, 0.0071851573060206569, 0.0071202368056487476, 0.0070587310272588934, 0.0070004317644450035, 0.0069451404068007674, 0.0068926339884321239, 0.0068427810898209797, 0.0067954015716012815, 0.0067502384136425763, 0.0067072396939958099, 0.0066662495506477452, 0.0066271389098454449, 0.006589818535488243, 0.0065541855275937765, 0.0065200984919902803, 0.0064874625090479889, 0.0064562252921881707, 0.0064262978634702589, 0.0063976117827057762, 0.0063700872698378621, 0.0063437012037961815, 0.0063183456106934545, 0.0062939495772132495, 0.0062705351411265946, 0.006248001633446661, 0.0062263178880673908, 0.0062054525514161326, 0.0061853501073370403, 0.0061659884711208887, 0.0061473022049067386, 0.0061292998760608935, 0.006111898005281168, 0.0060951107201070859, 0.006078900646283243, 0.0060632161366207769, 0.0060480731403765387, 0.0060334481274881974, 0.0060193100949885586, 0.0060056290419265102, 0.0059924166699380291, 0.0059796008727895054, 0.0059671813270652961, 0.0059551713838211654, 0.0059435714142695847, 0.0059323231191629085, 0.0059214454955926832, 0.0059109123068224563, 0.0059007156042687791, 0.0058908171181297408, 0.0058812258201843036, 0.0058719260994741064, 0.0058628842369129524, 0.0058541043378760749, 0.0058456188572665706, 0.0058373879207974759, 0.0058293822625011997, 0.0058216321978720332, 0.005814110200804073, 0.0058067910428735367, 0.0057996666117856926, 0.0057927731275169226, 0.0057860848584888385, 0.0057795904359259926, 0.0057732789853350763, 0.0057671371971605634, 0.0057611719255244616, 0.00575537028760817, 0.0057497405837454276, 0.0057442793940304425, 0.0057389495139294738, 0.0057337817678155892, 0.0057287559433558018, 0.005723616045046215, 0.005718096469648608, 0.0057127636026753628, 0.0057076091798550161, 0.0057026116451055053, 0.0056977754755869513, 0.0056930832492133815, 0.0056882110944094476]}
[2017-10-20 01:49:36,076 AE_UNIGRAMA_9L_UNDER_03.py:95]: done!
[2017-10-20 01:49:36,076 AE_UNIGRAMA_9L_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-10-20 01:49:36,076 AE_UNIGRAMA_9L_UNDER_03.py:100]: =======================================
[2017-10-20 01:49:36,076 AE_UNIGRAMA_9L_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8874703898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:49:36,108 AE_UNIGRAMA_9L_UNDER_03.py:113]: training ... 
[2017-10-20 01:50:55,470 AE_UNIGRAMA_9L_UNDER_03.py:125]: trained!
[2017-10-20 01:50:55,471 AE_UNIGRAMA_9L_UNDER_03.py:128]: Training history: 
{'val_loss': [0.010149107041135154, 0.0098965870715040701, 0.0096627794531586007, 0.0094459921530132846, 0.0092447981113727203, 0.0090579365702089763, 0.0088840602519731533, 0.0087221111638339927, 0.0085712329771882104, 0.0084304197528659187, 0.0082938282934041721, 0.0081648685221584541, 0.0080440300724514135, 0.0079305365605480613, 0.0078238749177260911, 0.0077237553832200821, 0.0076297091313232718, 0.007541263953793005, 0.0074579699214229354, 0.0073793763017842764, 0.0073052286568572088, 0.0072351903117999269, 0.0071689964594063259, 0.0071063538940561079, 0.0070470107708915678, 0.0069907838634481884, 0.0069374297122336013, 0.0068868188201328638, 0.0068387663784717318, 0.0067930049764954913, 0.0067494726570177695, 0.006708001593287106, 0.0066684744680875077, 0.0066307883235352414, 0.0065948639331614, 0.0065604931186732307, 0.006527619197493814, 0.0064961997459756842, 0.0064661088624629829, 0.0064372929734035937, 0.0064096735136022574, 0.006383206324866492, 0.0063578105708203348, 0.0063333955583020655, 0.0063099717465142776, 0.0062874598968704837, 0.0062658051946321604, 0.0062449888973652654, 0.0062249468511392861, 0.0062056694103605689, 0.0061870677583612029, 0.0061691663726527231, 0.0061518766425660773, 0.0061352086222304734, 0.0061191249773820313, 0.0061035819047002542, 0.006088582845577852, 0.0060740996958847165, 0.0060601254274244643, 0.0060466037523070676, 0.0060335589749357732, 0.0060209117615145375, 0.0060086649181286637, 0.0059968320112744672, 0.0059854060871921289, 0.00597434391901174, 0.0059636373048627461, 0.0059532918153697677, 0.0059432789897996257, 0.0059335673362930687, 0.005924164864570456, 0.0059150484162053879, 0.0059062093548255118, 0.0058976212104429318, 0.005889314784214842, 0.0058812918002997634, 0.0058734738891147989, 0.0058659172762309973, 0.0058585831507708061, 0.0058514615815119008, 0.0058445331734020027, 0.0058378245868481223, 0.0058313201278531197, 0.0058250224224696816, 0.005818893807528187, 0.0058129412783344443, 0.0058071552568070284, 0.0058015426343867773, 0.005796098212631883, 0.0057908217059136763, 0.0057856728492450098, 0.0057806877841736744, 0.005775849404138925, 0.0057711491749022972, 0.0057658909951582493, 0.0057606771034378985, 0.0057556509389974815, 0.0057507957362995712, 0.0057460958896322547, 0.0057415605720035649, 0.0057370313148959419, 0.0057323258335539402], 'loss': [0.010278571085671229, 0.010017196349021146, 0.0097734089379817625, 0.0095476061758283607, 0.0093380856953364389, 0.0091434612340158157, 0.0089625377487333995, 0.0087940703004772639, 0.0086370442702578629, 0.008490632940713401, 0.0083518251307313253, 0.0082181607222513112, 0.0080927095262044099, 0.0079750378353414756, 0.0078644275032189927, 0.0077604475719070028, 0.0076629090461749457, 0.0075711360471420446, 0.0074847307904510685, 0.0074032870597551224, 0.0073264108812774184, 0.0072537932302241832, 0.0071851573060206569, 0.0071202368056487476, 0.0070587310272588934, 0.0070004317644450035, 0.0069451404068007674, 0.0068926339884321239, 0.0068427810898209797, 0.0067954015716012815, 0.0067502384136425763, 0.0067072396939958099, 0.0066662495506477452, 0.0066271389098454449, 0.006589818535488243, 0.0065541855275937765, 0.0065200984919902803, 0.0064874625090479889, 0.0064562252921881707, 0.0064262978634702589, 0.0063976117827057762, 0.0063700872698378621, 0.0063437012037961815, 0.0063183456106934545, 0.0062939495772132495, 0.0062705351411265946, 0.006248001633446661, 0.0062263178880673908, 0.0062054525514161326, 0.0061853501073370403, 0.0061659884711208887, 0.0061473022049067386, 0.0061292998760608935, 0.006111898005281168, 0.0060951107201070859, 0.006078900646283243, 0.0060632161366207769, 0.0060480731403765387, 0.0060334481274881974, 0.0060193100949885586, 0.0060056290419265102, 0.0059924166699380291, 0.0059796008727895054, 0.0059671813270652961, 0.0059551713838211654, 0.0059435714142695847, 0.0059323231191629085, 0.0059214454955926832, 0.0059109123068224563, 0.0059007156042687791, 0.0058908171181297408, 0.0058812258201843036, 0.0058719260994741064, 0.0058628842369129524, 0.0058541043378760749, 0.0058456188572665706, 0.0058373879207974759, 0.0058293822625011997, 0.0058216321978720332, 0.005814110200804073, 0.0058067910428735367, 0.0057996666117856926, 0.0057927731275169226, 0.0057860848584888385, 0.0057795904359259926, 0.0057732789853350763, 0.0057671371971605634, 0.0057611719255244616, 0.00575537028760817, 0.0057497405837454276, 0.0057442793940304425, 0.0057389495139294738, 0.0057337817678155892, 0.0057287559433558018, 0.005723616045046215, 0.005718096469648608, 0.0057127636026753628, 0.0057076091798550161, 0.0057026116451055053, 0.0056977754755869513, 0.0056930832492133815, 0.0056882110944094476]}
[2017-10-20 01:50:55,471 AE_UNIGRAMA_9L_UNDER_03.py:132]: evaluating model ... 
[2017-10-20 01:50:55,544 AE_UNIGRAMA_9L_UNDER_03.py:136]: evaluated! 
[2017-10-20 01:50:55,544 AE_UNIGRAMA_9L_UNDER_03.py:138]: generating reports ... 
[2017-10-20 01:50:56,130 AE_UNIGRAMA_9L_UNDER_03.py:141]: done!
[2017-10-20 01:50:56,130 AE_UNIGRAMA_9L_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_9L_UNDER_03 finished!
