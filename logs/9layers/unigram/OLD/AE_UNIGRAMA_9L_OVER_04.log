[2017-10-20 01:45:46,550 AE_UNIGRAMA_9L_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_OVER_04
[2017-10-20 01:45:46,550 AE_UNIGRAMA_9L_OVER_04.py:149]: >> Printing header log
[2017-10-20 01:45:46,550 AE_UNIGRAMA_9L_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,34,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f33329577f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f33329578d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:45:46,551 AE_UNIGRAMA_9L_OVER_04.py:151]: >> Loading dataset... 
[2017-10-20 01:45:47,055 AE_UNIGRAMA_9L_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:45:47,055 AE_UNIGRAMA_9L_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:45:47,055 AE_UNIGRAMA_9L_OVER_04.py:60]: =======================================
[2017-10-20 01:45:47,055 AE_UNIGRAMA_9L_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f33329577f0>, 'discard_decoder_function': True}
[2017-10-20 01:45:47,247 AE_UNIGRAMA_9L_OVER_04.py:76]: training and evaluate autoencoder
[2017-10-20 01:46:49,010 AE_UNIGRAMA_9L_OVER_04.py:88]: trained and evaluated!
[2017-10-20 01:46:49,011 AE_UNIGRAMA_9L_OVER_04.py:91]: Training history: 
{'val_loss': [0.010311209953296584, 0.010215241984779286, 0.010125441795221936, 0.010041079888999684, 0.0099624453846462162, 0.0098890434867498159, 0.0098204956109528199, 0.0097563704787355376, 0.0096963488161009928, 0.0096400437537289899, 0.009587310718504027, 0.0095373542466959099, 0.0094897361943103564, 0.0094450372600145497, 0.0094029567062467005, 0.009363377646830446, 0.009326015384417706, 0.0092908159196099828, 0.0092575869152537061, 0.0092261603697580477, 0.0091964797182597195, 0.0091684182835777457, 0.0091411304559738671, 0.0091152562237029628, 0.009090763225902191, 0.0090674409525101952, 0.0090453335080558934, 0.0090243395341761054, 0.009004388880469321, 0.008985399798278915, 0.0089673568913539985, 0.0089501622496484384, 0.0089338142078605291, 0.0089182301344813905, 0.008903341419773253, 0.0088891743935062984, 0.0088756346008757678, 0.0088626832067689489, 0.0088503334539696624, 0.0088385459811160111, 0.0088272316132059336, 0.0088164326440556794, 0.0088060838637741973, 0.0087961648248108346, 0.0087866670933299355, 0.0087775460974102125, 0.008768796356443358, 0.0087604038348096016, 0.0087523305456268293, 0.0087445788881758777, 0.0087371367102551199, 0.0087299921297118565, 0.0087231106079810172, 0.0087164983042553896, 0.0087101439491856052, 0.0087040263958635383, 0.0086981449795533738, 0.008692475963647037, 0.0086870098964321567, 0.0086817428414263254, 0.0086766705955603745, 0.0086717732583058375, 0.0086670534747573073, 0.0086624997297516538, 0.0086581016714134176, 0.0086538547954650175, 0.0086497359746395431, 0.0086458083657637852, 0.008642007094776763, 0.0086383402527597311, 0.0086347860903877305, 0.008631357455757693, 0.0086280450771898578, 0.0086248383985409946, 0.0086217340026535517, 0.0086187324573227028, 0.0086158275548853403, 0.0086130179277860101, 0.0086102986735980755, 0.0086076638027748655, 0.0086051131595189252, 0.0086026437421325864, 0.0086002527151021364, 0.0085979417316117031, 0.0085956982776633425, 0.008593514838626394, 0.008591400786583419, 0.0085893587181586975, 0.0085873740818697732, 0.0085854560126408554, 0.0085835937517920163, 0.0085817843114742564, 0.0085800283183395647, 0.0085783257620014441, 0.0085766757821117198, 0.0085750727439957031, 0.0085735154462818989, 0.0085720108808139441, 0.0085705408868016371, 0.0085691148086302123, 0.0085677294489896437, 0.0085663879359466431], 'loss': [0.010356748206443632, 0.010258279707037786, 0.010166003294380698, 0.010079399901817164, 0.0099983981117313086, 0.0099228802111318085, 0.0098523715243073202, 0.0097864837177926659, 0.0097248529861941619, 0.0096671232901005266, 0.0096129832500803664, 0.0095621735617729079, 0.0095136205659470605, 0.0094677794778510044, 0.0094247181540940105, 0.0093841681751458648, 0.0093460009200355357, 0.0093099790589211903, 0.0092760214264966546, 0.0092439637728351422, 0.0092136303824959312, 0.0091849929093856635, 0.0091575139986961335, 0.0091310874086741149, 0.0091060451996073672, 0.0090823107546157602, 0.0090597312784105183, 0.0090383126376942027, 0.0090179683253645317, 0.008998627306180236, 0.0089802150480041646, 0.008962720920478888, 0.0089460590530299079, 0.0089302082673704316, 0.0089150967669444862, 0.0089006538731266401, 0.0088868982014924606, 0.0088737591919068482, 0.0088611825099690015, 0.008849203867062734, 0.0088377404355826968, 0.0088267578750839612, 0.0088162602182447949, 0.008806196922355073, 0.0087965575425205007, 0.0087873121556386897, 0.0087784441009383669, 0.0087699321863947289, 0.0087617657438708221, 0.0087539036480621755, 0.0087463657126132886, 0.0087391119381640681, 0.0087321527970848304, 0.0087254501320536172, 0.0087190161281126225, 0.0087128218278270525, 0.0087068644629879535, 0.0087011167813909884, 0.0086955898186648704, 0.0086902590330000962, 0.0086851236241575983, 0.0086801715015440029, 0.008675397136755237, 0.0086707894277622093, 0.0086663450940426823, 0.0086620455137245041, 0.0086578856890342244, 0.0086538778702695829, 0.0086500442219919864, 0.0086463232442837365, 0.0086427336643417341, 0.0086392588025049413, 0.0086359026170374064, 0.0086326639121598672, 0.0086295260488529028, 0.0086264908714443166, 0.0086235559981066752, 0.0086207043662319249, 0.0086179557574092066, 0.0086153003781548505, 0.0086127157880024237, 0.0086102177392973003, 0.0086077949994992978, 0.0086054543082470097, 0.0086031926294402906, 0.0086009917172850028, 0.0085988519856386846, 0.0085967760968131378, 0.0085947770194895225, 0.008592827502608336, 0.0085909466002166233, 0.008589119237710819, 0.008587337795074871, 0.0085856219726146987, 0.0085839426062529478, 0.0085823272132230597, 0.0085807558018588265, 0.0085792219095715151, 0.0085777437077410468, 0.0085762967117996251, 0.0085748938824145721, 0.0085735322767897266]}
[2017-10-20 01:46:49,012 AE_UNIGRAMA_9L_OVER_04.py:95]: done!
[2017-10-20 01:46:49,012 AE_UNIGRAMA_9L_OVER_04.py:155]: >> Executing classifier part ... 
[2017-10-20 01:46:49,012 AE_UNIGRAMA_9L_OVER_04.py:100]: =======================================
[2017-10-20 01:46:49,012 AE_UNIGRAMA_9L_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f33329578d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:46:49,058 AE_UNIGRAMA_9L_OVER_04.py:113]: training ... 
[2017-10-20 01:48:30,056 AE_UNIGRAMA_9L_OVER_04.py:125]: trained!
[2017-10-20 01:48:30,057 AE_UNIGRAMA_9L_OVER_04.py:128]: Training history: 
{'val_loss': [0.010311209953296584, 0.010215241984779286, 0.010125441795221936, 0.010041079888999684, 0.0099624453846462162, 0.0098890434867498159, 0.0098204956109528199, 0.0097563704787355376, 0.0096963488161009928, 0.0096400437537289899, 0.009587310718504027, 0.0095373542466959099, 0.0094897361943103564, 0.0094450372600145497, 0.0094029567062467005, 0.009363377646830446, 0.009326015384417706, 0.0092908159196099828, 0.0092575869152537061, 0.0092261603697580477, 0.0091964797182597195, 0.0091684182835777457, 0.0091411304559738671, 0.0091152562237029628, 0.009090763225902191, 0.0090674409525101952, 0.0090453335080558934, 0.0090243395341761054, 0.009004388880469321, 0.008985399798278915, 0.0089673568913539985, 0.0089501622496484384, 0.0089338142078605291, 0.0089182301344813905, 0.008903341419773253, 0.0088891743935062984, 0.0088756346008757678, 0.0088626832067689489, 0.0088503334539696624, 0.0088385459811160111, 0.0088272316132059336, 0.0088164326440556794, 0.0088060838637741973, 0.0087961648248108346, 0.0087866670933299355, 0.0087775460974102125, 0.008768796356443358, 0.0087604038348096016, 0.0087523305456268293, 0.0087445788881758777, 0.0087371367102551199, 0.0087299921297118565, 0.0087231106079810172, 0.0087164983042553896, 0.0087101439491856052, 0.0087040263958635383, 0.0086981449795533738, 0.008692475963647037, 0.0086870098964321567, 0.0086817428414263254, 0.0086766705955603745, 0.0086717732583058375, 0.0086670534747573073, 0.0086624997297516538, 0.0086581016714134176, 0.0086538547954650175, 0.0086497359746395431, 0.0086458083657637852, 0.008642007094776763, 0.0086383402527597311, 0.0086347860903877305, 0.008631357455757693, 0.0086280450771898578, 0.0086248383985409946, 0.0086217340026535517, 0.0086187324573227028, 0.0086158275548853403, 0.0086130179277860101, 0.0086102986735980755, 0.0086076638027748655, 0.0086051131595189252, 0.0086026437421325864, 0.0086002527151021364, 0.0085979417316117031, 0.0085956982776633425, 0.008593514838626394, 0.008591400786583419, 0.0085893587181586975, 0.0085873740818697732, 0.0085854560126408554, 0.0085835937517920163, 0.0085817843114742564, 0.0085800283183395647, 0.0085783257620014441, 0.0085766757821117198, 0.0085750727439957031, 0.0085735154462818989, 0.0085720108808139441, 0.0085705408868016371, 0.0085691148086302123, 0.0085677294489896437, 0.0085663879359466431], 'loss': [0.010356748206443632, 0.010258279707037786, 0.010166003294380698, 0.010079399901817164, 0.0099983981117313086, 0.0099228802111318085, 0.0098523715243073202, 0.0097864837177926659, 0.0097248529861941619, 0.0096671232901005266, 0.0096129832500803664, 0.0095621735617729079, 0.0095136205659470605, 0.0094677794778510044, 0.0094247181540940105, 0.0093841681751458648, 0.0093460009200355357, 0.0093099790589211903, 0.0092760214264966546, 0.0092439637728351422, 0.0092136303824959312, 0.0091849929093856635, 0.0091575139986961335, 0.0091310874086741149, 0.0091060451996073672, 0.0090823107546157602, 0.0090597312784105183, 0.0090383126376942027, 0.0090179683253645317, 0.008998627306180236, 0.0089802150480041646, 0.008962720920478888, 0.0089460590530299079, 0.0089302082673704316, 0.0089150967669444862, 0.0089006538731266401, 0.0088868982014924606, 0.0088737591919068482, 0.0088611825099690015, 0.008849203867062734, 0.0088377404355826968, 0.0088267578750839612, 0.0088162602182447949, 0.008806196922355073, 0.0087965575425205007, 0.0087873121556386897, 0.0087784441009383669, 0.0087699321863947289, 0.0087617657438708221, 0.0087539036480621755, 0.0087463657126132886, 0.0087391119381640681, 0.0087321527970848304, 0.0087254501320536172, 0.0087190161281126225, 0.0087128218278270525, 0.0087068644629879535, 0.0087011167813909884, 0.0086955898186648704, 0.0086902590330000962, 0.0086851236241575983, 0.0086801715015440029, 0.008675397136755237, 0.0086707894277622093, 0.0086663450940426823, 0.0086620455137245041, 0.0086578856890342244, 0.0086538778702695829, 0.0086500442219919864, 0.0086463232442837365, 0.0086427336643417341, 0.0086392588025049413, 0.0086359026170374064, 0.0086326639121598672, 0.0086295260488529028, 0.0086264908714443166, 0.0086235559981066752, 0.0086207043662319249, 0.0086179557574092066, 0.0086153003781548505, 0.0086127157880024237, 0.0086102177392973003, 0.0086077949994992978, 0.0086054543082470097, 0.0086031926294402906, 0.0086009917172850028, 0.0085988519856386846, 0.0085967760968131378, 0.0085947770194895225, 0.008592827502608336, 0.0085909466002166233, 0.008589119237710819, 0.008587337795074871, 0.0085856219726146987, 0.0085839426062529478, 0.0085823272132230597, 0.0085807558018588265, 0.0085792219095715151, 0.0085777437077410468, 0.0085762967117996251, 0.0085748938824145721, 0.0085735322767897266]}
[2017-10-20 01:48:30,057 AE_UNIGRAMA_9L_OVER_04.py:132]: evaluating model ... 
[2017-10-20 01:48:30,155 AE_UNIGRAMA_9L_OVER_04.py:136]: evaluated! 
[2017-10-20 01:48:30,155 AE_UNIGRAMA_9L_OVER_04.py:138]: generating reports ... 
[2017-10-20 01:48:30,742 AE_UNIGRAMA_9L_OVER_04.py:141]: done!
[2017-10-20 01:48:30,742 AE_UNIGRAMA_9L_OVER_04.py:157]: >> experiment AE_UNIGRAMA_9L_OVER_04 finished!
