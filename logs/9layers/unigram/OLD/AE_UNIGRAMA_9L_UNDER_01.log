[2017-10-20 01:54:40,590 AE_UNIGRAMA_9L_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_UNDER_01
[2017-10-20 01:54:40,590 AE_UNIGRAMA_9L_UNDER_01.py:149]: >> Printing header log
[2017-10-20 01:54:40,590 AE_UNIGRAMA_9L_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_UNDER_01
	layers = 96,28,26,24,22,20,19,17,15,13,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f567807b7b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f567807b898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:54:40,590 AE_UNIGRAMA_9L_UNDER_01.py:151]: >> Loading dataset... 
[2017-10-20 01:54:41,136 AE_UNIGRAMA_9L_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:54:41,136 AE_UNIGRAMA_9L_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:54:41,136 AE_UNIGRAMA_9L_UNDER_01.py:60]: =======================================
[2017-10-20 01:54:41,136 AE_UNIGRAMA_9L_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f567807b7b8>, 'discard_decoder_function': True}
[2017-10-20 01:54:41,323 AE_UNIGRAMA_9L_UNDER_01.py:76]: training and evaluate autoencoder
[2017-10-20 01:55:20,070 AE_UNIGRAMA_9L_UNDER_01.py:88]: trained and evaluated!
[2017-10-20 01:55:20,071 AE_UNIGRAMA_9L_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010317676205561951, 0.010224660976225559, 0.010138553788809306, 0.010058356992568004, 0.0099840243156570033, 0.009915019752506209, 0.0098508989376095597, 0.0097913049078342199, 0.0097358442746019718, 0.0096841314288209357, 0.0096358966885556965, 0.0095908862355140942, 0.0095487629170754578, 0.0095093154788128062, 0.0094723664016417852, 0.0094376968074465321, 0.0094051497112474913, 0.0093745755301753823, 0.0093457568990807545, 0.0093186281268315251, 0.009293012473330621, 0.0092688264761494003, 0.0092459407957014537, 0.0092242674687427213, 0.0092036553682780173, 0.0091835811879610492, 0.009164516228947055, 0.0091463705684061824, 0.0091290765971665487, 0.0091125708571929472, 0.0090968326828182854, 0.0090817823542150428, 0.0090674172955319335, 0.0090536467772544989, 0.0090404791051182602, 0.0090278487991832454, 0.0090157228303886262, 0.009004100537460754, 0.008992936334063794, 0.0089821944837233398, 0.0089718680447971513, 0.0089619199651878555, 0.0089523687120873253, 0.0089431594170934648, 0.0089342690671908361, 0.008925688830394728, 0.0089174033658488971, 0.0089094058565490752, 0.0089016798018135106, 0.0088942157222325034, 0.0088869824652390416, 0.0088799852898628299, 0.0088732089591126023, 0.0088666550828954104, 0.0088599116946518636, 0.0088532883673906326, 0.0088468721538061991, 0.0088406512202161835, 0.0088346255908557467, 0.0088287785988591869, 0.0088231129897239045, 0.0088175997020309739, 0.0088122589894497703, 0.0088070712526602379, 0.0088020316584790509, 0.0087971382854042449, 0.008792382478021556, 0.0087877518798615845, 0.0087832570920757195, 0.0087777626212533957, 0.0087722175716522903, 0.0087668391612798092, 0.0087616345066175577, 0.0087565762652118857, 0.0087516662235402921, 0.0087469021190774935, 0.008742279056321179, 0.008737795937764822, 0.0087334358316870433, 0.0087292034275912884, 0.008725090198163428, 0.0087210947896966696, 0.0087172108473858641, 0.0087131757988528694, 0.0087077276570009261, 0.0087021964283653126, 0.0086968521237871903, 0.0086916949042572626, 0.0086867058005696343, 0.0086818744019920274, 0.0086772015480996289, 0.008672680678088426, 0.0086683019697943141, 0.0086639834512509829, 0.0086598756937760184, 0.0086558909574350456, 0.0086520327545951733, 0.0086482867674701272, 0.0086446505136870983, 0.0086411161929867523, 0.0086376916038973395, 0.0086343343002673201], 'loss': [0.010361875260286559, 0.010267623527903972, 0.010179654061427934, 0.010097895659616225, 0.010022028787811438, 0.0099517229925005363, 0.0098864704567410127, 0.0098258456966273614, 0.009769534473504914, 0.0097171210568826397, 0.0096682678054063401, 0.0096227144124129468, 0.0095801974395456017, 0.0095404271155449232, 0.0095031932654625149, 0.0094683155109481932, 0.0094356026715692303, 0.009404896290259597, 0.0093760606606697553, 0.0093488843004507164, 0.0093233010215889693, 0.0092991476932331035, 0.0092763400664661808, 0.0092547774250769654, 0.0092343459576688883, 0.0092146234454034154, 0.0091956546272539842, 0.0091776482282365547, 0.0091605033581251012, 0.0091441686024182987, 0.0091285784823273916, 0.0091137099185684897, 0.0090995044742276428, 0.0090859259341940172, 0.0090729253327665182, 0.0090604837979267328, 0.0090485573422848329, 0.0090370991198001419, 0.0090261277752414978, 0.009015578905964234, 0.0090054309261206038, 0.0089956740988962249, 0.008986279878996601, 0.0089772553123034574, 0.0089685496013810762, 0.0089601487907012625, 0.0089520384582159121, 0.0089442095179488555, 0.0089366552709031124, 0.0089293545399367191, 0.0089222947055429269, 0.008915460434385656, 0.0089088468139816007, 0.008902445402323796, 0.0088961031419564473, 0.0088896505550676574, 0.0088833983410573393, 0.0088773452926978937, 0.0088714674285761252, 0.0088657762496958288, 0.0088602636254449234, 0.0088549193255855179, 0.0088497176514532056, 0.0088446786840112573, 0.0088397919995448094, 0.0088350381347286101, 0.0088304228538025643, 0.0088259441618931834, 0.0088215875516622147, 0.0088169010603352787, 0.0088115125114914452, 0.0088062752146999684, 0.0088011962999878807, 0.0087962870267989744, 0.0087915161486025895, 0.0087868872309846604, 0.0087824052287873572, 0.0087780437444250278, 0.0087738247535614489, 0.0087697270052128577, 0.00876573901440314, 0.0087618743342512875, 0.0087581188735662615, 0.0087544162956323442, 0.0087499368177943234, 0.0087445698410602308, 0.008739359238366445, 0.0087343234175011365, 0.008729466847324379, 0.0087247748779660725, 0.0087202304021696334, 0.0087158407428666509, 0.0087115923188896948, 0.0087074456781093962, 0.0087034241614042437, 0.0086995715821492729, 0.008695839750268523, 0.0086922209135175989, 0.0086887134256250081, 0.0086853113397497954, 0.0086820066569358121, 0.0086787921160725121]}
[2017-10-20 01:55:20,071 AE_UNIGRAMA_9L_UNDER_01.py:95]: done!
[2017-10-20 01:55:20,071 AE_UNIGRAMA_9L_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-10-20 01:55:20,072 AE_UNIGRAMA_9L_UNDER_01.py:100]: =======================================
[2017-10-20 01:55:20,072 AE_UNIGRAMA_9L_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f567807b898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:55:20,124 AE_UNIGRAMA_9L_UNDER_01.py:113]: training ... 
[2017-10-20 01:56:26,238 AE_UNIGRAMA_9L_UNDER_01.py:125]: trained!
[2017-10-20 01:56:26,238 AE_UNIGRAMA_9L_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010317676205561951, 0.010224660976225559, 0.010138553788809306, 0.010058356992568004, 0.0099840243156570033, 0.009915019752506209, 0.0098508989376095597, 0.0097913049078342199, 0.0097358442746019718, 0.0096841314288209357, 0.0096358966885556965, 0.0095908862355140942, 0.0095487629170754578, 0.0095093154788128062, 0.0094723664016417852, 0.0094376968074465321, 0.0094051497112474913, 0.0093745755301753823, 0.0093457568990807545, 0.0093186281268315251, 0.009293012473330621, 0.0092688264761494003, 0.0092459407957014537, 0.0092242674687427213, 0.0092036553682780173, 0.0091835811879610492, 0.009164516228947055, 0.0091463705684061824, 0.0091290765971665487, 0.0091125708571929472, 0.0090968326828182854, 0.0090817823542150428, 0.0090674172955319335, 0.0090536467772544989, 0.0090404791051182602, 0.0090278487991832454, 0.0090157228303886262, 0.009004100537460754, 0.008992936334063794, 0.0089821944837233398, 0.0089718680447971513, 0.0089619199651878555, 0.0089523687120873253, 0.0089431594170934648, 0.0089342690671908361, 0.008925688830394728, 0.0089174033658488971, 0.0089094058565490752, 0.0089016798018135106, 0.0088942157222325034, 0.0088869824652390416, 0.0088799852898628299, 0.0088732089591126023, 0.0088666550828954104, 0.0088599116946518636, 0.0088532883673906326, 0.0088468721538061991, 0.0088406512202161835, 0.0088346255908557467, 0.0088287785988591869, 0.0088231129897239045, 0.0088175997020309739, 0.0088122589894497703, 0.0088070712526602379, 0.0088020316584790509, 0.0087971382854042449, 0.008792382478021556, 0.0087877518798615845, 0.0087832570920757195, 0.0087777626212533957, 0.0087722175716522903, 0.0087668391612798092, 0.0087616345066175577, 0.0087565762652118857, 0.0087516662235402921, 0.0087469021190774935, 0.008742279056321179, 0.008737795937764822, 0.0087334358316870433, 0.0087292034275912884, 0.008725090198163428, 0.0087210947896966696, 0.0087172108473858641, 0.0087131757988528694, 0.0087077276570009261, 0.0087021964283653126, 0.0086968521237871903, 0.0086916949042572626, 0.0086867058005696343, 0.0086818744019920274, 0.0086772015480996289, 0.008672680678088426, 0.0086683019697943141, 0.0086639834512509829, 0.0086598756937760184, 0.0086558909574350456, 0.0086520327545951733, 0.0086482867674701272, 0.0086446505136870983, 0.0086411161929867523, 0.0086376916038973395, 0.0086343343002673201], 'loss': [0.010361875260286559, 0.010267623527903972, 0.010179654061427934, 0.010097895659616225, 0.010022028787811438, 0.0099517229925005363, 0.0098864704567410127, 0.0098258456966273614, 0.009769534473504914, 0.0097171210568826397, 0.0096682678054063401, 0.0096227144124129468, 0.0095801974395456017, 0.0095404271155449232, 0.0095031932654625149, 0.0094683155109481932, 0.0094356026715692303, 0.009404896290259597, 0.0093760606606697553, 0.0093488843004507164, 0.0093233010215889693, 0.0092991476932331035, 0.0092763400664661808, 0.0092547774250769654, 0.0092343459576688883, 0.0092146234454034154, 0.0091956546272539842, 0.0091776482282365547, 0.0091605033581251012, 0.0091441686024182987, 0.0091285784823273916, 0.0091137099185684897, 0.0090995044742276428, 0.0090859259341940172, 0.0090729253327665182, 0.0090604837979267328, 0.0090485573422848329, 0.0090370991198001419, 0.0090261277752414978, 0.009015578905964234, 0.0090054309261206038, 0.0089956740988962249, 0.008986279878996601, 0.0089772553123034574, 0.0089685496013810762, 0.0089601487907012625, 0.0089520384582159121, 0.0089442095179488555, 0.0089366552709031124, 0.0089293545399367191, 0.0089222947055429269, 0.008915460434385656, 0.0089088468139816007, 0.008902445402323796, 0.0088961031419564473, 0.0088896505550676574, 0.0088833983410573393, 0.0088773452926978937, 0.0088714674285761252, 0.0088657762496958288, 0.0088602636254449234, 0.0088549193255855179, 0.0088497176514532056, 0.0088446786840112573, 0.0088397919995448094, 0.0088350381347286101, 0.0088304228538025643, 0.0088259441618931834, 0.0088215875516622147, 0.0088169010603352787, 0.0088115125114914452, 0.0088062752146999684, 0.0088011962999878807, 0.0087962870267989744, 0.0087915161486025895, 0.0087868872309846604, 0.0087824052287873572, 0.0087780437444250278, 0.0087738247535614489, 0.0087697270052128577, 0.00876573901440314, 0.0087618743342512875, 0.0087581188735662615, 0.0087544162956323442, 0.0087499368177943234, 0.0087445698410602308, 0.008739359238366445, 0.0087343234175011365, 0.008729466847324379, 0.0087247748779660725, 0.0087202304021696334, 0.0087158407428666509, 0.0087115923188896948, 0.0087074456781093962, 0.0087034241614042437, 0.0086995715821492729, 0.008695839750268523, 0.0086922209135175989, 0.0086887134256250081, 0.0086853113397497954, 0.0086820066569358121, 0.0086787921160725121]}
[2017-10-20 01:56:26,238 AE_UNIGRAMA_9L_UNDER_01.py:132]: evaluating model ... 
[2017-10-20 01:56:26,296 AE_UNIGRAMA_9L_UNDER_01.py:136]: evaluated! 
[2017-10-20 01:56:26,296 AE_UNIGRAMA_9L_UNDER_01.py:138]: generating reports ... 
[2017-10-20 01:56:26,854 AE_UNIGRAMA_9L_UNDER_01.py:141]: done!
[2017-10-20 01:56:26,854 AE_UNIGRAMA_9L_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_9L_UNDER_01 finished!
