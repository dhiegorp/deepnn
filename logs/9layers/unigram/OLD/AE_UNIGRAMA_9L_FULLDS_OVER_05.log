[2017-11-14 07:31:22,728 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_FULLDS_OVER_05
[2017-11-14 07:31:22,728 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-14 07:31:22,728 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f24b285ee48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f24b2862390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 07:31:22,729 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-14 07:31:25,050 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-14 07:31:25,050 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-14 07:31:25,051 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-14 07:31:25,051 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f24b285ee48>, 'discard_decoder_function': True}
[2017-11-14 07:31:25,229 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-14 07:36:16,093 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-14 07:36:16,094 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0095153001586481163, 0.0088213111569325261, 0.0082821466565373095, 0.0078547867824477844, 0.007508926239557419, 0.0072349558472469067, 0.007016672691702021, 0.0068425822861695263, 0.0067031586716257557, 0.0065912589239478878, 0.0065011659731902937, 0.0064284661909697451, 0.0063696663731894632, 0.0063218701064712592, 0.0062828377693226146, 0.0062473544938909421, 0.0062175415400162375, 0.0061932402275823046, 0.0061733525671483795, 0.0061570018751855469, 0.0061434862368700098, 0.0061323841919424952, 0.0061230963826431417, 0.006115385937120783, 0.0061089184544384969, 0.0061035134148630299, 0.006098939718449956, 0.0060950928267217465, 0.0060918233742426088, 0.0060890358743503912, 0.0060866678022197321, 0.0060846227173615101, 0.0060828677336666531, 0.0060813697766908302, 0.0060800414974638665, 0.0060788725541465775, 0.0060778682414327299, 0.0060769949093473358, 0.0060762524500746623, 0.0060756126126409321, 0.0060750294387927886, 0.0060744596284481147, 0.0060739747036552385, 0.0060735855064841205, 0.0060731552344278315, 0.0060728300839097121, 0.0060725450411867471, 0.006072285652276333, 0.0060720538127673153, 0.0060718366076183347, 0.0060716144985648382, 0.0060713995119384967, 0.0060712235374940924, 0.0060710552436371839, 0.0060708988893459501, 0.00607075404849154, 0.0060706119443598326, 0.0060704772839632786, 0.0060703380643302839, 0.0060702054690328676, 0.0060700764358474933, 0.0060699614078403392, 0.0060698447198131609, 0.0060697252620340149, 0.0060696183200357415, 0.0060695103510498222, 0.0060694092195494754, 0.0060693068694746347, 0.0060692042590162415, 0.0060691022580590141, 0.0060690151018736411, 0.006068912961183801, 0.0060688090097030453, 0.0060687163247953096, 0.0060686197070092054, 0.006068523605968509, 0.0060684332776902317, 0.0060683383895765381, 0.0060682494973011512, 0.0060681564139886098, 0.006068041398217686, 0.0060678921901415215, 0.0060677789955152469, 0.0060676793202118469, 0.006067561128668594, 0.0060674526982997896, 0.0060673465236757212, 0.0060672481598737088, 0.0060671406453396632, 0.0060670402671803621, 0.0060669430724089469, 0.0060668374404574043, 0.0060667435920809957, 0.0060666158127241476, 0.006066438731457114, 0.0060663166660774401, 0.0060661855956881099, 0.006066061208847443, 0.0060659415224304878, 0.0060658345199356084, 0.0060657027575575177], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099449518136794438, 0.0091571880288891256, 0.0085455627371884575, 0.0080676220502140586, 0.0076831318648392342, 0.0073761177255883053, 0.0071325743552290493, 0.0069384052849939312, 0.006783481514463399, 0.0066593549444304845, 0.0065596965451959061, 0.0064794572041205018, 0.0064147080931978512, 0.0063623174964628059, 0.0063196480703681095, 0.0062834206056085282, 0.0062508608805678934, 0.0062242814557352715, 0.0062026152715573459, 0.0061848822144220592, 0.0061702672014891102, 0.0061582425074580734, 0.0061483074588228092, 0.0061400289984166849, 0.0061331394598220876, 0.0061273652085892891, 0.0061225374866557278, 0.0061184521177510397, 0.0061150169166014632, 0.006112093739387604, 0.0061096069516735942, 0.006107489435132298, 0.0061056612147382065, 0.0061040956525165672, 0.0061027501715246344, 0.0061015578497709217, 0.0061005212202996503, 0.0060996234952412137, 0.0060988486897873891, 0.0060981895192854935, 0.0060976075904282216, 0.0060970863459760523, 0.0060965580953991792, 0.0060961510025502545, 0.0060957660668221952, 0.0060953993393249774, 0.0060951083488611484, 0.0060948516445457788, 0.0060946128657036244, 0.0060944017304062504, 0.0060941954147346374, 0.006093980625365078, 0.0060937931281366429, 0.006093633466616147, 0.006093478901648984, 0.0060933341043088477, 0.0060931950795225414, 0.006093056327034059, 0.0060929291168525237, 0.0060927997476075951, 0.0060926732484068817, 0.0060925484925066784, 0.0060924406461070162, 0.0060923214778564735, 0.0060922109967867432, 0.0060921051578119081, 0.0060919960216556544, 0.0060918957995379081, 0.0060917992595566281, 0.0060916950565407186, 0.0060915956385703459, 0.006091506419879638, 0.0060914156082123644, 0.0060913201693682762, 0.0060912215183358135, 0.0060911319477841893, 0.0060910397816009978, 0.0060909440486821183, 0.0060908539166734145, 0.0060907537687459653, 0.0060906556542499584, 0.0060905143662594871, 0.006090388218348116, 0.0060902821191356664, 0.006090179176783235, 0.0060900676895719015, 0.0060899588591505471, 0.0060898564037791102, 0.0060897554638788126, 0.006089649801520324, 0.0060895505558223361, 0.0060894536099092454, 0.0060893451657004008, 0.0060892347406449167, 0.0060890868900139606, 0.0060889357027058277, 0.0060888132649380448, 0.0060886742039711087, 0.006088553970363903, 0.0060884357645867157, 0.0060883182236643324], 'acc': [0.58487786918355456, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822272449271, 0.59383822264767316, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822267327968, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822264767316, 0.5938382226001182]}
[2017-11-14 07:36:16,094 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:95]: done!
[2017-11-14 07:36:16,094 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-14 07:36:16,094 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-14 07:36:16,095 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f24b2862390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 07:36:16,127 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-14 07:43:10,298 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:125]: trained!
[2017-11-14 07:43:10,299 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0095153001586481163, 0.0088213111569325261, 0.0082821466565373095, 0.0078547867824477844, 0.007508926239557419, 0.0072349558472469067, 0.007016672691702021, 0.0068425822861695263, 0.0067031586716257557, 0.0065912589239478878, 0.0065011659731902937, 0.0064284661909697451, 0.0063696663731894632, 0.0063218701064712592, 0.0062828377693226146, 0.0062473544938909421, 0.0062175415400162375, 0.0061932402275823046, 0.0061733525671483795, 0.0061570018751855469, 0.0061434862368700098, 0.0061323841919424952, 0.0061230963826431417, 0.006115385937120783, 0.0061089184544384969, 0.0061035134148630299, 0.006098939718449956, 0.0060950928267217465, 0.0060918233742426088, 0.0060890358743503912, 0.0060866678022197321, 0.0060846227173615101, 0.0060828677336666531, 0.0060813697766908302, 0.0060800414974638665, 0.0060788725541465775, 0.0060778682414327299, 0.0060769949093473358, 0.0060762524500746623, 0.0060756126126409321, 0.0060750294387927886, 0.0060744596284481147, 0.0060739747036552385, 0.0060735855064841205, 0.0060731552344278315, 0.0060728300839097121, 0.0060725450411867471, 0.006072285652276333, 0.0060720538127673153, 0.0060718366076183347, 0.0060716144985648382, 0.0060713995119384967, 0.0060712235374940924, 0.0060710552436371839, 0.0060708988893459501, 0.00607075404849154, 0.0060706119443598326, 0.0060704772839632786, 0.0060703380643302839, 0.0060702054690328676, 0.0060700764358474933, 0.0060699614078403392, 0.0060698447198131609, 0.0060697252620340149, 0.0060696183200357415, 0.0060695103510498222, 0.0060694092195494754, 0.0060693068694746347, 0.0060692042590162415, 0.0060691022580590141, 0.0060690151018736411, 0.006068912961183801, 0.0060688090097030453, 0.0060687163247953096, 0.0060686197070092054, 0.006068523605968509, 0.0060684332776902317, 0.0060683383895765381, 0.0060682494973011512, 0.0060681564139886098, 0.006068041398217686, 0.0060678921901415215, 0.0060677789955152469, 0.0060676793202118469, 0.006067561128668594, 0.0060674526982997896, 0.0060673465236757212, 0.0060672481598737088, 0.0060671406453396632, 0.0060670402671803621, 0.0060669430724089469, 0.0060668374404574043, 0.0060667435920809957, 0.0060666158127241476, 0.006066438731457114, 0.0060663166660774401, 0.0060661855956881099, 0.006066061208847443, 0.0060659415224304878, 0.0060658345199356084, 0.0060657027575575177], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099449518136794438, 0.0091571880288891256, 0.0085455627371884575, 0.0080676220502140586, 0.0076831318648392342, 0.0073761177255883053, 0.0071325743552290493, 0.0069384052849939312, 0.006783481514463399, 0.0066593549444304845, 0.0065596965451959061, 0.0064794572041205018, 0.0064147080931978512, 0.0063623174964628059, 0.0063196480703681095, 0.0062834206056085282, 0.0062508608805678934, 0.0062242814557352715, 0.0062026152715573459, 0.0061848822144220592, 0.0061702672014891102, 0.0061582425074580734, 0.0061483074588228092, 0.0061400289984166849, 0.0061331394598220876, 0.0061273652085892891, 0.0061225374866557278, 0.0061184521177510397, 0.0061150169166014632, 0.006112093739387604, 0.0061096069516735942, 0.006107489435132298, 0.0061056612147382065, 0.0061040956525165672, 0.0061027501715246344, 0.0061015578497709217, 0.0061005212202996503, 0.0060996234952412137, 0.0060988486897873891, 0.0060981895192854935, 0.0060976075904282216, 0.0060970863459760523, 0.0060965580953991792, 0.0060961510025502545, 0.0060957660668221952, 0.0060953993393249774, 0.0060951083488611484, 0.0060948516445457788, 0.0060946128657036244, 0.0060944017304062504, 0.0060941954147346374, 0.006093980625365078, 0.0060937931281366429, 0.006093633466616147, 0.006093478901648984, 0.0060933341043088477, 0.0060931950795225414, 0.006093056327034059, 0.0060929291168525237, 0.0060927997476075951, 0.0060926732484068817, 0.0060925484925066784, 0.0060924406461070162, 0.0060923214778564735, 0.0060922109967867432, 0.0060921051578119081, 0.0060919960216556544, 0.0060918957995379081, 0.0060917992595566281, 0.0060916950565407186, 0.0060915956385703459, 0.006091506419879638, 0.0060914156082123644, 0.0060913201693682762, 0.0060912215183358135, 0.0060911319477841893, 0.0060910397816009978, 0.0060909440486821183, 0.0060908539166734145, 0.0060907537687459653, 0.0060906556542499584, 0.0060905143662594871, 0.006090388218348116, 0.0060902821191356664, 0.006090179176783235, 0.0060900676895719015, 0.0060899588591505471, 0.0060898564037791102, 0.0060897554638788126, 0.006089649801520324, 0.0060895505558223361, 0.0060894536099092454, 0.0060893451657004008, 0.0060892347406449167, 0.0060890868900139606, 0.0060889357027058277, 0.0060888132649380448, 0.0060886742039711087, 0.006088553970363903, 0.0060884357645867157, 0.0060883182236643324], 'acc': [0.58487786918355456, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822272449271, 0.59383822264767316, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822267327968, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822264767316, 0.5938382226001182]}
[2017-11-14 07:43:10,299 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-14 07:43:10,511 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-14 07:43:10,511 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-14 07:43:11,349 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:141]: done!
[2017-11-14 07:43:11,349 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_9L_FULLDS_OVER_05 finished!
[2017-11-18 16:23:50,752 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_9L_FULLDS_OVER_05 was already executed!
[2017-11-18 19:24:45,206 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_FULLDS_OVER_05
[2017-11-18 19:24:45,207 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 19:24:45,207 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,42
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8d1477aef0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8d147df438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:24:45,207 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 19:24:47,657 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:24:47,658 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:24:47,658 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 19:24:47,658 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8d1477aef0>, 'discard_decoder_function': True}
[2017-11-18 19:24:47,866 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 19:28:25,293 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 19:28:25,294 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0094522911485713096, 0.0086917772759758389, 0.0081160932990494063, 0.0076718611246709414, 0.0073246152394508364, 0.0070495906613496067, 0.0068296806916569863, 0.0066522414401072281, 0.0065079412857075355, 0.0063898262178654708, 0.0062927237081381489, 0.0062123969563846748, 0.0061455336933320974, 0.0060857646500137976, 0.0060320117941091312, 0.0059846190405233963, 0.0059455334158762824, 0.0059132783098515291, 0.0058863788057811417, 0.0058638002015465448, 0.0058448668867958865, 0.0058289043864085364, 0.0058154844508144579, 0.0058041486784902044, 0.0057945823459826119, 0.0057864993255659367, 0.0057796300904847915, 0.0057737716751392878, 0.00576877124148576, 0.005764493410270531, 0.00576084357866376, 0.0057577244703476867, 0.005755044454869563, 0.0057527271360542269, 0.0057507379728210942, 0.0057490244065402834, 0.0057475362994729683, 0.0057462526052178475, 0.0057451329364289708, 0.0057441690641132593, 0.0057433203674951425, 0.005742598184768093, 0.0057419565112153065, 0.005741374581526501, 0.0057408772973711331, 0.0057404336915034852, 0.0057400411744634536, 0.0057396981313253747, 0.005739397097817762, 0.0057391209444164603, 0.005738877310122896, 0.005738663666829253, 0.0057384724644393009, 0.005738295915319924, 0.0057381331488162894, 0.0057379890938187806, 0.0057378529467630567, 0.0057377055597459727, 0.0057375888137036618, 0.0057374692621419412, 0.0057373619815509237, 0.0057372531947912217, 0.0057371438126490809, 0.0057370374037397122, 0.005736925370100638, 0.0057368141176977914, 0.0057366989953946549, 0.0057365811740187535, 0.0057364528594337997, 0.0057363227011142347, 0.0057361886186442397, 0.0057360495639008626, 0.0057359214277252777, 0.0057358043205858276, 0.0057356824545796931, 0.0057355622936023738, 0.0057354404020969621, 0.0057353203954843912, 0.0057352143164398272, 0.005735106225091607, 0.0057350011782543392, 0.0057349056073076662, 0.0057348004022550877, 0.0057346968040847789, 0.005734585473643878, 0.0057344852673907746, 0.0057343826727624687, 0.0057342830443503565, 0.0057341791121224102, 0.0057340849132592984, 0.0057339878417058641, 0.0057338920581226057, 0.0057337935025626105, 0.0057336975212316059, 0.0057336098459049188, 0.0057335119301371775, 0.0057334157211951795, 0.0057333232465281245, 0.0057332290314070847, 0.0057331310794440614, 0.0057330308698538045], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099357851153705785, 0.0090621413328773239, 0.0084029898170678539, 0.0078998054824705472, 0.0075093450532167346, 0.0072023945548942599, 0.0069584000992404769, 0.006762492676209866, 0.0066039747489602327, 0.006474733898114142, 0.0063687950060959493, 0.0062815043030413466, 0.006209137224264985, 0.0061471467651129574, 0.006091643767553695, 0.0060408607388663556, 0.0059981930014297025, 0.005963152037629163, 0.0059340379389037903, 0.0059097248223399087, 0.0058893330058678974, 0.005872203263657505, 0.0058578075658737138, 0.0058456191975301917, 0.0058354338040826651, 0.0058267892347366379, 0.0058194771270142264, 0.0058132615073581617, 0.0058079633329759144, 0.0058034374881035071, 0.0057995634382572133, 0.005796270244138123, 0.005793447536476367, 0.0057910236444155523, 0.0057889354189237571, 0.0057871414403239865, 0.0057855961854956341, 0.0057842578822720585, 0.0057830999152556775, 0.0057820987690373211, 0.0057812304178494478, 0.0057804680943701241, 0.0057798174761575912, 0.0057792340474903062, 0.0057787207927272721, 0.0057782700849001731, 0.0057778711672732842, 0.0057775238301361271, 0.0057772126181294169, 0.0057769413068419597, 0.0057766934145963072, 0.0057764772098382053, 0.0057762791291752612, 0.0057761080027389292, 0.0057759448212374937, 0.0057758048212317344, 0.0057756693994760605, 0.0057755342663652265, 0.0057754096720489759, 0.0057752941155741477, 0.0057751851785542542, 0.0057750801820222464, 0.0057749809336950179, 0.005774880267750109, 0.0057747675203897149, 0.0057746596162610844, 0.0057745421730206869, 0.0057744304572940938, 0.0057743108595057369, 0.0057741849314788592, 0.0057740515937960788, 0.0057739157985739944, 0.0057737916448840926, 0.0057736761397937627, 0.0057735528841036752, 0.0057734302289663237, 0.0057733075085552293, 0.0057731895753616522, 0.0057730803036280601, 0.0057729701833929567, 0.0057728642798874248, 0.0057727593102193915, 0.0057726552370650809, 0.0057725554425989553, 0.0057724432438923832, 0.0057723369730934386, 0.0057722382424978836, 0.0057721379421316653, 0.0057720403425094609, 0.0057719383074163414, 0.0057718403598199242, 0.0057717421411831449, 0.0057716463943750188, 0.0057715503890440004, 0.0057714481831074305, 0.0057713546418316584, 0.005771257644076812, 0.0057711652548654698, 0.0057710644967828417, 0.0057709703176305549, 0.0057708717466184436], 'acc': [0.46827052905835503, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822267327968, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822267327968, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822262938279, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427]}
[2017-11-18 19:28:25,294 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:95]: done!
[2017-11-18 19:28:25,294 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 19:28:25,294 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 19:28:25,295 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8d147df438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:28:25,336 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 19:34:43,517 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:125]: trained!
[2017-11-18 19:34:43,518 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0094522911485713096, 0.0086917772759758389, 0.0081160932990494063, 0.0076718611246709414, 0.0073246152394508364, 0.0070495906613496067, 0.0068296806916569863, 0.0066522414401072281, 0.0065079412857075355, 0.0063898262178654708, 0.0062927237081381489, 0.0062123969563846748, 0.0061455336933320974, 0.0060857646500137976, 0.0060320117941091312, 0.0059846190405233963, 0.0059455334158762824, 0.0059132783098515291, 0.0058863788057811417, 0.0058638002015465448, 0.0058448668867958865, 0.0058289043864085364, 0.0058154844508144579, 0.0058041486784902044, 0.0057945823459826119, 0.0057864993255659367, 0.0057796300904847915, 0.0057737716751392878, 0.00576877124148576, 0.005764493410270531, 0.00576084357866376, 0.0057577244703476867, 0.005755044454869563, 0.0057527271360542269, 0.0057507379728210942, 0.0057490244065402834, 0.0057475362994729683, 0.0057462526052178475, 0.0057451329364289708, 0.0057441690641132593, 0.0057433203674951425, 0.005742598184768093, 0.0057419565112153065, 0.005741374581526501, 0.0057408772973711331, 0.0057404336915034852, 0.0057400411744634536, 0.0057396981313253747, 0.005739397097817762, 0.0057391209444164603, 0.005738877310122896, 0.005738663666829253, 0.0057384724644393009, 0.005738295915319924, 0.0057381331488162894, 0.0057379890938187806, 0.0057378529467630567, 0.0057377055597459727, 0.0057375888137036618, 0.0057374692621419412, 0.0057373619815509237, 0.0057372531947912217, 0.0057371438126490809, 0.0057370374037397122, 0.005736925370100638, 0.0057368141176977914, 0.0057366989953946549, 0.0057365811740187535, 0.0057364528594337997, 0.0057363227011142347, 0.0057361886186442397, 0.0057360495639008626, 0.0057359214277252777, 0.0057358043205858276, 0.0057356824545796931, 0.0057355622936023738, 0.0057354404020969621, 0.0057353203954843912, 0.0057352143164398272, 0.005735106225091607, 0.0057350011782543392, 0.0057349056073076662, 0.0057348004022550877, 0.0057346968040847789, 0.005734585473643878, 0.0057344852673907746, 0.0057343826727624687, 0.0057342830443503565, 0.0057341791121224102, 0.0057340849132592984, 0.0057339878417058641, 0.0057338920581226057, 0.0057337935025626105, 0.0057336975212316059, 0.0057336098459049188, 0.0057335119301371775, 0.0057334157211951795, 0.0057333232465281245, 0.0057332290314070847, 0.0057331310794440614, 0.0057330308698538045], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099357851153705785, 0.0090621413328773239, 0.0084029898170678539, 0.0078998054824705472, 0.0075093450532167346, 0.0072023945548942599, 0.0069584000992404769, 0.006762492676209866, 0.0066039747489602327, 0.006474733898114142, 0.0063687950060959493, 0.0062815043030413466, 0.006209137224264985, 0.0061471467651129574, 0.006091643767553695, 0.0060408607388663556, 0.0059981930014297025, 0.005963152037629163, 0.0059340379389037903, 0.0059097248223399087, 0.0058893330058678974, 0.005872203263657505, 0.0058578075658737138, 0.0058456191975301917, 0.0058354338040826651, 0.0058267892347366379, 0.0058194771270142264, 0.0058132615073581617, 0.0058079633329759144, 0.0058034374881035071, 0.0057995634382572133, 0.005796270244138123, 0.005793447536476367, 0.0057910236444155523, 0.0057889354189237571, 0.0057871414403239865, 0.0057855961854956341, 0.0057842578822720585, 0.0057830999152556775, 0.0057820987690373211, 0.0057812304178494478, 0.0057804680943701241, 0.0057798174761575912, 0.0057792340474903062, 0.0057787207927272721, 0.0057782700849001731, 0.0057778711672732842, 0.0057775238301361271, 0.0057772126181294169, 0.0057769413068419597, 0.0057766934145963072, 0.0057764772098382053, 0.0057762791291752612, 0.0057761080027389292, 0.0057759448212374937, 0.0057758048212317344, 0.0057756693994760605, 0.0057755342663652265, 0.0057754096720489759, 0.0057752941155741477, 0.0057751851785542542, 0.0057750801820222464, 0.0057749809336950179, 0.005774880267750109, 0.0057747675203897149, 0.0057746596162610844, 0.0057745421730206869, 0.0057744304572940938, 0.0057743108595057369, 0.0057741849314788592, 0.0057740515937960788, 0.0057739157985739944, 0.0057737916448840926, 0.0057736761397937627, 0.0057735528841036752, 0.0057734302289663237, 0.0057733075085552293, 0.0057731895753616522, 0.0057730803036280601, 0.0057729701833929567, 0.0057728642798874248, 0.0057727593102193915, 0.0057726552370650809, 0.0057725554425989553, 0.0057724432438923832, 0.0057723369730934386, 0.0057722382424978836, 0.0057721379421316653, 0.0057720403425094609, 0.0057719383074163414, 0.0057718403598199242, 0.0057717421411831449, 0.0057716463943750188, 0.0057715503890440004, 0.0057714481831074305, 0.0057713546418316584, 0.005771257644076812, 0.0057711652548654698, 0.0057710644967828417, 0.0057709703176305549, 0.0057708717466184436], 'acc': [0.46827052905835503, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822267327968, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822267327968, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822262938279, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427]}
[2017-11-18 19:34:43,518 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 19:34:43,729 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 19:34:43,729 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 19:34:44,599 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:141]: done!
[2017-11-18 19:34:44,599 AE_UNIGRAMA_9L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_9L_FULLDS_OVER_05 finished!
