[2017-11-13 16:06:43,709 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_FULLDS_UNDER_02
[2017-11-13 16:06:43,709 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-13 16:06:43,710 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2bf6619eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2bf661e400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 16:06:43,710 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-13 16:06:46,040 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 16:06:46,040 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-13 16:06:46,040 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:60]: =======================================
[2017-11-13 16:06:46,040 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2bf6619eb8>, 'discard_decoder_function': True}
[2017-11-13 16:06:46,247 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-13 16:10:53,317 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-13 16:10:53,318 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0093178072816273699, 0.0085339893722815672, 0.007962476462639187, 0.0075369076928255953, 0.0072136763065713859, 0.0069634648753916766, 0.0067665489585245304, 0.0066095301289301675, 0.0064826391757805092, 0.006378711490470537, 0.0062927932551049195, 0.0062211897615747211, 0.0061609044136087254, 0.0061096496308802222, 0.0060645669879434913, 0.0060203708535438837, 0.0059811179011030613, 0.0059461795036276771, 0.005906167971493949, 0.0058715636910407236, 0.0058427591965072067, 0.005818500774370035, 0.0057978459132629221, 0.0057802372340808421, 0.0057652088902816747, 0.0057522949246838224, 0.0057411315621248901, 0.0057315280167601571, 0.0057228548009529059, 0.0057126038494043786, 0.0057038666346910976, 0.0056963542224555243, 0.0056898614651126837, 0.0056842628435000023, 0.0056794087176794067, 0.0056751791536855936, 0.0056714981720597645, 0.0056682894346418902, 0.0056654843585603335, 0.0056630136299356737, 0.0056608477372057306, 0.0056589564191467049, 0.0056572751480420637, 0.0056557974989297679, 0.0056545017003049227, 0.0056533357456226545, 0.0056522786158634342, 0.0056513269671137302, 0.0056504621813077173, 0.0056496691538033975, 0.0056490065607467162, 0.0056484045069945376, 0.0056478523096334613, 0.0056473593316042642, 0.0056469150456418147, 0.0056465082340324433, 0.0056461338669154763, 0.0056457930689116954, 0.0056454750567363852, 0.0056451803679279889, 0.0056449034018869878, 0.005644636876259556, 0.0056443912822866822, 0.0056441639462237424, 0.0056439468943271258, 0.0056437471860459089, 0.0056435520583931432, 0.0056433713478431548, 0.005643190710282707, 0.0056430143948496539, 0.0056428394636508245, 0.0056426635104272951, 0.0056424569872504686, 0.0056422602050540333, 0.0056420791735383178, 0.0056418991381201851, 0.00564171674838293, 0.0056414784329133199, 0.0056412960856178146, 0.0056411137319047067, 0.0056409388002780364, 0.0056407775188933472, 0.0056406275607277226, 0.0056404884465145562, 0.0056403473946986362, 0.0056402080943749773, 0.005640064638696039, 0.0056399187224224698, 0.005639773829371553, 0.0056396214814616371, 0.0056394514591302704, 0.0056392792590922213, 0.0056391156001139031, 0.0056389609563278391, 0.0056388083038812599, 0.005638661062928825, 0.0056385137555755895, 0.0056383619496536549, 0.0056382103268473307, 0.0056380412052907478, 0.0056378583635830924], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098411986373188425, 0.0089146227855795481, 0.0082483410528216596, 0.0077581541284432263, 0.0073900554816480812, 0.0071082866266077172, 0.0068886741138793504, 0.0067148617210651528, 0.0065756410883212142, 0.0064624122837682995, 0.006369327851727182, 0.0062921581492861372, 0.0062275769120296942, 0.0061729875267694202, 0.0061261901719745085, 0.0060826705447365546, 0.0060408499391482687, 0.0060048024790258408, 0.0059679761604187944, 0.0059308459705862803, 0.0058998495020380201, 0.0058740392710606134, 0.0058521757294894058, 0.0058335676080303444, 0.0058177149394140464, 0.005804162808800601, 0.0057925041535201874, 0.0057824500479198267, 0.0057737863501660753, 0.0057643838565166966, 0.0057551567003746385, 0.0057472572222395926, 0.0057404686844179176, 0.0057346190138325244, 0.0057295757527958697, 0.005725204689974406, 0.0057213982822456044, 0.0057180896832943655, 0.0057152069090989355, 0.0057126849435811229, 0.0057104744400193032, 0.0057085370717516919, 0.0057068447606086845, 0.005705346159759977, 0.0057040243336412564, 0.0057028657672152875, 0.0057018194289891041, 0.0057008738470165129, 0.0057000222341427849, 0.0056992390939406392, 0.0056985577483132993, 0.005697969999175774, 0.0056974315666950843, 0.005696946045499726, 0.0056965110166316366, 0.005696120202665726, 0.0056957582247193035, 0.005695426659593392, 0.005695118299969262, 0.0056948370731314431, 0.0056945727695119379, 0.0056943255266314365, 0.0056940942945086157, 0.0056938740962777235, 0.0056936697799717453, 0.0056934752806767821, 0.0056932878033962775, 0.0056931104520625006, 0.0056929383926460301, 0.0056927720929801327, 0.0056926150566415767, 0.0056924569591188471, 0.0056922802318294967, 0.0056920774980402803, 0.0056918985849950332, 0.0056917277311423122, 0.0056915544101478451, 0.0056913489902469076, 0.005691142297279338, 0.0056909693046540985, 0.0056907931776316971, 0.0056906221880873237, 0.0056904722286343235, 0.0056903273116637627, 0.0056901924943475284, 0.0056900617989939064, 0.0056899296582441092, 0.0056897960732412859, 0.0056896535289884566, 0.0056895097476209952, 0.0056893567404214434, 0.0056891953511472469, 0.0056890375319238679, 0.0056888798950325749, 0.0056887300923051491, 0.0056885825105425737, 0.0056884357180092921, 0.0056882962477954159, 0.0056881565623267951, 0.0056879971621299034, 0.0056878291848944974], 'acc': [0.58585982573197726, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268059583, 0.59383822268791198, 0.59383822270254427, 0.59383822268059583, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822267327968, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.59383822267327968, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198]}
[2017-11-13 16:10:53,318 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:95]: done!
[2017-11-13 16:10:53,319 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-13 16:10:53,319 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:100]: =======================================
[2017-11-13 16:10:53,319 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2bf661e400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 16:10:53,368 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:113]: training ... 
[2017-11-13 16:17:14,474 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:125]: trained!
[2017-11-13 16:17:14,475 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0093178072816273699, 0.0085339893722815672, 0.007962476462639187, 0.0075369076928255953, 0.0072136763065713859, 0.0069634648753916766, 0.0067665489585245304, 0.0066095301289301675, 0.0064826391757805092, 0.006378711490470537, 0.0062927932551049195, 0.0062211897615747211, 0.0061609044136087254, 0.0061096496308802222, 0.0060645669879434913, 0.0060203708535438837, 0.0059811179011030613, 0.0059461795036276771, 0.005906167971493949, 0.0058715636910407236, 0.0058427591965072067, 0.005818500774370035, 0.0057978459132629221, 0.0057802372340808421, 0.0057652088902816747, 0.0057522949246838224, 0.0057411315621248901, 0.0057315280167601571, 0.0057228548009529059, 0.0057126038494043786, 0.0057038666346910976, 0.0056963542224555243, 0.0056898614651126837, 0.0056842628435000023, 0.0056794087176794067, 0.0056751791536855936, 0.0056714981720597645, 0.0056682894346418902, 0.0056654843585603335, 0.0056630136299356737, 0.0056608477372057306, 0.0056589564191467049, 0.0056572751480420637, 0.0056557974989297679, 0.0056545017003049227, 0.0056533357456226545, 0.0056522786158634342, 0.0056513269671137302, 0.0056504621813077173, 0.0056496691538033975, 0.0056490065607467162, 0.0056484045069945376, 0.0056478523096334613, 0.0056473593316042642, 0.0056469150456418147, 0.0056465082340324433, 0.0056461338669154763, 0.0056457930689116954, 0.0056454750567363852, 0.0056451803679279889, 0.0056449034018869878, 0.005644636876259556, 0.0056443912822866822, 0.0056441639462237424, 0.0056439468943271258, 0.0056437471860459089, 0.0056435520583931432, 0.0056433713478431548, 0.005643190710282707, 0.0056430143948496539, 0.0056428394636508245, 0.0056426635104272951, 0.0056424569872504686, 0.0056422602050540333, 0.0056420791735383178, 0.0056418991381201851, 0.00564171674838293, 0.0056414784329133199, 0.0056412960856178146, 0.0056411137319047067, 0.0056409388002780364, 0.0056407775188933472, 0.0056406275607277226, 0.0056404884465145562, 0.0056403473946986362, 0.0056402080943749773, 0.005640064638696039, 0.0056399187224224698, 0.005639773829371553, 0.0056396214814616371, 0.0056394514591302704, 0.0056392792590922213, 0.0056391156001139031, 0.0056389609563278391, 0.0056388083038812599, 0.005638661062928825, 0.0056385137555755895, 0.0056383619496536549, 0.0056382103268473307, 0.0056380412052907478, 0.0056378583635830924], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098411986373188425, 0.0089146227855795481, 0.0082483410528216596, 0.0077581541284432263, 0.0073900554816480812, 0.0071082866266077172, 0.0068886741138793504, 0.0067148617210651528, 0.0065756410883212142, 0.0064624122837682995, 0.006369327851727182, 0.0062921581492861372, 0.0062275769120296942, 0.0061729875267694202, 0.0061261901719745085, 0.0060826705447365546, 0.0060408499391482687, 0.0060048024790258408, 0.0059679761604187944, 0.0059308459705862803, 0.0058998495020380201, 0.0058740392710606134, 0.0058521757294894058, 0.0058335676080303444, 0.0058177149394140464, 0.005804162808800601, 0.0057925041535201874, 0.0057824500479198267, 0.0057737863501660753, 0.0057643838565166966, 0.0057551567003746385, 0.0057472572222395926, 0.0057404686844179176, 0.0057346190138325244, 0.0057295757527958697, 0.005725204689974406, 0.0057213982822456044, 0.0057180896832943655, 0.0057152069090989355, 0.0057126849435811229, 0.0057104744400193032, 0.0057085370717516919, 0.0057068447606086845, 0.005705346159759977, 0.0057040243336412564, 0.0057028657672152875, 0.0057018194289891041, 0.0057008738470165129, 0.0057000222341427849, 0.0056992390939406392, 0.0056985577483132993, 0.005697969999175774, 0.0056974315666950843, 0.005696946045499726, 0.0056965110166316366, 0.005696120202665726, 0.0056957582247193035, 0.005695426659593392, 0.005695118299969262, 0.0056948370731314431, 0.0056945727695119379, 0.0056943255266314365, 0.0056940942945086157, 0.0056938740962777235, 0.0056936697799717453, 0.0056934752806767821, 0.0056932878033962775, 0.0056931104520625006, 0.0056929383926460301, 0.0056927720929801327, 0.0056926150566415767, 0.0056924569591188471, 0.0056922802318294967, 0.0056920774980402803, 0.0056918985849950332, 0.0056917277311423122, 0.0056915544101478451, 0.0056913489902469076, 0.005691142297279338, 0.0056909693046540985, 0.0056907931776316971, 0.0056906221880873237, 0.0056904722286343235, 0.0056903273116637627, 0.0056901924943475284, 0.0056900617989939064, 0.0056899296582441092, 0.0056897960732412859, 0.0056896535289884566, 0.0056895097476209952, 0.0056893567404214434, 0.0056891953511472469, 0.0056890375319238679, 0.0056888798950325749, 0.0056887300923051491, 0.0056885825105425737, 0.0056884357180092921, 0.0056882962477954159, 0.0056881565623267951, 0.0056879971621299034, 0.0056878291848944974], 'acc': [0.58585982573197726, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268059583, 0.59383822268791198, 0.59383822270254427, 0.59383822268059583, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822267327968, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.59383822267327968, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198]}
[2017-11-13 16:17:14,475 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-13 16:17:14,629 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-13 16:17:14,629 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-13 16:17:15,568 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:141]: done!
[2017-11-13 16:17:15,569 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_9L_FULLDS_UNDER_02 finished!
[2017-11-14 07:04:16,213 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_9L_FULLDS_UNDER_02 was already executed!
[2017-11-18 14:56:04,686 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_9L_FULLDS_UNDER_02 was already executed!
[2017-11-18 16:22:34,761 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_9L_FULLDS_UNDER_02 was already executed!
[2017-11-18 17:31:44,614 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_9L_FULLDS_UNDER_02
[2017-11-18 17:31:44,614 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 17:31:44,614 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_9L_FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/9layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/9layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/9layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/9layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/9layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f81cae68eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f81cae6d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:31:44,615 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 17:31:46,848 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:31:46,848 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:31:46,848 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 17:31:46,848 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f81cae68eb8>, 'discard_decoder_function': True}
[2017-11-18 17:31:47,032 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 17:33:33,311 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 17:33:33,312 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.00987194400234165, 0.0095200324804138418, 0.0092902731869844817, 0.009137464073876474, 0.0090318021488754851, 0.0089560214752514144, 0.0088999265683722475, 0.0088570145178190583, 0.0088233840944452867, 0.0087965482309219686, 0.0087747097734836958, 0.0087566610623544001, 0.0087416016403277629, 0.0087289130109821297, 0.0087181723377818317, 0.0087089885354113238, 0.0087011220657192412, 0.0086943545409206829, 0.0086885083761806883, 0.00868346790712257, 0.0086790793624975937, 0.0086752689559558924, 0.0086719591327310049, 0.0086690707084986704, 0.0086665569583158734, 0.0086643534319907241, 0.0086624192221802804, 0.0086607219242668468, 0.0086592352452445932, 0.0086579353280587263, 0.0086567895302123894, 0.0086557727285860343, 0.0086548662577091394, 0.0086540808974437007, 0.0086533780090267149, 0.0086527574380934353, 0.0086522008963572719, 0.0086516985311715401, 0.008651217494333811, 0.0086508102133837275, 0.0086504462664862714, 0.0086500989752371533, 0.0086497965558695253, 0.008649524112356274, 0.0086492806401285826, 0.0086490652954855501, 0.0086488707452459356, 0.0086486926613781479, 0.0086485342300938184, 0.0086483893825651005, 0.0086482592359683561, 0.0086481395670072823, 0.0086480342686855362, 0.0086479391416658686, 0.0086478500800513253, 0.0086477716391422169, 0.0086476941018316378, 0.0086476226278725515, 0.0086475610247005747, 0.0086475030431104292, 0.0086474472133854178, 0.0086473977697745525, 0.0086473499731773706, 0.008647308878611551, 0.0086472696350536251, 0.0086472305256663894, 0.0086471931115532138, 0.0086471607918190158, 0.0086471273323184914, 0.0086470949735652659, 0.0086470647002763711, 0.0086470303991285809, 0.0086470041578058498, 0.0086469744595342023, 0.0086469484817610423, 0.0086469219378697126, 0.0086468948388129241, 0.0086468669764891964, 0.0086468402234695704, 0.0086468131285200485, 0.0086467914401017233, 0.0086467650567360419, 0.008646738550836924, 0.0086467163606475973, 0.0086466905050656025, 0.0086466645779487237, 0.008646641024831616, 0.0086466164893933793, 0.008646593153276828, 0.0086465708949753396, 0.0086465468212622611, 0.0086465221300901889, 0.0086464949269826601, 0.0086464720686780586, 0.0086464501978286666, 0.0086464257390593963, 0.0086464001357319901, 0.008646373833484813, 0.0086463497101422707, 0.0086463237576972513, 0.0086462996853532616], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010124816161439662, 0.0096843326558033512, 0.009398318614069489, 0.0092102440400569224, 0.0090830546736441042, 0.0089936285571536878, 0.0089285205182031476, 0.0088796106364787894, 0.0088417255111030452, 0.008811771530830393, 0.0087876685702862577, 0.0087678997926125945, 0.0087514710596019434, 0.0087376996396744816, 0.0087260717697093138, 0.0087161883454606615, 0.0087077212632543782, 0.008700457678101129, 0.0086941945521915205, 0.0086887858765058255, 0.0086841122251279709, 0.008680052861065584, 0.0086765184175903055, 0.008673439906299393, 0.0086707631256365044, 0.0086684252406495962, 0.0086663846428136505, 0.0086645878345227856, 0.0086630125703479645, 0.0086616321161756982, 0.0086604219994962581, 0.008659359357809383, 0.0086584085180424503, 0.0086575767063761296, 0.0086568421412707916, 0.0086561864321063504, 0.0086556105728498832, 0.00865509394522904, 0.0086546079091598793, 0.0086541734342040922, 0.0086537960333066283, 0.0086534517529468918, 0.0086531438747594891, 0.0086528671153435696, 0.008652619280884042, 0.0086523986967835843, 0.0086522067683138804, 0.0086520250496408008, 0.0086518648094588493, 0.0086517167607203672, 0.0086515863509822426, 0.0086514710879534735, 0.0086513615887906115, 0.0086512653830657718, 0.0086511734575152079, 0.008651092102995998, 0.0086510222094487652, 0.0086509468097011565, 0.0086508846907026281, 0.0086508246277698687, 0.0086507696241809786, 0.0086507206744746122, 0.0086506705160036817, 0.0086506273003270594, 0.0086505868788467923, 0.008650546922399081, 0.0086505080319367635, 0.0086504729522722066, 0.0086504413127968666, 0.0086504053210146193, 0.0086503713121366781, 0.008650338955221732, 0.0086503070554516202, 0.0086502834880863785, 0.008650257813442341, 0.0086502252971725809, 0.0086501991716710219, 0.0086501720954133745, 0.0086501402574875631, 0.0086501171533258404, 0.0086500835746144457, 0.00865006596407847, 0.0086500399704961765, 0.0086500114377538184, 0.0086499883618278497, 0.0086499628144161705, 0.0086499373242762013, 0.0086499136756331453, 0.0086498863485688533, 0.0086498630554447866, 0.0086498391450208663, 0.0086498099657140708, 0.0086497867571829479, 0.0086497633497440926, 0.0086497376385193253, 0.0086497157434651094, 0.0086496924673739473, 0.0086496695565185296, 0.0086496444314428343, 0.0086496203235401185, 0.0086495932870640172], 'acc': [0.009942310052780165, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032880912079, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.01055603289645889]}
[2017-11-18 17:33:33,312 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:95]: done!
[2017-11-18 17:33:33,312 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 17:33:33,312 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 17:33:33,312 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f81cae6d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:33:33,344 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 17:38:10,675 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 17:38:10,676 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.00987194400234165, 0.0095200324804138418, 0.0092902731869844817, 0.009137464073876474, 0.0090318021488754851, 0.0089560214752514144, 0.0088999265683722475, 0.0088570145178190583, 0.0088233840944452867, 0.0087965482309219686, 0.0087747097734836958, 0.0087566610623544001, 0.0087416016403277629, 0.0087289130109821297, 0.0087181723377818317, 0.0087089885354113238, 0.0087011220657192412, 0.0086943545409206829, 0.0086885083761806883, 0.00868346790712257, 0.0086790793624975937, 0.0086752689559558924, 0.0086719591327310049, 0.0086690707084986704, 0.0086665569583158734, 0.0086643534319907241, 0.0086624192221802804, 0.0086607219242668468, 0.0086592352452445932, 0.0086579353280587263, 0.0086567895302123894, 0.0086557727285860343, 0.0086548662577091394, 0.0086540808974437007, 0.0086533780090267149, 0.0086527574380934353, 0.0086522008963572719, 0.0086516985311715401, 0.008651217494333811, 0.0086508102133837275, 0.0086504462664862714, 0.0086500989752371533, 0.0086497965558695253, 0.008649524112356274, 0.0086492806401285826, 0.0086490652954855501, 0.0086488707452459356, 0.0086486926613781479, 0.0086485342300938184, 0.0086483893825651005, 0.0086482592359683561, 0.0086481395670072823, 0.0086480342686855362, 0.0086479391416658686, 0.0086478500800513253, 0.0086477716391422169, 0.0086476941018316378, 0.0086476226278725515, 0.0086475610247005747, 0.0086475030431104292, 0.0086474472133854178, 0.0086473977697745525, 0.0086473499731773706, 0.008647308878611551, 0.0086472696350536251, 0.0086472305256663894, 0.0086471931115532138, 0.0086471607918190158, 0.0086471273323184914, 0.0086470949735652659, 0.0086470647002763711, 0.0086470303991285809, 0.0086470041578058498, 0.0086469744595342023, 0.0086469484817610423, 0.0086469219378697126, 0.0086468948388129241, 0.0086468669764891964, 0.0086468402234695704, 0.0086468131285200485, 0.0086467914401017233, 0.0086467650567360419, 0.008646738550836924, 0.0086467163606475973, 0.0086466905050656025, 0.0086466645779487237, 0.008646641024831616, 0.0086466164893933793, 0.008646593153276828, 0.0086465708949753396, 0.0086465468212622611, 0.0086465221300901889, 0.0086464949269826601, 0.0086464720686780586, 0.0086464501978286666, 0.0086464257390593963, 0.0086464001357319901, 0.008646373833484813, 0.0086463497101422707, 0.0086463237576972513, 0.0086462996853532616], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010124816161439662, 0.0096843326558033512, 0.009398318614069489, 0.0092102440400569224, 0.0090830546736441042, 0.0089936285571536878, 0.0089285205182031476, 0.0088796106364787894, 0.0088417255111030452, 0.008811771530830393, 0.0087876685702862577, 0.0087678997926125945, 0.0087514710596019434, 0.0087376996396744816, 0.0087260717697093138, 0.0087161883454606615, 0.0087077212632543782, 0.008700457678101129, 0.0086941945521915205, 0.0086887858765058255, 0.0086841122251279709, 0.008680052861065584, 0.0086765184175903055, 0.008673439906299393, 0.0086707631256365044, 0.0086684252406495962, 0.0086663846428136505, 0.0086645878345227856, 0.0086630125703479645, 0.0086616321161756982, 0.0086604219994962581, 0.008659359357809383, 0.0086584085180424503, 0.0086575767063761296, 0.0086568421412707916, 0.0086561864321063504, 0.0086556105728498832, 0.00865509394522904, 0.0086546079091598793, 0.0086541734342040922, 0.0086537960333066283, 0.0086534517529468918, 0.0086531438747594891, 0.0086528671153435696, 0.008652619280884042, 0.0086523986967835843, 0.0086522067683138804, 0.0086520250496408008, 0.0086518648094588493, 0.0086517167607203672, 0.0086515863509822426, 0.0086514710879534735, 0.0086513615887906115, 0.0086512653830657718, 0.0086511734575152079, 0.008651092102995998, 0.0086510222094487652, 0.0086509468097011565, 0.0086508846907026281, 0.0086508246277698687, 0.0086507696241809786, 0.0086507206744746122, 0.0086506705160036817, 0.0086506273003270594, 0.0086505868788467923, 0.008650546922399081, 0.0086505080319367635, 0.0086504729522722066, 0.0086504413127968666, 0.0086504053210146193, 0.0086503713121366781, 0.008650338955221732, 0.0086503070554516202, 0.0086502834880863785, 0.008650257813442341, 0.0086502252971725809, 0.0086501991716710219, 0.0086501720954133745, 0.0086501402574875631, 0.0086501171533258404, 0.0086500835746144457, 0.00865006596407847, 0.0086500399704961765, 0.0086500114377538184, 0.0086499883618278497, 0.0086499628144161705, 0.0086499373242762013, 0.0086499136756331453, 0.0086498863485688533, 0.0086498630554447866, 0.0086498391450208663, 0.0086498099657140708, 0.0086497867571829479, 0.0086497633497440926, 0.0086497376385193253, 0.0086497157434651094, 0.0086496924673739473, 0.0086496695565185296, 0.0086496444314428343, 0.0086496203235401185, 0.0086495932870640172], 'acc': [0.009942310052780165, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032880912079, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.01055603289645889]}
[2017-11-18 17:38:10,676 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 17:38:10,817 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 17:38:10,818 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 17:38:11,706 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:141]: done!
[2017-11-18 17:38:11,706 AE_UNIGRAMA_9L_FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_9L_FULLDS_UNDER_02 finished!
