[2018-06-03 00:54:28,282 AE_BIGRAMA_4L_MINIDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_4L_MINIDS_OVER_02
[2018-06-03 00:54:28,282 AE_BIGRAMA_4L_MINIDS_OVER_02.py:146]: >> Printing header log
[2018-06-03 00:54:28,283 AE_BIGRAMA_4L_MINIDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_4L_MINIDS_OVER_02
	layers = 9216,14746,13272,11799,10325
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd9644dd630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd9644dde10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,283 AE_BIGRAMA_4L_MINIDS_OVER_02.py:148]: >> Loading dataset... 
[2018-06-03 00:54:53,811 AE_BIGRAMA_4L_MINIDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-06-03 00:54:53,812 AE_BIGRAMA_4L_MINIDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-06-03 00:54:53,812 AE_BIGRAMA_4L_MINIDS_OVER_02.py:57]: =======================================
[2018-06-03 00:54:53,812 AE_BIGRAMA_4L_MINIDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd9644dd630>, 'discard_decoder_function': True}
[2018-06-03 00:54:54,020 AE_BIGRAMA_4L_MINIDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-06-14 02:40:41,008 AE_BIGRAMA_4L_MINIDS_OVER_02.py:85]: trained and evaluated!
[2018-06-14 02:40:41,015 AE_BIGRAMA_4L_MINIDS_OVER_02.py:88]: Training history: 
{'val_loss': [0.00010695422627575266, 0.00010695271091009387, 0.0001069512001209588, 0.00010694967764023582, 0.00010694814747238316, 0.0001069466144442032, 0.00010694507626743406, 0.00010694354365042615, 0.00010694201226693438, 0.00010694047882758236, 0.0001069389457994024, 0.00010693741915332777, 0.00010693588008270633, 0.00010693433430819276, 0.00010693278199068045, 0.00010693122935138131, 0.00010692968888635031, 0.0001069281403230176, 0.00010692657558095849, 0.00010692502971705969, 0.0001069234802598747, 0.00010692192933677194, 0.00010692037244273593, 0.00010691879429289252, 0.00010691723069496435, 0.0001069156638255368, 0.00010691410333821459, 0.00010691253294700903, 0.00010691096257368052, 0.00010690939709866255, 0.00010690781789407344, 0.00010690624612633537, 0.00010690467271390909, 0.000106903106416547, 0.00010690153579293985, 0.00010689996189783334, 0.00010689838260385901, 0.00010689680086072942, 0.00010689522099468963, 0.00010689363540799519, 0.00010689205766932384, 0.00010689047134967055, 0.00010688888862330342, 0.00010688730662989519, 0.00010688572447559355, 0.00010688414264307872, 0.0001068825517469017, 0.00010688096885964119, 0.00010687937771318554, 0.00010687778329523052, 0.00010687620457332165, 0.00010687460860006365, 0.00010687301516534614, 0.0001068714153485233, 0.00010686981578197911, 0.00010686822266904844, 0.00010686662097513579, 0.00010686501216615896, 0.00010686340736164036, 0.00010686179756942601, 0.00010686018516716298, 0.00010685858436710263, 0.00010685697457488827, 0.0001068553573458229, 0.00010685375196923885, 0.00010685214160495903, 0.00010685053091889238, 0.00010684891769428525, 0.00010684730030432645, 0.00010684569517802104, 0.00010684407181712897, 0.00010684245058360534, 0.00010684083678693275, 0.00010683922397349766, 0.00010683759743049146, 0.00010683597054782138, 0.00010683434366515131, 0.00010683271858806284, 0.00010683108737914771, 0.00010682944873338154, 0.00010682781539709794, 0.0001068261841881828, 0.00010682454472007253, 0.00010682290451900337, 0.00010682126292352467, 0.0001068196251001026, 0.0001068179802331245, 0.000106816336760556, 0.00010681469328798747, 0.00010681305937963842, 0.00010681141975063474, 0.0001068097842869827, 0.00010680814751830634, 0.00010680650363456577, 0.00010680484323243494, 0.00010680319934869437, 0.00010680154320130042, 0.00010679988206621071, 0.00010679822813557044, 0.00010679657542056928, 0.00010679491371341411], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00010705285071693391, 0.00010705136931300351, 0.00010704988274243221, 0.00010704839448914757, 0.00010704689509677473, 0.00010704539027705892, 0.00010704387825248605, 0.00010704236117977322, 0.00010704084531576994, 0.00010703933587451753, 0.00010703781920470789, 0.00010703630796224122, 0.00010703479844988824, 0.0001070332781302497, 0.00010703175221736686, 0.00010703021760651515, 0.00010702868316156475, 0.00010702716559114796, 0.00010702563659724073, 0.00010702409575323966, 0.00010702257057506264, 0.00010702104572868824, 0.00010701951704288344, 0.0001070179840199443, 0.00010701643533118112, 0.00010701489605139243, 0.00010701335326397597, 0.00010701181948263082, 0.00010701027482289954, 0.00010700873096897464, 0.00010700719045677619, 0.00010700563842628655, 0.00010700409303184944, 0.00010700254619170089, 0.00010700100814432197, 0.0001069994615411753, 0.00010699791678664326, 0.00010699636136702677, 0.00010699480644511423, 0.00010699325616843847, 0.00010699169811810115, 0.0001069901445707995, 0.00010698858448224604, 0.00010698702586310422, 0.00010698546982728285, 0.00010698391497647087, 0.00010698235846664574, 0.00010698079475196358, 0.00010697923857394109, 0.00010697767234703902, 0.00010697610491142739, 0.00010697455115082403, 0.0001069729829568064, 0.00010697141687210546, 0.00010696984659247131, 0.0001069682741087197, 0.00010696670980153284, 0.00010696513309914782, 0.00010696355694186714, 0.00010696197917297367, 0.00010696039974506708, 0.00010695881830264453, 0.00010695724261936759, 0.00010695566018153716, 0.00010695406880873598, 0.00010695248817211982, 0.00010695090597129127, 0.0001069493245762691, 0.00010694773732730057, 0.00010694614389258306, 0.00010694456427507497, 0.00010694296228458972, 0.00010694136569774725, 0.00010693977558105602, 0.00010693819025180269, 0.0001069365873607103, 0.00010693498646043369, 0.00010693338442254805, 0.00010693178179215773, 0.00010693017444543006, 0.0001069285609366536, 0.00010692695340032444, 0.00010692534674090221, 0.00010692373285292275, 0.00010692211768513315, 0.00010692050422375707, 0.00010691889021727667, 0.00010691727279796924, 0.00010691565080452559, 0.00010691403509163167, 0.00010691242843220945, 0.00010691080871398382, 0.00010690919719602312, 0.00010690758871168644, 0.00010690596847205668, 0.00010690433225850044, 0.00010690271661670708, 0.00010690108552239137, 0.00010689945096784826, 0.00010689781961283049, 0.00010689619280824875], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-06-14 02:40:41,015 AE_BIGRAMA_4L_MINIDS_OVER_02.py:92]: done!
[2018-06-14 02:40:41,015 AE_BIGRAMA_4L_MINIDS_OVER_02.py:152]: >> Executing classifier part ... 
[2018-06-14 02:40:41,015 AE_BIGRAMA_4L_MINIDS_OVER_02.py:97]: =======================================
[2018-06-14 02:40:41,015 AE_BIGRAMA_4L_MINIDS_OVER_02.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd9644dde10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-14 02:40:41,421 AE_BIGRAMA_4L_MINIDS_OVER_02.py:110]: training ... 
