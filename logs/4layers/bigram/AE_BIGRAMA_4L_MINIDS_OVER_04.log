[2018-06-03 00:54:28,268 AE_BIGRAMA_4L_MINIDS_OVER_04.py:145]: >> Initializing execution of experiment AE_BIGRAMA_4L_MINIDS_OVER_04
[2018-06-03 00:54:28,268 AE_BIGRAMA_4L_MINIDS_OVER_04.py:146]: >> Printing header log
[2018-06-03 00:54:28,268 AE_BIGRAMA_4L_MINIDS_OVER_04.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_4L_MINIDS_OVER_04
	layers = 9216,16589,14931,13273,11615
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa01ae330b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa01ae33630>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,269 AE_BIGRAMA_4L_MINIDS_OVER_04.py:148]: >> Loading dataset... 
[2018-06-03 00:54:52,662 AE_BIGRAMA_4L_MINIDS_OVER_04.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-06-03 00:54:52,663 AE_BIGRAMA_4L_MINIDS_OVER_04.py:150]: >> Executing autoencoder part ... 
[2018-06-03 00:54:52,663 AE_BIGRAMA_4L_MINIDS_OVER_04.py:57]: =======================================
[2018-06-03 00:54:52,663 AE_BIGRAMA_4L_MINIDS_OVER_04.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa01ae330b8>, 'discard_decoder_function': True}
[2018-06-03 00:54:52,860 AE_BIGRAMA_4L_MINIDS_OVER_04.py:73]: training and evaluate autoencoder
[2018-06-23 10:16:34,914 AE_BIGRAMA_4L_MINIDS_OVER_04.py:85]: trained and evaluated!
[2018-06-23 10:16:34,915 AE_BIGRAMA_4L_MINIDS_OVER_04.py:88]: Training history: 
{'val_loss': [0.00010702864982943446, 0.00010702750433985195, 0.00010702635967261353, 0.00010702521319979349, 0.00010702405773481945, 0.00010702290178716517, 0.00010702174085181513, 0.00010702056699136102, 0.00010701939207616122, 0.00010701822157659172, 0.0001070170463396051, 0.00010701586300431675, 0.0001070146608623763, 0.00010701346249249249, 0.00010701226755500147, 0.00010701105822648862, 0.00010700985756834296, 0.00010700863769237314, 0.00010700742149907473, 0.00010700620939961981, 0.0001070049736667104, 0.0001070037510197985, 0.00010700251775392142, 0.00010700127647912784, 0.00010700002873284371, 0.00010699878688598468, 0.00010699754307265062, 0.00010699628454650791, 0.00010699503345721623, 0.00010699376511657541, 0.00010699250160273695, 0.00010699122934702312, 0.00010698995054831056, 0.00010698866692279563, 0.0001069873741442333, 0.00010698608676453879, 0.00010698478082847079, 0.00010698348404545021, 0.00010698217982557861, 0.00010698087846603433, 0.00010697956925846696, 0.00010697827125980726, 0.00010697696008576488, 0.000106975644424584, 0.00010697433562818869, 0.00010697300646983829, 0.00010697168868128897, 0.00010697036320560998, 0.00010696904010757809, 0.0001069677179927837, 0.00010696637567692764, 0.00010696503647167753, 0.00010696370470327845, 0.00010696237064661751, 0.00010696102800897462, 0.00010695967818475934, 0.00010695833195383027, 0.00010695698718881894, 0.00010695563482606317, 0.00010695427763650505, 0.00010695291856985713, 0.00010695156089761878, 0.00010695019316060368, 0.000106948823635884, 0.0001069474450296251, 0.0001069460699451442, 0.0001069446977924988, 0.00010694332099182151, 0.00010694194533527515, 0.00010694057556027684, 0.00010693919409369061, 0.00010693781033884253, 0.00010693642175719211, 0.00010693504054088452, 0.00010693363928440867, 0.0001069322458044477, 0.00010693085870659207, 0.000106929460882509, 0.00010692806127072136, 0.00010692665772598365, 0.00010692527177225895, 0.00010692388000849437, 0.00010692247490845369, 0.00010692109042064673, 0.00010691969570716962, 0.00010691830067190568, 0.00010691689884336437, 0.00010691550952875506, 0.00010691411081081971, 0.00010691270335100898, 0.00010691130602748319, 0.00010690989692298425, 0.00010690848177604386, 0.00010690707308271699, 0.00010690566406760328, 0.00010690425464131753, 0.000106902845304417, 0.00010690143251724665, 0.0001069000194976747, 0.00010689860279543133, 0.00010689719581830084], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00010711733634425904, 0.00010711622255393956, 0.00010711510461608724, 0.00010711398767364281, 0.00010711286528015521, 0.00010711173153427772, 0.00010711059480217658, 0.00010710945852037902, 0.00010710830910867748, 0.00010710715865416767, 0.0001071060116124849, 0.00010710486084987266, 0.00010710370311940526, 0.00010710253256713631, 0.00010710136139866249, 0.00010710018871337667, 0.00010709900702201952, 0.00010709783210891605, 0.00010709663688475176, 0.00010709544279819646, 0.0001070942493989466, 0.00010709303654184267, 0.00010709183420762207, 0.00010709062246442696, 0.0001070894081379114, 0.00010708818596663372, 0.00010708696429305998, 0.0001070857417425793, 0.0001070845067257999, 0.00010708327452934284, 0.00010708203218920545, 0.0001070807872657476, 0.0001070795368912466, 0.00010707828334092045, 0.00010707702348634437, 0.00010707575571590561, 0.00010707448742406273, 0.00010707321003134778, 0.00010707193249643171, 0.00010707065124058616, 0.00010706936818352637, 0.0001070680814055371, 0.00010706680344401765, 0.00010706551341910268, 0.00010706422081086723, 0.00010706292535860929, 0.00010706161890946426, 0.00010706031978367722, 0.00010705901390333669, 0.00010705770280895487, 0.00010705639624130892, 0.00010705507320203251, 0.00010705374639442628, 0.00010705243262192325, 0.00010705111034105287, 0.0001070497837704485, 0.00010704845174880097, 0.00010704712129136583, 0.00010704579735148231, 0.00010704446186960738, 0.00010704312259570244, 0.00010704178163908415, 0.0001070404429576839, 0.00010703910240396881, 0.00010703774976315802, 0.00010703639534483315, 0.00010703503893569251, 0.00010703368508617215, 0.00010703233296676548, 0.00010703097113028187, 0.0001070296257417285, 0.00010702826411854658, 0.00010702690090745208, 0.00010702553558704089, 0.00010702417453266347, 0.00010702279667485299, 0.0001070214259744992, 0.00010702005894767448, 0.0001070186868727098, 0.00010701730816169257, 0.00010701592653555225, 0.00010701455706760822, 0.00010701318650945554, 0.00010701180910194863, 0.00010701044214622448, 0.0001070090700712598, 0.00010700769982120957, 0.00010700632222410116, 0.00010700495204515149, 0.00010700357769496879, 0.00010700219222939807, 0.00010700081657570504, 0.00010699942973552345, 0.00010699803519278085, 0.00010699664880290282, 0.00010699526528074748, 0.00010699387749255838, 0.00010699248802165595, 0.00010699110035196778, 0.0001069897086769479, 0.00010698831565101731], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-06-23 10:16:34,915 AE_BIGRAMA_4L_MINIDS_OVER_04.py:92]: done!
[2018-06-23 10:16:34,915 AE_BIGRAMA_4L_MINIDS_OVER_04.py:152]: >> Executing classifier part ... 
[2018-06-23 10:16:34,915 AE_BIGRAMA_4L_MINIDS_OVER_04.py:97]: =======================================
[2018-06-23 10:16:34,915 AE_BIGRAMA_4L_MINIDS_OVER_04.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa01ae33630>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-23 10:16:34,965 AE_BIGRAMA_4L_MINIDS_OVER_04.py:110]: training ... 
[2018-06-23 20:41:18,919 AE_BIGRAMA_4L_MINIDS_OVER_04.py:122]: trained!
[2018-06-23 20:41:18,920 AE_BIGRAMA_4L_MINIDS_OVER_04.py:125]: Training history: 
{'val_loss': [0.00010702864982943446, 0.00010702750433985195, 0.00010702635967261353, 0.00010702521319979349, 0.00010702405773481945, 0.00010702290178716517, 0.00010702174085181513, 0.00010702056699136102, 0.00010701939207616122, 0.00010701822157659172, 0.0001070170463396051, 0.00010701586300431675, 0.0001070146608623763, 0.00010701346249249249, 0.00010701226755500147, 0.00010701105822648862, 0.00010700985756834296, 0.00010700863769237314, 0.00010700742149907473, 0.00010700620939961981, 0.0001070049736667104, 0.0001070037510197985, 0.00010700251775392142, 0.00010700127647912784, 0.00010700002873284371, 0.00010699878688598468, 0.00010699754307265062, 0.00010699628454650791, 0.00010699503345721623, 0.00010699376511657541, 0.00010699250160273695, 0.00010699122934702312, 0.00010698995054831056, 0.00010698866692279563, 0.0001069873741442333, 0.00010698608676453879, 0.00010698478082847079, 0.00010698348404545021, 0.00010698217982557861, 0.00010698087846603433, 0.00010697956925846696, 0.00010697827125980726, 0.00010697696008576488, 0.000106975644424584, 0.00010697433562818869, 0.00010697300646983829, 0.00010697168868128897, 0.00010697036320560998, 0.00010696904010757809, 0.0001069677179927837, 0.00010696637567692764, 0.00010696503647167753, 0.00010696370470327845, 0.00010696237064661751, 0.00010696102800897462, 0.00010695967818475934, 0.00010695833195383027, 0.00010695698718881894, 0.00010695563482606317, 0.00010695427763650505, 0.00010695291856985713, 0.00010695156089761878, 0.00010695019316060368, 0.000106948823635884, 0.0001069474450296251, 0.0001069460699451442, 0.0001069446977924988, 0.00010694332099182151, 0.00010694194533527515, 0.00010694057556027684, 0.00010693919409369061, 0.00010693781033884253, 0.00010693642175719211, 0.00010693504054088452, 0.00010693363928440867, 0.0001069322458044477, 0.00010693085870659207, 0.000106929460882509, 0.00010692806127072136, 0.00010692665772598365, 0.00010692527177225895, 0.00010692388000849437, 0.00010692247490845369, 0.00010692109042064673, 0.00010691969570716962, 0.00010691830067190568, 0.00010691689884336437, 0.00010691550952875506, 0.00010691411081081971, 0.00010691270335100898, 0.00010691130602748319, 0.00010690989692298425, 0.00010690848177604386, 0.00010690707308271699, 0.00010690566406760328, 0.00010690425464131753, 0.000106902845304417, 0.00010690143251724665, 0.0001069000194976747, 0.00010689860279543133, 0.00010689719581830084], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00010711733634425904, 0.00010711622255393956, 0.00010711510461608724, 0.00010711398767364281, 0.00010711286528015521, 0.00010711173153427772, 0.00010711059480217658, 0.00010710945852037902, 0.00010710830910867748, 0.00010710715865416767, 0.0001071060116124849, 0.00010710486084987266, 0.00010710370311940526, 0.00010710253256713631, 0.00010710136139866249, 0.00010710018871337667, 0.00010709900702201952, 0.00010709783210891605, 0.00010709663688475176, 0.00010709544279819646, 0.0001070942493989466, 0.00010709303654184267, 0.00010709183420762207, 0.00010709062246442696, 0.0001070894081379114, 0.00010708818596663372, 0.00010708696429305998, 0.0001070857417425793, 0.0001070845067257999, 0.00010708327452934284, 0.00010708203218920545, 0.0001070807872657476, 0.0001070795368912466, 0.00010707828334092045, 0.00010707702348634437, 0.00010707575571590561, 0.00010707448742406273, 0.00010707321003134778, 0.00010707193249643171, 0.00010707065124058616, 0.00010706936818352637, 0.0001070680814055371, 0.00010706680344401765, 0.00010706551341910268, 0.00010706422081086723, 0.00010706292535860929, 0.00010706161890946426, 0.00010706031978367722, 0.00010705901390333669, 0.00010705770280895487, 0.00010705639624130892, 0.00010705507320203251, 0.00010705374639442628, 0.00010705243262192325, 0.00010705111034105287, 0.0001070497837704485, 0.00010704845174880097, 0.00010704712129136583, 0.00010704579735148231, 0.00010704446186960738, 0.00010704312259570244, 0.00010704178163908415, 0.0001070404429576839, 0.00010703910240396881, 0.00010703774976315802, 0.00010703639534483315, 0.00010703503893569251, 0.00010703368508617215, 0.00010703233296676548, 0.00010703097113028187, 0.0001070296257417285, 0.00010702826411854658, 0.00010702690090745208, 0.00010702553558704089, 0.00010702417453266347, 0.00010702279667485299, 0.0001070214259744992, 0.00010702005894767448, 0.0001070186868727098, 0.00010701730816169257, 0.00010701592653555225, 0.00010701455706760822, 0.00010701318650945554, 0.00010701180910194863, 0.00010701044214622448, 0.0001070090700712598, 0.00010700769982120957, 0.00010700632222410116, 0.00010700495204515149, 0.00010700357769496879, 0.00010700219222939807, 0.00010700081657570504, 0.00010699942973552345, 0.00010699803519278085, 0.00010699664880290282, 0.00010699526528074748, 0.00010699387749255838, 0.00010699248802165595, 0.00010699110035196778, 0.0001069897086769479, 0.00010698831565101731], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-06-23 20:41:18,920 AE_BIGRAMA_4L_MINIDS_OVER_04.py:129]: evaluating model ... 
[2018-06-23 20:41:22,935 AE_BIGRAMA_4L_MINIDS_OVER_04.py:133]: evaluated! 
[2018-06-23 20:41:22,936 AE_BIGRAMA_4L_MINIDS_OVER_04.py:135]: generating reports ... 
[2018-06-23 20:41:23,515 AE_BIGRAMA_4L_MINIDS_OVER_04.py:138]: done!
[2018-06-23 20:41:23,515 AE_BIGRAMA_4L_MINIDS_OVER_04.py:154]: >> experiment AE_BIGRAMA_4L_MINIDS_OVER_04 finished!
