[2018-06-03 00:54:28,281 AE_BIGRAMA_4L_FULLDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_4L_FULLDS_OVER_02
[2018-06-03 00:54:28,282 AE_BIGRAMA_4L_FULLDS_OVER_02.py:146]: >> Printing header log
[2018-06-03 00:54:28,282 AE_BIGRAMA_4L_FULLDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_4L_FULLDS_OVER_02
	layers = 9216,14746,13272,11799,10325
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3b5cbed0b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f3b5cbed630>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,282 AE_BIGRAMA_4L_FULLDS_OVER_02.py:148]: >> Loading dataset... 
[2018-06-03 01:17:03,781 AE_BIGRAMA_4L_FULLDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-06-03 01:17:03,783 AE_BIGRAMA_4L_FULLDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-06-03 01:17:03,783 AE_BIGRAMA_4L_FULLDS_OVER_02.py:57]: =======================================
[2018-06-03 01:17:03,783 AE_BIGRAMA_4L_FULLDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3b5cbed0b8>, 'discard_decoder_function': True}
[2018-06-03 01:17:04,984 AE_BIGRAMA_4L_FULLDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-06-11 19:49:03,790 AE_BIGRAMA_4L_FULLDS_OVER_02.py:85]: trained and evaluated!
[2018-06-11 19:49:03,792 AE_BIGRAMA_4L_FULLDS_OVER_02.py:88]: Training history: 
{'val_loss': [0.00010697089367065591, 0.00010695984994355817, 0.00010694858005210207, 0.00010693715932023106, 0.00010692561888134259, 0.00010691398713065675, 0.00010690230007627545, 0.00010689055184609175, 0.00010687875913924397, 0.00010686692854981935, 0.00010685507027378501, 0.00010684318548235347, 0.00010683128563896847, 0.00010681936184722756, 0.00010680742948263841, 0.0001067954903688699, 0.0001067835500785408, 0.00010677160018052493, 0.00010675964799356393, 0.00010674769239457723, 0.00010673574166494695, 0.0001067237813409999, 0.0001067118245333646, 0.00010669986392062542, 0.00010668789805079961, 0.00010667593853172696, 0.00010666397799385981, 0.00010665201016933904, 0.00010664004045964733, 0.00010662807393469121, 0.00010661610475712575, 0.00010660412625799169, 0.0001065921515559395, 0.00010658017904924239, 0.00010656820646232526, 0.00010655623279243758, 0.00010654425841928756, 0.00010653228370119137, 0.00010652030557909147, 0.00010650833225949797, 0.00010649635807352804, 0.00010648437816786927, 0.00010647239561227518, 0.00010646040483947501, 0.00010644841005032484, 0.00010643640781408098, 0.00010642439623755047, 0.00010641238043609786, 0.00010640035853524823, 0.00010638832926752493, 0.00010637629402073467, 0.00010636425668020137, 0.00010635220768102227, 0.00010634016046540206, 0.00010632810722525686, 0.00010631605564834049, 0.00010630399788645904, 0.00010629193929563719, 0.00010627988622662807, 0.00010626783308542091, 0.00010625578612115684, 0.00010624373599354918, 0.00010623169432648172, 0.00010621965677470231, 0.00010620761603818732, 0.00010619558679720404, 0.00010618356398719397, 0.00010617154570159413, 0.00010615953391916551, 0.00010614752904635634, 0.00010613553003228408, 0.0001061235424896775, 0.00010611155535619315, 0.00010609957738651133, 0.00010608760889616423, 0.00010607564282044033, 0.0001060636865689973, 0.00010605174813977313, 0.00010603981005816914, 0.00010602788427162324, 0.0001060159684510803, 0.00010600406367148884, 0.00010599217143296362, 0.00010598028513339534, 0.00010596841090961707, 0.00010595654418908651, 0.00010594470179127204, 0.00010593286034005404, 0.0001059210347162499, 0.00010590922286355261, 0.00010589741770388063, 0.0001058856303343395, 0.00010587385596311882, 0.00010586208921547593, 0.0001058503407071961, 0.00010583859944545986, 0.00010582687576260836, 0.00010581516574657765, 0.00010580347149645877, 0.00010579178682193865, 0.00010578011209470347], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.0025725836089672913, 0.002940095553105476, 0.003675119441381845, 0.004777655273796398, 0.00735023888276369, 0.010290334435869165, 0.015067989709665565, 0.018743109151047408, 0.024990812201396546, 0.02682837192208747, 0.03234105108416024, 0.06909224549797868, 0.07276736493936053, 0.07791253215729511, 0.08011760382212423, 0.08158765159867695, 0.08342521131936788, 0.08452774715178243, 0.08489525909592062, 0.08563028298419699, 0.08636530687247336, 0.08783535464902609, 0.08820286659316427, 0.08820286659316427, 0.08930540242557883, 0.0900404263138552, 0.09040793825799338, 0.09040793825799338, 0.09114296214626975, 0.09151047409040794, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431], 'loss': [0.0001069810159788243, 0.00010697002794498663, 0.0001069587462873654, 0.00010694728734537031, 0.00010693569052455891, 0.00010692398597456338, 0.00010691221041454382, 0.00010690037875096989, 0.00010688849237883925, 0.00010687656634483583, 0.00010686460524477129, 0.00010685262359662369, 0.00010684061737526219, 0.0001068285993482196, 0.00010681655962905298, 0.00010680451471570821, 0.00010679246492701635, 0.00010678041503294056, 0.0001067683570359111, 0.00010675629891117059, 0.00010674423661661959, 0.0001067321793992527, 0.00010672011253121711, 0.00010670804955167047, 0.00010669598196023663, 0.00010668391077503163, 0.00010667184732036415, 0.00010665978253589418, 0.00010664771300289511, 0.00010663564088441705, 0.00010662357194710518, 0.00010661149767808018, 0.00010659941817200897, 0.00010658734087989369, 0.00010657526465680029, 0.00010656318759510075, 0.00010655111346986232, 0.00010653903728606462, 0.00010652696043156063, 0.00010651487936616427, 0.00010650280091839793, 0.00010649072067195986, 0.0001064786338059811, 0.00010646654670780046, 0.00010645444734132107, 0.00010644234417923349, 0.00010643023260250586, 0.00010641811229587939, 0.0001064059895886424, 0.00010639385952328403, 0.00010638172498982503, 0.00010636958647053088, 0.00010635744432978, 0.0001063452932028151, 0.00010633314636801325, 0.00010632099137310034, 0.00010630883870467198, 0.00010629668373297926, 0.0001062845265205381, 0.00010627237614733633, 0.00010626022777821568, 0.00010624808410850451, 0.00010623593993598689, 0.00010622380559186175, 0.00010621167445212299, 0.0001061995422469347, 0.00010618742053191434, 0.00010617530577580666, 0.00010616319452058937, 0.00010615108949910033, 0.00010613899254037616, 0.0001061269042427833, 0.00010611482562801021, 0.000106102746355034, 0.00010609067774012556, 0.00010607861970469348, 0.0001060665663784948, 0.00010605452011837893, 0.00010604249493237277, 0.00010603046745471236, 0.00010601845577481974, 0.00010600645019915816, 0.00010599446203060224, 0.00010598248267232274, 0.00010597051200375325, 0.00010595855178873525, 0.00010594660018572893, 0.00010593467300053987, 0.0001059227459752129, 0.00010591083545319029, 0.00010589893812202247, 0.000105887049780641, 0.00010587517630643352, 0.00010586331764938729, 0.0001058514648634771, 0.0001058396348574676, 0.00010582781024479404, 0.00010581600339378062, 0.00010580420933084097, 0.00010579243327783888, 0.0001057806667165365], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003682337056585246, 0.0003682337056585246, 0.0003682337056585246, 0.0007364674113170492, 0.0008592119798698908, 0.001104701117890092, 0.0015956793921014583, 0.0017184239597397815, 0.0019639130968454647, 0.0030686142138210385, 0.003927826193690929, 0.004909782742113662, 0.00638271756474776, 0.008592119798698908, 0.012888179698048362, 0.016447772186080765, 0.0209893212225359, 0.026267337671222607, 0.030072419296360696, 0.05437584386982332, 0.0747514422340482, 0.07782005644786924, 0.08101141524853349, 0.084202774012617, 0.08555296426669826, 0.08763962193209657, 0.08862157849606611, 0.09021725787170623, 0.09119921443567577, 0.09181293727935451, 0.09242666012211871, 0.0927948938113159, 0.09316312753252125, 0.0932858721019886, 0.09377685037528545, 0.09389959494383829, 0.09439057320250285, 0.09463606235424082, 0.09537252976738692, 0.09574076347213091, 0.09586350803976924, 0.09586350804068376, 0.0959862526092366, 0.09598625261198016, 0.0959862526092366, 0.09598625261198016, 0.09598625261015112, 0.0959862526092366, 0.09598625260832208, 0.09598625261015112, 0.09598625261198016, 0.09598625259368979, 0.09598625261015112, 0.09598625260832208, 0.09598625261015112, 0.09598625259368979, 0.0959862526092366, 0.09598625260832208, 0.09598625261015112, 0.09598625259368979, 0.0959862526092366, 0.09598625259368979, 0.09598625259368979, 0.09598625261015112, 0.0959862526092366, 0.09598625260832208, 0.09598625259368979, 0.09598625261015112, 0.0959862526092366, 0.09598625259368979, 0.09598625261015112, 0.09598625261015112, 0.0959862526092366, 0.09598625260832208, 0.09598625257905749, 0.09598625260832208, 0.09598625261015112, 0.0959862526092366, 0.09598625261015112, 0.09598625261015112]}
[2018-06-11 19:49:03,792 AE_BIGRAMA_4L_FULLDS_OVER_02.py:92]: done!
[2018-06-11 19:49:03,793 AE_BIGRAMA_4L_FULLDS_OVER_02.py:152]: >> Executing classifier part ... 
[2018-06-11 19:49:03,793 AE_BIGRAMA_4L_FULLDS_OVER_02.py:97]: =======================================
[2018-06-11 19:49:03,793 AE_BIGRAMA_4L_FULLDS_OVER_02.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f3b5cbed630>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-11 19:49:05,005 AE_BIGRAMA_4L_FULLDS_OVER_02.py:110]: training ... 
[2018-06-18 22:35:20,063 AE_BIGRAMA_4L_FULLDS_OVER_02.py:122]: trained!
[2018-06-18 22:35:20,068 AE_BIGRAMA_4L_FULLDS_OVER_02.py:125]: Training history: 
{'val_loss': [0.00010697089367065591, 0.00010695984994355817, 0.00010694858005210207, 0.00010693715932023106, 0.00010692561888134259, 0.00010691398713065675, 0.00010690230007627545, 0.00010689055184609175, 0.00010687875913924397, 0.00010686692854981935, 0.00010685507027378501, 0.00010684318548235347, 0.00010683128563896847, 0.00010681936184722756, 0.00010680742948263841, 0.0001067954903688699, 0.0001067835500785408, 0.00010677160018052493, 0.00010675964799356393, 0.00010674769239457723, 0.00010673574166494695, 0.0001067237813409999, 0.0001067118245333646, 0.00010669986392062542, 0.00010668789805079961, 0.00010667593853172696, 0.00010666397799385981, 0.00010665201016933904, 0.00010664004045964733, 0.00010662807393469121, 0.00010661610475712575, 0.00010660412625799169, 0.0001065921515559395, 0.00010658017904924239, 0.00010656820646232526, 0.00010655623279243758, 0.00010654425841928756, 0.00010653228370119137, 0.00010652030557909147, 0.00010650833225949797, 0.00010649635807352804, 0.00010648437816786927, 0.00010647239561227518, 0.00010646040483947501, 0.00010644841005032484, 0.00010643640781408098, 0.00010642439623755047, 0.00010641238043609786, 0.00010640035853524823, 0.00010638832926752493, 0.00010637629402073467, 0.00010636425668020137, 0.00010635220768102227, 0.00010634016046540206, 0.00010632810722525686, 0.00010631605564834049, 0.00010630399788645904, 0.00010629193929563719, 0.00010627988622662807, 0.00010626783308542091, 0.00010625578612115684, 0.00010624373599354918, 0.00010623169432648172, 0.00010621965677470231, 0.00010620761603818732, 0.00010619558679720404, 0.00010618356398719397, 0.00010617154570159413, 0.00010615953391916551, 0.00010614752904635634, 0.00010613553003228408, 0.0001061235424896775, 0.00010611155535619315, 0.00010609957738651133, 0.00010608760889616423, 0.00010607564282044033, 0.0001060636865689973, 0.00010605174813977313, 0.00010603981005816914, 0.00010602788427162324, 0.0001060159684510803, 0.00010600406367148884, 0.00010599217143296362, 0.00010598028513339534, 0.00010596841090961707, 0.00010595654418908651, 0.00010594470179127204, 0.00010593286034005404, 0.0001059210347162499, 0.00010590922286355261, 0.00010589741770388063, 0.0001058856303343395, 0.00010587385596311882, 0.00010586208921547593, 0.0001058503407071961, 0.00010583859944545986, 0.00010582687576260836, 0.00010581516574657765, 0.00010580347149645877, 0.00010579178682193865, 0.00010578011209470347], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.0025725836089672913, 0.002940095553105476, 0.003675119441381845, 0.004777655273796398, 0.00735023888276369, 0.010290334435869165, 0.015067989709665565, 0.018743109151047408, 0.024990812201396546, 0.02682837192208747, 0.03234105108416024, 0.06909224549797868, 0.07276736493936053, 0.07791253215729511, 0.08011760382212423, 0.08158765159867695, 0.08342521131936788, 0.08452774715178243, 0.08489525909592062, 0.08563028298419699, 0.08636530687247336, 0.08783535464902609, 0.08820286659316427, 0.08820286659316427, 0.08930540242557883, 0.0900404263138552, 0.09040793825799338, 0.09040793825799338, 0.09114296214626975, 0.09151047409040794, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431, 0.09224549797868431], 'loss': [0.0001069810159788243, 0.00010697002794498663, 0.0001069587462873654, 0.00010694728734537031, 0.00010693569052455891, 0.00010692398597456338, 0.00010691221041454382, 0.00010690037875096989, 0.00010688849237883925, 0.00010687656634483583, 0.00010686460524477129, 0.00010685262359662369, 0.00010684061737526219, 0.0001068285993482196, 0.00010681655962905298, 0.00010680451471570821, 0.00010679246492701635, 0.00010678041503294056, 0.0001067683570359111, 0.00010675629891117059, 0.00010674423661661959, 0.0001067321793992527, 0.00010672011253121711, 0.00010670804955167047, 0.00010669598196023663, 0.00010668391077503163, 0.00010667184732036415, 0.00010665978253589418, 0.00010664771300289511, 0.00010663564088441705, 0.00010662357194710518, 0.00010661149767808018, 0.00010659941817200897, 0.00010658734087989369, 0.00010657526465680029, 0.00010656318759510075, 0.00010655111346986232, 0.00010653903728606462, 0.00010652696043156063, 0.00010651487936616427, 0.00010650280091839793, 0.00010649072067195986, 0.0001064786338059811, 0.00010646654670780046, 0.00010645444734132107, 0.00010644234417923349, 0.00010643023260250586, 0.00010641811229587939, 0.0001064059895886424, 0.00010639385952328403, 0.00010638172498982503, 0.00010636958647053088, 0.00010635744432978, 0.0001063452932028151, 0.00010633314636801325, 0.00010632099137310034, 0.00010630883870467198, 0.00010629668373297926, 0.0001062845265205381, 0.00010627237614733633, 0.00010626022777821568, 0.00010624808410850451, 0.00010623593993598689, 0.00010622380559186175, 0.00010621167445212299, 0.0001061995422469347, 0.00010618742053191434, 0.00010617530577580666, 0.00010616319452058937, 0.00010615108949910033, 0.00010613899254037616, 0.0001061269042427833, 0.00010611482562801021, 0.000106102746355034, 0.00010609067774012556, 0.00010607861970469348, 0.0001060665663784948, 0.00010605452011837893, 0.00010604249493237277, 0.00010603046745471236, 0.00010601845577481974, 0.00010600645019915816, 0.00010599446203060224, 0.00010598248267232274, 0.00010597051200375325, 0.00010595855178873525, 0.00010594660018572893, 0.00010593467300053987, 0.0001059227459752129, 0.00010591083545319029, 0.00010589893812202247, 0.000105887049780641, 0.00010587517630643352, 0.00010586331764938729, 0.0001058514648634771, 0.0001058396348574676, 0.00010582781024479404, 0.00010581600339378062, 0.00010580420933084097, 0.00010579243327783888, 0.0001057806667165365], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003682337056585246, 0.0003682337056585246, 0.0003682337056585246, 0.0007364674113170492, 0.0008592119798698908, 0.001104701117890092, 0.0015956793921014583, 0.0017184239597397815, 0.0019639130968454647, 0.0030686142138210385, 0.003927826193690929, 0.004909782742113662, 0.00638271756474776, 0.008592119798698908, 0.012888179698048362, 0.016447772186080765, 0.0209893212225359, 0.026267337671222607, 0.030072419296360696, 0.05437584386982332, 0.0747514422340482, 0.07782005644786924, 0.08101141524853349, 0.084202774012617, 0.08555296426669826, 0.08763962193209657, 0.08862157849606611, 0.09021725787170623, 0.09119921443567577, 0.09181293727935451, 0.09242666012211871, 0.0927948938113159, 0.09316312753252125, 0.0932858721019886, 0.09377685037528545, 0.09389959494383829, 0.09439057320250285, 0.09463606235424082, 0.09537252976738692, 0.09574076347213091, 0.09586350803976924, 0.09586350804068376, 0.0959862526092366, 0.09598625261198016, 0.0959862526092366, 0.09598625261198016, 0.09598625261015112, 0.0959862526092366, 0.09598625260832208, 0.09598625261015112, 0.09598625261198016, 0.09598625259368979, 0.09598625261015112, 0.09598625260832208, 0.09598625261015112, 0.09598625259368979, 0.0959862526092366, 0.09598625260832208, 0.09598625261015112, 0.09598625259368979, 0.0959862526092366, 0.09598625259368979, 0.09598625259368979, 0.09598625261015112, 0.0959862526092366, 0.09598625260832208, 0.09598625259368979, 0.09598625261015112, 0.0959862526092366, 0.09598625259368979, 0.09598625261015112, 0.09598625261015112, 0.0959862526092366, 0.09598625260832208, 0.09598625257905749, 0.09598625260832208, 0.09598625261015112, 0.0959862526092366, 0.09598625261015112, 0.09598625261015112]}
[2018-06-18 22:35:20,068 AE_BIGRAMA_4L_FULLDS_OVER_02.py:129]: evaluating model ... 
[2018-06-18 22:38:53,416 AE_BIGRAMA_4L_FULLDS_OVER_02.py:133]: evaluated! 
[2018-06-18 22:38:53,417 AE_BIGRAMA_4L_FULLDS_OVER_02.py:135]: generating reports ... 
[2018-06-18 22:38:58,272 AE_BIGRAMA_4L_FULLDS_OVER_02.py:138]: done!
[2018-06-18 22:38:58,272 AE_BIGRAMA_4L_FULLDS_OVER_02.py:154]: >> experiment AE_BIGRAMA_4L_FULLDS_OVER_02 finished!
