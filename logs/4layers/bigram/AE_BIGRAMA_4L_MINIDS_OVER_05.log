[2018-06-03 00:54:28,509 AE_BIGRAMA_4L_MINIDS_OVER_05.py:145]: >> Initializing execution of experiment AE_BIGRAMA_4L_MINIDS_OVER_05
[2018-06-03 00:54:28,509 AE_BIGRAMA_4L_MINIDS_OVER_05.py:146]: >> Printing header log
[2018-06-03 00:54:28,509 AE_BIGRAMA_4L_MINIDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_4L_MINIDS_OVER_05
	layers = 9216,18432,16590,14747,12905
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbc52d385c0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbc52d38da0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,509 AE_BIGRAMA_4L_MINIDS_OVER_05.py:148]: >> Loading dataset... 
[2018-06-03 00:54:53,014 AE_BIGRAMA_4L_MINIDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-06-03 00:54:53,015 AE_BIGRAMA_4L_MINIDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-06-03 00:54:53,015 AE_BIGRAMA_4L_MINIDS_OVER_05.py:57]: =======================================
[2018-06-03 00:54:53,015 AE_BIGRAMA_4L_MINIDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbc52d385c0>, 'discard_decoder_function': True}
[2018-06-03 00:54:53,214 AE_BIGRAMA_4L_MINIDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-06-25 15:41:50,940 AE_BIGRAMA_4L_MINIDS_OVER_05.py:85]: trained and evaluated!
[2018-06-25 15:41:50,941 AE_BIGRAMA_4L_MINIDS_OVER_05.py:88]: Training history: 
{'val_loss': [0.00010703328995967138, 0.00010702818749327766, 0.00010702268409837926, 0.00010701691251204072, 0.0001070109061643376, 0.00010700473450759256, 0.00010699845827012998, 0.00010699203292022892, 0.00010698555527996908, 0.00010697895094508612, 0.00010697232242256028, 0.00010696564942194465, 0.00010695898934643308, 0.00010695235812447333, 0.00010694571095618879, 0.00010693904818124332, 0.00010693237396498859, 0.0001069257083297158, 0.0001069190414788039, 0.00010691235557096125, 0.00010690568380386177, 0.00010689898645470985, 0.00010689233276130361, 0.00010688561914404008, 0.00010687889891226961, 0.00010687221341559901, 0.0001068654910564601, 0.00010685877661685246, 0.00010685204927001781, 0.00010684532716115754, 0.00010683858665681721, 0.000106831864959129, 0.00010682515690162668, 0.00010681841296489357, 0.00010681167458792169, 0.00010680490506913614, 0.00010679814209334932, 0.00010679138827060992, 0.0001067845882714614, 0.00010677770995297549, 0.00010677088633824955, 0.00010676403451354542, 0.00010675718531676703, 0.00010675032744962146, 0.00010674343917362109, 0.00010673652000608568, 0.00010672960827540131, 0.00010672271372455787, 0.0001067157867089994, 0.00010670886058729321, 0.00010670194773035495, 0.00010669498442439362, 0.00010668805292169667, 0.00010668114340776596, 0.00010667419122132708, 0.00010666719187524155, 0.00010666025204184128, 0.00010665330436041794, 0.00010664634123322707, 0.00010663933813296194, 0.00010663230576797294, 0.00010662531444868096, 0.0001066182689261863, 0.00010661122111542979, 0.00010660420281967578, 0.00010659717504908754, 0.00010659011016575236, 0.00010658305189692409, 0.00010657595587177522, 0.0001065688647449369, 0.00010656178867057108, 0.00010655469681077387, 0.00010654761263810634, 0.00010654050974817192, 0.00010653343310174063, 0.00010652632588556115, 0.00010651918654433047, 0.00010651207294604565, 0.00010650491365403193, 0.00010649775010728134, 0.00010649061923977033, 0.00010648347718122871, 0.0001064763291517538, 0.00010646918063959867, 0.00010646199075995969, 0.00010645482957297913, 0.0001064476604664673, 0.0001064404818672442, 0.00010643329322112139, 0.0001064260977817212, 0.00010641893325173308, 0.00010641175620781294, 0.0001064045781806553, 0.00010639738994570454, 0.00010639018175997074, 0.00010638302654392345, 0.00010637585261060927, 0.00010636868071527832, 0.00010636146191057935, 0.00010635425846226267, 0.00010634705739159307], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002457002457, 0.002457002457002457, 0.007371007371007371, 0.014742014742014743, 0.0171990171990172, 0.019656019656019656, 0.03194103194103194, 0.04176904176904177, 0.051597051597051594, 0.08108108108108109, 0.09090909095485615, 0.10810810819963858, 0.1326781326049083, 0.15233415251721327, 0.15970515988822065, 0.19410319395674536, 0.21130221115576253, 0.25798525776558484, 0.29484029403482664, 0.31449631478921203, 0.33660933573064405, 0.36855036708588096, 0.3857493842848982, 0.3931203916559055, 0.41523341376892764, 0.4275184260539399, 0.44963144816696204, 0.4619164604519743, 0.4766584779765155, 0.4791154804335179, 0.4864864878045253, 0.4889434902615278, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255], 'loss': [0.00010713260056862778, 0.00010712761433354461, 0.00010712227356735411, 0.00010711653584672034, 0.00010711053768472431, 0.00010710429925022568, 0.00010709790617200251, 0.00010709139791086728, 0.00010708481222121895, 0.00010707824703223293, 0.00010707160057530342, 0.00010706492534634606, 0.00010705821018257248, 0.00010705150490177717, 0.00010704483301454627, 0.00010703814501118776, 0.00010703144013329564, 0.0001070247214381941, 0.00010701801200986595, 0.00010701130357694567, 0.00010700457018772777, 0.00010699785353084238, 0.00010699111115925336, 0.00010698440874618075, 0.00010697764257960331, 0.00010697087553611893, 0.0001069641377860665, 0.000106957370979584, 0.00010695060853393602, 0.00010694383447519609, 0.00010693706520389408, 0.00010693027161619951, 0.00010692349068440516, 0.00010691672418602509, 0.0001069099162123166, 0.00010690311719727905, 0.0001068962840065709, 0.00010688945560330064, 0.00010688262845614033, 0.00010687575281839605, 0.00010686880164815368, 0.00010686192008536248, 0.00010685500901583764, 0.00010684809033855256, 0.00010684116386390574, 0.00010683420975484008, 0.00010682722338981903, 0.00010682025067610605, 0.00010681328132781973, 0.0001068062912655694, 0.00010679929110703911, 0.00010679229720535836, 0.00010678525585590191, 0.00010677824289927029, 0.00010677123840360565, 0.00010676419266961448, 0.00010675709311249712, 0.00010675006050840991, 0.00010674302432559437, 0.00010673597216885234, 0.00010672888107270196, 0.00010672175809979919, 0.00010671468520539294, 0.00010670755580973929, 0.00010670042508687514, 0.00010669332680956791, 0.00010668622658884529, 0.00010667908610150382, 0.00010667196414770911, 0.00010666481207097586, 0.00010665765821672855, 0.00010665051232574429, 0.00010664335598297727, 0.00010663620478315097, 0.00010662903552378167, 0.00010662189122070998, 0.00010661471165175904, 0.00010660750001645419, 0.00010660030866850998, 0.00010659307198210677, 0.00010658583050826564, 0.0001065786202001713, 0.0001065713940603516, 0.00010656416562161369, 0.00010655693737247729, 0.00010654966537279444, 0.00010654242010692329, 0.0001065351666407872, 0.0001065279080080102, 0.00010652063567652473, 0.00010651335772809479, 0.00010650611260442475, 0.00010649885266813744, 0.00010649159443826363, 0.00010648432359988999, 0.00010647703569738121, 0.0001064697974704658, 0.00010646254405173008, 0.00010645529376141914, 0.00010644799344001205, 0.00010644071383256896], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016286644951140066, 0.0024429967426710096, 0.0024429967426710096, 0.008143322475570033, 0.012214983713355049, 0.019543973941368076, 0.028501628664495113, 0.04723127038257518, 0.06351791533371524, 0.0838762215954473, 0.10993485344446444, 0.12133550493453146, 0.14332247557003258, 0.16123778506482464, 0.18078175895765472, 0.2043973941853458, 0.2312703584032649, 0.26302931596091206, 0.29560260596026816, 0.32817589566839633, 0.3517915309446254, 0.38273615635179153, 0.4071661236814257, 0.42915309446254074, 0.44706840390879476, 0.4609120521172638, 0.4739413680781759, 0.48615635179153094, 0.497557003257329, 0.502442996742671, 0.5024429965485191, 0.504885993582418, 0.5048859932911901, 0.507328990130937, 0.507328990325089, 0.507328990325089, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.5073289900338611, 0.507328990130937, 0.5073289900338611, 0.507328990325089, 0.5073289900338611, 0.507328990276551, 0.507328990130937, 0.507328990228013, 0.507328990228013, 0.5073289900338611, 0.507328990422165, 0.507328990130937, 0.507328990228013, 0.507328990228013, 0.507328990228013, 0.507328990228013, 0.5073289900338611, 0.507328990130937, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.5073289900338611, 0.507328990325089, 0.507328990228013, 0.507328990228013, 0.507328990422165, 0.507328990325089, 0.507328990325089, 0.507328990325089, 0.507328990422165, 0.507328990422165, 0.507328990130937]}
[2018-06-25 15:41:50,941 AE_BIGRAMA_4L_MINIDS_OVER_05.py:92]: done!
[2018-06-25 15:41:50,941 AE_BIGRAMA_4L_MINIDS_OVER_05.py:152]: >> Executing classifier part ... 
[2018-06-25 15:41:50,941 AE_BIGRAMA_4L_MINIDS_OVER_05.py:97]: =======================================
[2018-06-25 15:41:50,941 AE_BIGRAMA_4L_MINIDS_OVER_05.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbc52d38da0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-25 15:41:50,980 AE_BIGRAMA_4L_MINIDS_OVER_05.py:110]: training ... 
[2018-06-26 01:00:59,407 AE_BIGRAMA_4L_MINIDS_OVER_05.py:122]: trained!
[2018-06-26 01:00:59,408 AE_BIGRAMA_4L_MINIDS_OVER_05.py:125]: Training history: 
{'val_loss': [0.00010703328995967138, 0.00010702818749327766, 0.00010702268409837926, 0.00010701691251204072, 0.0001070109061643376, 0.00010700473450759256, 0.00010699845827012998, 0.00010699203292022892, 0.00010698555527996908, 0.00010697895094508612, 0.00010697232242256028, 0.00010696564942194465, 0.00010695898934643308, 0.00010695235812447333, 0.00010694571095618879, 0.00010693904818124332, 0.00010693237396498859, 0.0001069257083297158, 0.0001069190414788039, 0.00010691235557096125, 0.00010690568380386177, 0.00010689898645470985, 0.00010689233276130361, 0.00010688561914404008, 0.00010687889891226961, 0.00010687221341559901, 0.0001068654910564601, 0.00010685877661685246, 0.00010685204927001781, 0.00010684532716115754, 0.00010683858665681721, 0.000106831864959129, 0.00010682515690162668, 0.00010681841296489357, 0.00010681167458792169, 0.00010680490506913614, 0.00010679814209334932, 0.00010679138827060992, 0.0001067845882714614, 0.00010677770995297549, 0.00010677088633824955, 0.00010676403451354542, 0.00010675718531676703, 0.00010675032744962146, 0.00010674343917362109, 0.00010673652000608568, 0.00010672960827540131, 0.00010672271372455787, 0.0001067157867089994, 0.00010670886058729321, 0.00010670194773035495, 0.00010669498442439362, 0.00010668805292169667, 0.00010668114340776596, 0.00010667419122132708, 0.00010666719187524155, 0.00010666025204184128, 0.00010665330436041794, 0.00010664634123322707, 0.00010663933813296194, 0.00010663230576797294, 0.00010662531444868096, 0.0001066182689261863, 0.00010661122111542979, 0.00010660420281967578, 0.00010659717504908754, 0.00010659011016575236, 0.00010658305189692409, 0.00010657595587177522, 0.0001065688647449369, 0.00010656178867057108, 0.00010655469681077387, 0.00010654761263810634, 0.00010654050974817192, 0.00010653343310174063, 0.00010652632588556115, 0.00010651918654433047, 0.00010651207294604565, 0.00010650491365403193, 0.00010649775010728134, 0.00010649061923977033, 0.00010648347718122871, 0.0001064763291517538, 0.00010646918063959867, 0.00010646199075995969, 0.00010645482957297913, 0.0001064476604664673, 0.0001064404818672442, 0.00010643329322112139, 0.0001064260977817212, 0.00010641893325173308, 0.00010641175620781294, 0.0001064045781806553, 0.00010639738994570454, 0.00010639018175997074, 0.00010638302654392345, 0.00010637585261060927, 0.00010636868071527832, 0.00010636146191057935, 0.00010635425846226267, 0.00010634705739159307], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002457002457, 0.002457002457002457, 0.007371007371007371, 0.014742014742014743, 0.0171990171990172, 0.019656019656019656, 0.03194103194103194, 0.04176904176904177, 0.051597051597051594, 0.08108108108108109, 0.09090909095485615, 0.10810810819963858, 0.1326781326049083, 0.15233415251721327, 0.15970515988822065, 0.19410319395674536, 0.21130221115576253, 0.25798525776558484, 0.29484029403482664, 0.31449631478921203, 0.33660933573064405, 0.36855036708588096, 0.3857493842848982, 0.3931203916559055, 0.41523341376892764, 0.4275184260539399, 0.44963144816696204, 0.4619164604519743, 0.4766584779765155, 0.4791154804335179, 0.4864864878045253, 0.4889434902615278, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255], 'loss': [0.00010713260056862778, 0.00010712761433354461, 0.00010712227356735411, 0.00010711653584672034, 0.00010711053768472431, 0.00010710429925022568, 0.00010709790617200251, 0.00010709139791086728, 0.00010708481222121895, 0.00010707824703223293, 0.00010707160057530342, 0.00010706492534634606, 0.00010705821018257248, 0.00010705150490177717, 0.00010704483301454627, 0.00010703814501118776, 0.00010703144013329564, 0.0001070247214381941, 0.00010701801200986595, 0.00010701130357694567, 0.00010700457018772777, 0.00010699785353084238, 0.00010699111115925336, 0.00010698440874618075, 0.00010697764257960331, 0.00010697087553611893, 0.0001069641377860665, 0.000106957370979584, 0.00010695060853393602, 0.00010694383447519609, 0.00010693706520389408, 0.00010693027161619951, 0.00010692349068440516, 0.00010691672418602509, 0.0001069099162123166, 0.00010690311719727905, 0.0001068962840065709, 0.00010688945560330064, 0.00010688262845614033, 0.00010687575281839605, 0.00010686880164815368, 0.00010686192008536248, 0.00010685500901583764, 0.00010684809033855256, 0.00010684116386390574, 0.00010683420975484008, 0.00010682722338981903, 0.00010682025067610605, 0.00010681328132781973, 0.0001068062912655694, 0.00010679929110703911, 0.00010679229720535836, 0.00010678525585590191, 0.00010677824289927029, 0.00010677123840360565, 0.00010676419266961448, 0.00010675709311249712, 0.00010675006050840991, 0.00010674302432559437, 0.00010673597216885234, 0.00010672888107270196, 0.00010672175809979919, 0.00010671468520539294, 0.00010670755580973929, 0.00010670042508687514, 0.00010669332680956791, 0.00010668622658884529, 0.00010667908610150382, 0.00010667196414770911, 0.00010666481207097586, 0.00010665765821672855, 0.00010665051232574429, 0.00010664335598297727, 0.00010663620478315097, 0.00010662903552378167, 0.00010662189122070998, 0.00010661471165175904, 0.00010660750001645419, 0.00010660030866850998, 0.00010659307198210677, 0.00010658583050826564, 0.0001065786202001713, 0.0001065713940603516, 0.00010656416562161369, 0.00010655693737247729, 0.00010654966537279444, 0.00010654242010692329, 0.0001065351666407872, 0.0001065279080080102, 0.00010652063567652473, 0.00010651335772809479, 0.00010650611260442475, 0.00010649885266813744, 0.00010649159443826363, 0.00010648432359988999, 0.00010647703569738121, 0.0001064697974704658, 0.00010646254405173008, 0.00010645529376141914, 0.00010644799344001205, 0.00010644071383256896], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016286644951140066, 0.0024429967426710096, 0.0024429967426710096, 0.008143322475570033, 0.012214983713355049, 0.019543973941368076, 0.028501628664495113, 0.04723127038257518, 0.06351791533371524, 0.0838762215954473, 0.10993485344446444, 0.12133550493453146, 0.14332247557003258, 0.16123778506482464, 0.18078175895765472, 0.2043973941853458, 0.2312703584032649, 0.26302931596091206, 0.29560260596026816, 0.32817589566839633, 0.3517915309446254, 0.38273615635179153, 0.4071661236814257, 0.42915309446254074, 0.44706840390879476, 0.4609120521172638, 0.4739413680781759, 0.48615635179153094, 0.497557003257329, 0.502442996742671, 0.5024429965485191, 0.504885993582418, 0.5048859932911901, 0.507328990130937, 0.507328990325089, 0.507328990325089, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.5073289900338611, 0.507328990130937, 0.5073289900338611, 0.507328990325089, 0.5073289900338611, 0.507328990276551, 0.507328990130937, 0.507328990228013, 0.507328990228013, 0.5073289900338611, 0.507328990422165, 0.507328990130937, 0.507328990228013, 0.507328990228013, 0.507328990228013, 0.507328990228013, 0.5073289900338611, 0.507328990130937, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.5073289900338611, 0.507328990325089, 0.507328990228013, 0.507328990228013, 0.507328990422165, 0.507328990325089, 0.507328990325089, 0.507328990325089, 0.507328990422165, 0.507328990422165, 0.507328990130937]}
[2018-06-26 01:00:59,408 AE_BIGRAMA_4L_MINIDS_OVER_05.py:129]: evaluating model ... 
[2018-06-26 01:01:04,023 AE_BIGRAMA_4L_MINIDS_OVER_05.py:133]: evaluated! 
[2018-06-26 01:01:04,024 AE_BIGRAMA_4L_MINIDS_OVER_05.py:135]: generating reports ... 
[2018-06-26 01:01:04,560 AE_BIGRAMA_4L_MINIDS_OVER_05.py:138]: done!
[2018-06-26 01:01:04,561 AE_BIGRAMA_4L_MINIDS_OVER_05.py:154]: >> experiment AE_BIGRAMA_4L_MINIDS_OVER_05 finished!
