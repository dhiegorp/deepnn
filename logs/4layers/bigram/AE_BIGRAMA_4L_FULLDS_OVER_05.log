[2018-06-03 00:54:28,543 AE_BIGRAMA_4L_FULLDS_OVER_05.py:145]: >> Initializing execution of experiment AE_BIGRAMA_4L_FULLDS_OVER_05
[2018-06-03 00:54:28,543 AE_BIGRAMA_4L_FULLDS_OVER_05.py:146]: >> Printing header log
[2018-06-03 00:54:28,544 AE_BIGRAMA_4L_FULLDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_4L_FULLDS_OVER_05
	layers = 9216,18432,16590,14747,12905
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe876228630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe876228e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,544 AE_BIGRAMA_4L_FULLDS_OVER_05.py:148]: >> Loading dataset... 
[2018-06-03 01:16:25,319 AE_BIGRAMA_4L_FULLDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-06-03 01:16:25,321 AE_BIGRAMA_4L_FULLDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-06-03 01:16:25,321 AE_BIGRAMA_4L_FULLDS_OVER_05.py:57]: =======================================
[2018-06-03 01:16:25,321 AE_BIGRAMA_4L_FULLDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe876228630>, 'discard_decoder_function': True}
[2018-06-03 01:16:29,698 AE_BIGRAMA_4L_FULLDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-06-15 20:14:48,812 AE_BIGRAMA_4L_FULLDS_OVER_05.py:85]: trained and evaluated!
[2018-06-15 20:14:48,814 AE_BIGRAMA_4L_FULLDS_OVER_05.py:88]: Training history: 
{'val_loss': [0.00010709920001968547, 0.00010709161415066535, 0.00010708385053008093, 0.00010707592802568558, 0.00010706785550179372, 0.00010705962640710208, 0.00010705124669126364, 0.00010704270756750999, 0.00010703399944687242, 0.00010702513174450956, 0.00010701608997268225, 0.0001070068560578155, 0.00010699737722581908, 0.00010698746167592573, 0.00010697664292592974, 0.00010696294070671143, 0.00010694121095902163, 0.00010690589805737066, 0.00010686237917242155, 0.00010681633605963257, 0.00010677016788914948, 0.00010672405277620073, 0.00010667799753414174, 0.00010663198324976107, 0.00010658601931147742, 0.00010654011678163428, 0.000106494262274181, 0.00010644846526845226, 0.00010640272302359674, 0.00010635701947956244, 0.00010631137933342563, 0.00010626579604190505, 0.0001062202932993265, 0.00010617481554261635, 0.00010612939994574108, 0.00010608403882362087, 0.00010603873342768834, 0.00010599350025653169, 0.00010594830417377345, 0.00010590316002814302, 0.00010585809000048141, 0.0001058130530234762, 0.00010576807568472263, 0.00010572314962529252, 0.00010567830462019069, 0.00010563348837664713, 0.00010558873286769575, 0.00010554404337983715, 0.00010549942511400394, 0.00010545485234897732, 0.0001054103171750614, 0.00010536585708175475, 0.00010532143738458617, 0.000105277103073628, 0.00010523281789477025, 0.00010518859158137773, 0.00010514442587957331, 0.0001051003171259752, 0.00010505627312331924, 0.00010501230051115074, 0.00010496837848039137, 0.00010492452751656529, 0.0001048807479886847, 0.00010483702470307406, 0.00010479335365407935, 0.00010474974071113351, 0.00010470619254586986, 0.00010466271470149312, 0.00010461931375069858, 0.00010457597487951889, 0.00010453269687395742, 0.00010448938762803844, 0.0001044457551729049, 0.00010440198900166095, 0.00010435813880259926, 0.00010431423240672565, 0.00010427013171791554, 0.00010422581461950392, 0.0001041812048061889, 0.00010413626366539131, 0.00010409108468554558, 0.00010404584912917974, 0.00010400063661200934, 0.00010395547323228736, 0.00010391040182484106, 0.00010386540434016147, 0.00010382049566708801, 0.00010377566150773555, 0.00010373089997425918, 0.00010368620203655639, 0.00010364158913476984, 0.00010359706360062869, 0.0001035526044271785, 0.00010350822783491134, 0.00010346393818779736, 0.00010341971189044885, 0.00010337556396540527, 0.0001033314840963695, 0.00010328749246135555, 0.000103243566063952, 0.00010319970944728713], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018375597206909224, 0.03234105108416024, 0.17750826901874311, 0.39287026828371924, 0.47078280044101434, 0.4902609334803381, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.00010710903999769735, 0.00010710164801861151, 0.00010709405195369258, 0.00010708627882677776, 0.00010707835309765925, 0.00010707026560686467, 0.00010706202319809888, 0.00010705362883818783, 0.00010704506845480255, 0.00010703634080923516, 0.00010702742509530121, 0.00010701832728326911, 0.00010700901552486043, 0.00010699936195630596, 0.00010698906285393206, 0.0001069771405655241, 0.00010696007538253285, 0.00010693175770826673, 0.00010689178075801949, 0.00010684683953629618, 0.00010680107898833909, 0.00010675532812052247, 0.00010670963875763393, 0.00010666400643961057, 0.00010661841570269811, 0.00010657287588855812, 0.00010652740037291381, 0.0001064819729882605, 0.00010643660279672438, 0.00010639128658230894, 0.00010634600978952663, 0.00010630079715056035, 0.00010625563956756055, 0.00010621056233267402, 0.0001061655109891938, 0.00010612052155163648, 0.00010607558812385967, 0.00010603070734786648, 0.00010598590046209413, 0.00010594112777877037, 0.00010589641164286387, 0.00010585176418067292, 0.00010580715348408246, 0.00010576260167300388, 0.00010571810261552053, 0.00010567368465008962, 0.00010562929448369305, 0.00010558496880066061, 0.00010554071212714344, 0.00010549652593673058, 0.0001054523848274259, 0.00010540828410160612, 0.00010536425603890938, 0.00010532026949123532, 0.00010527636540292573, 0.00010523251528012674, 0.00010518872226024342, 0.00010514499037287202, 0.00010510131649043139, 0.00010505770571243278, 0.00010501417229160818, 0.00010497068931575594, 0.00010492727674084426, 0.00010488393614227383, 0.0001048406544435046, 0.00010479742396222566, 0.00010475425467954687, 0.00010471114794223935, 0.00010466810908290929, 0.00010462514961519921, 0.00010458224749421682, 0.00010453937501827396, 0.00010449633393873639, 0.00010445300094031315, 0.00010440956695102665, 0.00010436601968471649, 0.00010432235972367359, 0.00010427845892995191, 0.00010423426817855764, 0.00010418974756380597, 0.00010414495777702521, 0.00010410001626326336, 0.00010405505079608806, 0.00010401012690466518, 0.00010396525573111414, 0.00010392047310329696, 0.00010387576540167836, 0.00010383114761399873, 0.00010378660203486224, 0.00010374212937248473, 0.0001036977200887261, 0.00010365339679112176, 0.0001036091590108025, 0.00010356499121703267, 0.00010352090657030224, 0.00010347690750515893, 0.00010343296997441547, 0.00010338911025453282, 0.00010334532111777994, 0.0001033016210036679, 0.00010325798616062033], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.009205842643292153, 0.09475880690816138, 0.2922548177133415, 0.44261691420886273, 0.4850865349281459, 0.4911010187872351, 0.4931876764709238, 0.49318767643800115, 0.49318767643800115, 0.4931876763867881, 0.4931876764343431, 0.49318767645263345, 0.4931876764892142, 0.49318767645263345, 0.49318767645263345, 0.4931876764489754, 0.4931876764892142, 0.4931876764343431, 0.4931876764160527, 0.49318767643800115, 0.49318767643800115, 0.4931876764709238, 0.4931876764160527, 0.4931876764709238, 0.4931876764892142, 0.4931876764892142, 0.49318767646726575, 0.4931876764892142, 0.4931876764745819, 0.49318767645263345, 0.49318767643800115, 0.49318767645263345, 0.4931876764892142, 0.4931876764892142, 0.49318767643800115, 0.4931876764709238, 0.49318767643800115, 0.49318767645263345, 0.4931876764892142, 0.49318767645263345, 0.49318767645263345, 0.49318767645263345, 0.49318767643800115, 0.4931876764892142, 0.49318767643800115, 0.4931876764892142, 0.49318767645263345, 0.49318767643800115, 0.4931876764892142, 0.4931876764343431, 0.4931876764709238, 0.49318767643800115, 0.4931876763867881, 0.4931876764489754, 0.4931876764745819, 0.4931876763867881, 0.4931876763867881, 0.4931876764709238, 0.4931876764343431, 0.49318767644714634, 0.4931876764160527, 0.49318767642336886, 0.4931876764343431, 0.49318767643800115, 0.4931876764709238, 0.4931876764709238, 0.4931876764343431, 0.4931876764892142, 0.4931876763867881, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876764160527, 0.4931876764892142, 0.4931876764892142, 0.49318767643800115, 0.4931876764709238, 0.4931876764892142, 0.49318767643800115]}
[2018-06-15 20:14:48,814 AE_BIGRAMA_4L_FULLDS_OVER_05.py:92]: done!
[2018-06-15 20:14:48,814 AE_BIGRAMA_4L_FULLDS_OVER_05.py:152]: >> Executing classifier part ... 
[2018-06-15 20:14:48,814 AE_BIGRAMA_4L_FULLDS_OVER_05.py:97]: =======================================
[2018-06-15 20:14:48,814 AE_BIGRAMA_4L_FULLDS_OVER_05.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe876228e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-15 20:14:49,076 AE_BIGRAMA_4L_FULLDS_OVER_05.py:110]: training ... 
[2018-06-23 10:16:39,265 AE_BIGRAMA_4L_FULLDS_OVER_05.py:122]: trained!
[2018-06-23 10:16:39,267 AE_BIGRAMA_4L_FULLDS_OVER_05.py:125]: Training history: 
{'val_loss': [0.00010709920001968547, 0.00010709161415066535, 0.00010708385053008093, 0.00010707592802568558, 0.00010706785550179372, 0.00010705962640710208, 0.00010705124669126364, 0.00010704270756750999, 0.00010703399944687242, 0.00010702513174450956, 0.00010701608997268225, 0.0001070068560578155, 0.00010699737722581908, 0.00010698746167592573, 0.00010697664292592974, 0.00010696294070671143, 0.00010694121095902163, 0.00010690589805737066, 0.00010686237917242155, 0.00010681633605963257, 0.00010677016788914948, 0.00010672405277620073, 0.00010667799753414174, 0.00010663198324976107, 0.00010658601931147742, 0.00010654011678163428, 0.000106494262274181, 0.00010644846526845226, 0.00010640272302359674, 0.00010635701947956244, 0.00010631137933342563, 0.00010626579604190505, 0.0001062202932993265, 0.00010617481554261635, 0.00010612939994574108, 0.00010608403882362087, 0.00010603873342768834, 0.00010599350025653169, 0.00010594830417377345, 0.00010590316002814302, 0.00010585809000048141, 0.0001058130530234762, 0.00010576807568472263, 0.00010572314962529252, 0.00010567830462019069, 0.00010563348837664713, 0.00010558873286769575, 0.00010554404337983715, 0.00010549942511400394, 0.00010545485234897732, 0.0001054103171750614, 0.00010536585708175475, 0.00010532143738458617, 0.000105277103073628, 0.00010523281789477025, 0.00010518859158137773, 0.00010514442587957331, 0.0001051003171259752, 0.00010505627312331924, 0.00010501230051115074, 0.00010496837848039137, 0.00010492452751656529, 0.0001048807479886847, 0.00010483702470307406, 0.00010479335365407935, 0.00010474974071113351, 0.00010470619254586986, 0.00010466271470149312, 0.00010461931375069858, 0.00010457597487951889, 0.00010453269687395742, 0.00010448938762803844, 0.0001044457551729049, 0.00010440198900166095, 0.00010435813880259926, 0.00010431423240672565, 0.00010427013171791554, 0.00010422581461950392, 0.0001041812048061889, 0.00010413626366539131, 0.00010409108468554558, 0.00010404584912917974, 0.00010400063661200934, 0.00010395547323228736, 0.00010391040182484106, 0.00010386540434016147, 0.00010382049566708801, 0.00010377566150773555, 0.00010373089997425918, 0.00010368620203655639, 0.00010364158913476984, 0.00010359706360062869, 0.0001035526044271785, 0.00010350822783491134, 0.00010346393818779736, 0.00010341971189044885, 0.00010337556396540527, 0.0001033314840963695, 0.00010328749246135555, 0.000103243566063952, 0.00010319970944728713], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0018375597206909224, 0.03234105108416024, 0.17750826901874311, 0.39287026828371924, 0.47078280044101434, 0.4902609334803381, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.00010710903999769735, 0.00010710164801861151, 0.00010709405195369258, 0.00010708627882677776, 0.00010707835309765925, 0.00010707026560686467, 0.00010706202319809888, 0.00010705362883818783, 0.00010704506845480255, 0.00010703634080923516, 0.00010702742509530121, 0.00010701832728326911, 0.00010700901552486043, 0.00010699936195630596, 0.00010698906285393206, 0.0001069771405655241, 0.00010696007538253285, 0.00010693175770826673, 0.00010689178075801949, 0.00010684683953629618, 0.00010680107898833909, 0.00010675532812052247, 0.00010670963875763393, 0.00010666400643961057, 0.00010661841570269811, 0.00010657287588855812, 0.00010652740037291381, 0.0001064819729882605, 0.00010643660279672438, 0.00010639128658230894, 0.00010634600978952663, 0.00010630079715056035, 0.00010625563956756055, 0.00010621056233267402, 0.0001061655109891938, 0.00010612052155163648, 0.00010607558812385967, 0.00010603070734786648, 0.00010598590046209413, 0.00010594112777877037, 0.00010589641164286387, 0.00010585176418067292, 0.00010580715348408246, 0.00010576260167300388, 0.00010571810261552053, 0.00010567368465008962, 0.00010562929448369305, 0.00010558496880066061, 0.00010554071212714344, 0.00010549652593673058, 0.0001054523848274259, 0.00010540828410160612, 0.00010536425603890938, 0.00010532026949123532, 0.00010527636540292573, 0.00010523251528012674, 0.00010518872226024342, 0.00010514499037287202, 0.00010510131649043139, 0.00010505770571243278, 0.00010501417229160818, 0.00010497068931575594, 0.00010492727674084426, 0.00010488393614227383, 0.0001048406544435046, 0.00010479742396222566, 0.00010475425467954687, 0.00010471114794223935, 0.00010466810908290929, 0.00010462514961519921, 0.00010458224749421682, 0.00010453937501827396, 0.00010449633393873639, 0.00010445300094031315, 0.00010440956695102665, 0.00010436601968471649, 0.00010432235972367359, 0.00010427845892995191, 0.00010423426817855764, 0.00010418974756380597, 0.00010414495777702521, 0.00010410001626326336, 0.00010405505079608806, 0.00010401012690466518, 0.00010396525573111414, 0.00010392047310329696, 0.00010387576540167836, 0.00010383114761399873, 0.00010378660203486224, 0.00010374212937248473, 0.0001036977200887261, 0.00010365339679112176, 0.0001036091590108025, 0.00010356499121703267, 0.00010352090657030224, 0.00010347690750515893, 0.00010343296997441547, 0.00010338911025453282, 0.00010334532111777994, 0.0001033016210036679, 0.00010325798616062033], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.009205842643292153, 0.09475880690816138, 0.2922548177133415, 0.44261691420886273, 0.4850865349281459, 0.4911010187872351, 0.4931876764709238, 0.49318767643800115, 0.49318767643800115, 0.4931876763867881, 0.4931876764343431, 0.49318767645263345, 0.4931876764892142, 0.49318767645263345, 0.49318767645263345, 0.4931876764489754, 0.4931876764892142, 0.4931876764343431, 0.4931876764160527, 0.49318767643800115, 0.49318767643800115, 0.4931876764709238, 0.4931876764160527, 0.4931876764709238, 0.4931876764892142, 0.4931876764892142, 0.49318767646726575, 0.4931876764892142, 0.4931876764745819, 0.49318767645263345, 0.49318767643800115, 0.49318767645263345, 0.4931876764892142, 0.4931876764892142, 0.49318767643800115, 0.4931876764709238, 0.49318767643800115, 0.49318767645263345, 0.4931876764892142, 0.49318767645263345, 0.49318767645263345, 0.49318767645263345, 0.49318767643800115, 0.4931876764892142, 0.49318767643800115, 0.4931876764892142, 0.49318767645263345, 0.49318767643800115, 0.4931876764892142, 0.4931876764343431, 0.4931876764709238, 0.49318767643800115, 0.4931876763867881, 0.4931876764489754, 0.4931876764745819, 0.4931876763867881, 0.4931876763867881, 0.4931876764709238, 0.4931876764343431, 0.49318767644714634, 0.4931876764160527, 0.49318767642336886, 0.4931876764343431, 0.49318767643800115, 0.4931876764709238, 0.4931876764709238, 0.4931876764343431, 0.4931876764892142, 0.4931876763867881, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876764160527, 0.4931876764892142, 0.4931876764892142, 0.49318767643800115, 0.4931876764709238, 0.4931876764892142, 0.49318767643800115]}
[2018-06-23 10:16:39,267 AE_BIGRAMA_4L_FULLDS_OVER_05.py:129]: evaluating model ... 
[2018-06-23 10:18:52,046 AE_BIGRAMA_4L_FULLDS_OVER_05.py:133]: evaluated! 
[2018-06-23 10:18:52,048 AE_BIGRAMA_4L_FULLDS_OVER_05.py:135]: generating reports ... 
[2018-06-23 10:18:56,108 AE_BIGRAMA_4L_FULLDS_OVER_05.py:138]: done!
[2018-06-23 10:18:56,109 AE_BIGRAMA_4L_FULLDS_OVER_05.py:154]: >> experiment AE_BIGRAMA_4L_FULLDS_OVER_05 finished!
