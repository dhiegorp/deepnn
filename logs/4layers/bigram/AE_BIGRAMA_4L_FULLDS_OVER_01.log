[2018-06-03 00:54:28,526 AE_BIGRAMA_4L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_BIGRAMA_4L_FULLDS_OVER_01
[2018-06-03 00:54:28,526 AE_BIGRAMA_4L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-06-03 00:54:28,527 AE_BIGRAMA_4L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_4L_FULLDS_OVER_01
	layers = 9216,9216,8295,7375,6454
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f22184ac630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f22184ace10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,527 AE_BIGRAMA_4L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-06-03 01:16:41,817 AE_BIGRAMA_4L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-06-03 01:16:41,818 AE_BIGRAMA_4L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-06-03 01:16:41,819 AE_BIGRAMA_4L_FULLDS_OVER_01.py:57]: =======================================
[2018-06-03 01:16:41,819 AE_BIGRAMA_4L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f22184ac630>, 'discard_decoder_function': True}
[2018-06-03 01:16:47,518 AE_BIGRAMA_4L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-06-07 04:40:20,258 AE_BIGRAMA_4L_FULLDS_OVER_01.py:85]: trained and evaluated!
[2018-06-07 04:40:20,259 AE_BIGRAMA_4L_FULLDS_OVER_01.py:88]: Training history: 
{'val_loss': [0.00010707974573214395, 0.00010705041073159839, 0.00010701016352203641, 0.00010696841647315141, 0.0001069264241809086, 0.0001068842932122829, 0.00010684203362686731, 0.00010679967377977193, 0.00010675722496330434, 0.00010671467268705136, 0.00010667205121299202, 0.00010662935996354202, 0.00010658662035477799, 0.00010654381918515538, 0.00010650096780580983, 0.00010645808453097643, 0.0001064151613038892, 0.00010637218997151807, 0.00010632918725171934, 0.00010628611472176794, 0.00010624298343865936, 0.00010619980391924082, 0.00010615657888029766, 0.00010611329353192855, 0.00010606993554163935, 0.00010602653341161023, 0.00010598302901707431, 0.00010593943559701217, 0.0001058957682434873, 0.00010585198845355459, 0.00010580815848063895, 0.0001057642719418992, 0.00010572037284070121, 0.0001056764449003989, 0.00010563254239787124, 0.00010558863563565944, 0.0001055447561348912, 0.00010550086849446291, 0.00010545696216811335, 0.00010541304835188604, 0.0001053691493416041, 0.00010532524198041602, 0.00010528132515058923, 0.00010523742687565766, 0.00010519349997286787, 0.0001051495807658539, 0.00010510568904757359, 0.00010506179631584677, 0.00010501791670009646, 0.00010497411127986102, 0.00010493034291326197, 0.00010488662426971762, 0.00010484295511926387, 0.0001047993278249529, 0.00010475576276802285, 0.00010471225639205194, 0.0001046687944365911, 0.00010462538501456036, 0.00010458204751246934, 0.00010453877058720442, 0.00010449553673475288, 0.00010445233755072856, 0.00010440920612589791, 0.00010436612100140026, 0.0001043231196105802, 0.00010428017137088454, 0.00010423727111881671, 0.00010419443242225946, 0.00010415164822452328, 0.00010410892480416329, 0.00010406626505177494, 0.00010402365863501707, 0.00010398111026013203, 0.00010393861072588125, 0.00010389617779298156, 0.00010385380684878066, 0.00010381149416304669, 0.00010376924329754944, 0.00010372706431188189, 0.00010368494369164133, 0.00010364289805842002, 0.0001036008960836184, 0.00010355895843726673, 0.00010351709276166081, 0.00010347529410455018, 0.00010343353999630167, 0.00010339185611535007, 0.00010335022861839045, 0.00010330867190759401, 0.00010326717398471676, 0.00010322574726514688, 0.00010318439370625334, 0.00010314308833553775, 0.00010310187316958296, 0.00010306070139999572, 0.00010301959825597857, 0.00010297857051612488, 0.00010293760185298252, 0.00010289670698960285, 0.00010285588278136025, 0.00010281510299095372], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000735023888276369, 0.017640573318632856, 0.06541712605659684, 0.14038956266078648, 0.3175303197353914, 0.4597574421168688, 0.4898934215361999, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.00010709253864292418, 0.00010707031900615983, 0.00010703519292622626, 0.00010699424474504035, 0.00010695266936773449, 0.00010691088710299016, 0.00010686898748786477, 0.00010682695661435686, 0.00010678483556970171, 0.00010674263362500723, 0.00010670033521381443, 0.00010665796332321957, 0.00010661552395385591, 0.00010657304135117541, 0.00010653049694259746, 0.00010648790705548881, 0.00010644529149577949, 0.00010640263599644818, 0.00010635993818189067, 0.0001063172076858071, 0.0001062744008104768, 0.00010623153943825076, 0.00010618862627963977, 0.00010614566658151397, 0.00010610264594467552, 0.00010605954424347023, 0.00010601638753541809, 0.00010597311948744206, 0.00010592974984041239, 0.00010588631187332851, 0.00010584276574480771, 0.00010579917785030756, 0.0001057555531357288, 0.00010571192288670674, 0.00010566827473223801, 0.00010562464700528597, 0.00010558102215227913, 0.00010553742505633166, 0.00010549381594482832, 0.00010545018977809451, 0.000105406560891026, 0.00010536294525375583, 0.00010531930894872928, 0.00010527566342439375, 0.00010523202775970865, 0.00010518837119595834, 0.0001051447202925762, 0.00010510109985497804, 0.00010505748834375723, 0.0001050138896724091, 0.00010497036469123093, 0.00010492687757414689, 0.0001048834387845324, 0.00010484005061761404, 0.00010479670557952165, 0.00010475342198473451, 0.00010471019776486944, 0.0001046670171980708, 0.00010462388888741944, 0.00010458083067584616, 0.00010453783325562661, 0.0001044948790794409, 0.0001044519585305575, 0.00010440910605970248, 0.00010436630040789764, 0.00010432357993668508, 0.00010428091198061425, 0.00010423829048814608, 0.0001041957302264291, 0.00010415322625313492, 0.00010411078117071113, 0.0001040684014102576, 0.0001040260727628035, 0.00010398380361887558, 0.00010394158088139294, 0.00010389942744635719, 0.00010385733734439303, 0.0001038153033924236, 0.00010377333171432781, 0.00010373142999509586, 0.0001036895882795173, 0.00010364782262792672, 0.00010360609992833142, 0.00010356444438956692, 0.00010352285613487884, 0.00010348133711565635, 0.00010343986152980156, 0.00010339845749071446, 0.00010335710834505251, 0.00010331583224564677, 0.00010327461619276247, 0.0001032334693324757, 0.00010319239677144236, 0.00010315137418561907, 0.00010311043907293539, 0.00010306955241632541, 0.00010302873139247901, 0.00010298798824200935, 0.00010294729986082611, 0.00010290668351046227, 0.00010286614062074571], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006259972997109437, 0.046274702345335775, 0.10298269301949212, 0.22081747885216843, 0.3876273475337704, 0.4801767522043226, 0.49245120906326484, 0.4931876764745819, 0.49318767645263345, 0.4931876763867881, 0.4931876764709238, 0.4931876764160527, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115, 0.49318767645263345, 0.49318767645263345, 0.4931876764892142, 0.4931876764160527, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.49318767643800115, 0.4931876764709238, 0.4931876763867881, 0.4931876764343431, 0.4931876764892142, 0.4931876764709238, 0.4931876764709238, 0.4931876764343431, 0.49318767645263345, 0.4931876763867881, 0.4931876764709238, 0.4931876764160527, 0.4931876764709238, 0.4931876764892142, 0.4931876764343431, 0.4931876764892142, 0.4931876764892142, 0.49318767645263345, 0.4931876764709238, 0.4931876764745819, 0.4931876764892142, 0.4931876764709238, 0.4931876764709238, 0.4931876764892142, 0.49318767643800115, 0.49318767643800115, 0.49318767645263345, 0.49318767643800115, 0.4931876763867881, 0.4931876764892142, 0.4931876764160527, 0.4931876764709238, 0.4931876763867881, 0.49318767643800115, 0.4931876763867881, 0.4931876764160527, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764892142, 0.4931876764892142, 0.49318767645263345, 0.49318767645263345, 0.4931876764892142, 0.49318767643800115, 0.49318767645263345, 0.49318767643800115, 0.4931876764892142, 0.4931876764892142, 0.4931876764160527, 0.4931876764709238, 0.4931876764489754, 0.4931876764343431, 0.4931876764343431, 0.4931876764160527, 0.4931876764343431, 0.49318767643800115, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876764892142, 0.4931876764892142, 0.4931876764709238, 0.49318767642336886, 0.4931876764160527, 0.4931876763867881, 0.49318767643800115, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.4931876764343431, 0.4931876763867881]}
[2018-06-07 04:40:20,260 AE_BIGRAMA_4L_FULLDS_OVER_01.py:92]: done!
[2018-06-07 04:40:20,260 AE_BIGRAMA_4L_FULLDS_OVER_01.py:152]: >> Executing classifier part ... 
[2018-06-07 04:40:20,260 AE_BIGRAMA_4L_FULLDS_OVER_01.py:97]: =======================================
[2018-06-07 04:40:20,260 AE_BIGRAMA_4L_FULLDS_OVER_01.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f22184ace10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-07 04:40:20,669 AE_BIGRAMA_4L_FULLDS_OVER_01.py:110]: training ... 
[2018-06-11 01:55:18,868 AE_BIGRAMA_4L_FULLDS_OVER_01.py:122]: trained!
[2018-06-11 01:55:18,870 AE_BIGRAMA_4L_FULLDS_OVER_01.py:125]: Training history: 
{'val_loss': [0.00010707974573214395, 0.00010705041073159839, 0.00010701016352203641, 0.00010696841647315141, 0.0001069264241809086, 0.0001068842932122829, 0.00010684203362686731, 0.00010679967377977193, 0.00010675722496330434, 0.00010671467268705136, 0.00010667205121299202, 0.00010662935996354202, 0.00010658662035477799, 0.00010654381918515538, 0.00010650096780580983, 0.00010645808453097643, 0.0001064151613038892, 0.00010637218997151807, 0.00010632918725171934, 0.00010628611472176794, 0.00010624298343865936, 0.00010619980391924082, 0.00010615657888029766, 0.00010611329353192855, 0.00010606993554163935, 0.00010602653341161023, 0.00010598302901707431, 0.00010593943559701217, 0.0001058957682434873, 0.00010585198845355459, 0.00010580815848063895, 0.0001057642719418992, 0.00010572037284070121, 0.0001056764449003989, 0.00010563254239787124, 0.00010558863563565944, 0.0001055447561348912, 0.00010550086849446291, 0.00010545696216811335, 0.00010541304835188604, 0.0001053691493416041, 0.00010532524198041602, 0.00010528132515058923, 0.00010523742687565766, 0.00010519349997286787, 0.0001051495807658539, 0.00010510568904757359, 0.00010506179631584677, 0.00010501791670009646, 0.00010497411127986102, 0.00010493034291326197, 0.00010488662426971762, 0.00010484295511926387, 0.0001047993278249529, 0.00010475576276802285, 0.00010471225639205194, 0.0001046687944365911, 0.00010462538501456036, 0.00010458204751246934, 0.00010453877058720442, 0.00010449553673475288, 0.00010445233755072856, 0.00010440920612589791, 0.00010436612100140026, 0.0001043231196105802, 0.00010428017137088454, 0.00010423727111881671, 0.00010419443242225946, 0.00010415164822452328, 0.00010410892480416329, 0.00010406626505177494, 0.00010402365863501707, 0.00010398111026013203, 0.00010393861072588125, 0.00010389617779298156, 0.00010385380684878066, 0.00010381149416304669, 0.00010376924329754944, 0.00010372706431188189, 0.00010368494369164133, 0.00010364289805842002, 0.0001036008960836184, 0.00010355895843726673, 0.00010351709276166081, 0.00010347529410455018, 0.00010343353999630167, 0.00010339185611535007, 0.00010335022861839045, 0.00010330867190759401, 0.00010326717398471676, 0.00010322574726514688, 0.00010318439370625334, 0.00010314308833553775, 0.00010310187316958296, 0.00010306070139999572, 0.00010301959825597857, 0.00010297857051612488, 0.00010293760185298252, 0.00010289670698960285, 0.00010285588278136025, 0.00010281510299095372], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000735023888276369, 0.017640573318632856, 0.06541712605659684, 0.14038956266078648, 0.3175303197353914, 0.4597574421168688, 0.4898934215361999, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.00010709253864292418, 0.00010707031900615983, 0.00010703519292622626, 0.00010699424474504035, 0.00010695266936773449, 0.00010691088710299016, 0.00010686898748786477, 0.00010682695661435686, 0.00010678483556970171, 0.00010674263362500723, 0.00010670033521381443, 0.00010665796332321957, 0.00010661552395385591, 0.00010657304135117541, 0.00010653049694259746, 0.00010648790705548881, 0.00010644529149577949, 0.00010640263599644818, 0.00010635993818189067, 0.0001063172076858071, 0.0001062744008104768, 0.00010623153943825076, 0.00010618862627963977, 0.00010614566658151397, 0.00010610264594467552, 0.00010605954424347023, 0.00010601638753541809, 0.00010597311948744206, 0.00010592974984041239, 0.00010588631187332851, 0.00010584276574480771, 0.00010579917785030756, 0.0001057555531357288, 0.00010571192288670674, 0.00010566827473223801, 0.00010562464700528597, 0.00010558102215227913, 0.00010553742505633166, 0.00010549381594482832, 0.00010545018977809451, 0.000105406560891026, 0.00010536294525375583, 0.00010531930894872928, 0.00010527566342439375, 0.00010523202775970865, 0.00010518837119595834, 0.0001051447202925762, 0.00010510109985497804, 0.00010505748834375723, 0.0001050138896724091, 0.00010497036469123093, 0.00010492687757414689, 0.0001048834387845324, 0.00010484005061761404, 0.00010479670557952165, 0.00010475342198473451, 0.00010471019776486944, 0.0001046670171980708, 0.00010462388888741944, 0.00010458083067584616, 0.00010453783325562661, 0.0001044948790794409, 0.0001044519585305575, 0.00010440910605970248, 0.00010436630040789764, 0.00010432357993668508, 0.00010428091198061425, 0.00010423829048814608, 0.0001041957302264291, 0.00010415322625313492, 0.00010411078117071113, 0.0001040684014102576, 0.0001040260727628035, 0.00010398380361887558, 0.00010394158088139294, 0.00010389942744635719, 0.00010385733734439303, 0.0001038153033924236, 0.00010377333171432781, 0.00010373142999509586, 0.0001036895882795173, 0.00010364782262792672, 0.00010360609992833142, 0.00010356444438956692, 0.00010352285613487884, 0.00010348133711565635, 0.00010343986152980156, 0.00010339845749071446, 0.00010335710834505251, 0.00010331583224564677, 0.00010327461619276247, 0.0001032334693324757, 0.00010319239677144236, 0.00010315137418561907, 0.00010311043907293539, 0.00010306955241632541, 0.00010302873139247901, 0.00010298798824200935, 0.00010294729986082611, 0.00010290668351046227, 0.00010286614062074571], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.006259972997109437, 0.046274702345335775, 0.10298269301949212, 0.22081747885216843, 0.3876273475337704, 0.4801767522043226, 0.49245120906326484, 0.4931876764745819, 0.49318767645263345, 0.4931876763867881, 0.4931876764709238, 0.4931876764160527, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115, 0.49318767645263345, 0.49318767645263345, 0.4931876764892142, 0.4931876764160527, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.49318767643800115, 0.4931876764709238, 0.4931876763867881, 0.4931876764343431, 0.4931876764892142, 0.4931876764709238, 0.4931876764709238, 0.4931876764343431, 0.49318767645263345, 0.4931876763867881, 0.4931876764709238, 0.4931876764160527, 0.4931876764709238, 0.4931876764892142, 0.4931876764343431, 0.4931876764892142, 0.4931876764892142, 0.49318767645263345, 0.4931876764709238, 0.4931876764745819, 0.4931876764892142, 0.4931876764709238, 0.4931876764709238, 0.4931876764892142, 0.49318767643800115, 0.49318767643800115, 0.49318767645263345, 0.49318767643800115, 0.4931876763867881, 0.4931876764892142, 0.4931876764160527, 0.4931876764709238, 0.4931876763867881, 0.49318767643800115, 0.4931876763867881, 0.4931876764160527, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764892142, 0.4931876764892142, 0.49318767645263345, 0.49318767645263345, 0.4931876764892142, 0.49318767643800115, 0.49318767645263345, 0.49318767643800115, 0.4931876764892142, 0.4931876764892142, 0.4931876764160527, 0.4931876764709238, 0.4931876764489754, 0.4931876764343431, 0.4931876764343431, 0.4931876764160527, 0.4931876764343431, 0.49318767643800115, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876764892142, 0.4931876764892142, 0.4931876764709238, 0.49318767642336886, 0.4931876764160527, 0.4931876763867881, 0.49318767643800115, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.4931876764343431, 0.4931876763867881]}
[2018-06-11 01:55:18,870 AE_BIGRAMA_4L_FULLDS_OVER_01.py:129]: evaluating model ... 
[2018-06-11 01:57:38,293 AE_BIGRAMA_4L_FULLDS_OVER_01.py:133]: evaluated! 
[2018-06-11 01:57:38,293 AE_BIGRAMA_4L_FULLDS_OVER_01.py:135]: generating reports ... 
[2018-06-11 01:57:42,268 AE_BIGRAMA_4L_FULLDS_OVER_01.py:138]: done!
[2018-06-11 01:57:42,269 AE_BIGRAMA_4L_FULLDS_OVER_01.py:154]: >> experiment AE_BIGRAMA_4L_FULLDS_OVER_01 finished!
