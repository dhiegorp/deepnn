[2018-06-03 00:54:28,246 AE_BIGRAMA_4L_MINIDS_OVER_01.py:145]: >> Initializing execution of experiment AE_BIGRAMA_4L_MINIDS_OVER_01
[2018-06-03 00:54:28,246 AE_BIGRAMA_4L_MINIDS_OVER_01.py:146]: >> Printing header log
[2018-06-03 00:54:28,246 AE_BIGRAMA_4L_MINIDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_4L_MINIDS_OVER_01
	layers = 9216,9216,8295,7375,6454
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efed1771630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efed1771e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-06-03 00:54:28,246 AE_BIGRAMA_4L_MINIDS_OVER_01.py:148]: >> Loading dataset... 
[2018-06-03 00:55:00,399 AE_BIGRAMA_4L_MINIDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-06-03 00:55:00,401 AE_BIGRAMA_4L_MINIDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-06-03 00:55:00,401 AE_BIGRAMA_4L_MINIDS_OVER_01.py:57]: =======================================
[2018-06-03 00:55:00,401 AE_BIGRAMA_4L_MINIDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efed1771630>, 'discard_decoder_function': True}
[2018-06-03 00:55:00,666 AE_BIGRAMA_4L_MINIDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-06-05 01:19:33,701 AE_BIGRAMA_4L_MINIDS_OVER_01.py:85]: trained and evaluated!
[2018-06-05 01:19:33,703 AE_BIGRAMA_4L_MINIDS_OVER_01.py:88]: Training history: 
{'val_loss': [0.00010696433594176335, 0.00010695821400108251, 0.00010695207380793797, 0.00010694580304085137, 0.00010693956947589695, 0.00010693328580158334, 0.00010692699819431968, 0.00010692071738033339, 0.0001069144304345204, 0.00010690814634903474, 0.00010690182507929395, 0.00010689546160184817, 0.00010688909762384512, 0.00010688277476304725, 0.00010687643588441641, 0.00010687009398456484, 0.00010686375460537672, 0.00010685743739372531, 0.00010685110480781456, 0.00010684475595379221, 0.0001068383985187879, 0.00010683204060110334, 0.00010682567875046873, 0.0001068193132171627, 0.00010681298234744835, 0.00010680661509794593, 0.00010680024295013297, 0.0001067938884648412, 0.000106787465796497, 0.00010678105857392031, 0.00010677467965070703, 0.00010676830349843583, 0.00010676190576857043, 0.00010675549650801053, 0.00010674911333006036, 0.00010674271486723607, 0.00010673633683787507, 0.000106729936497961, 0.00010672354089546404, 0.00010671711202378497, 0.0001067106716214114, 0.0001067042828837, 0.00010669781182219299, 0.00010669138050135866, 0.00010668495154029436, 0.00010667850239604542, 0.00010667205684508268, 0.00010666561742594663, 0.00010665915169179924, 0.00010665269452075678, 0.00010664623663463247, 0.00010663975511505372, 0.0001066332719686638, 0.00010662683337187184, 0.00010662038031254989, 0.00010661391359516499, 0.00010660743756383928, 0.00010660095457834277, 0.00010659446971575645, 0.00010658800725310844, 0.00010658152271230894, 0.00010657505567313723, 0.00010656858275241748, 0.00010656211473000824, 0.00010655562439704593, 0.00010654911640156243, 0.00010654262533564126, 0.00010653612150550941, 0.00010652962831221978, 0.00010652310993017272, 0.00010651657953475091, 0.00010651010668553933, 0.00010650361511906088, 0.00010649713565534237, 0.00010649061940066374, 0.00010648413854253567, 0.00010647762489790572, 0.00010647111697393041, 0.0001064646239415342, 0.00010645810670361806, 0.00010645162486225248, 0.00010644510689137746, 0.00010643859530260777, 0.00010643208149708442, 0.00010642556810273311, 0.00010641906191283122, 0.00010641251303254414, 0.00010640598124271277, 0.00010639946883159897, 0.00010639294431772522, 0.000106386451285329, 0.00010637989906203437, 0.00010637339351570614, 0.00010636685747113788, 0.00010636032780867496, 0.00010635380027358047, 0.00010634726726810999, 0.00010634075206817706, 0.00010633422020683752, 0.00010632769177789075, 0.00010632118835893095], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002457002457, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.007371007371007371, 0.007371007371007371, 0.009828009828009828, 0.012285012285012284, 0.022113022113022112, 0.05405405409981929, 0.07125307129883648, 0.08845208854361893, 0.10073710082863122, 0.1253071253986558, 0.14742014734692305, 0.16953316913043545, 0.19164619149974288, 0.2162162165823381, 0.2334152337813553, 0.2457002460663676, 0.2972972964918291, 0.3169533161478488, 0.3415233407178733, 0.36855036774490035, 0.3906633898579225, 0.4176904179833152, 0.43243243272532994, 0.4447174450103422, 0.46437346408056684, 0.4742014727369866, 0.4766584751939891, 0.48402948256499645, 0.48894348747900135, 0.4914004927185302, 0.4914004927185302, 0.4938574951755327, 0.4938574951755327, 0.4938574951755327, 0.49631449763253516, 0.49631449763253516, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255], 'loss': [0.0001070600933994846, 0.00010705394580780532, 0.0001070477227310283, 0.00010704147450835216, 0.00010703512444596962, 0.00010702880106999839, 0.00010702243048325333, 0.000107016050392733, 0.00010700968167830277, 0.00010700330011837081, 0.00010699692012265124, 0.00010699050685186819, 0.00010698406969129596, 0.00010697763274402543, 0.00010697124352893285, 0.00010696483300737156, 0.00010695841897818251, 0.0001069520144527687, 0.00010694563196852943, 0.00010693923057154039, 0.00010693281495443876, 0.00010692638630223391, 0.00010691995916684107, 0.00010691353077533828, 0.00010690709577148314, 0.00010690069717111624, 0.00010689426958541983, 0.00010688783251964836, 0.00010688140891558348, 0.0001068749255396453, 0.00010686846000994843, 0.00010686201927064787, 0.00010685558398239047, 0.00010684912283722832, 0.00010684265545891683, 0.00010683621284730143, 0.0001068297578167877, 0.00010682332440084514, 0.00010681686820902221, 0.00010681041481382144, 0.0001068039321488889, 0.00010679743260942272, 0.00010679099111171615, 0.0001067844636771291, 0.00010677797089221642, 0.00010677148417455178, 0.00010676497844933663, 0.00010675847483343818, 0.0001067519749384692, 0.00010674545321562738, 0.0001067389377259349, 0.0001067324280664886, 0.0001067258926449383, 0.00010671935001853096, 0.00010671285654631283, 0.00010670635093959862, 0.00010669982407381607, 0.00010669328749095657, 0.00010668674157022313, 0.00010668019301876887, 0.00010667366816750227, 0.00010666711724602924, 0.00010666058336499113, 0.00010665404178139205, 0.00010664750602803912, 0.00010664094493918558, 0.00010663436908511511, 0.0001066278081147625, 0.00010662123119418361, 0.00010661467159844189, 0.00010660808491338566, 0.00010660148467182209, 0.0001065949402205003, 0.00010658837801773792, 0.00010658182868417747, 0.00010657524204652162, 0.00010656868797292363, 0.0001065621030416813, 0.00010655552304007799, 0.00010654895642908072, 0.00010654236507508752, 0.00010653580984018033, 0.00010652921573696537, 0.00010652263130342697, 0.00010651604352816211, 0.00010650945821771677, 0.00010650288139193862, 0.000106496257402787, 0.00010648965640281743, 0.00010648307014436458, 0.00010647647888517213, 0.00010646991556850095, 0.00010646329221925441, 0.00010645671401886537, 0.00010645010571923798, 0.00010644350543027403, 0.00010643690680032323, 0.00010643030158172025, 0.00010642371420935859, 0.00010641711183477811, 0.00010641050998160178], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016286644951140066, 0.0024429967426710096, 0.003257328990228013, 0.005700325732899023, 0.008957654723127036, 0.02280130293159609, 0.035830618916777135, 0.052931596091205214, 0.06107491859104423, 0.0765472312946273, 0.09201954397394137, 0.10749185672606242, 0.1245928338762215, 0.1449511400651466, 0.16205211726384364, 0.19055374597687674, 0.21416938110749187, 0.24511400661173394, 0.263843648305545, 0.2956026058631922, 0.31840390860063633, 0.3477198697068404, 0.3802931596091205, 0.39983713364756457, 0.42263843628793274, 0.4397394138749337, 0.4511400652436558, 0.46172638426774487, 0.4739413679810999, 0.48127035820911296, 0.4861563518886069, 0.495114006417582, 0.4991856675582911, 0.501628664495114, 0.501628664495114, 0.5032573291843799, 0.503257328990228, 0.504885993485342, 0.505700325732899, 0.505700325635823, 0.505700325829975, 0.505700325635823, 0.5057003255387471, 0.505700325829975, 0.506514657980456, 0.506514657980456, 0.507328990228013, 0.507328990130937, 0.507328990325089, 0.5073289900338611, 0.507328990130937, 0.507328990130937, 0.507328990228013, 0.507328990228013, 0.507328990228013, 0.5073289900338611, 0.5073289900338611, 0.5073289900338611, 0.507328990228013, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.5073289900338611, 0.507328990228013, 0.507328990130937, 0.507328990130937, 0.507328990325089]}
[2018-06-05 01:19:33,703 AE_BIGRAMA_4L_MINIDS_OVER_01.py:92]: done!
[2018-06-05 01:19:33,703 AE_BIGRAMA_4L_MINIDS_OVER_01.py:152]: >> Executing classifier part ... 
[2018-06-05 01:19:33,703 AE_BIGRAMA_4L_MINIDS_OVER_01.py:97]: =======================================
[2018-06-05 01:19:33,703 AE_BIGRAMA_4L_MINIDS_OVER_01.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efed1771e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-06-05 01:19:34,489 AE_BIGRAMA_4L_MINIDS_OVER_01.py:110]: training ... 
[2018-06-05 18:02:06,632 AE_BIGRAMA_4L_MINIDS_OVER_01.py:122]: trained!
[2018-06-05 18:02:06,634 AE_BIGRAMA_4L_MINIDS_OVER_01.py:125]: Training history: 
{'val_loss': [0.00010696433594176335, 0.00010695821400108251, 0.00010695207380793797, 0.00010694580304085137, 0.00010693956947589695, 0.00010693328580158334, 0.00010692699819431968, 0.00010692071738033339, 0.0001069144304345204, 0.00010690814634903474, 0.00010690182507929395, 0.00010689546160184817, 0.00010688909762384512, 0.00010688277476304725, 0.00010687643588441641, 0.00010687009398456484, 0.00010686375460537672, 0.00010685743739372531, 0.00010685110480781456, 0.00010684475595379221, 0.0001068383985187879, 0.00010683204060110334, 0.00010682567875046873, 0.0001068193132171627, 0.00010681298234744835, 0.00010680661509794593, 0.00010680024295013297, 0.0001067938884648412, 0.000106787465796497, 0.00010678105857392031, 0.00010677467965070703, 0.00010676830349843583, 0.00010676190576857043, 0.00010675549650801053, 0.00010674911333006036, 0.00010674271486723607, 0.00010673633683787507, 0.000106729936497961, 0.00010672354089546404, 0.00010671711202378497, 0.0001067106716214114, 0.0001067042828837, 0.00010669781182219299, 0.00010669138050135866, 0.00010668495154029436, 0.00010667850239604542, 0.00010667205684508268, 0.00010666561742594663, 0.00010665915169179924, 0.00010665269452075678, 0.00010664623663463247, 0.00010663975511505372, 0.0001066332719686638, 0.00010662683337187184, 0.00010662038031254989, 0.00010661391359516499, 0.00010660743756383928, 0.00010660095457834277, 0.00010659446971575645, 0.00010658800725310844, 0.00010658152271230894, 0.00010657505567313723, 0.00010656858275241748, 0.00010656211473000824, 0.00010655562439704593, 0.00010654911640156243, 0.00010654262533564126, 0.00010653612150550941, 0.00010652962831221978, 0.00010652310993017272, 0.00010651657953475091, 0.00010651010668553933, 0.00010650361511906088, 0.00010649713565534237, 0.00010649061940066374, 0.00010648413854253567, 0.00010647762489790572, 0.00010647111697393041, 0.0001064646239415342, 0.00010645810670361806, 0.00010645162486225248, 0.00010644510689137746, 0.00010643859530260777, 0.00010643208149708442, 0.00010642556810273311, 0.00010641906191283122, 0.00010641251303254414, 0.00010640598124271277, 0.00010639946883159897, 0.00010639294431772522, 0.000106386451285329, 0.00010637989906203437, 0.00010637339351570614, 0.00010636685747113788, 0.00010636032780867496, 0.00010635380027358047, 0.00010634726726810999, 0.00010634075206817706, 0.00010633422020683752, 0.00010632769177789075, 0.00010632118835893095], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002457002457, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.007371007371007371, 0.007371007371007371, 0.009828009828009828, 0.012285012285012284, 0.022113022113022112, 0.05405405409981929, 0.07125307129883648, 0.08845208854361893, 0.10073710082863122, 0.1253071253986558, 0.14742014734692305, 0.16953316913043545, 0.19164619149974288, 0.2162162165823381, 0.2334152337813553, 0.2457002460663676, 0.2972972964918291, 0.3169533161478488, 0.3415233407178733, 0.36855036774490035, 0.3906633898579225, 0.4176904179833152, 0.43243243272532994, 0.4447174450103422, 0.46437346408056684, 0.4742014727369866, 0.4766584751939891, 0.48402948256499645, 0.48894348747900135, 0.4914004927185302, 0.4914004927185302, 0.4938574951755327, 0.4938574951755327, 0.4938574951755327, 0.49631449763253516, 0.49631449763253516, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255, 0.49877149950374255], 'loss': [0.0001070600933994846, 0.00010705394580780532, 0.0001070477227310283, 0.00010704147450835216, 0.00010703512444596962, 0.00010702880106999839, 0.00010702243048325333, 0.000107016050392733, 0.00010700968167830277, 0.00010700330011837081, 0.00010699692012265124, 0.00010699050685186819, 0.00010698406969129596, 0.00010697763274402543, 0.00010697124352893285, 0.00010696483300737156, 0.00010695841897818251, 0.0001069520144527687, 0.00010694563196852943, 0.00010693923057154039, 0.00010693281495443876, 0.00010692638630223391, 0.00010691995916684107, 0.00010691353077533828, 0.00010690709577148314, 0.00010690069717111624, 0.00010689426958541983, 0.00010688783251964836, 0.00010688140891558348, 0.0001068749255396453, 0.00010686846000994843, 0.00010686201927064787, 0.00010685558398239047, 0.00010684912283722832, 0.00010684265545891683, 0.00010683621284730143, 0.0001068297578167877, 0.00010682332440084514, 0.00010681686820902221, 0.00010681041481382144, 0.0001068039321488889, 0.00010679743260942272, 0.00010679099111171615, 0.0001067844636771291, 0.00010677797089221642, 0.00010677148417455178, 0.00010676497844933663, 0.00010675847483343818, 0.0001067519749384692, 0.00010674545321562738, 0.0001067389377259349, 0.0001067324280664886, 0.0001067258926449383, 0.00010671935001853096, 0.00010671285654631283, 0.00010670635093959862, 0.00010669982407381607, 0.00010669328749095657, 0.00010668674157022313, 0.00010668019301876887, 0.00010667366816750227, 0.00010666711724602924, 0.00010666058336499113, 0.00010665404178139205, 0.00010664750602803912, 0.00010664094493918558, 0.00010663436908511511, 0.0001066278081147625, 0.00010662123119418361, 0.00010661467159844189, 0.00010660808491338566, 0.00010660148467182209, 0.0001065949402205003, 0.00010658837801773792, 0.00010658182868417747, 0.00010657524204652162, 0.00010656868797292363, 0.0001065621030416813, 0.00010655552304007799, 0.00010654895642908072, 0.00010654236507508752, 0.00010653580984018033, 0.00010652921573696537, 0.00010652263130342697, 0.00010651604352816211, 0.00010650945821771677, 0.00010650288139193862, 0.000106496257402787, 0.00010648965640281743, 0.00010648307014436458, 0.00010647647888517213, 0.00010646991556850095, 0.00010646329221925441, 0.00010645671401886537, 0.00010645010571923798, 0.00010644350543027403, 0.00010643690680032323, 0.00010643030158172025, 0.00010642371420935859, 0.00010641711183477811, 0.00010641050998160178], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0016286644951140066, 0.0024429967426710096, 0.003257328990228013, 0.005700325732899023, 0.008957654723127036, 0.02280130293159609, 0.035830618916777135, 0.052931596091205214, 0.06107491859104423, 0.0765472312946273, 0.09201954397394137, 0.10749185672606242, 0.1245928338762215, 0.1449511400651466, 0.16205211726384364, 0.19055374597687674, 0.21416938110749187, 0.24511400661173394, 0.263843648305545, 0.2956026058631922, 0.31840390860063633, 0.3477198697068404, 0.3802931596091205, 0.39983713364756457, 0.42263843628793274, 0.4397394138749337, 0.4511400652436558, 0.46172638426774487, 0.4739413679810999, 0.48127035820911296, 0.4861563518886069, 0.495114006417582, 0.4991856675582911, 0.501628664495114, 0.501628664495114, 0.5032573291843799, 0.503257328990228, 0.504885993485342, 0.505700325732899, 0.505700325635823, 0.505700325829975, 0.505700325635823, 0.5057003255387471, 0.505700325829975, 0.506514657980456, 0.506514657980456, 0.507328990228013, 0.507328990130937, 0.507328990325089, 0.5073289900338611, 0.507328990130937, 0.507328990130937, 0.507328990228013, 0.507328990228013, 0.507328990228013, 0.5073289900338611, 0.5073289900338611, 0.5073289900338611, 0.507328990228013, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.507328990130937, 0.507328990228013, 0.5073289900338611, 0.507328990228013, 0.507328990130937, 0.507328990130937, 0.507328990325089]}
[2018-06-05 18:02:06,634 AE_BIGRAMA_4L_MINIDS_OVER_01.py:129]: evaluating model ... 
[2018-06-05 18:02:27,532 AE_BIGRAMA_4L_MINIDS_OVER_01.py:133]: evaluated! 
[2018-06-05 18:02:27,533 AE_BIGRAMA_4L_MINIDS_OVER_01.py:135]: generating reports ... 
[2018-06-05 18:02:30,401 AE_BIGRAMA_4L_MINIDS_OVER_01.py:138]: done!
[2018-06-05 18:02:30,401 AE_BIGRAMA_4L_MINIDS_OVER_01.py:154]: >> experiment AE_BIGRAMA_4L_MINIDS_OVER_01 finished!
