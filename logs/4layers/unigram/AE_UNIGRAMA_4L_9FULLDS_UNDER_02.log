[2017-11-18 17:17:11,159 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_9FULLDS_UNDER_02
[2017-11-18 17:17:11,160 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:148]: >> Printing header log
[2017-11-18 17:17:11,160 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_9FULLDS_UNDER_02
	layers = 96,76,69,63,56,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f89b1563eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f89b1568400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:17:11,160 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:150]: >> Loading dataset... 
[2017-11-18 17:17:13,272 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:17:13,273 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:152]: >> Executing autoencoder part ... 
[2017-11-18 17:17:13,273 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:59]: =======================================
[2017-11-18 17:17:13,273 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f89b1563eb8>, 'discard_decoder_function': True}
[2017-11-18 17:17:13,393 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:75]: training and evaluate autoencoder
[2017-11-18 17:18:47,889 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:87]: trained and evaluated!
[2017-11-18 17:18:47,891 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:90]: Training history: 
{'val_loss': [0.0097113987543879961, 0.0091359829940846505, 0.0086617423283077925, 0.0082795822083161445, 0.0079681688766667768, 0.0077074652127661451, 0.0074924638370604405, 0.0073143709298649044, 0.00716610004795453, 0.0070417818362807161, 0.0069370788671979898, 0.0068485594004767756, 0.0067732468199837807, 0.0067088958848019985, 0.0066537528369987834, 0.0066063683404724459, 0.0065654878071942273, 0.0065301677562263532, 0.006499437746879032, 0.0064727416046741404, 0.0064494314629862477, 0.0064290452456578903, 0.0064112052935128023, 0.0063955609788327525, 0.0063818200923145109, 0.0063696816600058246, 0.0063589736274198838, 0.0063495155770772471, 0.0063411247854397246, 0.006333653684941664, 0.0063270201985455585, 0.0063210834126278771, 0.0063157483931248872, 0.0063109583819838831, 0.0063066373591868152, 0.0063027076474337874, 0.0062991352175978156, 0.0062957941531383383, 0.0062926776244420423, 0.0062897933365688831, 0.0062871411407160347, 0.0062847074432875608, 0.0062824485482780136, 0.006280347502690106, 0.0062783888582405812, 0.0062765662726261291, 0.0062748561940987307, 0.0062732349196260671, 0.0062716890972563553, 0.0062702133688899092, 0.00626879334899856, 0.0062674346747193781, 0.0062661209866405904, 0.006264867757603482, 0.0062636488237244022, 0.006262474042356277, 0.0062613284858118214, 0.0062602083262046524, 0.0062591056992326892, 0.0062580163875893885, 0.0062569319446821375, 0.0062558569152863786, 0.0062547822138729267, 0.0062537078483996091, 0.0062526163376576153, 0.0062515238437388133, 0.0062504052973459505, 0.0062492315771926887, 0.0062480411563822997, 0.0062468447968074886, 0.0062454235450785985, 0.0062433313712709059, 0.0062399051712298112, 0.0062360935429475982, 0.0062322433139801641, 0.0062285124973552449, 0.0062249744809323351, 0.0062216977265898586, 0.0062187474329833681, 0.0062161803185475668, 0.0062139693723607487, 0.0062119890152771426, 0.0062100655926875456, 0.0062081491090672193, 0.0062061556420182533, 0.0062040259669891165, 0.0062018338898391914, 0.006199483572478375, 0.0061969141530106445, 0.0061942971002951252, 0.0061916747392805208, 0.0061890914085882794, 0.0061865429574837968, 0.0061840363725977421, 0.0061815654320210404, 0.0061791453850056832, 0.0061767724770826699, 0.0061743954888475493, 0.0061720315037033045, 0.0061696623734382311, 0.0061672760700092998], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010032547890684553, 0.0094213463245772493, 0.0088979818225931179, 0.0084739765442694726, 0.0081309105947611881, 0.0078477241173528327, 0.0076122508037113346, 0.0074178911712968537, 0.0072566438025626996, 0.0071220554770816975, 0.0070090364645702449, 0.0069137427182983579, 0.0068330084699261724, 0.0067642110814178655, 0.0067053731051125607, 0.0066549299618386334, 0.0066115578323418861, 0.0065741033570634504, 0.0065417035015390684, 0.0065135009370413171, 0.0064890112515140659, 0.0064675948773838263, 0.0064488716982053556, 0.0064324864770609414, 0.0064181088349549069, 0.0064054685966029989, 0.0063943131369558837, 0.0063844647172098144, 0.0063757626504978076, 0.0063680294844318131, 0.0063611514869438583, 0.006355035774411143, 0.0063495617357590337, 0.0063446393459774689, 0.0063402065073304694, 0.0063362093501746824, 0.0063325737179358143, 0.0063292346834725793, 0.0063261035485694976, 0.0063232149880453059, 0.0063205292464176893, 0.0063180687988312516, 0.0063158091628880341, 0.006313701663751576, 0.0063117439659136094, 0.0063099215563116439, 0.00630821691991971, 0.0063066074706507021, 0.0063050817832560153, 0.0063036246679296186, 0.0063022297670545973, 0.0063008917849412599, 0.0062996061411675379, 0.0062983657106641935, 0.0062971681844439884, 0.0062960045344394137, 0.0062948773343907563, 0.0062937814830006178, 0.0062927007247633596, 0.0062916352401248725, 0.0062905770578007029, 0.0062895245892725625, 0.0062884763121532671, 0.0062874292972978562, 0.0062863672613650392, 0.0062852988607277937, 0.0062842134673688418, 0.006283086727208574, 0.0062819245008803653, 0.0062807562842286556, 0.0062795191369031684, 0.0062778074914143465, 0.0062751024866590285, 0.006271514074829578, 0.006267739595563899, 0.0062639991466673416, 0.0062604256153081083, 0.0062570816215264426, 0.0062540309001603957, 0.0062513238254500612, 0.0062489755206131068, 0.0062469465886583917, 0.0062450491453447674, 0.0062431810831606966, 0.006241285945347709, 0.0062392698716917765, 0.00623715299994304, 0.0062349550601479512, 0.006232526528049908, 0.0062299884527206523, 0.00622742305701452, 0.0062248720021556491, 0.0062223552823719675, 0.006219887150145406, 0.0062174458888099755, 0.0062150568066879778, 0.0062126974350935928, 0.0062103749924912414, 0.0062080509441090684, 0.00620572990923617, 0.0062033977983463424], 'acc': [0.47588069227205049, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.59383822272449271, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822267327968, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822262206665, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124]}
[2017-11-18 17:18:47,891 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:94]: done!
[2017-11-18 17:18:47,891 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:154]: >> Executing classifier part ... 
[2017-11-18 17:18:47,891 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:99]: =======================================
[2017-11-18 17:18:47,891 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f89b1568400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:18:47,958 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:112]: training ... 
[2017-11-18 17:22:15,724 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:124]: trained!
[2017-11-18 17:22:15,726 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:127]: Training history: 
{'val_loss': [0.0097113987543879961, 0.0091359829940846505, 0.0086617423283077925, 0.0082795822083161445, 0.0079681688766667768, 0.0077074652127661451, 0.0074924638370604405, 0.0073143709298649044, 0.00716610004795453, 0.0070417818362807161, 0.0069370788671979898, 0.0068485594004767756, 0.0067732468199837807, 0.0067088958848019985, 0.0066537528369987834, 0.0066063683404724459, 0.0065654878071942273, 0.0065301677562263532, 0.006499437746879032, 0.0064727416046741404, 0.0064494314629862477, 0.0064290452456578903, 0.0064112052935128023, 0.0063955609788327525, 0.0063818200923145109, 0.0063696816600058246, 0.0063589736274198838, 0.0063495155770772471, 0.0063411247854397246, 0.006333653684941664, 0.0063270201985455585, 0.0063210834126278771, 0.0063157483931248872, 0.0063109583819838831, 0.0063066373591868152, 0.0063027076474337874, 0.0062991352175978156, 0.0062957941531383383, 0.0062926776244420423, 0.0062897933365688831, 0.0062871411407160347, 0.0062847074432875608, 0.0062824485482780136, 0.006280347502690106, 0.0062783888582405812, 0.0062765662726261291, 0.0062748561940987307, 0.0062732349196260671, 0.0062716890972563553, 0.0062702133688899092, 0.00626879334899856, 0.0062674346747193781, 0.0062661209866405904, 0.006264867757603482, 0.0062636488237244022, 0.006262474042356277, 0.0062613284858118214, 0.0062602083262046524, 0.0062591056992326892, 0.0062580163875893885, 0.0062569319446821375, 0.0062558569152863786, 0.0062547822138729267, 0.0062537078483996091, 0.0062526163376576153, 0.0062515238437388133, 0.0062504052973459505, 0.0062492315771926887, 0.0062480411563822997, 0.0062468447968074886, 0.0062454235450785985, 0.0062433313712709059, 0.0062399051712298112, 0.0062360935429475982, 0.0062322433139801641, 0.0062285124973552449, 0.0062249744809323351, 0.0062216977265898586, 0.0062187474329833681, 0.0062161803185475668, 0.0062139693723607487, 0.0062119890152771426, 0.0062100655926875456, 0.0062081491090672193, 0.0062061556420182533, 0.0062040259669891165, 0.0062018338898391914, 0.006199483572478375, 0.0061969141530106445, 0.0061942971002951252, 0.0061916747392805208, 0.0061890914085882794, 0.0061865429574837968, 0.0061840363725977421, 0.0061815654320210404, 0.0061791453850056832, 0.0061767724770826699, 0.0061743954888475493, 0.0061720315037033045, 0.0061696623734382311, 0.0061672760700092998], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010032547890684553, 0.0094213463245772493, 0.0088979818225931179, 0.0084739765442694726, 0.0081309105947611881, 0.0078477241173528327, 0.0076122508037113346, 0.0074178911712968537, 0.0072566438025626996, 0.0071220554770816975, 0.0070090364645702449, 0.0069137427182983579, 0.0068330084699261724, 0.0067642110814178655, 0.0067053731051125607, 0.0066549299618386334, 0.0066115578323418861, 0.0065741033570634504, 0.0065417035015390684, 0.0065135009370413171, 0.0064890112515140659, 0.0064675948773838263, 0.0064488716982053556, 0.0064324864770609414, 0.0064181088349549069, 0.0064054685966029989, 0.0063943131369558837, 0.0063844647172098144, 0.0063757626504978076, 0.0063680294844318131, 0.0063611514869438583, 0.006355035774411143, 0.0063495617357590337, 0.0063446393459774689, 0.0063402065073304694, 0.0063362093501746824, 0.0063325737179358143, 0.0063292346834725793, 0.0063261035485694976, 0.0063232149880453059, 0.0063205292464176893, 0.0063180687988312516, 0.0063158091628880341, 0.006313701663751576, 0.0063117439659136094, 0.0063099215563116439, 0.00630821691991971, 0.0063066074706507021, 0.0063050817832560153, 0.0063036246679296186, 0.0063022297670545973, 0.0063008917849412599, 0.0062996061411675379, 0.0062983657106641935, 0.0062971681844439884, 0.0062960045344394137, 0.0062948773343907563, 0.0062937814830006178, 0.0062927007247633596, 0.0062916352401248725, 0.0062905770578007029, 0.0062895245892725625, 0.0062884763121532671, 0.0062874292972978562, 0.0062863672613650392, 0.0062852988607277937, 0.0062842134673688418, 0.006283086727208574, 0.0062819245008803653, 0.0062807562842286556, 0.0062795191369031684, 0.0062778074914143465, 0.0062751024866590285, 0.006271514074829578, 0.006267739595563899, 0.0062639991466673416, 0.0062604256153081083, 0.0062570816215264426, 0.0062540309001603957, 0.0062513238254500612, 0.0062489755206131068, 0.0062469465886583917, 0.0062450491453447674, 0.0062431810831606966, 0.006241285945347709, 0.0062392698716917765, 0.00623715299994304, 0.0062349550601479512, 0.006232526528049908, 0.0062299884527206523, 0.00622742305701452, 0.0062248720021556491, 0.0062223552823719675, 0.006219887150145406, 0.0062174458888099755, 0.0062150568066879778, 0.0062126974350935928, 0.0062103749924912414, 0.0062080509441090684, 0.00620572990923617, 0.0062033977983463424], 'acc': [0.47588069227205049, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.59383822272449271, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822267327968, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822262206665, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124]}
[2017-11-18 17:22:15,726 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:131]: evaluating model ... 
[2017-11-18 17:22:15,875 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:135]: evaluated! 
[2017-11-18 17:22:15,875 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:137]: generating reports ... 
[2017-11-18 17:22:16,733 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:140]: done!
[2017-11-18 17:22:16,734 AE_UNIGRAMA_4L_9FULLDS_UNDER_02.py:156]: >> experiment AE_UNIGRAMA_4L_9FULLDS_UNDER_02 finished!
