[2017-11-13 00:09:04,913 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_MINIDS_UNDER_03
[2017-11-13 00:09:04,913 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:148]: >> Printing header log
[2017-11-13 00:09:04,913 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_MINIDS_UNDER_03
	layers = 96,86,78,71,63
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f78c707fc18>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f78c707f4a8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 00:09:04,913 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:150]: >> Loading dataset... 
[2017-11-13 00:09:05,599 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-13 00:09:05,599 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:152]: >> Executing autoencoder part ... 
[2017-11-13 00:09:05,600 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:59]: =======================================
[2017-11-13 00:09:05,600 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f78c707fc18>, 'discard_decoder_function': True}
[2017-11-13 00:09:05,723 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:75]: training and evaluate autoencoder
[2017-11-13 00:10:17,179 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:87]: trained and evaluated!
[2017-11-13 00:10:17,180 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:90]: Training history: 
{'val_loss': [0.010024789727698028, 0.0098775320038974948, 0.0097311228846085566, 0.009586945498105983, 0.0094451872029490628, 0.0093072889490420051, 0.0091746824838525743, 0.0090470996418739336, 0.0089245534962437856, 0.0088068460422432993, 0.0086938917990012233, 0.008585093549857795, 0.0084804315708549936, 0.0083801078378157104, 0.0082838699623222246, 0.0081914158150221336, 0.008102631132329596, 0.0080173737230991114, 0.0079352176249664289, 0.0078558387671039901, 0.0077792739454089046, 0.0077056840692255575, 0.0076348845583826411, 0.0075667841865449149, 0.0075012786559705176, 0.0074383046419176247, 0.0073777899651556213, 0.0073195671797712716, 0.0072635028071590738, 0.0072094743541653052, 0.0071573890884126428, 0.0071071678665241564, 0.0070587417515874133, 0.0070119651352993622, 0.0069667169630361313, 0.0069228642253156706, 0.0068804414208881474, 0.0068392447441760935, 0.0067993788512555201, 0.0067606671509024821, 0.0067231333104817393, 0.0066867950978276901, 0.0066515699368261049, 0.006617280433030598, 0.0065838841247098821, 0.006551535034960752, 0.0065202436056749748, 0.0064899761361315788, 0.0064606263153393472, 0.0064320305784728001, 0.0064042195033794441, 0.0063771339770420333, 0.0063509287963513994, 0.0063255299523223511, 0.0063009538054189275, 0.0062771456776581514, 0.006254090650568, 0.0062317933080558658, 0.0062102000609898875, 0.0061892763396455006, 0.0061690034171684085, 0.0061493384284850164, 0.0061301810763859394, 0.0061115117563578722, 0.0060934216168373268, 0.0060758810320723673, 0.0060588950568249231, 0.0060424337901008839, 0.0060264857080816999, 0.0060110253603872753, 0.0059960550043496501, 0.0059815358117804428, 0.0059674455053744264, 0.0059537900071660382, 0.0059405628100148364, 0.0059277158798338309, 0.00591524613183338, 0.0059031425251670488, 0.0058913768051005204, 0.0058799647781513217, 0.0058688673166537369, 0.0058581097065349939, 0.0058476541980713274, 0.0058375047398627243, 0.0058276482068389986, 0.005818055423329754, 0.0058087574138018724, 0.0057997108232853136, 0.0057909210215990872, 0.0057823606385922124, 0.0057740502118316505, 0.0057659429449546514, 0.0057580721803480363, 0.0057504110567991838, 0.0057429621051512244, 0.0057357086602695369, 0.0057286521156758178, 0.0057217752488267683, 0.0057150723004097386, 0.0057085427718728673, 0.005702165860793515], 'val_acc': [0.0037174721189591076, 0.004646840148698885, 0.034386617100371747, 0.34851301137399499, 0.50464684059185605, 0.53996282483565317, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010076699753251263, 0.0099499464222786976, 0.009802184602876492, 0.0096562451596549845, 0.0095122779737276467, 0.0093713842936835549, 0.0092350801100385439, 0.0091040247299129708, 0.0089779745074150454, 0.0088568864168156198, 0.0087406285274281553, 0.0086289623863285286, 0.0085213303493854448, 0.0084180174179068357, 0.0083189135727592244, 0.0082237368367140684, 0.0081323038090590546, 0.0080444765029350305, 0.0079600237414112623, 0.0078785035921777029, 0.0077997409399729349, 0.0077239319650065918, 0.0076510054571639931, 0.0075808228425722803, 0.0075132629256546681, 0.0074482952160434485, 0.007385816361832981, 0.0073257507776387024, 0.007267888557548236, 0.0072121037514886023, 0.0071583486859902474, 0.0071065095141667417, 0.0070564935671322427, 0.0070082238201594604, 0.0069615324211009782, 0.0069163426634933989, 0.0068725374290867312, 0.0068300974603396625, 0.0067889341270549941, 0.0067490377290530404, 0.0067103212609424612, 0.0066727904105454809, 0.006636428603525809, 0.0066011280299936546, 0.0065666874137964067, 0.0065332649824608484, 0.0065008868977367955, 0.006469555150204611, 0.0064392381075245326, 0.0064097605602725302, 0.0063810474016047104, 0.006353139741942699, 0.0063259963383503169, 0.0062997469371705609, 0.0062742963835102474, 0.0062496718863562237, 0.0062258108012428585, 0.0062027171442483233, 0.0061803648758338471, 0.0061587129442505512, 0.0061377248252823847, 0.006117377679202003, 0.0060976103790214295, 0.0060783179445946661, 0.0060595615876274161, 0.0060413941768465707, 0.0060237769201196409, 0.0060067208078543903, 0.0059901896446883755, 0.0059741735910583509, 0.0059586329796061273, 0.0059435745857463673, 0.0059289772134473442, 0.0059147992588639182, 0.0059010619927282416, 0.0058877495273182969, 0.0058748116702432088, 0.0058622458293122719, 0.0058500501023835581, 0.0058381889180292293, 0.0058266941218144078, 0.0058154996619608481, 0.0058046476503338419, 0.0057941005870324374, 0.0057838743984168044, 0.0057739220730177307, 0.0057642411425728041, 0.0057548546065137327, 0.0057457290846252267, 0.0057368374303138981, 0.0057281903085684071, 0.0057197971508186254, 0.0057115969937878586, 0.0057036485107983086, 0.0056958982644267223, 0.0056883638210081765, 0.005681032233899568, 0.0056738936123063247, 0.0056669328321108034, 0.0056601447996596985, 0.0056535374331983523], 'acc': [0.00061462814996926854, 0.0012292562999385371, 0.014751075603841783, 0.14874001245741911, 0.46158574081009418, 0.51997541458092367, 0.57713583289441261, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376783541539, 0.58881376763392457, 0.58881376811017561, 0.5888137674873859, 0.58881376785373274, 0.5888137674873859, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376800027152, 0.58881376800027152, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376752402059, 0.58881376737748181, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376785373274, 0.58881376737748181, 0.58881376759728987, 0.58881376772551131, 0.58881376785373274, 0.5888137674873859, 0.58881376774382865, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376737748181, 0.58881376763392457, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.5888137674873859, 0.58881376800027152, 0.5888137674873859, 0.58881376811017561, 0.58881376785373274, 0.5888137674873859, 0.5888137674873859, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376737748181, 0.58881376759728987, 0.5888137674873859, 0.5888137674873859, 0.58881376785373274, 0.58881376759728987, 0.58881376785373274, 0.58881376785373274, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376737748181, 0.58881376763392457, 0.58881376737748181, 0.58881376811017561, 0.58881376811017561, 0.5888137674873859, 0.5888137674873859, 0.58881376763392457, 0.58881376772551131, 0.58881376763392457, 0.5888137674873859, 0.58881376774382865, 0.58881376772551131, 0.58881376772551131, 0.58881376811017561, 0.58881376746906855, 0.58881376772551131, 0.58881376746906855, 0.58881376737748181, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376772551131, 0.58881376746906855, 0.5888137674873859, 0.58881376737748181, 0.5888137674873859, 0.58881376763392457]}
[2017-11-13 00:10:17,181 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:94]: done!
[2017-11-13 00:10:17,181 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:154]: >> Executing classifier part ... 
[2017-11-13 00:10:17,181 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:99]: =======================================
[2017-11-13 00:10:17,181 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f78c707f4a8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 00:10:17,226 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:112]: training ... 
[2017-11-13 00:12:05,489 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:124]: trained!
[2017-11-13 00:12:05,491 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:127]: Training history: 
{'val_loss': [0.010024789727698028, 0.0098775320038974948, 0.0097311228846085566, 0.009586945498105983, 0.0094451872029490628, 0.0093072889490420051, 0.0091746824838525743, 0.0090470996418739336, 0.0089245534962437856, 0.0088068460422432993, 0.0086938917990012233, 0.008585093549857795, 0.0084804315708549936, 0.0083801078378157104, 0.0082838699623222246, 0.0081914158150221336, 0.008102631132329596, 0.0080173737230991114, 0.0079352176249664289, 0.0078558387671039901, 0.0077792739454089046, 0.0077056840692255575, 0.0076348845583826411, 0.0075667841865449149, 0.0075012786559705176, 0.0074383046419176247, 0.0073777899651556213, 0.0073195671797712716, 0.0072635028071590738, 0.0072094743541653052, 0.0071573890884126428, 0.0071071678665241564, 0.0070587417515874133, 0.0070119651352993622, 0.0069667169630361313, 0.0069228642253156706, 0.0068804414208881474, 0.0068392447441760935, 0.0067993788512555201, 0.0067606671509024821, 0.0067231333104817393, 0.0066867950978276901, 0.0066515699368261049, 0.006617280433030598, 0.0065838841247098821, 0.006551535034960752, 0.0065202436056749748, 0.0064899761361315788, 0.0064606263153393472, 0.0064320305784728001, 0.0064042195033794441, 0.0063771339770420333, 0.0063509287963513994, 0.0063255299523223511, 0.0063009538054189275, 0.0062771456776581514, 0.006254090650568, 0.0062317933080558658, 0.0062102000609898875, 0.0061892763396455006, 0.0061690034171684085, 0.0061493384284850164, 0.0061301810763859394, 0.0061115117563578722, 0.0060934216168373268, 0.0060758810320723673, 0.0060588950568249231, 0.0060424337901008839, 0.0060264857080816999, 0.0060110253603872753, 0.0059960550043496501, 0.0059815358117804428, 0.0059674455053744264, 0.0059537900071660382, 0.0059405628100148364, 0.0059277158798338309, 0.00591524613183338, 0.0059031425251670488, 0.0058913768051005204, 0.0058799647781513217, 0.0058688673166537369, 0.0058581097065349939, 0.0058476541980713274, 0.0058375047398627243, 0.0058276482068389986, 0.005818055423329754, 0.0058087574138018724, 0.0057997108232853136, 0.0057909210215990872, 0.0057823606385922124, 0.0057740502118316505, 0.0057659429449546514, 0.0057580721803480363, 0.0057504110567991838, 0.0057429621051512244, 0.0057357086602695369, 0.0057286521156758178, 0.0057217752488267683, 0.0057150723004097386, 0.0057085427718728673, 0.005702165860793515], 'val_acc': [0.0037174721189591076, 0.004646840148698885, 0.034386617100371747, 0.34851301137399499, 0.50464684059185605, 0.53996282483565317, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926, 0.59200743472265926], 'loss': [0.010076699753251263, 0.0099499464222786976, 0.009802184602876492, 0.0096562451596549845, 0.0095122779737276467, 0.0093713842936835549, 0.0092350801100385439, 0.0091040247299129708, 0.0089779745074150454, 0.0088568864168156198, 0.0087406285274281553, 0.0086289623863285286, 0.0085213303493854448, 0.0084180174179068357, 0.0083189135727592244, 0.0082237368367140684, 0.0081323038090590546, 0.0080444765029350305, 0.0079600237414112623, 0.0078785035921777029, 0.0077997409399729349, 0.0077239319650065918, 0.0076510054571639931, 0.0075808228425722803, 0.0075132629256546681, 0.0074482952160434485, 0.007385816361832981, 0.0073257507776387024, 0.007267888557548236, 0.0072121037514886023, 0.0071583486859902474, 0.0071065095141667417, 0.0070564935671322427, 0.0070082238201594604, 0.0069615324211009782, 0.0069163426634933989, 0.0068725374290867312, 0.0068300974603396625, 0.0067889341270549941, 0.0067490377290530404, 0.0067103212609424612, 0.0066727904105454809, 0.006636428603525809, 0.0066011280299936546, 0.0065666874137964067, 0.0065332649824608484, 0.0065008868977367955, 0.006469555150204611, 0.0064392381075245326, 0.0064097605602725302, 0.0063810474016047104, 0.006353139741942699, 0.0063259963383503169, 0.0062997469371705609, 0.0062742963835102474, 0.0062496718863562237, 0.0062258108012428585, 0.0062027171442483233, 0.0061803648758338471, 0.0061587129442505512, 0.0061377248252823847, 0.006117377679202003, 0.0060976103790214295, 0.0060783179445946661, 0.0060595615876274161, 0.0060413941768465707, 0.0060237769201196409, 0.0060067208078543903, 0.0059901896446883755, 0.0059741735910583509, 0.0059586329796061273, 0.0059435745857463673, 0.0059289772134473442, 0.0059147992588639182, 0.0059010619927282416, 0.0058877495273182969, 0.0058748116702432088, 0.0058622458293122719, 0.0058500501023835581, 0.0058381889180292293, 0.0058266941218144078, 0.0058154996619608481, 0.0058046476503338419, 0.0057941005870324374, 0.0057838743984168044, 0.0057739220730177307, 0.0057642411425728041, 0.0057548546065137327, 0.0057457290846252267, 0.0057368374303138981, 0.0057281903085684071, 0.0057197971508186254, 0.0057115969937878586, 0.0057036485107983086, 0.0056958982644267223, 0.0056883638210081765, 0.005681032233899568, 0.0056738936123063247, 0.0056669328321108034, 0.0056601447996596985, 0.0056535374331983523], 'acc': [0.00061462814996926854, 0.0012292562999385371, 0.014751075603841783, 0.14874001245741911, 0.46158574081009418, 0.51997541458092367, 0.57713583289441261, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376783541539, 0.58881376763392457, 0.58881376811017561, 0.5888137674873859, 0.58881376785373274, 0.5888137674873859, 0.58881376785373274, 0.58881376774382865, 0.58881376774382865, 0.58881376737748181, 0.58881376811017561, 0.58881376774382865, 0.58881376800027152, 0.58881376800027152, 0.58881376774382865, 0.58881376774382865, 0.58881376811017561, 0.58881376752402059, 0.58881376737748181, 0.5888137674873859, 0.58881376774382865, 0.58881376800027152, 0.58881376811017561, 0.58881376737748181, 0.58881376785373274, 0.58881376737748181, 0.58881376759728987, 0.58881376772551131, 0.58881376785373274, 0.5888137674873859, 0.58881376774382865, 0.58881376737748181, 0.58881376785373274, 0.58881376811017561, 0.58881376737748181, 0.58881376763392457, 0.58881376811017561, 0.58881376737748181, 0.58881376737748181, 0.58881376737748181, 0.5888137674873859, 0.58881376800027152, 0.5888137674873859, 0.58881376811017561, 0.58881376785373274, 0.5888137674873859, 0.5888137674873859, 0.5888137674873859, 0.58881376811017561, 0.58881376811017561, 0.58881376737748181, 0.58881376759728987, 0.5888137674873859, 0.5888137674873859, 0.58881376785373274, 0.58881376759728987, 0.58881376785373274, 0.58881376785373274, 0.58881376774382865, 0.58881376800027152, 0.58881376737748181, 0.58881376737748181, 0.58881376763392457, 0.58881376737748181, 0.58881376811017561, 0.58881376811017561, 0.5888137674873859, 0.5888137674873859, 0.58881376763392457, 0.58881376772551131, 0.58881376763392457, 0.5888137674873859, 0.58881376774382865, 0.58881376772551131, 0.58881376772551131, 0.58881376811017561, 0.58881376746906855, 0.58881376772551131, 0.58881376746906855, 0.58881376737748181, 0.58881376785373274, 0.58881376726757773, 0.5888137674873859, 0.58881376811017561, 0.58881376774382865, 0.58881376772551131, 0.58881376746906855, 0.5888137674873859, 0.58881376737748181, 0.5888137674873859, 0.58881376763392457]}
[2017-11-13 00:12:05,491 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:131]: evaluating model ... 
[2017-11-13 00:12:05,551 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:135]: evaluated! 
[2017-11-13 00:12:05,551 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:137]: generating reports ... 
[2017-11-13 00:12:06,575 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:140]: done!
[2017-11-13 00:12:06,576 AE_UNIGRAMA_4L_MINIDS_UNDER_03.py:156]: >> experiment AE_UNIGRAMA_4L_MINIDS_UNDER_03 finished!
