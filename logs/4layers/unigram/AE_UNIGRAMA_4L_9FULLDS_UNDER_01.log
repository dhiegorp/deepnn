[2017-11-18 16:46:50,201 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_9FULLDS_UNDER_01
[2017-11-18 16:46:50,201 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:148]: >> Printing header log
[2017-11-18 16:46:50,202 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_9FULLDS_UNDER_01
	layers = 96,28,26,24,22,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9ba1799e48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9ba179d390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:46:50,202 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:150]: >> Loading dataset... 
[2017-11-18 16:46:52,797 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:46:52,797 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:152]: >> Executing autoencoder part ... 
[2017-11-18 16:46:52,798 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:59]: =======================================
[2017-11-18 16:46:52,798 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9ba1799e48>, 'discard_decoder_function': True}
[2017-11-18 16:46:52,921 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:75]: training and evaluate autoencoder
[2017-11-18 16:48:10,207 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:87]: trained and evaluated!
[2017-11-18 16:48:10,208 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:90]: Training history: 
{'val_loss': [0.0095112942945032777, 0.0088802071549039432, 0.0084081546292913752, 0.0080411842415292045, 0.007746559763015773, 0.0074970455395618439, 0.0072835468162071593, 0.0071030008130512096, 0.0069457042650160478, 0.0068092195148408982, 0.0066891231562823152, 0.0065846086903456396, 0.006491031764689196, 0.0064087440797121961, 0.0063331427478061381, 0.0062655129987446651, 0.0061921648767074107, 0.0061246381091273625, 0.0060663390896108192, 0.0060157213243356373, 0.0059715297301763653, 0.0059328484061444151, 0.005898579725607523, 0.0058664295841891487, 0.0058380271440241121, 0.0058129006264801796, 0.0057906665537541934, 0.0057709562811775984, 0.0057534031936702359, 0.0057378288643220379, 0.0057239255743653664, 0.0057115431423020065, 0.0057004844101206792, 0.005690612848789918, 0.0056817839788091571, 0.0056738234001004065, 0.0056664008260949306, 0.0056593899729941279, 0.0056519188839621853, 0.0056448492766773819, 0.0056385684094245611, 0.0056329826462071953, 0.0056280027196195983, 0.0056235358944400262, 0.0056190265635064759, 0.0056138309183435013, 0.0056092440174979486, 0.00560518703269418, 0.0056015804908157918, 0.0055983617164376675, 0.0055954688722736658, 0.005592881384857056, 0.0055905547149948985, 0.0055884504383577061, 0.0055865522064008459, 0.0055848340626576017, 0.0055832733861891195, 0.0055818359830643663, 0.0055805193021577241, 0.0055793095719772956, 0.0055781897789436213, 0.0055771737944920715, 0.0055762250418783339, 0.005575341704065026, 0.0055745248564713053, 0.0055737560692810427, 0.0055730418141764267, 0.0055723668031431445, 0.0055717306847532459, 0.0055711244710251132, 0.0055705482197171766, 0.0055700006039257994, 0.0055694801942368323, 0.0055689738053850387, 0.0055684862210518332, 0.0055680099587397391, 0.0055675477042584761, 0.0055671020926759112, 0.0055666721574154374, 0.0055662438713078473, 0.0055658222210875213, 0.0055654126950887058, 0.0055650048490472684, 0.0055646096431170699, 0.0055642146517059536, 0.0055638240219546683, 0.0055634308573356923, 0.0055630392782925432, 0.0055626626146148828, 0.0055622799336213381, 0.0055618933760531956, 0.005561512184285862, 0.0055611260610611037, 0.0055607478343975792, 0.005560361067872277, 0.0055599756382620708, 0.005559591728169163, 0.0055592076893819196, 0.0055588160427400167, 0.0055584210532969658, 0.0055580254126811118], 'val_acc': [0.60161705255420805, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099129767036078027, 0.0091871649066423648, 0.0086442639229779624, 0.008231332555675713, 0.0079054373293146584, 0.0076382610366974779, 0.0074080892215407784, 0.0072136899086344833, 0.0070469939425757758, 0.0069018803405772877, 0.0067749355320192396, 0.0066641110475208808, 0.0065664110977439972, 0.0064795559591794213, 0.006401944109031203, 0.0063307893085697573, 0.0062623957110420504, 0.0061905323294551189, 0.0061279917816007678, 0.0060738747149209306, 0.0060267585656766046, 0.0059856377990475801, 0.0059495436102407935, 0.0059165509186279953, 0.0058864564657150949, 0.0058599460868998705, 0.0058364863700070043, 0.0058157111714020552, 0.0057972941412283508, 0.0057808956751153849, 0.0057663488634135535, 0.0057533661201248747, 0.005741805204673751, 0.0057314821117484078, 0.0057222689715138286, 0.0057139997174491235, 0.0057064246722832333, 0.0056992812169393619, 0.0056921874502326459, 0.0056847889229885724, 0.0056781483287929322, 0.0056722514649478846, 0.0056670018331970457, 0.0056623154113713227, 0.0056579836312833703, 0.0056529382140983481, 0.0056480320145486798, 0.0056436970848025422, 0.0056398637426807443, 0.0056364540587065847, 0.0056334111414967731, 0.0056306858532399586, 0.0056282442026055193, 0.0056260475643986028, 0.0056240680927944113, 0.0056222797251073613, 0.0056206572581276003, 0.0056191876148149996, 0.0056178368296169222, 0.0056165937570702065, 0.0056154551684679914, 0.0056144121293094209, 0.0056134520853730495, 0.0056125547028017166, 0.0056117228758743717, 0.0056109538405166096, 0.0056102322852343038, 0.0056095566580899002, 0.0056089133227581701, 0.0056083082326389396, 0.0056077348110881615, 0.005607184105886189, 0.0056066646262257101, 0.0056061618234923361, 0.0056056803464112183, 0.0056052126958751345, 0.0056047646542689844, 0.0056043243386277551, 0.0056038949662268276, 0.0056034771923757238, 0.0056030635778110084, 0.0056026574672118964, 0.0056022608279930391, 0.0056018650064678576, 0.0056014745852875575, 0.0056010930158442059, 0.0056007113305428166, 0.0056003302768877867, 0.0055999529003393717, 0.0055995789393453385, 0.0055992071518755201, 0.0055988335255380273, 0.0055984599911667815, 0.0055980866954276551, 0.0055977174712954761, 0.005597343538937297, 0.0055969675920667736, 0.0055965887031908766, 0.0055962094219866284, 0.0055958273226942362, 0.0055954452999355938], 'acc': [0.26917883877785231, 0.59371547809741065, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822262938279, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822268059583, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822267327968, 0.59383822264767316, 0.59383822267327968, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539]}
[2017-11-18 16:48:10,208 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:94]: done!
[2017-11-18 16:48:10,208 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:154]: >> Executing classifier part ... 
[2017-11-18 16:48:10,208 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:99]: =======================================
[2017-11-18 16:48:10,208 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9ba179d390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:48:10,240 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:112]: training ... 
[2017-11-18 16:51:50,702 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:124]: trained!
[2017-11-18 16:51:50,704 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:127]: Training history: 
{'val_loss': [0.0095112942945032777, 0.0088802071549039432, 0.0084081546292913752, 0.0080411842415292045, 0.007746559763015773, 0.0074970455395618439, 0.0072835468162071593, 0.0071030008130512096, 0.0069457042650160478, 0.0068092195148408982, 0.0066891231562823152, 0.0065846086903456396, 0.006491031764689196, 0.0064087440797121961, 0.0063331427478061381, 0.0062655129987446651, 0.0061921648767074107, 0.0061246381091273625, 0.0060663390896108192, 0.0060157213243356373, 0.0059715297301763653, 0.0059328484061444151, 0.005898579725607523, 0.0058664295841891487, 0.0058380271440241121, 0.0058129006264801796, 0.0057906665537541934, 0.0057709562811775984, 0.0057534031936702359, 0.0057378288643220379, 0.0057239255743653664, 0.0057115431423020065, 0.0057004844101206792, 0.005690612848789918, 0.0056817839788091571, 0.0056738234001004065, 0.0056664008260949306, 0.0056593899729941279, 0.0056519188839621853, 0.0056448492766773819, 0.0056385684094245611, 0.0056329826462071953, 0.0056280027196195983, 0.0056235358944400262, 0.0056190265635064759, 0.0056138309183435013, 0.0056092440174979486, 0.00560518703269418, 0.0056015804908157918, 0.0055983617164376675, 0.0055954688722736658, 0.005592881384857056, 0.0055905547149948985, 0.0055884504383577061, 0.0055865522064008459, 0.0055848340626576017, 0.0055832733861891195, 0.0055818359830643663, 0.0055805193021577241, 0.0055793095719772956, 0.0055781897789436213, 0.0055771737944920715, 0.0055762250418783339, 0.005575341704065026, 0.0055745248564713053, 0.0055737560692810427, 0.0055730418141764267, 0.0055723668031431445, 0.0055717306847532459, 0.0055711244710251132, 0.0055705482197171766, 0.0055700006039257994, 0.0055694801942368323, 0.0055689738053850387, 0.0055684862210518332, 0.0055680099587397391, 0.0055675477042584761, 0.0055671020926759112, 0.0055666721574154374, 0.0055662438713078473, 0.0055658222210875213, 0.0055654126950887058, 0.0055650048490472684, 0.0055646096431170699, 0.0055642146517059536, 0.0055638240219546683, 0.0055634308573356923, 0.0055630392782925432, 0.0055626626146148828, 0.0055622799336213381, 0.0055618933760531956, 0.005561512184285862, 0.0055611260610611037, 0.0055607478343975792, 0.005560361067872277, 0.0055599756382620708, 0.005559591728169163, 0.0055592076893819196, 0.0055588160427400167, 0.0055584210532969658, 0.0055580254126811118], 'val_acc': [0.60161705255420805, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099129767036078027, 0.0091871649066423648, 0.0086442639229779624, 0.008231332555675713, 0.0079054373293146584, 0.0076382610366974779, 0.0074080892215407784, 0.0072136899086344833, 0.0070469939425757758, 0.0069018803405772877, 0.0067749355320192396, 0.0066641110475208808, 0.0065664110977439972, 0.0064795559591794213, 0.006401944109031203, 0.0063307893085697573, 0.0062623957110420504, 0.0061905323294551189, 0.0061279917816007678, 0.0060738747149209306, 0.0060267585656766046, 0.0059856377990475801, 0.0059495436102407935, 0.0059165509186279953, 0.0058864564657150949, 0.0058599460868998705, 0.0058364863700070043, 0.0058157111714020552, 0.0057972941412283508, 0.0057808956751153849, 0.0057663488634135535, 0.0057533661201248747, 0.005741805204673751, 0.0057314821117484078, 0.0057222689715138286, 0.0057139997174491235, 0.0057064246722832333, 0.0056992812169393619, 0.0056921874502326459, 0.0056847889229885724, 0.0056781483287929322, 0.0056722514649478846, 0.0056670018331970457, 0.0056623154113713227, 0.0056579836312833703, 0.0056529382140983481, 0.0056480320145486798, 0.0056436970848025422, 0.0056398637426807443, 0.0056364540587065847, 0.0056334111414967731, 0.0056306858532399586, 0.0056282442026055193, 0.0056260475643986028, 0.0056240680927944113, 0.0056222797251073613, 0.0056206572581276003, 0.0056191876148149996, 0.0056178368296169222, 0.0056165937570702065, 0.0056154551684679914, 0.0056144121293094209, 0.0056134520853730495, 0.0056125547028017166, 0.0056117228758743717, 0.0056109538405166096, 0.0056102322852343038, 0.0056095566580899002, 0.0056089133227581701, 0.0056083082326389396, 0.0056077348110881615, 0.005607184105886189, 0.0056066646262257101, 0.0056061618234923361, 0.0056056803464112183, 0.0056052126958751345, 0.0056047646542689844, 0.0056043243386277551, 0.0056038949662268276, 0.0056034771923757238, 0.0056030635778110084, 0.0056026574672118964, 0.0056022608279930391, 0.0056018650064678576, 0.0056014745852875575, 0.0056010930158442059, 0.0056007113305428166, 0.0056003302768877867, 0.0055999529003393717, 0.0055995789393453385, 0.0055992071518755201, 0.0055988335255380273, 0.0055984599911667815, 0.0055980866954276551, 0.0055977174712954761, 0.005597343538937297, 0.0055969675920667736, 0.0055965887031908766, 0.0055962094219866284, 0.0055958273226942362, 0.0055954452999355938], 'acc': [0.26917883877785231, 0.59371547809741065, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822262938279, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822268059583, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822267327968, 0.59383822264767316, 0.59383822267327968, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539]}
[2017-11-18 16:51:50,704 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:131]: evaluating model ... 
[2017-11-18 16:51:50,831 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:135]: evaluated! 
[2017-11-18 16:51:50,831 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:137]: generating reports ... 
[2017-11-18 16:51:51,702 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:140]: done!
[2017-11-18 16:51:51,702 AE_UNIGRAMA_4L_9FULLDS_UNDER_01.py:156]: >> experiment AE_UNIGRAMA_4L_9FULLDS_UNDER_01 finished!
