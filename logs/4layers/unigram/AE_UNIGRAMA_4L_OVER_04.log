[2017-10-20 01:37:58,515 AE_UNIGRAMA_4L_OVER_04.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_OVER_04
[2017-10-20 01:37:58,515 AE_UNIGRAMA_4L_OVER_04.py:148]: >> Printing header log
[2017-10-20 01:37:58,516 AE_UNIGRAMA_4L_OVER_04.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_OVER_04
	layers = 96,134,122,109,97,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f96dbe147b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f96dbe14898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:37:58,516 AE_UNIGRAMA_4L_OVER_04.py:150]: >> Loading dataset... 
[2017-10-20 01:37:59,122 AE_UNIGRAMA_4L_OVER_04.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:37:59,122 AE_UNIGRAMA_4L_OVER_04.py:152]: >> Executing autoencoder part ... 
[2017-10-20 01:37:59,122 AE_UNIGRAMA_4L_OVER_04.py:59]: =======================================
[2017-10-20 01:37:59,122 AE_UNIGRAMA_4L_OVER_04.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f96dbe147b8>, 'discard_decoder_function': True}
[2017-10-20 01:37:59,238 AE_UNIGRAMA_4L_OVER_04.py:75]: training and evaluate autoencoder
[2017-10-20 01:38:41,311 AE_UNIGRAMA_4L_OVER_04.py:87]: trained and evaluated!
[2017-10-20 01:38:41,311 AE_UNIGRAMA_4L_OVER_04.py:90]: Training history: 
{'val_loss': [0.010153219720078667, 0.009973955911940802, 0.0097868756415343192, 0.0096093715968295981, 0.0094418697073003176, 0.0092812297090223289, 0.0091288925276646823, 0.008984735377520656, 0.008845870791619373, 0.0087110201852416899, 0.0085823717579023989, 0.0084602454344856245, 0.0083447344753489611, 0.0082355587739760556, 0.0081323318609268468, 0.0080349228888417709, 0.0079429479658631365, 0.0078562261038165552, 0.0077743877892185098, 0.0076971193792845461, 0.0076241331334229298, 0.0075550992249556193, 0.0074898546430036484, 0.0074281369103984321, 0.0073696513812587386, 0.007314326743626462, 0.0072619214006543822, 0.0072122836956359637, 0.0071652356611363946, 0.0071206484751630446, 0.0070784028643762981, 0.007038273166546591, 0.0070001908844565374, 0.0069640309248659689, 0.0069296879877360556, 0.0068970507990610422, 0.0068660442800465345, 0.0068365349555491962, 0.0068084808952801733, 0.0067818264120351867, 0.0067564380739479702, 0.0067322473059024069, 0.0067092034529520677, 0.0066872561492413614, 0.0066663498270107249, 0.0066462957826494947, 0.0066271105341502504, 0.0066086779500887519, 0.0065909529357566932, 0.0065737537413032305, 0.006557207014480931, 0.0065413895149656386, 0.0065262887980027271, 0.0065118026171835158, 0.0064979238941102226, 0.0064846860282954007, 0.0064720360486037673, 0.0064599196301932454, 0.0064483165401674558, 0.0064372157082515577, 0.0064265845710460142, 0.0064163990041801924, 0.0064066598385738617, 0.006397315335622729, 0.0063883847570856932, 0.0063797937789204836, 0.0063715516070257114, 0.0063636451976920817, 0.0063560665169640762, 0.0063487538950150781, 0.0063417499874576537, 0.0063350097324740709, 0.0063285460664464863, 0.0063223368055481451, 0.0063163603320163866, 0.0063106134398857681, 0.00630507529557416, 0.0062997584442389945, 0.0062946387995934617, 0.0062897058955106375, 0.0062849452670622049, 0.0062803690110551378, 0.0062759719654003707, 0.0062717263392937893, 0.0062676477367162265, 0.0062637125214624143, 0.0062599194731189417, 0.0062562797779432021, 0.0062527728983682324, 0.0062493948044331548, 0.0062461302002898827, 0.0062429806179467411, 0.0062399480273760159, 0.0062370141604603663, 0.0062341815324631769, 0.0062314439911159885, 0.0062287813900765657, 0.0062261854062985534, 0.0062236308421399515, 0.0062211317436070245, 0.0062186940396585432, 0.00621631200387243], 'loss': [0.010231342577657673, 0.010060271295732014, 0.0098728696914697697, 0.0096893083892611535, 0.009515986768683371, 0.0093510618625688418, 0.009193439859171074, 0.0090443014534168538, 0.0089022225283026772, 0.0087640451676067425, 0.0086312034581206877, 0.0085047945796930501, 0.0083849260694568856, 0.0082716346931882481, 0.0081644474271714649, 0.008063186942894509, 0.0079675975754243435, 0.0078773643891885195, 0.007792223026814568, 0.0077118173673217764, 0.0076358513940943118, 0.0075640505524357917, 0.007496113605572903, 0.0074318452035869714, 0.007371012170953057, 0.0073133456831558684, 0.0072587459930862725, 0.0072070081007324007, 0.0071579771884559629, 0.0071114757053609007, 0.0070673899379339626, 0.0070255795927614099, 0.0069858448742473869, 0.0069481094222408205, 0.0069122556717201985, 0.0068781870384669111, 0.0068457883318454558, 0.0068149893368882278, 0.0067856595196063418, 0.0067577486140533282, 0.0067312190716727859, 0.0067059347894301465, 0.006681825615037473, 0.0066588230459128303, 0.0066369258576561025, 0.0066159875235178569, 0.0065959152544046665, 0.0065766699350546052, 0.006558179121221786, 0.0065403438010668011, 0.0065231094372669978, 0.0065065923369573755, 0.0064908062464476878, 0.0064757041960551683, 0.0064612248329733073, 0.0064473424668377464, 0.006434101991174535, 0.0064214315770861376, 0.0064092976445837046, 0.0063976546123820756, 0.0063865061242021183, 0.0063758273889466931, 0.006365580686906693, 0.0063557878632348012, 0.0063463801042404032, 0.0063373761405548989, 0.0063287040087627389, 0.0063203894141111256, 0.0063124082807380511, 0.0063047449115363821, 0.0062973575203461411, 0.0062902694795287564, 0.0062834353222824824, 0.0062768973665427562, 0.0062705937308759029, 0.006264524090721443, 0.0062586836669692508, 0.006253053213812562, 0.0062476453541926288, 0.0062424294128510284, 0.0062374027346311792, 0.0062325483865774915, 0.0062278821158835915, 0.0062233825779755237, 0.006219046537265795, 0.0062148820697006521, 0.0062108503613957575, 0.0062069554012394714, 0.0062032361685446643, 0.0061996303774649996, 0.006196161370023801, 0.0061928024212128561, 0.0061895672112277445, 0.0061864379367527235, 0.0061834143173034274, 0.0061804915869353222, 0.0061776604473055066, 0.0061749112073929673, 0.0061721930789206576, 0.0061695442793143259, 0.0061669503144013166, 0.0061644206576841557]}
[2017-10-20 01:38:41,311 AE_UNIGRAMA_4L_OVER_04.py:94]: done!
[2017-10-20 01:38:41,312 AE_UNIGRAMA_4L_OVER_04.py:154]: >> Executing classifier part ... 
[2017-10-20 01:38:41,312 AE_UNIGRAMA_4L_OVER_04.py:99]: =======================================
[2017-10-20 01:38:41,312 AE_UNIGRAMA_4L_OVER_04.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f96dbe14898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:38:41,348 AE_UNIGRAMA_4L_OVER_04.py:112]: training ... 
[2017-10-20 01:39:48,704 AE_UNIGRAMA_4L_OVER_04.py:124]: trained!
[2017-10-20 01:39:48,704 AE_UNIGRAMA_4L_OVER_04.py:127]: Training history: 
{'val_loss': [0.010153219720078667, 0.009973955911940802, 0.0097868756415343192, 0.0096093715968295981, 0.0094418697073003176, 0.0092812297090223289, 0.0091288925276646823, 0.008984735377520656, 0.008845870791619373, 0.0087110201852416899, 0.0085823717579023989, 0.0084602454344856245, 0.0083447344753489611, 0.0082355587739760556, 0.0081323318609268468, 0.0080349228888417709, 0.0079429479658631365, 0.0078562261038165552, 0.0077743877892185098, 0.0076971193792845461, 0.0076241331334229298, 0.0075550992249556193, 0.0074898546430036484, 0.0074281369103984321, 0.0073696513812587386, 0.007314326743626462, 0.0072619214006543822, 0.0072122836956359637, 0.0071652356611363946, 0.0071206484751630446, 0.0070784028643762981, 0.007038273166546591, 0.0070001908844565374, 0.0069640309248659689, 0.0069296879877360556, 0.0068970507990610422, 0.0068660442800465345, 0.0068365349555491962, 0.0068084808952801733, 0.0067818264120351867, 0.0067564380739479702, 0.0067322473059024069, 0.0067092034529520677, 0.0066872561492413614, 0.0066663498270107249, 0.0066462957826494947, 0.0066271105341502504, 0.0066086779500887519, 0.0065909529357566932, 0.0065737537413032305, 0.006557207014480931, 0.0065413895149656386, 0.0065262887980027271, 0.0065118026171835158, 0.0064979238941102226, 0.0064846860282954007, 0.0064720360486037673, 0.0064599196301932454, 0.0064483165401674558, 0.0064372157082515577, 0.0064265845710460142, 0.0064163990041801924, 0.0064066598385738617, 0.006397315335622729, 0.0063883847570856932, 0.0063797937789204836, 0.0063715516070257114, 0.0063636451976920817, 0.0063560665169640762, 0.0063487538950150781, 0.0063417499874576537, 0.0063350097324740709, 0.0063285460664464863, 0.0063223368055481451, 0.0063163603320163866, 0.0063106134398857681, 0.00630507529557416, 0.0062997584442389945, 0.0062946387995934617, 0.0062897058955106375, 0.0062849452670622049, 0.0062803690110551378, 0.0062759719654003707, 0.0062717263392937893, 0.0062676477367162265, 0.0062637125214624143, 0.0062599194731189417, 0.0062562797779432021, 0.0062527728983682324, 0.0062493948044331548, 0.0062461302002898827, 0.0062429806179467411, 0.0062399480273760159, 0.0062370141604603663, 0.0062341815324631769, 0.0062314439911159885, 0.0062287813900765657, 0.0062261854062985534, 0.0062236308421399515, 0.0062211317436070245, 0.0062186940396585432, 0.00621631200387243], 'loss': [0.010231342577657673, 0.010060271295732014, 0.0098728696914697697, 0.0096893083892611535, 0.009515986768683371, 0.0093510618625688418, 0.009193439859171074, 0.0090443014534168538, 0.0089022225283026772, 0.0087640451676067425, 0.0086312034581206877, 0.0085047945796930501, 0.0083849260694568856, 0.0082716346931882481, 0.0081644474271714649, 0.008063186942894509, 0.0079675975754243435, 0.0078773643891885195, 0.007792223026814568, 0.0077118173673217764, 0.0076358513940943118, 0.0075640505524357917, 0.007496113605572903, 0.0074318452035869714, 0.007371012170953057, 0.0073133456831558684, 0.0072587459930862725, 0.0072070081007324007, 0.0071579771884559629, 0.0071114757053609007, 0.0070673899379339626, 0.0070255795927614099, 0.0069858448742473869, 0.0069481094222408205, 0.0069122556717201985, 0.0068781870384669111, 0.0068457883318454558, 0.0068149893368882278, 0.0067856595196063418, 0.0067577486140533282, 0.0067312190716727859, 0.0067059347894301465, 0.006681825615037473, 0.0066588230459128303, 0.0066369258576561025, 0.0066159875235178569, 0.0065959152544046665, 0.0065766699350546052, 0.006558179121221786, 0.0065403438010668011, 0.0065231094372669978, 0.0065065923369573755, 0.0064908062464476878, 0.0064757041960551683, 0.0064612248329733073, 0.0064473424668377464, 0.006434101991174535, 0.0064214315770861376, 0.0064092976445837046, 0.0063976546123820756, 0.0063865061242021183, 0.0063758273889466931, 0.006365580686906693, 0.0063557878632348012, 0.0063463801042404032, 0.0063373761405548989, 0.0063287040087627389, 0.0063203894141111256, 0.0063124082807380511, 0.0063047449115363821, 0.0062973575203461411, 0.0062902694795287564, 0.0062834353222824824, 0.0062768973665427562, 0.0062705937308759029, 0.006264524090721443, 0.0062586836669692508, 0.006253053213812562, 0.0062476453541926288, 0.0062424294128510284, 0.0062374027346311792, 0.0062325483865774915, 0.0062278821158835915, 0.0062233825779755237, 0.006219046537265795, 0.0062148820697006521, 0.0062108503613957575, 0.0062069554012394714, 0.0062032361685446643, 0.0061996303774649996, 0.006196161370023801, 0.0061928024212128561, 0.0061895672112277445, 0.0061864379367527235, 0.0061834143173034274, 0.0061804915869353222, 0.0061776604473055066, 0.0061749112073929673, 0.0061721930789206576, 0.0061695442793143259, 0.0061669503144013166, 0.0061644206576841557]}
[2017-10-20 01:39:48,704 AE_UNIGRAMA_4L_OVER_04.py:131]: evaluating model ... 
[2017-10-20 01:39:48,757 AE_UNIGRAMA_4L_OVER_04.py:135]: evaluated! 
[2017-10-20 01:39:48,757 AE_UNIGRAMA_4L_OVER_04.py:137]: generating reports ... 
[2017-10-20 01:39:49,368 AE_UNIGRAMA_4L_OVER_04.py:140]: done!
[2017-10-20 01:39:49,369 AE_UNIGRAMA_4L_OVER_04.py:156]: >> experiment AE_UNIGRAMA_4L_OVER_04 finished!
