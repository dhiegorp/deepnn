[2017-11-13 15:14:35,964 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_OVER_04
[2017-11-13 15:14:35,964 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:148]: >> Printing header log
[2017-11-13 15:14:35,964 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_OVER_04
	layers = 96,134,122,109,97
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f54b5bb6eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f54b5bbb400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 15:14:35,964 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:150]: >> Loading dataset... 
[2017-11-13 15:14:38,445 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 15:14:38,445 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:152]: >> Executing autoencoder part ... 
[2017-11-13 15:14:38,445 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:59]: =======================================
[2017-11-13 15:14:38,445 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f54b5bb6eb8>, 'discard_decoder_function': True}
[2017-11-13 15:14:38,562 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:75]: training and evaluate autoencoder
[2017-11-13 15:18:27,451 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:87]: trained and evaluated!
[2017-11-13 15:18:27,452 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:90]: Training history: 
{'val_loss': [0.0096405404789297287, 0.0086680629062344822, 0.007894573332580989, 0.0073253451654867558, 0.0068943314485317621, 0.0065565703846432082, 0.0062876317604899801, 0.0060758012559474365, 0.0059072569449723465, 0.0057722032640043072, 0.0056625377297475363, 0.0055725170621660066, 0.0054976460933774292, 0.0054346691309284448, 0.0053802621339504959, 0.005331976599091146, 0.0052902622716395247, 0.0052543066243323795, 0.0052232013732771291, 0.0051961328269717324, 0.0051723799403162671, 0.0051513243133242586, 0.0051325763946584602, 0.0051157527919126235, 0.005100524530703943, 0.0050866498612894247, 0.005073966776325105, 0.0050623555886239163, 0.0050516516734866127, 0.0050417320777650801, 0.0050325532125850584, 0.0050240211469969771, 0.0050160363449166419, 0.0050085149308374283, 0.0050013796025041718, 0.0049945463549458001, 0.0049879759135431868, 0.0049816252901953009, 0.0049754811087345998, 0.0049695324994526455, 0.0049637791706479807, 0.0049581558952564615, 0.004952646431693508, 0.0049472608998348032, 0.0049419502554155365, 0.0049366550411391033, 0.004931382696462254, 0.004925902112113645, 0.0049201108408987093, 0.0049144291110680425, 0.0049085401797626755, 0.0049025909274368817, 0.0048966646828174929, 0.0048907967864473111, 0.0048848847436415051, 0.0048789906593430504, 0.0048731218379823296, 0.0048673229642179532, 0.0048615220612930167, 0.0048557111180706778, 0.0048498905682953421, 0.0048440421388259661, 0.0048382065233420913, 0.0048324265600295409, 0.0048267153972737257, 0.0048210479400214116, 0.0048153930648652038, 0.0048097644442947731, 0.0048041644151733615, 0.0047985678333316772, 0.0047930062375243967, 0.004787439775034698, 0.0047818467861095509, 0.0047762263316396885, 0.0047706041368869778, 0.0047649783928574328, 0.0047593401983354305, 0.0047536782307864515, 0.0047479936670277844, 0.0047422608861905748, 0.0047364932946478812, 0.004730708057349031, 0.0047249276491682273, 0.0047191057056606154, 0.004713276389439326, 0.0047074188646860082, 0.0047015375368713299, 0.0046955805852186405, 0.0046896073984845415, 0.004683559202718816, 0.004677471916904233, 0.0046713439014715299, 0.0046651541991813063, 0.0046589200742418154, 0.0046526552511681005, 0.0046463509421221958, 0.0046400013897439293, 0.0046335987411973362, 0.0046271342290096461, 0.0046206066644696115, 0.0046140548206820607], 'val_acc': [0.0033076074972436605, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099822071994669359, 0.0091548355727678159, 0.0082705927994666962, 0.007605802058422307, 0.0071123932552050306, 0.006733445473697996, 0.0064322699852012496, 0.0061946735052387089, 0.0060067706111175193, 0.0058569890633065396, 0.0057363323552955345, 0.0056379592682646359, 0.0055567824075528236, 0.0054889893159498918, 0.0054313972344519363, 0.0053809063168562881, 0.0053365889429585166, 0.0052984479695423201, 0.005265539856125742, 0.0052370177282401575, 0.0052120893793776166, 0.0051900905987257656, 0.005170544026479193, 0.0051530921069018768, 0.0051373356037144576, 0.0051230642590427145, 0.0051100337251424573, 0.0050981149215279103, 0.0050871741139582949, 0.0050770581262196456, 0.0050676695799460308, 0.0050589757516721363, 0.0050508577403010797, 0.0050432375486818056, 0.0050360327212722288, 0.0050291476074601146, 0.0050225448007034067, 0.005016192869808307, 0.0050100320299127773, 0.0050040847572188343, 0.0049983186942685366, 0.0049927185743505768, 0.0049872439721265647, 0.0049818732496362435, 0.0049765940070402859, 0.0049713642695490912, 0.0049661637137653021, 0.0049608988156746806, 0.0049552649061345416, 0.0049496119163132046, 0.0049439333166643139, 0.0049380487050782011, 0.0049321880551861904, 0.0049263716830123348, 0.0049205663682792547, 0.0049147408150847054, 0.0049089484890835798, 0.0049031984039397238, 0.0048974892900159484, 0.0048917835077966583, 0.0048860567070317879, 0.0048802944814288589, 0.004874530257717757, 0.0048687949403868952, 0.0048631173022396839, 0.0048574936611396561, 0.0048518879223640992, 0.0048463081763706331, 0.0048407415884664795, 0.004835189902295093, 0.0048296670846085955, 0.0048241504597542435, 0.0048186248190640654, 0.0048130695754736458, 0.004807505431391022, 0.0048019394428964563, 0.0047963656441298158, 0.0047907737928862305, 0.004785159383676978, 0.0047795041281937078, 0.0047738069501055361, 0.004768087349800507, 0.0047623507414555916, 0.0047566045324689745, 0.0047508333293542516, 0.004745040531804628, 0.004739215967261518, 0.0047333417700383433, 0.0047274331246826553, 0.0047214581466853674, 0.0047154416823084076, 0.0047093865329499614, 0.0047032891386760709, 0.0046971318359658575, 0.0046909351267192178, 0.0046847014665892623, 0.0046784216213989213, 0.0046721023662427098, 0.0046657232081372853, 0.004659284045856903, 0.0046527957486801972], 'acc': [0.0031913587823738801, 0.49208297530639328, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822262206665, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427]}
[2017-11-13 15:18:27,452 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:94]: done!
[2017-11-13 15:18:27,452 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:154]: >> Executing classifier part ... 
[2017-11-13 15:18:27,452 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:99]: =======================================
[2017-11-13 15:18:27,452 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f54b5bbb400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 15:18:27,500 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:112]: training ... 
[2017-11-13 15:24:24,327 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:124]: trained!
[2017-11-13 15:24:24,327 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:127]: Training history: 
{'val_loss': [0.0096405404789297287, 0.0086680629062344822, 0.007894573332580989, 0.0073253451654867558, 0.0068943314485317621, 0.0065565703846432082, 0.0062876317604899801, 0.0060758012559474365, 0.0059072569449723465, 0.0057722032640043072, 0.0056625377297475363, 0.0055725170621660066, 0.0054976460933774292, 0.0054346691309284448, 0.0053802621339504959, 0.005331976599091146, 0.0052902622716395247, 0.0052543066243323795, 0.0052232013732771291, 0.0051961328269717324, 0.0051723799403162671, 0.0051513243133242586, 0.0051325763946584602, 0.0051157527919126235, 0.005100524530703943, 0.0050866498612894247, 0.005073966776325105, 0.0050623555886239163, 0.0050516516734866127, 0.0050417320777650801, 0.0050325532125850584, 0.0050240211469969771, 0.0050160363449166419, 0.0050085149308374283, 0.0050013796025041718, 0.0049945463549458001, 0.0049879759135431868, 0.0049816252901953009, 0.0049754811087345998, 0.0049695324994526455, 0.0049637791706479807, 0.0049581558952564615, 0.004952646431693508, 0.0049472608998348032, 0.0049419502554155365, 0.0049366550411391033, 0.004931382696462254, 0.004925902112113645, 0.0049201108408987093, 0.0049144291110680425, 0.0049085401797626755, 0.0049025909274368817, 0.0048966646828174929, 0.0048907967864473111, 0.0048848847436415051, 0.0048789906593430504, 0.0048731218379823296, 0.0048673229642179532, 0.0048615220612930167, 0.0048557111180706778, 0.0048498905682953421, 0.0048440421388259661, 0.0048382065233420913, 0.0048324265600295409, 0.0048267153972737257, 0.0048210479400214116, 0.0048153930648652038, 0.0048097644442947731, 0.0048041644151733615, 0.0047985678333316772, 0.0047930062375243967, 0.004787439775034698, 0.0047818467861095509, 0.0047762263316396885, 0.0047706041368869778, 0.0047649783928574328, 0.0047593401983354305, 0.0047536782307864515, 0.0047479936670277844, 0.0047422608861905748, 0.0047364932946478812, 0.004730708057349031, 0.0047249276491682273, 0.0047191057056606154, 0.004713276389439326, 0.0047074188646860082, 0.0047015375368713299, 0.0046955805852186405, 0.0046896073984845415, 0.004683559202718816, 0.004677471916904233, 0.0046713439014715299, 0.0046651541991813063, 0.0046589200742418154, 0.0046526552511681005, 0.0046463509421221958, 0.0046400013897439293, 0.0046335987411973362, 0.0046271342290096461, 0.0046206066644696115, 0.0046140548206820607], 'val_acc': [0.0033076074972436605, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099822071994669359, 0.0091548355727678159, 0.0082705927994666962, 0.007605802058422307, 0.0071123932552050306, 0.006733445473697996, 0.0064322699852012496, 0.0061946735052387089, 0.0060067706111175193, 0.0058569890633065396, 0.0057363323552955345, 0.0056379592682646359, 0.0055567824075528236, 0.0054889893159498918, 0.0054313972344519363, 0.0053809063168562881, 0.0053365889429585166, 0.0052984479695423201, 0.005265539856125742, 0.0052370177282401575, 0.0052120893793776166, 0.0051900905987257656, 0.005170544026479193, 0.0051530921069018768, 0.0051373356037144576, 0.0051230642590427145, 0.0051100337251424573, 0.0050981149215279103, 0.0050871741139582949, 0.0050770581262196456, 0.0050676695799460308, 0.0050589757516721363, 0.0050508577403010797, 0.0050432375486818056, 0.0050360327212722288, 0.0050291476074601146, 0.0050225448007034067, 0.005016192869808307, 0.0050100320299127773, 0.0050040847572188343, 0.0049983186942685366, 0.0049927185743505768, 0.0049872439721265647, 0.0049818732496362435, 0.0049765940070402859, 0.0049713642695490912, 0.0049661637137653021, 0.0049608988156746806, 0.0049552649061345416, 0.0049496119163132046, 0.0049439333166643139, 0.0049380487050782011, 0.0049321880551861904, 0.0049263716830123348, 0.0049205663682792547, 0.0049147408150847054, 0.0049089484890835798, 0.0049031984039397238, 0.0048974892900159484, 0.0048917835077966583, 0.0048860567070317879, 0.0048802944814288589, 0.004874530257717757, 0.0048687949403868952, 0.0048631173022396839, 0.0048574936611396561, 0.0048518879223640992, 0.0048463081763706331, 0.0048407415884664795, 0.004835189902295093, 0.0048296670846085955, 0.0048241504597542435, 0.0048186248190640654, 0.0048130695754736458, 0.004807505431391022, 0.0048019394428964563, 0.0047963656441298158, 0.0047907737928862305, 0.004785159383676978, 0.0047795041281937078, 0.0047738069501055361, 0.004768087349800507, 0.0047623507414555916, 0.0047566045324689745, 0.0047508333293542516, 0.004745040531804628, 0.004739215967261518, 0.0047333417700383433, 0.0047274331246826553, 0.0047214581466853674, 0.0047154416823084076, 0.0047093865329499614, 0.0047032891386760709, 0.0046971318359658575, 0.0046909351267192178, 0.0046847014665892623, 0.0046784216213989213, 0.0046721023662427098, 0.0046657232081372853, 0.004659284045856903, 0.0046527957486801972], 'acc': [0.0031913587823738801, 0.49208297530639328, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822262206665, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427]}
[2017-11-13 15:24:24,327 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:131]: evaluating model ... 
[2017-11-13 15:24:24,442 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:135]: evaluated! 
[2017-11-13 15:24:24,443 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:137]: generating reports ... 
[2017-11-13 15:24:25,346 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:140]: done!
[2017-11-13 15:24:25,346 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:156]: >> experiment AE_UNIGRAMA_4L_FULLDS_OVER_04 finished!
[2017-11-14 07:03:56,343 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_OVER_04 was already executed!
[2017-11-18 14:55:46,394 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_OVER_04 was already executed!
[2017-11-18 16:22:17,041 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_OVER_04 was already executed!
[2017-11-18 16:51:14,349 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_OVER_04
[2017-11-18 16:51:14,349 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:148]: >> Printing header log
[2017-11-18 16:51:14,349 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_OVER_04
	layers = 96,134,122,109,97
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6dd0aede48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6dd0af1390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:51:14,349 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:150]: >> Loading dataset... 
[2017-11-18 16:51:16,591 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:51:16,591 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:152]: >> Executing autoencoder part ... 
[2017-11-18 16:51:16,591 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:59]: =======================================
[2017-11-18 16:51:16,592 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6dd0aede48>, 'discard_decoder_function': True}
[2017-11-18 16:51:16,697 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:75]: training and evaluate autoencoder
[2017-11-18 16:53:37,380 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:87]: trained and evaluated!
[2017-11-18 16:53:37,381 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:90]: Training history: 
{'val_loss': [0.0096950068332608118, 0.0090753259260490816, 0.0084107621055738487, 0.007890629259857819, 0.0074902734521041237, 0.0071659871381842691, 0.0069111438715561422, 0.0067098799184887497, 0.0065484960619613493, 0.0064176915039591432, 0.0063105921561527516, 0.0062228826077251765, 0.00615069003666531, 0.0060908643957343842, 0.0060408635080190639, 0.0059987537038999582, 0.0059628468779528709, 0.0059319540918337504, 0.0059049250896012449, 0.0058809173735285105, 0.0058594921156962547, 0.0058400071448023892, 0.005822134816533763, 0.0058048794016780083, 0.0057890841614000451, 0.0057736557170075123, 0.0057589262949822358, 0.0057459958348606704, 0.0057345692188818199, 0.0057243083206473281, 0.0057150061361735376, 0.0057064506081704741, 0.0056985271419475502, 0.0056911220478673644, 0.0056841596746245639, 0.0056775595366616635, 0.0056712533156834171, 0.0056651696742973327, 0.00565925943449575, 0.0056534338446771427, 0.0056475948078406561, 0.0056418273340395897, 0.0056361451127060862, 0.0056305482816046944, 0.0056250127944041106, 0.0056195520831478054, 0.0056141295177825771, 0.0056087198258726384, 0.0056033344481219785, 0.0055979567862128468, 0.0055925793424166552, 0.0055872609660690678, 0.0055819560450394608, 0.0055766660292783134, 0.0055713795010994428, 0.0055660753273355503, 0.005560720673047255, 0.0055550952227727997, 0.0055490824097349217, 0.0055427829232183243, 0.0055363385681232707, 0.0055298283912661771, 0.0055232846008860829, 0.005516739852742889, 0.0055101828792367578, 0.0055036338345510133, 0.0054970374097277497, 0.0054904025356747, 0.0054837444719975864, 0.0054770638643072914, 0.0054701539393115992, 0.0054628428126329703, 0.0054554642765628405, 0.0054479282054480591, 0.0054400807690835095, 0.0054319007990478608, 0.0054235068460990075, 0.005414875693402251, 0.0054061293748482236, 0.0053970594563545748, 0.0053877518534556287, 0.0053783548531731408, 0.0053688546825605568, 0.005359238646743091, 0.0053495013938675258, 0.0053397404698765222, 0.0053299030761218376, 0.0053201722677178251, 0.0053106021247797319, 0.0053011714138117309, 0.0052918337054228227, 0.0052825954187992047, 0.0052734228842852395, 0.005264281597808524, 0.005255122676271656, 0.0052459296418794765, 0.0052366698055433293, 0.0052273421878941857, 0.0052179580993159036, 0.0052085540460447277, 0.0051991258279305086], 'val_acc': [0.0014700477765527381, 0.0014700477765527381, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098008577135390729, 0.0094460146341619651, 0.0087411371747319194, 0.0081524465568487119, 0.0076995032596100877, 0.0073418851489251719, 0.0070557288222044172, 0.006831143474064807, 0.0066526940747925409, 0.0065089275044660794, 0.0063919395808397081, 0.006296167733831114, 0.0062176398887779467, 0.0061528209865054822, 0.0060989405348603424, 0.0060537671541713517, 0.0060155712098602949, 0.0059828650427183605, 0.005954507910395577, 0.005929467929141923, 0.0059071693377258606, 0.0058870966266966439, 0.0058688497699168878, 0.0058515292899396186, 0.0058354184722405091, 0.0058202648299768046, 0.0058053272502064501, 0.0057918635785476338, 0.0057800219575341229, 0.0057694768042471549, 0.0057599766586765569, 0.0057513011506619962, 0.0057432892003794079, 0.0057358426555517454, 0.0057288533395239254, 0.0057222546223787436, 0.0057159704896979783, 0.0057099424573504023, 0.0057041168505993743, 0.0056984162942805994, 0.0056927585985195577, 0.0056871127986411005, 0.0056815406426351149, 0.0056760540977737698, 0.0056706287700815945, 0.0056652603078804105, 0.0056599419963195953, 0.0056546342400718508, 0.0056493450592340457, 0.0056440551623284114, 0.0056387824590527214, 0.0056335346438210147, 0.0056283177059851166, 0.0056231219101547684, 0.0056179326068899402, 0.0056127344061622474, 0.0056074950339921239, 0.0056021259363150363, 0.0055963955102853059, 0.005590325567393039, 0.0055840430966778128, 0.0055776646268617244, 0.0055712319598904166, 0.0055647914445802081, 0.0055583514025332199, 0.0055519058811498321, 0.0055454531661654899, 0.005538945119851763, 0.0055323901584062585, 0.0055258229635066014, 0.0055191690539245011, 0.0055121170358355788, 0.0055048606916667641, 0.0054974935398880284, 0.0054898761757307107, 0.0054819126317019887, 0.0054736898013869467, 0.0054652380470789595, 0.0054566321968373835, 0.0054478002126838836, 0.0054386676155049937, 0.0054293826194526931, 0.0054200157708116535, 0.005410514598922893, 0.0054008773387089325, 0.0053911834309451215, 0.0053814319795749991, 0.0053716938612529712, 0.0053621281127692209, 0.0053527247963391584, 0.0053434445883045797, 0.005334276567373621, 0.0053251729313889109, 0.0053161138790287282, 0.0053070816608074729, 0.0052980315881024859, 0.0052889233587781383, 0.0052797485554936735, 0.0052705221988120828, 0.005261258087842848, 0.0052519734964648962], 'acc': [0.0023321468025039893, 0.0015956793911869401, 0.28231250766421939, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822262938279, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539]}
[2017-11-18 16:53:37,381 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:94]: done!
[2017-11-18 16:53:37,381 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:154]: >> Executing classifier part ... 
[2017-11-18 16:53:37,381 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:99]: =======================================
[2017-11-18 16:53:37,381 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6dd0af1390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:53:37,412 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:112]: training ... 
[2017-11-18 16:59:33,179 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:124]: trained!
[2017-11-18 16:59:33,180 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:127]: Training history: 
{'val_loss': [0.0096950068332608118, 0.0090753259260490816, 0.0084107621055738487, 0.007890629259857819, 0.0074902734521041237, 0.0071659871381842691, 0.0069111438715561422, 0.0067098799184887497, 0.0065484960619613493, 0.0064176915039591432, 0.0063105921561527516, 0.0062228826077251765, 0.00615069003666531, 0.0060908643957343842, 0.0060408635080190639, 0.0059987537038999582, 0.0059628468779528709, 0.0059319540918337504, 0.0059049250896012449, 0.0058809173735285105, 0.0058594921156962547, 0.0058400071448023892, 0.005822134816533763, 0.0058048794016780083, 0.0057890841614000451, 0.0057736557170075123, 0.0057589262949822358, 0.0057459958348606704, 0.0057345692188818199, 0.0057243083206473281, 0.0057150061361735376, 0.0057064506081704741, 0.0056985271419475502, 0.0056911220478673644, 0.0056841596746245639, 0.0056775595366616635, 0.0056712533156834171, 0.0056651696742973327, 0.00565925943449575, 0.0056534338446771427, 0.0056475948078406561, 0.0056418273340395897, 0.0056361451127060862, 0.0056305482816046944, 0.0056250127944041106, 0.0056195520831478054, 0.0056141295177825771, 0.0056087198258726384, 0.0056033344481219785, 0.0055979567862128468, 0.0055925793424166552, 0.0055872609660690678, 0.0055819560450394608, 0.0055766660292783134, 0.0055713795010994428, 0.0055660753273355503, 0.005560720673047255, 0.0055550952227727997, 0.0055490824097349217, 0.0055427829232183243, 0.0055363385681232707, 0.0055298283912661771, 0.0055232846008860829, 0.005516739852742889, 0.0055101828792367578, 0.0055036338345510133, 0.0054970374097277497, 0.0054904025356747, 0.0054837444719975864, 0.0054770638643072914, 0.0054701539393115992, 0.0054628428126329703, 0.0054554642765628405, 0.0054479282054480591, 0.0054400807690835095, 0.0054319007990478608, 0.0054235068460990075, 0.005414875693402251, 0.0054061293748482236, 0.0053970594563545748, 0.0053877518534556287, 0.0053783548531731408, 0.0053688546825605568, 0.005359238646743091, 0.0053495013938675258, 0.0053397404698765222, 0.0053299030761218376, 0.0053201722677178251, 0.0053106021247797319, 0.0053011714138117309, 0.0052918337054228227, 0.0052825954187992047, 0.0052734228842852395, 0.005264281597808524, 0.005255122676271656, 0.0052459296418794765, 0.0052366698055433293, 0.0052273421878941857, 0.0052179580993159036, 0.0052085540460447277, 0.0051991258279305086], 'val_acc': [0.0014700477765527381, 0.0014700477765527381, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098008577135390729, 0.0094460146341619651, 0.0087411371747319194, 0.0081524465568487119, 0.0076995032596100877, 0.0073418851489251719, 0.0070557288222044172, 0.006831143474064807, 0.0066526940747925409, 0.0065089275044660794, 0.0063919395808397081, 0.006296167733831114, 0.0062176398887779467, 0.0061528209865054822, 0.0060989405348603424, 0.0060537671541713517, 0.0060155712098602949, 0.0059828650427183605, 0.005954507910395577, 0.005929467929141923, 0.0059071693377258606, 0.0058870966266966439, 0.0058688497699168878, 0.0058515292899396186, 0.0058354184722405091, 0.0058202648299768046, 0.0058053272502064501, 0.0057918635785476338, 0.0057800219575341229, 0.0057694768042471549, 0.0057599766586765569, 0.0057513011506619962, 0.0057432892003794079, 0.0057358426555517454, 0.0057288533395239254, 0.0057222546223787436, 0.0057159704896979783, 0.0057099424573504023, 0.0057041168505993743, 0.0056984162942805994, 0.0056927585985195577, 0.0056871127986411005, 0.0056815406426351149, 0.0056760540977737698, 0.0056706287700815945, 0.0056652603078804105, 0.0056599419963195953, 0.0056546342400718508, 0.0056493450592340457, 0.0056440551623284114, 0.0056387824590527214, 0.0056335346438210147, 0.0056283177059851166, 0.0056231219101547684, 0.0056179326068899402, 0.0056127344061622474, 0.0056074950339921239, 0.0056021259363150363, 0.0055963955102853059, 0.005590325567393039, 0.0055840430966778128, 0.0055776646268617244, 0.0055712319598904166, 0.0055647914445802081, 0.0055583514025332199, 0.0055519058811498321, 0.0055454531661654899, 0.005538945119851763, 0.0055323901584062585, 0.0055258229635066014, 0.0055191690539245011, 0.0055121170358355788, 0.0055048606916667641, 0.0054974935398880284, 0.0054898761757307107, 0.0054819126317019887, 0.0054736898013869467, 0.0054652380470789595, 0.0054566321968373835, 0.0054478002126838836, 0.0054386676155049937, 0.0054293826194526931, 0.0054200157708116535, 0.005410514598922893, 0.0054008773387089325, 0.0053911834309451215, 0.0053814319795749991, 0.0053716938612529712, 0.0053621281127692209, 0.0053527247963391584, 0.0053434445883045797, 0.005334276567373621, 0.0053251729313889109, 0.0053161138790287282, 0.0053070816608074729, 0.0052980315881024859, 0.0052889233587781383, 0.0052797485554936735, 0.0052705221988120828, 0.005261258087842848, 0.0052519734964648962], 'acc': [0.0023321468025039893, 0.0015956793911869401, 0.28231250766421939, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822262938279, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539]}
[2017-11-18 16:59:33,180 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:131]: evaluating model ... 
[2017-11-18 16:59:33,294 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:135]: evaluated! 
[2017-11-18 16:59:33,294 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:137]: generating reports ... 
[2017-11-18 16:59:34,221 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:140]: done!
[2017-11-18 16:59:34,221 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:156]: >> experiment AE_UNIGRAMA_4L_FULLDS_OVER_04 finished!
