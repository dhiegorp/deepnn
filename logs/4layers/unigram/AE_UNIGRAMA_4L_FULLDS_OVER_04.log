[2018-07-21 00:52:16,396 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_OVER_04
[2018-07-21 00:52:16,396 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:146]: >> Printing header log
[2018-07-21 00:52:16,396 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_OVER_04
	layers = 96,163,148,132,117
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2d93f690f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2d93f69668>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,397 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,368 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,368 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,368 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:57]: =======================================
[2018-07-21 00:52:18,368 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2d93f690f0>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,480 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:73]: training and evaluate autoencoder
[2018-07-21 00:56:27,704 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:85]: trained and evaluated!
[2018-07-21 00:56:27,705 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:88]: Training history: 
{'val_loss': [0.009363775353403664, 0.00871937936606575, 0.00816643188318367, 0.007717011747139039, 0.0073513289157455895, 0.007055326994201829, 0.006805950637635711, 0.006594188485530064, 0.0064200067713662285, 0.006276270200952597, 0.006157380350937643, 0.006058405573250166, 0.005975470140758451, 0.005905614382026389, 0.005846558517452298, 0.005796384003878636, 0.005753327839457125, 0.005714148475190584, 0.005679591887968345, 0.005649546570394795, 0.0056222795978741625, 0.005593695176815979, 0.005568222416659289, 0.005546277550910625, 0.0055270436946686, 0.005508885098684912, 0.0054929744758058265, 0.005478363335683657, 0.005464138023234227, 0.005448542782767802, 0.005433881194979358, 0.005421016289989811, 0.005409585409214154, 0.005399261956205485, 0.0053898431945151315, 0.005381175425627194, 0.005373149659130031, 0.005365630650026221, 0.0053585425623545735, 0.005351660309293715, 0.005344822705038459, 0.005337875012875847, 0.005330922772857343, 0.005322868824867653, 0.005314175727069022, 0.005305040574066809, 0.005295773698133373, 0.00528757784341745, 0.005280274372083744, 0.005273616245770824, 0.005267350984075323, 0.005261377765424344, 0.005255648139309725, 0.0052499800027327225, 0.005244240489573064, 0.005238480271086321, 0.005232664973391867, 0.0052265140650850726, 0.005220496391012268, 0.0052146625385723405, 0.005208959882050062, 0.005203328365429234, 0.005197761874702081, 0.005192241249814799, 0.005186743777329482, 0.005181260518979545, 0.005175761840412669, 0.0051702409756781646, 0.005164686701329304, 0.005159071496373281, 0.005153301550939307, 0.005146865110802617, 0.00513921187855495, 0.005130936261588206, 0.005122644095419769, 0.005114652583692517, 0.005106962079802465, 0.005099408545619297, 0.005091990850789172, 0.005084669527480326, 0.005077424589137231, 0.005070266999422036, 0.005063189465627184, 0.005056177781489553, 0.005049215068113783, 0.005042286046470205, 0.005035393153194397, 0.005028507667715164, 0.005021612993254983, 0.005014688966218046, 0.005007735822429879, 0.005000743451940689, 0.004993707301418233, 0.004986641425755763, 0.00497953341484894, 0.00497238187522219, 0.004965145244252502, 0.004957816555075422, 0.00495040504989522, 0.004942896024870609, 0.004935273399969473], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009745711825831003, 0.009034353187663234, 0.008438175563347607, 0.007940292166806853, 0.00753592463368894, 0.00720839927788507, 0.006939743102093873, 0.006709648148999546, 0.006518587776018155, 0.00636139082947223, 0.006231615174382493, 0.006124000055883485, 0.006034228314977215, 0.00595884655497221, 0.005895263128514409, 0.005841432939652443, 0.005795541057886486, 0.005755238059237809, 0.005718608174474876, 0.0056868144565932815, 0.005658755573094608, 0.005631258479216973, 0.005604307313897909, 0.00558098572784971, 0.005560768501037679, 0.005542285232017659, 0.005525453376825073, 0.005510497566646808, 0.005496572197966046, 0.005481889325088777, 0.005466857445906979, 0.005453387954825271, 0.005441484371253017, 0.005430851207639804, 0.005421200144715444, 0.005412365075205826, 0.005404198757720657, 0.005396604520130761, 0.005389466236902297, 0.005382633643418942, 0.005375921855859776, 0.00536914417954333, 0.005362315389827375, 0.005355050812707557, 0.005346590124584604, 0.00533773191107456, 0.005328361465118627, 0.0053196084959178935, 0.005311888386772625, 0.005304975368206441, 0.005298582660026297, 0.005292499373797604, 0.005286712291472943, 0.005281077238213355, 0.005275441805142884, 0.005269738031434412, 0.005264016468001536, 0.005258030559510044, 0.005251954804796817, 0.0052460822992610266, 0.005240368091984733, 0.005234757689565943, 0.005229221459096786, 0.005223739973750783, 0.005218290314670482, 0.005212851633753651, 0.005207423225620894, 0.0052019722958745705, 0.0051964775972252126, 0.00519095163994023, 0.005185339192772835, 0.005179372292429911, 0.005172336775109005, 0.005164409596786201, 0.005156111863821405, 0.005148022520084154, 0.005140258467762956, 0.005132715559113102, 0.00512530268610623, 0.00511801502608724, 0.00511080160843579, 0.005103680761070307, 0.005096643102147591, 0.005089680084036609, 0.005082774222033388, 0.005075924575355805, 0.0050691035387545325, 0.005062307192832762, 0.005055505629126826, 0.005048686256148657, 0.005041828412129127, 0.005034940337335385, 0.005028017676316866, 0.005021051521322376, 0.0050140395168385594, 0.005006977812457581, 0.004999870297854406, 0.004992675927390024, 0.0049853886490681095, 0.004978008885681904, 0.004970523231307634], 'acc': [0.31508530741661506, 0.5938382227025443, 0.5938382226476732, 0.5938382227244927, 0.593838222687912, 0.5938382227025443, 0.5938382226366989, 0.5938382226659635, 0.593838222687912, 0.593838222687912, 0.593838222687912, 0.5938382226659635, 0.5938382226366989, 0.5938382226366989, 0.5938382226842539, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226842539, 0.593838222687912, 0.593838222687912, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226366989, 0.5938382227025443, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382227025443, 0.5938382226659635, 0.5938382226842539, 0.5938382226842539, 0.5938382227025443, 0.5938382227244927, 0.5938382226366989, 0.5938382226366989, 0.5938382226513312, 0.5938382226842539, 0.5938382226513312, 0.5938382226476732, 0.5938382227025443, 0.593838222687912, 0.5938382226513312, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.5938382227244927, 0.5938382227025443, 0.5938382227025443, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226476732, 0.5938382226001182, 0.5938382227025443, 0.5938382226366989, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226842539, 0.5938382226513312, 0.5938382227025443, 0.5938382226842539, 0.5938382227025443, 0.593838222687912, 0.5938382226513312, 0.5938382226732797, 0.5938382226001182, 0.593838222687912, 0.5938382226659635, 0.5938382227244927, 0.5938382227025443, 0.593838222687912, 0.5938382227025443, 0.5938382227025443, 0.5938382226842539, 0.5938382226366989, 0.5938382226659635, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226842539, 0.593838222687912, 0.5938382226659635, 0.5938382226366989, 0.593838222687912, 0.5938382226001182, 0.593838222687912]}
[2018-07-21 00:56:27,705 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:92]: done!
[2018-07-21 00:56:27,705 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:152]: >> Executing classifier part ... 
[2018-07-21 00:56:27,705 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:97]: =======================================
[2018-07-21 00:56:27,705 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2d93f69668>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 00:56:27,762 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:110]: training ... 
[2018-07-21 01:05:27,914 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:122]: trained!
[2018-07-21 01:05:27,915 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:125]: Training history: 
{'val_loss': [0.009363775353403664, 0.00871937936606575, 0.00816643188318367, 0.007717011747139039, 0.0073513289157455895, 0.007055326994201829, 0.006805950637635711, 0.006594188485530064, 0.0064200067713662285, 0.006276270200952597, 0.006157380350937643, 0.006058405573250166, 0.005975470140758451, 0.005905614382026389, 0.005846558517452298, 0.005796384003878636, 0.005753327839457125, 0.005714148475190584, 0.005679591887968345, 0.005649546570394795, 0.0056222795978741625, 0.005593695176815979, 0.005568222416659289, 0.005546277550910625, 0.0055270436946686, 0.005508885098684912, 0.0054929744758058265, 0.005478363335683657, 0.005464138023234227, 0.005448542782767802, 0.005433881194979358, 0.005421016289989811, 0.005409585409214154, 0.005399261956205485, 0.0053898431945151315, 0.005381175425627194, 0.005373149659130031, 0.005365630650026221, 0.0053585425623545735, 0.005351660309293715, 0.005344822705038459, 0.005337875012875847, 0.005330922772857343, 0.005322868824867653, 0.005314175727069022, 0.005305040574066809, 0.005295773698133373, 0.00528757784341745, 0.005280274372083744, 0.005273616245770824, 0.005267350984075323, 0.005261377765424344, 0.005255648139309725, 0.0052499800027327225, 0.005244240489573064, 0.005238480271086321, 0.005232664973391867, 0.0052265140650850726, 0.005220496391012268, 0.0052146625385723405, 0.005208959882050062, 0.005203328365429234, 0.005197761874702081, 0.005192241249814799, 0.005186743777329482, 0.005181260518979545, 0.005175761840412669, 0.0051702409756781646, 0.005164686701329304, 0.005159071496373281, 0.005153301550939307, 0.005146865110802617, 0.00513921187855495, 0.005130936261588206, 0.005122644095419769, 0.005114652583692517, 0.005106962079802465, 0.005099408545619297, 0.005091990850789172, 0.005084669527480326, 0.005077424589137231, 0.005070266999422036, 0.005063189465627184, 0.005056177781489553, 0.005049215068113783, 0.005042286046470205, 0.005035393153194397, 0.005028507667715164, 0.005021612993254983, 0.005014688966218046, 0.005007735822429879, 0.005000743451940689, 0.004993707301418233, 0.004986641425755763, 0.00497953341484894, 0.00497238187522219, 0.004965145244252502, 0.004957816555075422, 0.00495040504989522, 0.004942896024870609, 0.004935273399969473], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009745711825831003, 0.009034353187663234, 0.008438175563347607, 0.007940292166806853, 0.00753592463368894, 0.00720839927788507, 0.006939743102093873, 0.006709648148999546, 0.006518587776018155, 0.00636139082947223, 0.006231615174382493, 0.006124000055883485, 0.006034228314977215, 0.00595884655497221, 0.005895263128514409, 0.005841432939652443, 0.005795541057886486, 0.005755238059237809, 0.005718608174474876, 0.0056868144565932815, 0.005658755573094608, 0.005631258479216973, 0.005604307313897909, 0.00558098572784971, 0.005560768501037679, 0.005542285232017659, 0.005525453376825073, 0.005510497566646808, 0.005496572197966046, 0.005481889325088777, 0.005466857445906979, 0.005453387954825271, 0.005441484371253017, 0.005430851207639804, 0.005421200144715444, 0.005412365075205826, 0.005404198757720657, 0.005396604520130761, 0.005389466236902297, 0.005382633643418942, 0.005375921855859776, 0.00536914417954333, 0.005362315389827375, 0.005355050812707557, 0.005346590124584604, 0.00533773191107456, 0.005328361465118627, 0.0053196084959178935, 0.005311888386772625, 0.005304975368206441, 0.005298582660026297, 0.005292499373797604, 0.005286712291472943, 0.005281077238213355, 0.005275441805142884, 0.005269738031434412, 0.005264016468001536, 0.005258030559510044, 0.005251954804796817, 0.0052460822992610266, 0.005240368091984733, 0.005234757689565943, 0.005229221459096786, 0.005223739973750783, 0.005218290314670482, 0.005212851633753651, 0.005207423225620894, 0.0052019722958745705, 0.0051964775972252126, 0.00519095163994023, 0.005185339192772835, 0.005179372292429911, 0.005172336775109005, 0.005164409596786201, 0.005156111863821405, 0.005148022520084154, 0.005140258467762956, 0.005132715559113102, 0.00512530268610623, 0.00511801502608724, 0.00511080160843579, 0.005103680761070307, 0.005096643102147591, 0.005089680084036609, 0.005082774222033388, 0.005075924575355805, 0.0050691035387545325, 0.005062307192832762, 0.005055505629126826, 0.005048686256148657, 0.005041828412129127, 0.005034940337335385, 0.005028017676316866, 0.005021051521322376, 0.0050140395168385594, 0.005006977812457581, 0.004999870297854406, 0.004992675927390024, 0.0049853886490681095, 0.004978008885681904, 0.004970523231307634], 'acc': [0.31508530741661506, 0.5938382227025443, 0.5938382226476732, 0.5938382227244927, 0.593838222687912, 0.5938382227025443, 0.5938382226366989, 0.5938382226659635, 0.593838222687912, 0.593838222687912, 0.593838222687912, 0.5938382226659635, 0.5938382226366989, 0.5938382226366989, 0.5938382226842539, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226842539, 0.593838222687912, 0.593838222687912, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226366989, 0.5938382227025443, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382227025443, 0.5938382226659635, 0.5938382226842539, 0.5938382226842539, 0.5938382227025443, 0.5938382227244927, 0.5938382226366989, 0.5938382226366989, 0.5938382226513312, 0.5938382226842539, 0.5938382226513312, 0.5938382226476732, 0.5938382227025443, 0.593838222687912, 0.5938382226513312, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.5938382227244927, 0.5938382227025443, 0.5938382227025443, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226476732, 0.5938382226001182, 0.5938382227025443, 0.5938382226366989, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226842539, 0.5938382226513312, 0.5938382227025443, 0.5938382226842539, 0.5938382227025443, 0.593838222687912, 0.5938382226513312, 0.5938382226732797, 0.5938382226001182, 0.593838222687912, 0.5938382226659635, 0.5938382227244927, 0.5938382227025443, 0.593838222687912, 0.5938382227025443, 0.5938382227025443, 0.5938382226842539, 0.5938382226366989, 0.5938382226659635, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226842539, 0.593838222687912, 0.5938382226659635, 0.5938382226366989, 0.593838222687912, 0.5938382226001182, 0.593838222687912]}
[2018-07-21 01:05:27,915 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:129]: evaluating model ... 
[2018-07-21 01:05:28,049 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:133]: evaluated! 
[2018-07-21 01:05:28,049 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:135]: generating reports ... 
[2018-07-21 01:05:29,083 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:138]: done!
[2018-07-21 01:05:29,084 AE_UNIGRAMA_4L_FULLDS_OVER_04.py:154]: >> experiment AE_UNIGRAMA_4L_FULLDS_OVER_04 finished!
