[2017-11-14 08:06:13,310 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_OVER_05
[2017-11-14 08:06:13,310 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:148]: >> Printing header log
[2017-11-14 08:06:13,310 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_OVER_05
	layers = 96,172,156,139,123
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc054ea1eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc054ea6400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 08:06:13,310 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:150]: >> Loading dataset... 
[2017-11-14 08:06:15,493 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-14 08:06:15,493 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:152]: >> Executing autoencoder part ... 
[2017-11-14 08:06:15,493 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:59]: =======================================
[2017-11-14 08:06:15,493 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc054ea1eb8>, 'discard_decoder_function': True}
[2017-11-14 08:06:15,590 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:75]: training and evaluate autoencoder
[2017-11-14 08:10:15,901 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:87]: trained and evaluated!
[2017-11-14 08:10:15,902 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:90]: Training history: 
{'val_loss': [0.0096534028466556798, 0.0093431264423559542, 0.0090982401545013376, 0.0088957090355874808, 0.0087402313458228402, 0.0084634472758744368, 0.0078002048094333509, 0.0073008989600019062, 0.0069212662169038262, 0.006627462185489391, 0.0063955285439239685, 0.0062089302658881393, 0.006055519173215446, 0.0059211735202232977, 0.0058069349405551187, 0.0057121215915962508, 0.0056326230923730422, 0.005564252050844723, 0.0055069707279962596, 0.0054586843166634499, 0.0054176108351505084, 0.0053825044664097361, 0.0053522518396313216, 0.0053260104469913892, 0.0053031454108366577, 0.0052829988037935297, 0.0052650644621397317, 0.0052489989119020898, 0.0052345096441180896, 0.0052212321639981, 0.0052086379873959596, 0.0051954545060809987, 0.0051826320362517945, 0.0051715254020534571, 0.0051617056448135809, 0.0051527763529482492, 0.0051444078776273477, 0.0051356529540086942, 0.0051265506539151526, 0.0051180732374698015, 0.0051103970558731343, 0.0051033931623635015, 0.0050969866547837597, 0.0050909897645895026, 0.0050853284559144512, 0.0050799953235290711, 0.0050749615494857341, 0.0050701045840040801, 0.0050654407989888153, 0.0050609020530994059, 0.0050564501872672968, 0.0050520653809389615, 0.0050477268644401486, 0.0050434047397833973, 0.0050391103455044526, 0.0050348377161416628, 0.0050305468532558326, 0.0050262290869217581, 0.0050219027879991893, 0.005017565301739608, 0.0050131668069203772, 0.0050084773225703635, 0.0050035825829052097, 0.0049986103997120513, 0.0049935290709723886, 0.0049883539157617356, 0.00498308405384164, 0.0049777410342400838, 0.0049723671582034244, 0.0049669878872728212, 0.0049615950366938728, 0.0049562057134007725, 0.004950823288346555, 0.0049454533883145583, 0.0049401363367314061, 0.0049348671769826663, 0.0049296160838992846, 0.0049243837645299967, 0.0049191122917915005, 0.0049138192582166302, 0.0049085157826023974, 0.0049031859958419098, 0.0048978182633339987, 0.0048924221667313575, 0.0048869765860441684, 0.0048814915295673873, 0.0048759493829483268, 0.0048703325563923304, 0.004864617711558078, 0.0048588505234687055, 0.0048529240500403709, 0.0048461628891082699, 0.0048370826314280456, 0.0048271822088522282, 0.0048178401564305069, 0.0048090457600171417, 0.0048006731784570166, 0.0047925959326852573, 0.0047847088419506103, 0.0047769808325607115, 0.0047693783407931605], 'val_acc': [0.0029400955531054761, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.47739801543550164, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098389484304022504, 0.0094921126689867501, 0.0092165976208573516, 0.008993324943136493, 0.0088150495325142117, 0.0086575748583632723, 0.008121492585908734, 0.0075448043791322755, 0.0071111505432643121, 0.0067783266847089669, 0.0065185289703765881, 0.0063116401771173324, 0.0061438689321006087, 0.0060018007896156514, 0.0058779223991014505, 0.0057745479278557251, 0.0056883816342543419, 0.0056152732048183225, 0.0055530897320634686, 0.0055009843461509052, 0.00545691447754323, 0.0054193375973625134, 0.0053871402518561508, 0.005359346436742911, 0.0053351892201142824, 0.0053140807569797884, 0.0052953910038453147, 0.0052787187826805202, 0.005263733241626609, 0.0052501456149569919, 0.0052374556673341101, 0.0052249863403924183, 0.0052118586857346017, 0.0052000536474536329, 0.0051897929110729475, 0.0051805668910484062, 0.0051720334005812907, 0.0051636042765430754, 0.0051546402214575349, 0.0051457953053007932, 0.0051377476184437196, 0.0051304207177019032, 0.0051237616015384867, 0.0051175820820350887, 0.0051117638522459345, 0.0051062707441725313, 0.0051010905707725299, 0.0050961528131968081, 0.005091392001080209, 0.0050867964995779643, 0.0050823285934980898, 0.005077934773517442, 0.0050735904534402344, 0.0050692887642337725, 0.005064987091831584, 0.0050607052089481162, 0.0050564375229324356, 0.005052120668240412, 0.0050478027589944728, 0.0050434719168021957, 0.0050391151954567266, 0.0050345949785299418, 0.0050297840000546913, 0.0050248565017167405, 0.0050198270423044943, 0.0050146933584423155, 0.0050094602516370709, 0.0050041291917482991, 0.0049987428790929803, 0.0049933527516388843, 0.0049879628834221474, 0.0049825550485788732, 0.0049771618659191844, 0.004971786109462876, 0.0049664635285305309, 0.004961188392407531, 0.0049559370874883036, 0.0049507027889513977, 0.0049454633512789007, 0.0049402105173993885, 0.0049349382480626328, 0.004929637716337993, 0.0049243170361176212, 0.0049189536729275386, 0.0049135555392372417, 0.0049081159393724117, 0.0049026327056103111, 0.0048970725203630961, 0.0048914445620793787, 0.0048857410542385241, 0.0048799406408662769, 0.004873772982665241, 0.004865985678659087, 0.0048564798121477869, 0.0048470726606280722, 0.004838262505054737, 0.004829912525945201, 0.0048218950205355078, 0.0048141143925986866, 0.0048064875041047891, 0.0047989871841149457], 'acc': [0.0015956793911869401, 0.0094513317785687983, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.074628697672811509, 0.5861053148837152, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822262206665, 0.59383822272449271, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822262938279, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182]}
[2017-11-14 08:10:15,903 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:94]: done!
[2017-11-14 08:10:15,903 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:154]: >> Executing classifier part ... 
[2017-11-14 08:10:15,903 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:99]: =======================================
[2017-11-14 08:10:15,903 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc054ea6400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 08:10:15,963 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:112]: training ... 
[2017-11-14 08:15:52,787 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:124]: trained!
[2017-11-14 08:15:52,788 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:127]: Training history: 
{'val_loss': [0.0096534028466556798, 0.0093431264423559542, 0.0090982401545013376, 0.0088957090355874808, 0.0087402313458228402, 0.0084634472758744368, 0.0078002048094333509, 0.0073008989600019062, 0.0069212662169038262, 0.006627462185489391, 0.0063955285439239685, 0.0062089302658881393, 0.006055519173215446, 0.0059211735202232977, 0.0058069349405551187, 0.0057121215915962508, 0.0056326230923730422, 0.005564252050844723, 0.0055069707279962596, 0.0054586843166634499, 0.0054176108351505084, 0.0053825044664097361, 0.0053522518396313216, 0.0053260104469913892, 0.0053031454108366577, 0.0052829988037935297, 0.0052650644621397317, 0.0052489989119020898, 0.0052345096441180896, 0.0052212321639981, 0.0052086379873959596, 0.0051954545060809987, 0.0051826320362517945, 0.0051715254020534571, 0.0051617056448135809, 0.0051527763529482492, 0.0051444078776273477, 0.0051356529540086942, 0.0051265506539151526, 0.0051180732374698015, 0.0051103970558731343, 0.0051033931623635015, 0.0050969866547837597, 0.0050909897645895026, 0.0050853284559144512, 0.0050799953235290711, 0.0050749615494857341, 0.0050701045840040801, 0.0050654407989888153, 0.0050609020530994059, 0.0050564501872672968, 0.0050520653809389615, 0.0050477268644401486, 0.0050434047397833973, 0.0050391103455044526, 0.0050348377161416628, 0.0050305468532558326, 0.0050262290869217581, 0.0050219027879991893, 0.005017565301739608, 0.0050131668069203772, 0.0050084773225703635, 0.0050035825829052097, 0.0049986103997120513, 0.0049935290709723886, 0.0049883539157617356, 0.00498308405384164, 0.0049777410342400838, 0.0049723671582034244, 0.0049669878872728212, 0.0049615950366938728, 0.0049562057134007725, 0.004950823288346555, 0.0049454533883145583, 0.0049401363367314061, 0.0049348671769826663, 0.0049296160838992846, 0.0049243837645299967, 0.0049191122917915005, 0.0049138192582166302, 0.0049085157826023974, 0.0049031859958419098, 0.0048978182633339987, 0.0048924221667313575, 0.0048869765860441684, 0.0048814915295673873, 0.0048759493829483268, 0.0048703325563923304, 0.004864617711558078, 0.0048588505234687055, 0.0048529240500403709, 0.0048461628891082699, 0.0048370826314280456, 0.0048271822088522282, 0.0048178401564305069, 0.0048090457600171417, 0.0048006731784570166, 0.0047925959326852573, 0.0047847088419506103, 0.0047769808325607115, 0.0047693783407931605], 'val_acc': [0.0029400955531054761, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.47739801543550164, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098389484304022504, 0.0094921126689867501, 0.0092165976208573516, 0.008993324943136493, 0.0088150495325142117, 0.0086575748583632723, 0.008121492585908734, 0.0075448043791322755, 0.0071111505432643121, 0.0067783266847089669, 0.0065185289703765881, 0.0063116401771173324, 0.0061438689321006087, 0.0060018007896156514, 0.0058779223991014505, 0.0057745479278557251, 0.0056883816342543419, 0.0056152732048183225, 0.0055530897320634686, 0.0055009843461509052, 0.00545691447754323, 0.0054193375973625134, 0.0053871402518561508, 0.005359346436742911, 0.0053351892201142824, 0.0053140807569797884, 0.0052953910038453147, 0.0052787187826805202, 0.005263733241626609, 0.0052501456149569919, 0.0052374556673341101, 0.0052249863403924183, 0.0052118586857346017, 0.0052000536474536329, 0.0051897929110729475, 0.0051805668910484062, 0.0051720334005812907, 0.0051636042765430754, 0.0051546402214575349, 0.0051457953053007932, 0.0051377476184437196, 0.0051304207177019032, 0.0051237616015384867, 0.0051175820820350887, 0.0051117638522459345, 0.0051062707441725313, 0.0051010905707725299, 0.0050961528131968081, 0.005091392001080209, 0.0050867964995779643, 0.0050823285934980898, 0.005077934773517442, 0.0050735904534402344, 0.0050692887642337725, 0.005064987091831584, 0.0050607052089481162, 0.0050564375229324356, 0.005052120668240412, 0.0050478027589944728, 0.0050434719168021957, 0.0050391151954567266, 0.0050345949785299418, 0.0050297840000546913, 0.0050248565017167405, 0.0050198270423044943, 0.0050146933584423155, 0.0050094602516370709, 0.0050041291917482991, 0.0049987428790929803, 0.0049933527516388843, 0.0049879628834221474, 0.0049825550485788732, 0.0049771618659191844, 0.004971786109462876, 0.0049664635285305309, 0.004961188392407531, 0.0049559370874883036, 0.0049507027889513977, 0.0049454633512789007, 0.0049402105173993885, 0.0049349382480626328, 0.004929637716337993, 0.0049243170361176212, 0.0049189536729275386, 0.0049135555392372417, 0.0049081159393724117, 0.0049026327056103111, 0.0048970725203630961, 0.0048914445620793787, 0.0048857410542385241, 0.0048799406408662769, 0.004873772982665241, 0.004865985678659087, 0.0048564798121477869, 0.0048470726606280722, 0.004838262505054737, 0.004829912525945201, 0.0048218950205355078, 0.0048141143925986866, 0.0048064875041047891, 0.0047989871841149457], 'acc': [0.0015956793911869401, 0.0094513317785687983, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.074628697672811509, 0.5861053148837152, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822262206665, 0.59383822272449271, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822262938279, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822262938279, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182]}
[2017-11-14 08:15:52,788 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:131]: evaluating model ... 
[2017-11-14 08:15:52,969 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:135]: evaluated! 
[2017-11-14 08:15:52,969 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:137]: generating reports ... 
[2017-11-14 08:15:53,816 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:140]: done!
[2017-11-14 08:15:53,816 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:156]: >> experiment AE_UNIGRAMA_4L_FULLDS_OVER_05 finished!
[2017-11-18 16:24:06,279 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_OVER_05 was already executed!
[2017-11-18 19:56:07,111 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_OVER_05
[2017-11-18 19:56:07,111 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:148]: >> Printing header log
[2017-11-18 19:56:07,111 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_OVER_05
	layers = 96,172,156,139,123
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f271f63de48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f271f641390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:56:07,111 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:150]: >> Loading dataset... 
[2017-11-18 19:56:09,376 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:56:09,376 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:152]: >> Executing autoencoder part ... 
[2017-11-18 19:56:09,376 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:59]: =======================================
[2017-11-18 19:56:09,376 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f271f63de48>, 'discard_decoder_function': True}
[2017-11-18 19:56:09,470 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:75]: training and evaluate autoencoder
[2017-11-18 19:59:03,506 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:87]: trained and evaluated!
[2017-11-18 19:59:03,507 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:90]: Training history: 
{'val_loss': [0.009817895534948386, 0.0095254262390408566, 0.009286784382454177, 0.0090978581719141551, 0.0089485775720422565, 0.0088288332977411246, 0.0087363468640535603, 0.008664825388347782, 0.0086091782651959384, 0.0085654306341508921, 0.0085306015041564723, 0.0085025084054714314, 0.0084794837593325841, 0.0084601949215159841, 0.0084422225665160069, 0.0084256455230361307, 0.0084118317879082003, 0.0084001865831451229, 0.0083902068412186736, 0.0083814641099336923, 0.0083734335731037272, 0.0083658035546103106, 0.0083580671592955423, 0.0083493682463783112, 0.0083415715663239642, 0.0083343353422303187, 0.0083262636704464158, 0.0083185343899432451, 0.0083118337882530022, 0.008305191381730739, 0.0082983877479027891, 0.0082913187244487395, 0.0082848412479324968, 0.0082792087127096896, 0.0082742334649826572, 0.0082698098398561598, 0.0082658348017697683, 0.0082622159358684919, 0.0082588874714744093, 0.0082557774811178077, 0.0082528433556785172, 0.0082500410693718516, 0.0082473490255084245, 0.0082447595123539778, 0.0082422693108387488, 0.0082398597370095215, 0.0082375154796630445, 0.0082352309433338794, 0.0082329771129256313, 0.0082307346144643873, 0.0082285092213971126, 0.0082263300535554886, 0.0082241810419456749, 0.0082220641097949954, 0.0082199606104579014, 0.0082178683150580193, 0.0082158037283016627, 0.0082137576728451341, 0.0082117223301652557, 0.008209683713309799, 0.0082076358835143411, 0.0082055863457807538, 0.0082035579169987098, 0.0082015400616885416, 0.0081995281359014457, 0.0081975199121301426, 0.0081954846796619026, 0.0081934028393077264, 0.0081913075486840861, 0.0081892025378730877, 0.0081871045857410535, 0.0081849963219753526, 0.0081828904917647799, 0.0081807783620349191, 0.0081786551091440757, 0.008176497288817695, 0.0081743371396714691, 0.0081721600716696072, 0.0081699710005250139, 0.0081677692769473852, 0.0081655547363038063, 0.0081633453424068466, 0.0081611335882010028, 0.0081589207746627923, 0.0081567084697410277, 0.0081544882747611996, 0.0081522689060263883, 0.0081500392961659802, 0.0081477981383848257, 0.0081455371137578361, 0.0081432619433643317, 0.0081409456284332691, 0.0081385593345879581, 0.0081361037840226788, 0.0081336289142470326, 0.0081311291465669244, 0.0081286074570388715, 0.0081260753723627413, 0.0081235419213361096, 0.0081209943933396693, 0.0081183989321794506], 'val_acc': [0.012862918044836457, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.0099846262422373013, 0.009666107981693815, 0.0094005791137752402, 0.009187118340513634, 0.0090190902446299816, 0.0088849855442621143, 0.0087792634773312186, 0.0086977544922083958, 0.0086345729866555837, 0.0085852248591878552, 0.0085461868946713152, 0.0085149347658446412, 0.0084895396898237128, 0.0084685642161119994, 0.0084503102770738907, 0.0084328217058322157, 0.0084177346652499641, 0.0084051242826626068, 0.0083944216764739975, 0.0083851813188030068, 0.0083769250331222241, 0.0083691979240824096, 0.0083617541799098864, 0.0083534396208371862, 0.0083453031709481481, 0.0083379429343567023, 0.0083306930473158233, 0.0083227857703401797, 0.0083159243895354357, 0.0083095419968359386, 0.0083031322879320545, 0.0082963514185178042, 0.008289707273819176, 0.0082838458527024501, 0.0082787084369768723, 0.0082741531108351581, 0.0082700737664340909, 0.0082663839940830836, 0.0082629991654588775, 0.0082598578172725697, 0.0082569016851059517, 0.0082540918983874823, 0.008251392924194469, 0.0082488022639486003, 0.0082463132908216375, 0.008243903108704773, 0.0082415641106919364, 0.0082392858658445478, 0.0082370498722570719, 0.008234835967373063, 0.0082326394081576638, 0.0082304671928478609, 0.0082283295958281311, 0.0082262182893805148, 0.008224125888884045, 0.0082220410810614555, 0.0082199702545089626, 0.0082179133629290777, 0.0082158731295286745, 0.0082138418193119598, 0.0082117873446324735, 0.0082097260774826215, 0.0082076822765463266, 0.0082056552126667133, 0.0082036448166833351, 0.0082016328613319419, 0.0081996068852146897, 0.0081975484006010825, 0.0081954673541922637, 0.0081933767432366376, 0.008191288035850855, 0.0081892008024399433, 0.0081871032632079843, 0.0081850025170461319, 0.0081829005931561803, 0.0081807671926894619, 0.0081786193512357261, 0.0081764617725626973, 0.0081742955770696089, 0.0081721154754683945, 0.0081699247023531291, 0.008167731382590181, 0.0081655399898887676, 0.0081633472617620023, 0.0081611535904810833, 0.0081589505639065776, 0.0081567399911843114, 0.0081545277564393469, 0.0081522976416041407, 0.0081500533452193262, 0.0081477870548980081, 0.0081454952168220664, 0.0081431497800859756, 0.0081407366197259502, 0.0081382836974819798, 0.0081358054581706293, 0.0081333100541509766, 0.0081307974179772938, 0.0081282799548617057, 0.0081257637967637342, 0.0081232184336381373], 'acc': [0.0085921197986989079, 0.010678777464097214, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889]}
[2017-11-18 19:59:03,508 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:94]: done!
[2017-11-18 19:59:03,508 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:154]: >> Executing classifier part ... 
[2017-11-18 19:59:03,508 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:99]: =======================================
[2017-11-18 19:59:03,508 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f271f641390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:59:03,545 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:112]: training ... 
[2017-11-18 20:06:20,587 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:124]: trained!
[2017-11-18 20:06:20,588 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:127]: Training history: 
{'val_loss': [0.009817895534948386, 0.0095254262390408566, 0.009286784382454177, 0.0090978581719141551, 0.0089485775720422565, 0.0088288332977411246, 0.0087363468640535603, 0.008664825388347782, 0.0086091782651959384, 0.0085654306341508921, 0.0085306015041564723, 0.0085025084054714314, 0.0084794837593325841, 0.0084601949215159841, 0.0084422225665160069, 0.0084256455230361307, 0.0084118317879082003, 0.0084001865831451229, 0.0083902068412186736, 0.0083814641099336923, 0.0083734335731037272, 0.0083658035546103106, 0.0083580671592955423, 0.0083493682463783112, 0.0083415715663239642, 0.0083343353422303187, 0.0083262636704464158, 0.0083185343899432451, 0.0083118337882530022, 0.008305191381730739, 0.0082983877479027891, 0.0082913187244487395, 0.0082848412479324968, 0.0082792087127096896, 0.0082742334649826572, 0.0082698098398561598, 0.0082658348017697683, 0.0082622159358684919, 0.0082588874714744093, 0.0082557774811178077, 0.0082528433556785172, 0.0082500410693718516, 0.0082473490255084245, 0.0082447595123539778, 0.0082422693108387488, 0.0082398597370095215, 0.0082375154796630445, 0.0082352309433338794, 0.0082329771129256313, 0.0082307346144643873, 0.0082285092213971126, 0.0082263300535554886, 0.0082241810419456749, 0.0082220641097949954, 0.0082199606104579014, 0.0082178683150580193, 0.0082158037283016627, 0.0082137576728451341, 0.0082117223301652557, 0.008209683713309799, 0.0082076358835143411, 0.0082055863457807538, 0.0082035579169987098, 0.0082015400616885416, 0.0081995281359014457, 0.0081975199121301426, 0.0081954846796619026, 0.0081934028393077264, 0.0081913075486840861, 0.0081892025378730877, 0.0081871045857410535, 0.0081849963219753526, 0.0081828904917647799, 0.0081807783620349191, 0.0081786551091440757, 0.008176497288817695, 0.0081743371396714691, 0.0081721600716696072, 0.0081699710005250139, 0.0081677692769473852, 0.0081655547363038063, 0.0081633453424068466, 0.0081611335882010028, 0.0081589207746627923, 0.0081567084697410277, 0.0081544882747611996, 0.0081522689060263883, 0.0081500392961659802, 0.0081477981383848257, 0.0081455371137578361, 0.0081432619433643317, 0.0081409456284332691, 0.0081385593345879581, 0.0081361037840226788, 0.0081336289142470326, 0.0081311291465669244, 0.0081286074570388715, 0.0081260753723627413, 0.0081235419213361096, 0.0081209943933396693, 0.0081183989321794506], 'val_acc': [0.012862918044836457, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.0099846262422373013, 0.009666107981693815, 0.0094005791137752402, 0.009187118340513634, 0.0090190902446299816, 0.0088849855442621143, 0.0087792634773312186, 0.0086977544922083958, 0.0086345729866555837, 0.0085852248591878552, 0.0085461868946713152, 0.0085149347658446412, 0.0084895396898237128, 0.0084685642161119994, 0.0084503102770738907, 0.0084328217058322157, 0.0084177346652499641, 0.0084051242826626068, 0.0083944216764739975, 0.0083851813188030068, 0.0083769250331222241, 0.0083691979240824096, 0.0083617541799098864, 0.0083534396208371862, 0.0083453031709481481, 0.0083379429343567023, 0.0083306930473158233, 0.0083227857703401797, 0.0083159243895354357, 0.0083095419968359386, 0.0083031322879320545, 0.0082963514185178042, 0.008289707273819176, 0.0082838458527024501, 0.0082787084369768723, 0.0082741531108351581, 0.0082700737664340909, 0.0082663839940830836, 0.0082629991654588775, 0.0082598578172725697, 0.0082569016851059517, 0.0082540918983874823, 0.008251392924194469, 0.0082488022639486003, 0.0082463132908216375, 0.008243903108704773, 0.0082415641106919364, 0.0082392858658445478, 0.0082370498722570719, 0.008234835967373063, 0.0082326394081576638, 0.0082304671928478609, 0.0082283295958281311, 0.0082262182893805148, 0.008224125888884045, 0.0082220410810614555, 0.0082199702545089626, 0.0082179133629290777, 0.0082158731295286745, 0.0082138418193119598, 0.0082117873446324735, 0.0082097260774826215, 0.0082076822765463266, 0.0082056552126667133, 0.0082036448166833351, 0.0082016328613319419, 0.0081996068852146897, 0.0081975484006010825, 0.0081954673541922637, 0.0081933767432366376, 0.008191288035850855, 0.0081892008024399433, 0.0081871032632079843, 0.0081850025170461319, 0.0081829005931561803, 0.0081807671926894619, 0.0081786193512357261, 0.0081764617725626973, 0.0081742955770696089, 0.0081721154754683945, 0.0081699247023531291, 0.008167731382590181, 0.0081655399898887676, 0.0081633472617620023, 0.0081611535904810833, 0.0081589505639065776, 0.0081567399911843114, 0.0081545277564393469, 0.0081522976416041407, 0.0081500533452193262, 0.0081477870548980081, 0.0081454952168220664, 0.0081431497800859756, 0.0081407366197259502, 0.0081382836974819798, 0.0081358054581706293, 0.0081333100541509766, 0.0081307974179772938, 0.0081282799548617057, 0.0081257637967637342, 0.0081232184336381373], 'acc': [0.0085921197986989079, 0.010678777464097214, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889]}
[2017-11-18 20:06:20,588 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:131]: evaluating model ... 
[2017-11-18 20:06:20,756 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:135]: evaluated! 
[2017-11-18 20:06:20,756 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:137]: generating reports ... 
[2017-11-18 20:06:21,638 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:140]: done!
[2017-11-18 20:06:21,638 AE_UNIGRAMA_4L_FULLDS_OVER_05.py:156]: >> experiment AE_UNIGRAMA_4L_FULLDS_OVER_05 finished!
