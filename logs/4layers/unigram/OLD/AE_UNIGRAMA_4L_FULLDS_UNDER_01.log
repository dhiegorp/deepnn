[2017-11-13 16:17:20,720 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_UNDER_01
[2017-11-13 16:17:20,720 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:148]: >> Printing header log
[2017-11-13 16:17:20,721 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_UNDER_01
	layers = 96,28,26,24,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8adb849eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8adb84e400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 16:17:20,721 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:150]: >> Loading dataset... 
[2017-11-13 16:17:23,148 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 16:17:23,149 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:152]: >> Executing autoencoder part ... 
[2017-11-13 16:17:23,149 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:59]: =======================================
[2017-11-13 16:17:23,149 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8adb849eb8>, 'discard_decoder_function': True}
[2017-11-13 16:17:23,266 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:75]: training and evaluate autoencoder
[2017-11-13 16:19:55,775 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:87]: trained and evaluated!
[2017-11-13 16:19:55,777 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:90]: Training history: 
{'val_loss': [0.0095304292624967587, 0.0088896832279299655, 0.0083617467809029029, 0.007930083175007362, 0.0075808087771485301, 0.0072960315985164956, 0.0070617892094865546, 0.0068673940527073842, 0.0067047548010734483, 0.0065676351933535056, 0.0064511713561578319, 0.0063519460602277714, 0.0062670181714168088, 0.0061938219360777209, 0.0061305826396374349, 0.0060757217459512063, 0.0060279502530638041, 0.0059862673905216367, 0.0059497598589468821, 0.0059176682303250603, 0.0058894009512151946, 0.0058644258311769289, 0.0058423512856907618, 0.005822634808489836, 0.0058049853933576012, 0.0057889639363322611, 0.0057723754448751148, 0.005757473290321862, 0.0057442839432320187, 0.0057325538532594159, 0.0057220949925029102, 0.0057127722652813157, 0.0057044094304346408, 0.0056968823566283921, 0.0056901068061464243, 0.0056839622071992437, 0.0056783362596033249, 0.0056731983385562559, 0.0056684843166288053, 0.0056641759166582316, 0.0056602105519534774, 0.0056565319990053995, 0.0056531286565843627, 0.0056499656172074274, 0.0056470065202751567, 0.0056442166892527569, 0.0056415803988732176, 0.0056390672934456196, 0.0056366608102485201, 0.0056343592080578221, 0.0056321397827625366, 0.005629982503311752, 0.005627888317713812, 0.0056258366219541934, 0.0056238384442989196, 0.0056218917981147474, 0.0056199881037507574, 0.0056181191365778423, 0.0056162832026054633, 0.0056144894186807102, 0.005612725093437086, 0.0056109939985427675, 0.0056092904083833283, 0.0056075901162729504, 0.0056058720537337783, 0.0056040738689590308, 0.0056020511366982797, 0.0055997193627879546, 0.0055971293244168616, 0.0055944072750069469, 0.005590900754811395, 0.0055874122801458943, 0.0055842402538141588, 0.0055813027506619586, 0.0055785414803696497, 0.0055759211500558299, 0.0055733924805714133, 0.0055709702596143679, 0.005568640293157805, 0.0055663867103834721, 0.0055641986324271482, 0.0055620753631072418, 0.0055599981240034161, 0.0055579735026569906, 0.0055559913583136805, 0.0055540534475142633, 0.0055521540264183164, 0.0055502880996490872, 0.0055484398751964913, 0.0055466172635693549, 0.0055448129943078085, 0.0055430219293931739, 0.0055412483651112957, 0.0055394969858846618, 0.0055377527051261302, 0.0055360178051920977, 0.0055342863471470076, 0.0055325701634253441, 0.0055308576733338038, 0.0055291523407523142, 0.0055274573373459406], 'val_acc': [0.58838662256523333, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098909553259517845, 0.0092069280475681661, 0.0086268324548305648, 0.0081511552687251951, 0.0077652370865724596, 0.0074521432087379571, 0.007195835848439156, 0.0069842521241043325, 0.0068080747809626434, 0.0066601952755778234, 0.0065351657365242209, 0.0064287977057645275, 0.0063380170420335308, 0.0062601535086183584, 0.0061929330982064832, 0.0061347800093435817, 0.0060842701459580826, 0.0060402459058120925, 0.0060017908496590817, 0.0059680826611619347, 0.005938400616049693, 0.0059122488011126026, 0.0058891433188825483, 0.0058686681699025587, 0.0058503209720605189, 0.0058338494631993932, 0.0058178316716164646, 0.0058021956974828193, 0.0057883556931982291, 0.005776087350400771, 0.0057651542135248764, 0.0057553947590336316, 0.0057466923520065015, 0.0057388661796579418, 0.0057318227630708974, 0.0057254801812963874, 0.0057196916622063183, 0.0057143750653101599, 0.0057095279114631123, 0.0057050807444291628, 0.005701005716154374, 0.0056972497780041981, 0.0056937699386447839, 0.0056905440975982451, 0.0056875402510108549, 0.0056847223366253011, 0.0056820581519659149, 0.00567953343454822, 0.0056771190311291934, 0.0056748086355907336, 0.0056725869448980126, 0.0056704275255854307, 0.005668337759644715, 0.0056663043518088065, 0.0056643098249470874, 0.0056623718675010608, 0.0056604772140969855, 0.0056586206674130437, 0.0056567956674379912, 0.0056550068990776107, 0.0056532557522854044, 0.0056515336001244547, 0.0056498401548644396, 0.0056481540551297322, 0.0056464580781401168, 0.0056447185350418988, 0.0056428086443339976, 0.0056405947123573819, 0.0056380734926292442, 0.0056353974918218362, 0.0056323274568009516, 0.0056286851189138003, 0.0056253514874246872, 0.0056223003563544418, 0.0056194532624334629, 0.0056167637956870201, 0.0056141888179439183, 0.0056117019031118641, 0.0056093218494003188, 0.0056070279793218698, 0.0056048090177232305, 0.0056026549463422002, 0.0056005523410217993, 0.0055985058164785316, 0.0055965074001133215, 0.00559455049476262, 0.0055926335188813394, 0.005590755568639613, 0.0055889013528341901, 0.00558706836168391, 0.0055852573377776328, 0.0055834655679681882, 0.0055816875139899063, 0.0055799265612752197, 0.005578183523688259, 0.0055764459647518099, 0.0055747197449849302, 0.0055730042011903789, 0.0055712980073737784, 0.0055696028987764473, 0.0055679159722600386], 'acc': [0.18104823859349284, 0.59248803244846293, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822267327968, 0.59383822264767316, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822262938279, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822262938279, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.5938382226001182]}
[2017-11-13 16:19:55,778 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:94]: done!
[2017-11-13 16:19:55,778 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:154]: >> Executing classifier part ... 
[2017-11-13 16:19:55,778 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:99]: =======================================
[2017-11-13 16:19:55,778 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8adb84e400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 16:19:55,851 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:112]: training ... 
[2017-11-13 16:24:11,315 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:124]: trained!
[2017-11-13 16:24:11,316 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:127]: Training history: 
{'val_loss': [0.0095304292624967587, 0.0088896832279299655, 0.0083617467809029029, 0.007930083175007362, 0.0075808087771485301, 0.0072960315985164956, 0.0070617892094865546, 0.0068673940527073842, 0.0067047548010734483, 0.0065676351933535056, 0.0064511713561578319, 0.0063519460602277714, 0.0062670181714168088, 0.0061938219360777209, 0.0061305826396374349, 0.0060757217459512063, 0.0060279502530638041, 0.0059862673905216367, 0.0059497598589468821, 0.0059176682303250603, 0.0058894009512151946, 0.0058644258311769289, 0.0058423512856907618, 0.005822634808489836, 0.0058049853933576012, 0.0057889639363322611, 0.0057723754448751148, 0.005757473290321862, 0.0057442839432320187, 0.0057325538532594159, 0.0057220949925029102, 0.0057127722652813157, 0.0057044094304346408, 0.0056968823566283921, 0.0056901068061464243, 0.0056839622071992437, 0.0056783362596033249, 0.0056731983385562559, 0.0056684843166288053, 0.0056641759166582316, 0.0056602105519534774, 0.0056565319990053995, 0.0056531286565843627, 0.0056499656172074274, 0.0056470065202751567, 0.0056442166892527569, 0.0056415803988732176, 0.0056390672934456196, 0.0056366608102485201, 0.0056343592080578221, 0.0056321397827625366, 0.005629982503311752, 0.005627888317713812, 0.0056258366219541934, 0.0056238384442989196, 0.0056218917981147474, 0.0056199881037507574, 0.0056181191365778423, 0.0056162832026054633, 0.0056144894186807102, 0.005612725093437086, 0.0056109939985427675, 0.0056092904083833283, 0.0056075901162729504, 0.0056058720537337783, 0.0056040738689590308, 0.0056020511366982797, 0.0055997193627879546, 0.0055971293244168616, 0.0055944072750069469, 0.005590900754811395, 0.0055874122801458943, 0.0055842402538141588, 0.0055813027506619586, 0.0055785414803696497, 0.0055759211500558299, 0.0055733924805714133, 0.0055709702596143679, 0.005568640293157805, 0.0055663867103834721, 0.0055641986324271482, 0.0055620753631072418, 0.0055599981240034161, 0.0055579735026569906, 0.0055559913583136805, 0.0055540534475142633, 0.0055521540264183164, 0.0055502880996490872, 0.0055484398751964913, 0.0055466172635693549, 0.0055448129943078085, 0.0055430219293931739, 0.0055412483651112957, 0.0055394969858846618, 0.0055377527051261302, 0.0055360178051920977, 0.0055342863471470076, 0.0055325701634253441, 0.0055308576733338038, 0.0055291523407523142, 0.0055274573373459406], 'val_acc': [0.58838662256523333, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098909553259517845, 0.0092069280475681661, 0.0086268324548305648, 0.0081511552687251951, 0.0077652370865724596, 0.0074521432087379571, 0.007195835848439156, 0.0069842521241043325, 0.0068080747809626434, 0.0066601952755778234, 0.0065351657365242209, 0.0064287977057645275, 0.0063380170420335308, 0.0062601535086183584, 0.0061929330982064832, 0.0061347800093435817, 0.0060842701459580826, 0.0060402459058120925, 0.0060017908496590817, 0.0059680826611619347, 0.005938400616049693, 0.0059122488011126026, 0.0058891433188825483, 0.0058686681699025587, 0.0058503209720605189, 0.0058338494631993932, 0.0058178316716164646, 0.0058021956974828193, 0.0057883556931982291, 0.005776087350400771, 0.0057651542135248764, 0.0057553947590336316, 0.0057466923520065015, 0.0057388661796579418, 0.0057318227630708974, 0.0057254801812963874, 0.0057196916622063183, 0.0057143750653101599, 0.0057095279114631123, 0.0057050807444291628, 0.005701005716154374, 0.0056972497780041981, 0.0056937699386447839, 0.0056905440975982451, 0.0056875402510108549, 0.0056847223366253011, 0.0056820581519659149, 0.00567953343454822, 0.0056771190311291934, 0.0056748086355907336, 0.0056725869448980126, 0.0056704275255854307, 0.005668337759644715, 0.0056663043518088065, 0.0056643098249470874, 0.0056623718675010608, 0.0056604772140969855, 0.0056586206674130437, 0.0056567956674379912, 0.0056550068990776107, 0.0056532557522854044, 0.0056515336001244547, 0.0056498401548644396, 0.0056481540551297322, 0.0056464580781401168, 0.0056447185350418988, 0.0056428086443339976, 0.0056405947123573819, 0.0056380734926292442, 0.0056353974918218362, 0.0056323274568009516, 0.0056286851189138003, 0.0056253514874246872, 0.0056223003563544418, 0.0056194532624334629, 0.0056167637956870201, 0.0056141888179439183, 0.0056117019031118641, 0.0056093218494003188, 0.0056070279793218698, 0.0056048090177232305, 0.0056026549463422002, 0.0056005523410217993, 0.0055985058164785316, 0.0055965074001133215, 0.00559455049476262, 0.0055926335188813394, 0.005590755568639613, 0.0055889013528341901, 0.00558706836168391, 0.0055852573377776328, 0.0055834655679681882, 0.0055816875139899063, 0.0055799265612752197, 0.005578183523688259, 0.0055764459647518099, 0.0055747197449849302, 0.0055730042011903789, 0.0055712980073737784, 0.0055696028987764473, 0.0055679159722600386], 'acc': [0.18104823859349284, 0.59248803244846293, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822267327968, 0.59383822264767316, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822262938279, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822262938279, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.5938382226001182]}
[2017-11-13 16:24:11,317 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:131]: evaluating model ... 
[2017-11-13 16:24:11,403 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:135]: evaluated! 
[2017-11-13 16:24:11,403 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:137]: generating reports ... 
[2017-11-13 16:24:12,356 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:140]: done!
[2017-11-13 16:24:12,356 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:156]: >> experiment AE_UNIGRAMA_4L_FULLDS_UNDER_01 finished!
[2017-11-14 07:04:20,174 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_UNDER_01 was already executed!
[2017-11-18 14:56:08,516 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_UNDER_01 was already executed!
[2017-11-18 16:22:38,487 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_UNDER_01 was already executed!
[2017-11-18 17:38:15,425 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_UNDER_01
[2017-11-18 17:38:15,426 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:148]: >> Printing header log
[2017-11-18 17:38:15,426 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_UNDER_01
	layers = 96,28,26,24,22
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f460a244eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f460a249400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:38:15,426 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:150]: >> Loading dataset... 
[2017-11-18 17:38:17,618 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:38:17,619 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:152]: >> Executing autoencoder part ... 
[2017-11-18 17:38:17,619 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:59]: =======================================
[2017-11-18 17:38:17,619 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f460a244eb8>, 'discard_decoder_function': True}
[2017-11-18 17:38:17,711 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:75]: training and evaluate autoencoder
[2017-11-18 17:39:37,604 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:87]: trained and evaluated!
[2017-11-18 17:39:37,605 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:90]: Training history: 
{'val_loss': [0.0095680325820176795, 0.0090166976263295496, 0.0085427106804091546, 0.0081507894919020801, 0.0078219946226374126, 0.007546234022290643, 0.0073136687557699377, 0.0071159615956632935, 0.0069467347219328984, 0.0068001552027653943, 0.006670652817693792, 0.006556746154066582, 0.0064578097765784041, 0.0063717127623613571, 0.0062964714646684423, 0.0062307134066673818, 0.0061730860540138823, 0.0061222493336376832, 0.0060767501233934878, 0.0060341850911273601, 0.0059949702361461014, 0.0059601527084937019, 0.005929259133094957, 0.0059017613489086339, 0.0058772044128148609, 0.0058552211003178832, 0.0058355217327893281, 0.0058178156324227926, 0.0058018939087159851, 0.0057874924787523849, 0.0057744297584178574, 0.0057625513477096912, 0.0057517146024762631, 0.005741785732120171, 0.0057325830542096006, 0.0057240126905904638, 0.0057153053775440676, 0.0057062554539060468, 0.0056976645668774832, 0.0056897177736937882, 0.0056823292557692286, 0.0056754046105887525, 0.0056689282840214333, 0.005662833624551924, 0.0056570623486204563, 0.0056514132762610506, 0.0056457562930505474, 0.0056402483546523835, 0.0056339049748104315, 0.0056271481004949876, 0.0056203135924337818, 0.0056135857167856707, 0.0056071918246735717, 0.0056011472150645069, 0.0055953120365766253, 0.0055897272253037323, 0.0055845182111609326, 0.0055796336516969313, 0.0055750503841560306, 0.0055707114828577303, 0.0055665949287487882, 0.0055626804102862507, 0.0055589205053186907, 0.0055553108550955906, 0.0055518412774477324, 0.0055484249827632386, 0.0055450838890394897, 0.0055418474174788145, 0.0055387100466321336, 0.005535681265481953, 0.0055327294637387133, 0.0055298435507572909, 0.0055270254398391162, 0.0055242684624099321, 0.0055215742861908865, 0.0055189387283593591, 0.0055163389335200598, 0.0055137902375198391, 0.0055112349887189238, 0.0055084199833217154, 0.0055054431143348563, 0.0055023811699207135, 0.0054991195533350681, 0.0054958739200040825, 0.0054926739584446466, 0.0054895444690136568, 0.0054864373508339715, 0.0054832906843885606, 0.0054800953998927603, 0.0054769396585286024, 0.0054738297079611423, 0.0054707332507894398, 0.0054676517432104442, 0.0054645897756929306, 0.0054615353271248793, 0.0054584840314824907, 0.0054554331433151202, 0.0054523894195888127, 0.0054493422532890185, 0.0054462720797106611, 0.0054431059910309632], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098760371805526829, 0.0092909451168498268, 0.0087782412682131453, 0.008348403346377405, 0.0079903372208931563, 0.0076900613712558644, 0.007437796681288072, 0.0072244560991657266, 0.007042480174774891, 0.006886064145179966, 0.0067492152018488781, 0.0066282813587264042, 0.0065227963746634747, 0.0064311204166065273, 0.0063511302147224785, 0.0062813180029745244, 0.0062202015956601981, 0.0061664931863986252, 0.0061188502374607111, 0.006075256991385225, 0.0060345447030431933, 0.0059977875327081225, 0.0059652214793723185, 0.0059363286418910475, 0.005910587551412212, 0.0058875771389037971, 0.0058669735243372743, 0.0058485040916362004, 0.0058318932572265624, 0.0058169307827819665, 0.0058033913480831471, 0.0057911098016990908, 0.0057799362851739134, 0.0057697242822160166, 0.0057603413896660099, 0.0057516079372003336, 0.0057432487618090796, 0.0057342956330166742, 0.0057255252925979732, 0.0057172390754190935, 0.0057095785341092385, 0.0057023937712311814, 0.0056956504549677059, 0.0056893045398883034, 0.0056833131131362267, 0.0056775725437839203, 0.0056718384685975412, 0.0056662162531743877, 0.0056603551089852346, 0.0056536935071610766, 0.0056468829940362064, 0.0056400118681244485, 0.0056333748911916335, 0.005627124323847434, 0.0056211714868526254, 0.0056154276762759893, 0.0056100425266307399, 0.0056050215011920514, 0.0056002957886879404, 0.0055958441329123825, 0.0055916306773175252, 0.0055876259413771071, 0.0055837968395337258, 0.0055801165403348511, 0.0055765920036076966, 0.0055731783281040984, 0.0055698075053276707, 0.005566532257315614, 0.0055633670667226843, 0.0055602973953371394, 0.0055573230308764172, 0.0055544288366908634, 0.0055516046703724181, 0.0055488532133458968, 0.0055461613393014992, 0.0055435384371985176, 0.0055409522879284823, 0.0055384120540502499, 0.0055359022144163749, 0.0055332723607740015, 0.0055303873385782734, 0.0055274210559444056, 0.0055243050659216442, 0.005521090925050774, 0.005517934319727023, 0.0055148341389249711, 0.005511781728100679, 0.0055087293832931754, 0.0055055997392835536, 0.0055024674360833426, 0.00549938480300129, 0.0054963358349954554, 0.0054933017890132635, 0.0054902832439447987, 0.0054872738578914315, 0.005484274397562443, 0.0054812809004643488, 0.0054783019039112762, 0.0054753340249285567, 0.0054723564448500173, 0.0054693313828669829], 'acc': [0.40788020132669894, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822262938279]}
[2017-11-18 17:39:37,606 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:94]: done!
[2017-11-18 17:39:37,606 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:154]: >> Executing classifier part ... 
[2017-11-18 17:39:37,606 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:99]: =======================================
[2017-11-18 17:39:37,606 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f460a249400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:39:37,676 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:112]: training ... 
[2017-11-18 17:43:12,014 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:124]: trained!
[2017-11-18 17:43:12,016 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:127]: Training history: 
{'val_loss': [0.0095680325820176795, 0.0090166976263295496, 0.0085427106804091546, 0.0081507894919020801, 0.0078219946226374126, 0.007546234022290643, 0.0073136687557699377, 0.0071159615956632935, 0.0069467347219328984, 0.0068001552027653943, 0.006670652817693792, 0.006556746154066582, 0.0064578097765784041, 0.0063717127623613571, 0.0062964714646684423, 0.0062307134066673818, 0.0061730860540138823, 0.0061222493336376832, 0.0060767501233934878, 0.0060341850911273601, 0.0059949702361461014, 0.0059601527084937019, 0.005929259133094957, 0.0059017613489086339, 0.0058772044128148609, 0.0058552211003178832, 0.0058355217327893281, 0.0058178156324227926, 0.0058018939087159851, 0.0057874924787523849, 0.0057744297584178574, 0.0057625513477096912, 0.0057517146024762631, 0.005741785732120171, 0.0057325830542096006, 0.0057240126905904638, 0.0057153053775440676, 0.0057062554539060468, 0.0056976645668774832, 0.0056897177736937882, 0.0056823292557692286, 0.0056754046105887525, 0.0056689282840214333, 0.005662833624551924, 0.0056570623486204563, 0.0056514132762610506, 0.0056457562930505474, 0.0056402483546523835, 0.0056339049748104315, 0.0056271481004949876, 0.0056203135924337818, 0.0056135857167856707, 0.0056071918246735717, 0.0056011472150645069, 0.0055953120365766253, 0.0055897272253037323, 0.0055845182111609326, 0.0055796336516969313, 0.0055750503841560306, 0.0055707114828577303, 0.0055665949287487882, 0.0055626804102862507, 0.0055589205053186907, 0.0055553108550955906, 0.0055518412774477324, 0.0055484249827632386, 0.0055450838890394897, 0.0055418474174788145, 0.0055387100466321336, 0.005535681265481953, 0.0055327294637387133, 0.0055298435507572909, 0.0055270254398391162, 0.0055242684624099321, 0.0055215742861908865, 0.0055189387283593591, 0.0055163389335200598, 0.0055137902375198391, 0.0055112349887189238, 0.0055084199833217154, 0.0055054431143348563, 0.0055023811699207135, 0.0054991195533350681, 0.0054958739200040825, 0.0054926739584446466, 0.0054895444690136568, 0.0054864373508339715, 0.0054832906843885606, 0.0054800953998927603, 0.0054769396585286024, 0.0054738297079611423, 0.0054707332507894398, 0.0054676517432104442, 0.0054645897756929306, 0.0054615353271248793, 0.0054584840314824907, 0.0054554331433151202, 0.0054523894195888127, 0.0054493422532890185, 0.0054462720797106611, 0.0054431059910309632], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098760371805526829, 0.0092909451168498268, 0.0087782412682131453, 0.008348403346377405, 0.0079903372208931563, 0.0076900613712558644, 0.007437796681288072, 0.0072244560991657266, 0.007042480174774891, 0.006886064145179966, 0.0067492152018488781, 0.0066282813587264042, 0.0065227963746634747, 0.0064311204166065273, 0.0063511302147224785, 0.0062813180029745244, 0.0062202015956601981, 0.0061664931863986252, 0.0061188502374607111, 0.006075256991385225, 0.0060345447030431933, 0.0059977875327081225, 0.0059652214793723185, 0.0059363286418910475, 0.005910587551412212, 0.0058875771389037971, 0.0058669735243372743, 0.0058485040916362004, 0.0058318932572265624, 0.0058169307827819665, 0.0058033913480831471, 0.0057911098016990908, 0.0057799362851739134, 0.0057697242822160166, 0.0057603413896660099, 0.0057516079372003336, 0.0057432487618090796, 0.0057342956330166742, 0.0057255252925979732, 0.0057172390754190935, 0.0057095785341092385, 0.0057023937712311814, 0.0056956504549677059, 0.0056893045398883034, 0.0056833131131362267, 0.0056775725437839203, 0.0056718384685975412, 0.0056662162531743877, 0.0056603551089852346, 0.0056536935071610766, 0.0056468829940362064, 0.0056400118681244485, 0.0056333748911916335, 0.005627124323847434, 0.0056211714868526254, 0.0056154276762759893, 0.0056100425266307399, 0.0056050215011920514, 0.0056002957886879404, 0.0055958441329123825, 0.0055916306773175252, 0.0055876259413771071, 0.0055837968395337258, 0.0055801165403348511, 0.0055765920036076966, 0.0055731783281040984, 0.0055698075053276707, 0.005566532257315614, 0.0055633670667226843, 0.0055602973953371394, 0.0055573230308764172, 0.0055544288366908634, 0.0055516046703724181, 0.0055488532133458968, 0.0055461613393014992, 0.0055435384371985176, 0.0055409522879284823, 0.0055384120540502499, 0.0055359022144163749, 0.0055332723607740015, 0.0055303873385782734, 0.0055274210559444056, 0.0055243050659216442, 0.005521090925050774, 0.005517934319727023, 0.0055148341389249711, 0.005511781728100679, 0.0055087293832931754, 0.0055055997392835536, 0.0055024674360833426, 0.00549938480300129, 0.0054963358349954554, 0.0054933017890132635, 0.0054902832439447987, 0.0054872738578914315, 0.005484274397562443, 0.0054812809004643488, 0.0054783019039112762, 0.0054753340249285567, 0.0054723564448500173, 0.0054693313828669829], 'acc': [0.40788020132669894, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.59383822262938279]}
[2017-11-18 17:43:12,016 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:131]: evaluating model ... 
[2017-11-18 17:43:12,140 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:135]: evaluated! 
[2017-11-18 17:43:12,140 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:137]: generating reports ... 
[2017-11-18 17:43:13,006 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:140]: done!
[2017-11-18 17:43:13,006 AE_UNIGRAMA_4L_FULLDS_UNDER_01.py:156]: >> experiment AE_UNIGRAMA_4L_FULLDS_UNDER_01 finished!
