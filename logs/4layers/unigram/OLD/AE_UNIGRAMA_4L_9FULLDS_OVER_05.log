[2017-11-18 17:29:24,358 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_9FULLDS_OVER_05
[2017-11-18 17:29:24,359 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:148]: >> Printing header log
[2017-11-18 17:29:24,359 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_9FULLDS_OVER_05
	layers = 96,172,156,139,123,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f730c5bceb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f730c5c1400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:29:24,359 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:150]: >> Loading dataset... 
[2017-11-18 17:29:26,826 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:29:26,826 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:152]: >> Executing autoencoder part ... 
[2017-11-18 17:29:26,827 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:59]: =======================================
[2017-11-18 17:29:26,827 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f730c5bceb8>, 'discard_decoder_function': True}
[2017-11-18 17:29:26,950 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:75]: training and evaluate autoencoder
[2017-11-18 17:32:23,690 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:87]: trained and evaluated!
[2017-11-18 17:32:23,691 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:90]: Training history: 
{'val_loss': [0.0095814368285400287, 0.0088942379710216235, 0.0083513066384123986, 0.0079231215021389884, 0.0075814465599224239, 0.0073096388849973656, 0.0070916174547127264, 0.0069147906122740818, 0.0067702144636296469, 0.006651083085664063, 0.0065522529657153859, 0.0064696151315166489, 0.0064004226289935979, 0.0063422313304012179, 0.0062928429821171401, 0.0062507878402326749, 0.0062147957606200717, 0.0061838771459584571, 0.0061572144362145882, 0.0061342477401768467, 0.0061143597917208909, 0.0060970101649956811, 0.0060812970804778235, 0.0060673596592259261, 0.0060555056891466045, 0.0060452058393123485, 0.006036153903113968, 0.006028093030273734, 0.0060209135981177369, 0.006014436559624305, 0.0060085808899861485, 0.0060031822801645306, 0.0059981832016520924, 0.0059935738176322357, 0.0059893614979948913, 0.0059855024117082415, 0.0059818956534282734, 0.0059785183442284881, 0.0059753060586461631, 0.005972250841762658, 0.0059693405025278224, 0.0059665207303916702, 0.0059638144579318647, 0.0059611722133000875, 0.0059585617269050139, 0.0059559716414714983, 0.005953434964187391, 0.0059509333939308994, 0.0059484348091434101, 0.0059459610820434047, 0.0059435084009168615, 0.0059410639391997769, 0.0059386527999032131, 0.0059362596000323278, 0.0059338476017181847, 0.0059314172310896357, 0.0059289835034556431, 0.0059265302197589447, 0.0059240600300418163, 0.0059215444949096514, 0.0059190335386945774, 0.0059165154733153954, 0.0059139862697152575, 0.0059114172182756775, 0.0059087837750871845, 0.0059061352876677306, 0.0059034821724718335, 0.0059007675653424156, 0.005897966136940944, 0.005894981932633641, 0.0058918905250888312, 0.0058887394173197426, 0.0058855813451676748, 0.0058824279343347224, 0.0058792876968730501, 0.0058761292210965255, 0.0058729382359670205, 0.0058696707889460947, 0.0058662451972082141, 0.0058625672268073697, 0.0058588241421210609, 0.0058550662061597264, 0.0058509426975081298, 0.0058461591630122626, 0.0058407993683949498, 0.005835440744605163, 0.0058309545676993703, 0.0058259922623099024, 0.0058205202535905141, 0.0058152647859265275, 0.0058103075247731657, 0.0058057452594804573, 0.0058012183027281033, 0.0057967004777116785, 0.0057920898061494851, 0.0057874547278433932, 0.0057828682103426695, 0.0057783261326048215, 0.0057736744046401542, 0.0057689816082934879, 0.0057642910961001473], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099783336191114746, 0.0092272321571625349, 0.0086168707155785899, 0.0081348177574861198, 0.0077530497135106366, 0.0074490183165082683, 0.0072063986810796008, 0.0070109749370043896, 0.0068519380893222182, 0.0067215205496125637, 0.0066137241746151614, 0.0065241022290058581, 0.0064491259476678183, 0.0063863059334233778, 0.0063333389450679007, 0.006288330642705617, 0.0062499610327410087, 0.0062170917998413608, 0.0061888518945897109, 0.0061645169294977332, 0.0061435149311543803, 0.0061252939303790711, 0.0061091874195467414, 0.0060946250150792506, 0.0060820617038919852, 0.0060713184994352883, 0.0060619226361007484, 0.0060536295280836285, 0.0060462534169977294, 0.0060396505369080845, 0.0060336891954074949, 0.0060282564645753592, 0.0060232459220313228, 0.0060186131047529614, 0.0060143671740988244, 0.0060104879058396343, 0.0060068995301908136, 0.0060035305076436615, 0.0060003593888001616, 0.0059973402237454461, 0.0059944537207159594, 0.0059916854493559596, 0.0059890177632917858, 0.0059864262958692011, 0.0059838838951541693, 0.0059813570688001154, 0.0059788585082062315, 0.0059763990856804951, 0.0059739666996880174, 0.0059715358153345889, 0.005969132975599375, 0.0059667326323848075, 0.0059643639547665075, 0.0059620213816730036, 0.0059596750754014804, 0.0059572989157660175, 0.0059549148915589547, 0.005952517064355704, 0.0059500957861025085, 0.0059476517717240484, 0.0059451646374076026, 0.0059426838193261155, 0.0059401997550476053, 0.0059376914404873117, 0.0059351145109906838, 0.0059325112780615301, 0.0059298904112190269, 0.0059272347964534795, 0.0059245202260082069, 0.0059216357792159623, 0.0059186024701640486, 0.0059155015771237126, 0.0059123665487732791, 0.005909240831190825, 0.0059061109271722183, 0.0059029783287540679, 0.0058997924252361432, 0.005896540458173628, 0.0058931814588042098, 0.0058895932588572189, 0.0058858415521832203, 0.0058820990362466732, 0.0058782046755776491, 0.0058737525223612943, 0.0058686867401683326, 0.0058632266514640693, 0.0058583968293963876, 0.0058537532512098096, 0.0058484462177173097, 0.0058430943660263386, 0.0058379707118578379, 0.005833245328180213, 0.0058287069547500285, 0.0058241870390427098, 0.0058196469275704939, 0.0058150448402218644, 0.0058104651092447737, 0.0058059546375393177, 0.0058014315155879934, 0.0057967737801437021, 0.0057921313903164986], 'acc': [0.36516509142275511, 0.59383822264767316, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 17:32:23,691 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:94]: done!
[2017-11-18 17:32:23,691 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:154]: >> Executing classifier part ... 
[2017-11-18 17:32:23,691 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:99]: =======================================
[2017-11-18 17:32:23,691 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f730c5c1400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:32:23,725 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:112]: training ... 
[2017-11-18 17:38:50,297 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:124]: trained!
[2017-11-18 17:38:50,298 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:127]: Training history: 
{'val_loss': [0.0095814368285400287, 0.0088942379710216235, 0.0083513066384123986, 0.0079231215021389884, 0.0075814465599224239, 0.0073096388849973656, 0.0070916174547127264, 0.0069147906122740818, 0.0067702144636296469, 0.006651083085664063, 0.0065522529657153859, 0.0064696151315166489, 0.0064004226289935979, 0.0063422313304012179, 0.0062928429821171401, 0.0062507878402326749, 0.0062147957606200717, 0.0061838771459584571, 0.0061572144362145882, 0.0061342477401768467, 0.0061143597917208909, 0.0060970101649956811, 0.0060812970804778235, 0.0060673596592259261, 0.0060555056891466045, 0.0060452058393123485, 0.006036153903113968, 0.006028093030273734, 0.0060209135981177369, 0.006014436559624305, 0.0060085808899861485, 0.0060031822801645306, 0.0059981832016520924, 0.0059935738176322357, 0.0059893614979948913, 0.0059855024117082415, 0.0059818956534282734, 0.0059785183442284881, 0.0059753060586461631, 0.005972250841762658, 0.0059693405025278224, 0.0059665207303916702, 0.0059638144579318647, 0.0059611722133000875, 0.0059585617269050139, 0.0059559716414714983, 0.005953434964187391, 0.0059509333939308994, 0.0059484348091434101, 0.0059459610820434047, 0.0059435084009168615, 0.0059410639391997769, 0.0059386527999032131, 0.0059362596000323278, 0.0059338476017181847, 0.0059314172310896357, 0.0059289835034556431, 0.0059265302197589447, 0.0059240600300418163, 0.0059215444949096514, 0.0059190335386945774, 0.0059165154733153954, 0.0059139862697152575, 0.0059114172182756775, 0.0059087837750871845, 0.0059061352876677306, 0.0059034821724718335, 0.0059007675653424156, 0.005897966136940944, 0.005894981932633641, 0.0058918905250888312, 0.0058887394173197426, 0.0058855813451676748, 0.0058824279343347224, 0.0058792876968730501, 0.0058761292210965255, 0.0058729382359670205, 0.0058696707889460947, 0.0058662451972082141, 0.0058625672268073697, 0.0058588241421210609, 0.0058550662061597264, 0.0058509426975081298, 0.0058461591630122626, 0.0058407993683949498, 0.005835440744605163, 0.0058309545676993703, 0.0058259922623099024, 0.0058205202535905141, 0.0058152647859265275, 0.0058103075247731657, 0.0058057452594804573, 0.0058012183027281033, 0.0057967004777116785, 0.0057920898061494851, 0.0057874547278433932, 0.0057828682103426695, 0.0057783261326048215, 0.0057736744046401542, 0.0057689816082934879, 0.0057642910961001473], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099783336191114746, 0.0092272321571625349, 0.0086168707155785899, 0.0081348177574861198, 0.0077530497135106366, 0.0074490183165082683, 0.0072063986810796008, 0.0070109749370043896, 0.0068519380893222182, 0.0067215205496125637, 0.0066137241746151614, 0.0065241022290058581, 0.0064491259476678183, 0.0063863059334233778, 0.0063333389450679007, 0.006288330642705617, 0.0062499610327410087, 0.0062170917998413608, 0.0061888518945897109, 0.0061645169294977332, 0.0061435149311543803, 0.0061252939303790711, 0.0061091874195467414, 0.0060946250150792506, 0.0060820617038919852, 0.0060713184994352883, 0.0060619226361007484, 0.0060536295280836285, 0.0060462534169977294, 0.0060396505369080845, 0.0060336891954074949, 0.0060282564645753592, 0.0060232459220313228, 0.0060186131047529614, 0.0060143671740988244, 0.0060104879058396343, 0.0060068995301908136, 0.0060035305076436615, 0.0060003593888001616, 0.0059973402237454461, 0.0059944537207159594, 0.0059916854493559596, 0.0059890177632917858, 0.0059864262958692011, 0.0059838838951541693, 0.0059813570688001154, 0.0059788585082062315, 0.0059763990856804951, 0.0059739666996880174, 0.0059715358153345889, 0.005969132975599375, 0.0059667326323848075, 0.0059643639547665075, 0.0059620213816730036, 0.0059596750754014804, 0.0059572989157660175, 0.0059549148915589547, 0.005952517064355704, 0.0059500957861025085, 0.0059476517717240484, 0.0059451646374076026, 0.0059426838193261155, 0.0059401997550476053, 0.0059376914404873117, 0.0059351145109906838, 0.0059325112780615301, 0.0059298904112190269, 0.0059272347964534795, 0.0059245202260082069, 0.0059216357792159623, 0.0059186024701640486, 0.0059155015771237126, 0.0059123665487732791, 0.005909240831190825, 0.0059061109271722183, 0.0059029783287540679, 0.0058997924252361432, 0.005896540458173628, 0.0058931814588042098, 0.0058895932588572189, 0.0058858415521832203, 0.0058820990362466732, 0.0058782046755776491, 0.0058737525223612943, 0.0058686867401683326, 0.0058632266514640693, 0.0058583968293963876, 0.0058537532512098096, 0.0058484462177173097, 0.0058430943660263386, 0.0058379707118578379, 0.005833245328180213, 0.0058287069547500285, 0.0058241870390427098, 0.0058196469275704939, 0.0058150448402218644, 0.0058104651092447737, 0.0058059546375393177, 0.0058014315155879934, 0.0057967737801437021, 0.0057921313903164986], 'acc': [0.36516509142275511, 0.59383822264767316, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 17:38:50,298 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:131]: evaluating model ... 
[2017-11-18 17:38:50,423 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:135]: evaluated! 
[2017-11-18 17:38:50,423 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:137]: generating reports ... 
[2017-11-18 17:38:51,319 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:140]: done!
[2017-11-18 17:38:51,320 AE_UNIGRAMA_4L_9FULLDS_OVER_05.py:156]: >> experiment AE_UNIGRAMA_4L_9FULLDS_OVER_05 finished!
