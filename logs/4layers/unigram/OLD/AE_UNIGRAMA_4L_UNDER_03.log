[2017-10-20 01:44:23,379 AE_UNIGRAMA_4L_UNDER_03.py:272]: >> Initializing execution of experiment AE_UNIGRAMA_4L_UNDER_03
[2017-10-20 01:44:23,380 AE_UNIGRAMA_4L_UNDER_03.py:273]: >> Printing header log
[2017-10-20 01:44:23,380 AE_UNIGRAMA_4L_UNDER_03.py:164]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_UNDER_03
	layers = 96,86,78,71,63,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2975438b00>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2975438be0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:44:23,380 AE_UNIGRAMA_4L_UNDER_03.py:275]: >> Loading dataset... 
[2017-10-21 17:39:51,378 AE_UNIGRAMA_4L_UNDER_03.py:272]: >> Initializing execution of experiment AE_UNIGRAMA_4L_UNDER_03
[2017-10-21 17:39:51,378 AE_UNIGRAMA_4L_UNDER_03.py:273]: >> Printing header log
[2017-10-21 17:39:51,378 AE_UNIGRAMA_4L_UNDER_03.py:164]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_UNDER_03
	layers = 96,86,78,71,63,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc94b33ca58>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc94b33cb38>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 17:39:51,378 AE_UNIGRAMA_4L_UNDER_03.py:275]: >> Loading dataset... 
[2017-10-21 17:45:31,422 AE_UNIGRAMA_4L_UNDER_03.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_UNDER_03
[2017-10-21 17:45:31,422 AE_UNIGRAMA_4L_UNDER_03.py:148]: >> Printing header log
[2017-10-21 17:45:31,422 AE_UNIGRAMA_4L_UNDER_03.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_UNDER_03
	layers = 96,86,78,71,63,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb16552d780>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fb16552d860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 17:45:31,422 AE_UNIGRAMA_4L_UNDER_03.py:150]: >> Loading dataset... 
[2017-10-21 17:45:31,936 AE_UNIGRAMA_4L_UNDER_03.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 17:45:31,936 AE_UNIGRAMA_4L_UNDER_03.py:152]: >> Executing autoencoder part ... 
[2017-10-21 17:45:31,936 AE_UNIGRAMA_4L_UNDER_03.py:59]: =======================================
[2017-10-21 17:45:31,936 AE_UNIGRAMA_4L_UNDER_03.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fb16552d780>, 'discard_decoder_function': True}
[2017-10-21 17:45:32,036 AE_UNIGRAMA_4L_UNDER_03.py:75]: training and evaluate autoencoder
[2017-10-21 17:46:11,562 AE_UNIGRAMA_4L_UNDER_03.py:87]: trained and evaluated!
[2017-10-21 17:46:11,562 AE_UNIGRAMA_4L_UNDER_03.py:90]: Training history: 
{'val_loss': [0.010030930432522164, 0.0098511385229385039, 0.009683756573215737, 0.0095219908517588034, 0.0093651627117705607, 0.0092160925788451753, 0.0090742799484596817, 0.0089377658130067872, 0.0088059383074036313, 0.0086794916547308625, 0.0085591593701877123, 0.0084451922461335101, 0.0083367302944558266, 0.0082335391196121065, 0.0081353252113114723, 0.0080418406161704686, 0.0079527269723413153, 0.0078676215868069329, 0.0077861671017475948, 0.0077079266662879063, 0.0076325410547697413, 0.0075601798423382428, 0.0074910516798717824, 0.0074250838688148888, 0.0073621318066236473, 0.0073018187058043965, 0.007243770382412083, 0.0071878389915846098, 0.0071326478394821676, 0.0070789039089971095, 0.007027500030345744, 0.0069783111449095618, 0.0069311943933450821, 0.006885995053198036, 0.0068425401840982161, 0.0068007020546351892, 0.0067604000448183502, 0.0067215090873737763, 0.0066841420038952926, 0.0066483060528132994, 0.0066139143060712788, 0.0065808066436986272, 0.006548863330156608, 0.0065180641550529181, 0.0064883970354292471, 0.0064597488467522711, 0.0064321559504173058, 0.0064055629188824988, 0.0063799323694136503, 0.006355212504549651, 0.0063313571545797432, 0.0063083476220780364, 0.0062860401406136367, 0.0062645085010552938, 0.006243781248959245, 0.0062238122873202132, 0.0062045217993700373, 0.0061858951539964478, 0.0061678957197552056, 0.0061505017854051741, 0.0061336892386933024, 0.0061174031748647585, 0.0061016581419398351, 0.0060864130388183666, 0.0060716580104456736, 0.0060573788065477153, 0.0060435347864923649, 0.0060301316161137973, 0.0060171111725741602, 0.0060045210364167356, 0.00599229690137572, 0.0059804384956711068, 0.0059689541769709061, 0.0059578048851216371, 0.0059469854355301555, 0.0059364824711611724, 0.0059262820429490624, 0.0059163565920548142, 0.0059066403858003564, 0.0058970847028588054, 0.0058876553076045888, 0.0058783965088343975, 0.0058693194789569613, 0.005860432189608817, 0.0058517968074373594, 0.0058434000169532889, 0.0058352747641254536, 0.005827383688723731, 0.0058197314889069825, 0.0058123106050363927, 0.0058051002935461393, 0.0057981059502214749, 0.0057913120247451346, 0.0057847222199033403, 0.0057783161106495168, 0.0057721041232956828, 0.0057660652476892596, 0.005760200448043395, 0.0057545091444453338, 0.0057489758558211274, 0.005743594251600783, 0.0057383654604503216], 'loss': [0.010122958637691562, 0.0099356348437990381, 0.009762100337305608, 0.0095973935072123095, 0.0094371243255795632, 0.0092834809671379932, 0.0091375564874711396, 0.0089979593567069346, 0.0088631001901575291, 0.0087331616483999671, 0.0086088664967111077, 0.00849089969393752, 0.0083789489917186922, 0.0082723011509426621, 0.0081708921072632529, 0.0080743216970716805, 0.0079823661882936336, 0.0078945855490437453, 0.0078106649112947785, 0.007730200899319555, 0.0076528136150770636, 0.0075782412538887645, 0.0075068677104116587, 0.0074387096024857357, 0.0073736432293508968, 0.007311467645997805, 0.0072517213279973273, 0.0071941558397578256, 0.0071381419910245061, 0.0070828536812149647, 0.0070296471057540999, 0.0069787533245133562, 0.0069300062833073392, 0.006883277405813547, 0.0068383960164373611, 0.0067952039652145121, 0.0067535943592673588, 0.0067134491696303504, 0.0066747547249803715, 0.0066376374779725886, 0.0066019971895053958, 0.006567744873051967, 0.0065347352065145969, 0.0065028700841901011, 0.0064721075851142812, 0.0064424652232460506, 0.0064138467226133953, 0.0063862704160178481, 0.0063596695172700619, 0.006334011568318647, 0.0063092518290453299, 0.006285339062970496, 0.0062622307953164305, 0.0062398499312347512, 0.0062182596277905776, 0.0061974486976646721, 0.0061773951986796591, 0.0061579924574798432, 0.0061392596394473893, 0.0061211447436396848, 0.0061036094587545824, 0.0060866672758038195, 0.0060702466380741782, 0.0060543535356240982, 0.0060389531486093554, 0.0060240407683271237, 0.0060096176807123529, 0.0059956012178640572, 0.0059820372135033252, 0.005968854025054377, 0.0059560908851246383, 0.0059437049843586148, 0.0059316707007957886, 0.0059200181982399279, 0.0059086936222619455, 0.0058977071409924819, 0.0058870337598401308, 0.0058766593335204389, 0.0058665352314825102, 0.0058566081476728099, 0.0058468234769372615, 0.0058372040209374735, 0.0058277549113924876, 0.0058185128264985498, 0.0058094984207808353, 0.0058007352941365567, 0.0057922185280720332, 0.0057839707161752669, 0.0057759546716574448, 0.0057681855412466841, 0.0057606436134749351, 0.0057533053748799598, 0.0057461912178199169, 0.0057392694581512955, 0.0057325620981552661, 0.005726034186331678, 0.005719695911418186, 0.0057135310428149512, 0.0057075482975753374, 0.0057017347310597023, 0.0056960837948167517, 0.0056905722115062904]}
[2017-10-21 17:46:11,562 AE_UNIGRAMA_4L_UNDER_03.py:94]: done!
[2017-10-21 17:46:11,563 AE_UNIGRAMA_4L_UNDER_03.py:154]: >> Executing classifier part ... 
[2017-10-21 17:46:11,563 AE_UNIGRAMA_4L_UNDER_03.py:99]: =======================================
[2017-10-21 17:46:11,563 AE_UNIGRAMA_4L_UNDER_03.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fb16552d860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-21 17:46:11,620 AE_UNIGRAMA_4L_UNDER_03.py:112]: training ... 
[2017-10-21 17:47:21,835 AE_UNIGRAMA_4L_UNDER_03.py:124]: trained!
[2017-10-21 17:47:21,835 AE_UNIGRAMA_4L_UNDER_03.py:127]: Training history: 
{'val_loss': [0.010030930432522164, 0.0098511385229385039, 0.009683756573215737, 0.0095219908517588034, 0.0093651627117705607, 0.0092160925788451753, 0.0090742799484596817, 0.0089377658130067872, 0.0088059383074036313, 0.0086794916547308625, 0.0085591593701877123, 0.0084451922461335101, 0.0083367302944558266, 0.0082335391196121065, 0.0081353252113114723, 0.0080418406161704686, 0.0079527269723413153, 0.0078676215868069329, 0.0077861671017475948, 0.0077079266662879063, 0.0076325410547697413, 0.0075601798423382428, 0.0074910516798717824, 0.0074250838688148888, 0.0073621318066236473, 0.0073018187058043965, 0.007243770382412083, 0.0071878389915846098, 0.0071326478394821676, 0.0070789039089971095, 0.007027500030345744, 0.0069783111449095618, 0.0069311943933450821, 0.006885995053198036, 0.0068425401840982161, 0.0068007020546351892, 0.0067604000448183502, 0.0067215090873737763, 0.0066841420038952926, 0.0066483060528132994, 0.0066139143060712788, 0.0065808066436986272, 0.006548863330156608, 0.0065180641550529181, 0.0064883970354292471, 0.0064597488467522711, 0.0064321559504173058, 0.0064055629188824988, 0.0063799323694136503, 0.006355212504549651, 0.0063313571545797432, 0.0063083476220780364, 0.0062860401406136367, 0.0062645085010552938, 0.006243781248959245, 0.0062238122873202132, 0.0062045217993700373, 0.0061858951539964478, 0.0061678957197552056, 0.0061505017854051741, 0.0061336892386933024, 0.0061174031748647585, 0.0061016581419398351, 0.0060864130388183666, 0.0060716580104456736, 0.0060573788065477153, 0.0060435347864923649, 0.0060301316161137973, 0.0060171111725741602, 0.0060045210364167356, 0.00599229690137572, 0.0059804384956711068, 0.0059689541769709061, 0.0059578048851216371, 0.0059469854355301555, 0.0059364824711611724, 0.0059262820429490624, 0.0059163565920548142, 0.0059066403858003564, 0.0058970847028588054, 0.0058876553076045888, 0.0058783965088343975, 0.0058693194789569613, 0.005860432189608817, 0.0058517968074373594, 0.0058434000169532889, 0.0058352747641254536, 0.005827383688723731, 0.0058197314889069825, 0.0058123106050363927, 0.0058051002935461393, 0.0057981059502214749, 0.0057913120247451346, 0.0057847222199033403, 0.0057783161106495168, 0.0057721041232956828, 0.0057660652476892596, 0.005760200448043395, 0.0057545091444453338, 0.0057489758558211274, 0.005743594251600783, 0.0057383654604503216], 'loss': [0.010122958637691562, 0.0099356348437990381, 0.009762100337305608, 0.0095973935072123095, 0.0094371243255795632, 0.0092834809671379932, 0.0091375564874711396, 0.0089979593567069346, 0.0088631001901575291, 0.0087331616483999671, 0.0086088664967111077, 0.00849089969393752, 0.0083789489917186922, 0.0082723011509426621, 0.0081708921072632529, 0.0080743216970716805, 0.0079823661882936336, 0.0078945855490437453, 0.0078106649112947785, 0.007730200899319555, 0.0076528136150770636, 0.0075782412538887645, 0.0075068677104116587, 0.0074387096024857357, 0.0073736432293508968, 0.007311467645997805, 0.0072517213279973273, 0.0071941558397578256, 0.0071381419910245061, 0.0070828536812149647, 0.0070296471057540999, 0.0069787533245133562, 0.0069300062833073392, 0.006883277405813547, 0.0068383960164373611, 0.0067952039652145121, 0.0067535943592673588, 0.0067134491696303504, 0.0066747547249803715, 0.0066376374779725886, 0.0066019971895053958, 0.006567744873051967, 0.0065347352065145969, 0.0065028700841901011, 0.0064721075851142812, 0.0064424652232460506, 0.0064138467226133953, 0.0063862704160178481, 0.0063596695172700619, 0.006334011568318647, 0.0063092518290453299, 0.006285339062970496, 0.0062622307953164305, 0.0062398499312347512, 0.0062182596277905776, 0.0061974486976646721, 0.0061773951986796591, 0.0061579924574798432, 0.0061392596394473893, 0.0061211447436396848, 0.0061036094587545824, 0.0060866672758038195, 0.0060702466380741782, 0.0060543535356240982, 0.0060389531486093554, 0.0060240407683271237, 0.0060096176807123529, 0.0059956012178640572, 0.0059820372135033252, 0.005968854025054377, 0.0059560908851246383, 0.0059437049843586148, 0.0059316707007957886, 0.0059200181982399279, 0.0059086936222619455, 0.0058977071409924819, 0.0058870337598401308, 0.0058766593335204389, 0.0058665352314825102, 0.0058566081476728099, 0.0058468234769372615, 0.0058372040209374735, 0.0058277549113924876, 0.0058185128264985498, 0.0058094984207808353, 0.0058007352941365567, 0.0057922185280720332, 0.0057839707161752669, 0.0057759546716574448, 0.0057681855412466841, 0.0057606436134749351, 0.0057533053748799598, 0.0057461912178199169, 0.0057392694581512955, 0.0057325620981552661, 0.005726034186331678, 0.005719695911418186, 0.0057135310428149512, 0.0057075482975753374, 0.0057017347310597023, 0.0056960837948167517, 0.0056905722115062904]}
[2017-10-21 17:47:21,835 AE_UNIGRAMA_4L_UNDER_03.py:131]: evaluating model ... 
[2017-10-21 17:47:21,894 AE_UNIGRAMA_4L_UNDER_03.py:135]: evaluated! 
[2017-10-21 17:47:21,895 AE_UNIGRAMA_4L_UNDER_03.py:137]: generating reports ... 
[2017-10-21 17:47:22,460 AE_UNIGRAMA_4L_UNDER_03.py:140]: done!
[2017-10-21 17:47:22,460 AE_UNIGRAMA_4L_UNDER_03.py:156]: >> experiment AE_UNIGRAMA_4L_UNDER_03 finished!
