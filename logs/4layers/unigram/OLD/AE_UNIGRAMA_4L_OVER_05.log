[2017-10-20 01:41:54,334 AE_UNIGRAMA_4L_OVER_05.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_OVER_05
[2017-10-20 01:41:54,334 AE_UNIGRAMA_4L_OVER_05.py:148]: >> Printing header log
[2017-10-20 01:41:54,334 AE_UNIGRAMA_4L_OVER_05.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_OVER_05
	layers = 96,172,156,139,123,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4357fc77f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4357fc78d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:41:54,334 AE_UNIGRAMA_4L_OVER_05.py:150]: >> Loading dataset... 
[2017-10-20 01:41:54,940 AE_UNIGRAMA_4L_OVER_05.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:41:54,940 AE_UNIGRAMA_4L_OVER_05.py:152]: >> Executing autoencoder part ... 
[2017-10-20 01:41:54,940 AE_UNIGRAMA_4L_OVER_05.py:59]: =======================================
[2017-10-20 01:41:54,940 AE_UNIGRAMA_4L_OVER_05.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4357fc77f0>, 'discard_decoder_function': True}
[2017-10-20 01:41:55,055 AE_UNIGRAMA_4L_OVER_05.py:75]: training and evaluate autoencoder
[2017-10-20 01:42:46,683 AE_UNIGRAMA_4L_OVER_05.py:87]: trained and evaluated!
[2017-10-20 01:42:46,684 AE_UNIGRAMA_4L_OVER_05.py:90]: Training history: 
{'val_loss': [0.010033659249211777, 0.0098134319619950748, 0.0096046332976188805, 0.0093998625929913992, 0.0092053789001470612, 0.0090205608226608166, 0.0088447633832970073, 0.0086773296638104555, 0.0085185601490248529, 0.008367841675545204, 0.0082251225324645356, 0.0080900643969501699, 0.0079622846841119702, 0.0078414802224856545, 0.0077271998105189832, 0.007619246480411756, 0.0075171926823967448, 0.0074205495673318337, 0.0073291534734509023, 0.007242634563557942, 0.007160694764227672, 0.0070830911526034088, 0.0070093888477820443, 0.0069395428900797347, 0.0068728459209591482, 0.0068095198912082105, 0.0067495409568917135, 0.0066927916588448684, 0.0066390560185155901, 0.006588073866268738, 0.0065397777591163784, 0.0064939843598046934, 0.0064505791329678326, 0.0064094081818780492, 0.0063703549527268869, 0.0063333603324971016, 0.0062982309038394227, 0.0062648891592502155, 0.0062332522871879842, 0.0062032127614413497, 0.0061746724815450633, 0.0061476049948220582, 0.0061219246005535565, 0.0060975264816728447, 0.0060743116842908269, 0.006052266609020614, 0.0060312967525871274, 0.0060113421260451962, 0.0059923165370485152, 0.0059732728582360265, 0.0059545542577413161, 0.0059367076400321213, 0.0059197388423198214, 0.0059035630311581504, 0.005888173282215697, 0.0058735048633802777, 0.0058595104018385529, 0.00584613824554037, 0.005833380540562828, 0.0058212133650719896, 0.005809603110094274, 0.0057985295184981422, 0.0057879584966068149, 0.0057778681825749493, 0.0057682361363755284, 0.0057590396721677707, 0.0057502665061877562, 0.0057418994314719311, 0.0057339033901303675, 0.005726262355798018, 0.0057189642680206482, 0.0057119793435177835, 0.0057053082747225642, 0.0056989311697619336, 0.0056928131369299159, 0.0056869771719311249, 0.0056813699383717929, 0.0056759768639964682, 0.0056706692878032263, 0.0056651264626435853, 0.0056592364670868039, 0.0056536185025448694, 0.005648254098363747, 0.0056431122214211406, 0.0056381992524884451, 0.0056335041749543862, 0.005629011019579651, 0.0056247070906025988, 0.0056206079296850803, 0.0056166646683581695, 0.0056128948061384236, 0.0056092924019494911, 0.00560582045908865, 0.0056025030136413068, 0.0055993149718304332, 0.0055962552534603279, 0.0055933222226576956, 0.0055905029897796174, 0.0055877932426987081, 0.0055851961994979908, 0.0055826981015309526, 0.0055802940238668794], 'loss': [0.010147694260747468, 0.0099177560937884542, 0.0097025385797344325, 0.0094944776860698271, 0.0092934795238018113, 0.0091027726282462366, 0.0089214520183172625, 0.0087487727756249654, 0.0085845673708651576, 0.0084286902727216898, 0.0082809663490468408, 0.008141070681600646, 0.0080086178196102989, 0.0078833836835443278, 0.0077649751261961962, 0.0076529054267683418, 0.0075469841939049698, 0.0074467932125387489, 0.0073518758612789656, 0.0072620674714757461, 0.0071769846770992551, 0.0070963623205379574, 0.0070198871122046933, 0.0069473145847891689, 0.0068783078516690957, 0.0068125001263026818, 0.0067501302147953881, 0.0066910324524916348, 0.0066350723405556953, 0.0065820468784285307, 0.0065316984970317194, 0.0064839814330514729, 0.0064387193370951633, 0.0063958077516335799, 0.0063550402003912264, 0.0063163884835273085, 0.0062797232393631006, 0.0062448821370000478, 0.0062117945762338563, 0.0061803905756430862, 0.0061505353939733812, 0.0061221518310516174, 0.0060952225208886941, 0.0060696561500823932, 0.0060453373024648843, 0.0060221726279740106, 0.0060001719750454804, 0.0059792153556163172, 0.0059592473648657955, 0.0059398919657060499, 0.005920395185540132, 0.0059016541398709075, 0.005883782521318404, 0.0058667707447587671, 0.0058505474744317684, 0.0058350947742209017, 0.0058203378066045046, 0.0058062656304026829, 0.0057927975522671362, 0.0057799575135418623, 0.0057676855108935955, 0.0057559733979687892, 0.0057448012500740334, 0.0057341174537930738, 0.0057239137849236423, 0.0057141740995870823, 0.0057048537810210007, 0.0056959673737707536, 0.0056874689914528844, 0.0056793443101888141, 0.0056715704172680221, 0.0056641427098848406, 0.0056570332294722681, 0.0056502272377217666, 0.0056437106972495035, 0.0056374514845818667, 0.0056314695481675748, 0.0056257207108605439, 0.0056201474739384014, 0.0056145461001413394, 0.0056085553814181352, 0.0056025919712823485, 0.0055968935810917896, 0.0055914577837980779, 0.0055862351984115339, 0.0055812298985382456, 0.0055764500903493436, 0.0055718619454269694, 0.0055674787973681696, 0.0055632820285939156, 0.0055592392191185528, 0.0055553781904151963, 0.0055516732077571648, 0.0055481067354336937, 0.0055446881739641346, 0.0055413964646968579, 0.0055382540761467385, 0.0055352226503596362, 0.0055323147181176521, 0.0055295111881666342, 0.0055268220586293521, 0.0055242324231928597]}
[2017-10-20 01:42:46,684 AE_UNIGRAMA_4L_OVER_05.py:94]: done!
[2017-10-20 01:42:46,684 AE_UNIGRAMA_4L_OVER_05.py:154]: >> Executing classifier part ... 
[2017-10-20 01:42:46,684 AE_UNIGRAMA_4L_OVER_05.py:99]: =======================================
[2017-10-20 01:42:46,684 AE_UNIGRAMA_4L_OVER_05.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4357fc78d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:42:46,718 AE_UNIGRAMA_4L_OVER_05.py:112]: training ... 
[2017-10-20 01:44:06,064 AE_UNIGRAMA_4L_OVER_05.py:124]: trained!
[2017-10-20 01:44:06,065 AE_UNIGRAMA_4L_OVER_05.py:127]: Training history: 
{'val_loss': [0.010033659249211777, 0.0098134319619950748, 0.0096046332976188805, 0.0093998625929913992, 0.0092053789001470612, 0.0090205608226608166, 0.0088447633832970073, 0.0086773296638104555, 0.0085185601490248529, 0.008367841675545204, 0.0082251225324645356, 0.0080900643969501699, 0.0079622846841119702, 0.0078414802224856545, 0.0077271998105189832, 0.007619246480411756, 0.0075171926823967448, 0.0074205495673318337, 0.0073291534734509023, 0.007242634563557942, 0.007160694764227672, 0.0070830911526034088, 0.0070093888477820443, 0.0069395428900797347, 0.0068728459209591482, 0.0068095198912082105, 0.0067495409568917135, 0.0066927916588448684, 0.0066390560185155901, 0.006588073866268738, 0.0065397777591163784, 0.0064939843598046934, 0.0064505791329678326, 0.0064094081818780492, 0.0063703549527268869, 0.0063333603324971016, 0.0062982309038394227, 0.0062648891592502155, 0.0062332522871879842, 0.0062032127614413497, 0.0061746724815450633, 0.0061476049948220582, 0.0061219246005535565, 0.0060975264816728447, 0.0060743116842908269, 0.006052266609020614, 0.0060312967525871274, 0.0060113421260451962, 0.0059923165370485152, 0.0059732728582360265, 0.0059545542577413161, 0.0059367076400321213, 0.0059197388423198214, 0.0059035630311581504, 0.005888173282215697, 0.0058735048633802777, 0.0058595104018385529, 0.00584613824554037, 0.005833380540562828, 0.0058212133650719896, 0.005809603110094274, 0.0057985295184981422, 0.0057879584966068149, 0.0057778681825749493, 0.0057682361363755284, 0.0057590396721677707, 0.0057502665061877562, 0.0057418994314719311, 0.0057339033901303675, 0.005726262355798018, 0.0057189642680206482, 0.0057119793435177835, 0.0057053082747225642, 0.0056989311697619336, 0.0056928131369299159, 0.0056869771719311249, 0.0056813699383717929, 0.0056759768639964682, 0.0056706692878032263, 0.0056651264626435853, 0.0056592364670868039, 0.0056536185025448694, 0.005648254098363747, 0.0056431122214211406, 0.0056381992524884451, 0.0056335041749543862, 0.005629011019579651, 0.0056247070906025988, 0.0056206079296850803, 0.0056166646683581695, 0.0056128948061384236, 0.0056092924019494911, 0.00560582045908865, 0.0056025030136413068, 0.0055993149718304332, 0.0055962552534603279, 0.0055933222226576956, 0.0055905029897796174, 0.0055877932426987081, 0.0055851961994979908, 0.0055826981015309526, 0.0055802940238668794], 'loss': [0.010147694260747468, 0.0099177560937884542, 0.0097025385797344325, 0.0094944776860698271, 0.0092934795238018113, 0.0091027726282462366, 0.0089214520183172625, 0.0087487727756249654, 0.0085845673708651576, 0.0084286902727216898, 0.0082809663490468408, 0.008141070681600646, 0.0080086178196102989, 0.0078833836835443278, 0.0077649751261961962, 0.0076529054267683418, 0.0075469841939049698, 0.0074467932125387489, 0.0073518758612789656, 0.0072620674714757461, 0.0071769846770992551, 0.0070963623205379574, 0.0070198871122046933, 0.0069473145847891689, 0.0068783078516690957, 0.0068125001263026818, 0.0067501302147953881, 0.0066910324524916348, 0.0066350723405556953, 0.0065820468784285307, 0.0065316984970317194, 0.0064839814330514729, 0.0064387193370951633, 0.0063958077516335799, 0.0063550402003912264, 0.0063163884835273085, 0.0062797232393631006, 0.0062448821370000478, 0.0062117945762338563, 0.0061803905756430862, 0.0061505353939733812, 0.0061221518310516174, 0.0060952225208886941, 0.0060696561500823932, 0.0060453373024648843, 0.0060221726279740106, 0.0060001719750454804, 0.0059792153556163172, 0.0059592473648657955, 0.0059398919657060499, 0.005920395185540132, 0.0059016541398709075, 0.005883782521318404, 0.0058667707447587671, 0.0058505474744317684, 0.0058350947742209017, 0.0058203378066045046, 0.0058062656304026829, 0.0057927975522671362, 0.0057799575135418623, 0.0057676855108935955, 0.0057559733979687892, 0.0057448012500740334, 0.0057341174537930738, 0.0057239137849236423, 0.0057141740995870823, 0.0057048537810210007, 0.0056959673737707536, 0.0056874689914528844, 0.0056793443101888141, 0.0056715704172680221, 0.0056641427098848406, 0.0056570332294722681, 0.0056502272377217666, 0.0056437106972495035, 0.0056374514845818667, 0.0056314695481675748, 0.0056257207108605439, 0.0056201474739384014, 0.0056145461001413394, 0.0056085553814181352, 0.0056025919712823485, 0.0055968935810917896, 0.0055914577837980779, 0.0055862351984115339, 0.0055812298985382456, 0.0055764500903493436, 0.0055718619454269694, 0.0055674787973681696, 0.0055632820285939156, 0.0055592392191185528, 0.0055553781904151963, 0.0055516732077571648, 0.0055481067354336937, 0.0055446881739641346, 0.0055413964646968579, 0.0055382540761467385, 0.0055352226503596362, 0.0055323147181176521, 0.0055295111881666342, 0.0055268220586293521, 0.0055242324231928597]}
[2017-10-20 01:44:06,065 AE_UNIGRAMA_4L_OVER_05.py:131]: evaluating model ... 
[2017-10-20 01:44:06,124 AE_UNIGRAMA_4L_OVER_05.py:135]: evaluated! 
[2017-10-20 01:44:06,124 AE_UNIGRAMA_4L_OVER_05.py:137]: generating reports ... 
[2017-10-20 01:44:06,739 AE_UNIGRAMA_4L_OVER_05.py:140]: done!
[2017-10-20 01:44:06,739 AE_UNIGRAMA_4L_OVER_05.py:156]: >> experiment AE_UNIGRAMA_4L_OVER_05 finished!
