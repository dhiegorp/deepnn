[2017-10-20 01:40:05,511 AE_UNIGRAMA_4L_UNDER_02.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_UNDER_02
[2017-10-20 01:40:05,511 AE_UNIGRAMA_4L_UNDER_02.py:148]: >> Printing header log
[2017-10-20 01:40:05,511 AE_UNIGRAMA_4L_UNDER_02.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_UNDER_02
	layers = 96,76,69,63,56,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efd6659a7b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efd6659a898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:40:05,511 AE_UNIGRAMA_4L_UNDER_02.py:150]: >> Loading dataset... 
[2017-10-20 01:40:06,110 AE_UNIGRAMA_4L_UNDER_02.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:40:06,110 AE_UNIGRAMA_4L_UNDER_02.py:152]: >> Executing autoencoder part ... 
[2017-10-20 01:40:06,110 AE_UNIGRAMA_4L_UNDER_02.py:59]: =======================================
[2017-10-20 01:40:06,110 AE_UNIGRAMA_4L_UNDER_02.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7efd6659a7b8>, 'discard_decoder_function': True}
[2017-10-20 01:40:06,221 AE_UNIGRAMA_4L_UNDER_02.py:75]: training and evaluate autoencoder
[2017-10-20 01:40:39,663 AE_UNIGRAMA_4L_UNDER_02.py:87]: trained and evaluated!
[2017-10-20 01:40:39,664 AE_UNIGRAMA_4L_UNDER_02.py:90]: Training history: 
{'val_loss': [0.010172667092605595, 0.010085315505894366, 0.010002835643335789, 0.0099252716890885929, 0.0098510173921469869, 0.0097810637870574969, 0.0097147941582431136, 0.0096519813357011097, 0.0095702507273470599, 0.009406660489571804, 0.0092517932786928235, 0.0091003094311651236, 0.0089534496279177166, 0.0088129615494254351, 0.0086804128643194547, 0.0085553657159652408, 0.0084369453154919758, 0.0083250810122152026, 0.0082191022833096056, 0.0081182670810685722, 0.0080220871726154833, 0.0079301051868188119, 0.0078420914643786872, 0.007758076207497638, 0.0076778157679952656, 0.0076010178300278562, 0.0075274879652937549, 0.0074571563020957889, 0.0073900233684142287, 0.007325977625387641, 0.0072648143707376434, 0.0072063696085991249, 0.0071504706669197208, 0.0070969917617572063, 0.0070457656826256156, 0.0069965271358845621, 0.006949218402038498, 0.0069038919727127572, 0.0068604253409049543, 0.0068187920954840111, 0.0067788490776291123, 0.0067404889930939805, 0.0067037038512001695, 0.0066683557711984809, 0.00663437006725033, 0.0066016791873095646, 0.0065702372040170277, 0.0065400020416729069, 0.0065108635307023072, 0.0064827719751787008, 0.0064556489103096346, 0.0064294749739334045, 0.0064041918579862906, 0.0063797765096379475, 0.0063561452241081284, 0.0063332355647005116, 0.0063107732551857887, 0.0062890838135767823, 0.0062681377093311138, 0.0062478939330960076, 0.006228347487235269, 0.0062094530035295007, 0.006191209493530395, 0.0061735723541571745, 0.0061564910083621409, 0.0061399908130469151, 0.0061240307969425466, 0.0061085739979679704, 0.0060936143019385495, 0.0060791278562636625, 0.0060651063811740244, 0.0060515345063849894, 0.0060383817475275258, 0.0060256414416637342, 0.0060132945953525578, 0.006001320137853516, 0.0059897157218182619, 0.0059784835439909345, 0.0059676054747408204, 0.0059570523453218562, 0.0059468114790143132, 0.005936900745786477, 0.0059272841183420225, 0.0059179493267656922, 0.0059088927427078265, 0.0059000894212645223, 0.0058915398661808895, 0.0058832391282910533, 0.0058751663947858778, 0.0058673333158529599, 0.0058597031007884383, 0.0058522898890770499, 0.0058450884043782618, 0.0058380773474486563, 0.0058312597113304868, 0.0058246132585334292, 0.0058181658491049115, 0.0058118813968917916, 0.0058057466366061711, 0.0057997956463450833, 0.0057940125590031028, 0.0057883693604664291], 'loss': [0.010215595333660095, 0.010127183984101881, 0.010043109464902744, 0.0099638990631994474, 0.0098888241138123771, 0.009817422847890311, 0.0097501864256114047, 0.0096865398815037945, 0.0096233637480279306, 0.0094930478076884987, 0.0093334594926926789, 0.0091801212434259091, 0.0090295795846980047, 0.008885463388875978, 0.0087482770383999105, 0.008618874601291673, 0.0084966308183707043, 0.0083810342344115985, 0.0082716640702047515, 0.0081678410286808497, 0.0080688552886302584, 0.0079742800581744638, 0.0078838326122220234, 0.0077973337427294544, 0.0077147156929742652, 0.0076357351522148573, 0.0075600837965821592, 0.007487629288114887, 0.0074184189190528256, 0.0073523147846786758, 0.0072892147987009418, 0.0072289051470296947, 0.0071712415954458732, 0.007116051193283208, 0.0070631888082002521, 0.0070124462595496833, 0.0069636652096144317, 0.0069168301187020617, 0.0068719428886682915, 0.0068288827884527862, 0.0067876045899517195, 0.0067479607910169697, 0.0067098851916142675, 0.0066733364620862488, 0.0066381779744918903, 0.0066043453905834477, 0.0065717786137236729, 0.006540434549779579, 0.0065102726684742422, 0.0064811617815460649, 0.0064530459801610913, 0.0064258921906333727, 0.0063996926266596992, 0.0063743395968406166, 0.0063498267450569669, 0.0063260821345105956, 0.0063029175807997242, 0.0062803678888857326, 0.00625860181705226, 0.0062375589234945628, 0.0062172060209019055, 0.0061975602345620117, 0.0061785481007541878, 0.0061601694345877226, 0.0061423864244805684, 0.0061251676710667091, 0.0061085094398971749, 0.0060923909797083037, 0.0060767707175654762, 0.0060616363848536086, 0.006046972232661825, 0.0060327657619771704, 0.0060190066506888105, 0.0060056625217423717, 0.00599273012781581, 0.0059801838875902201, 0.0059680116552339787, 0.0059562266312571631, 0.00594479871911501, 0.0059337237218455548, 0.0059229864423479784, 0.0059125547560038346, 0.0059024549424808561, 0.0058926557918830783, 0.0058831305314054607, 0.0058738799455456013, 0.0058648930390301883, 0.0058561540746828967, 0.005847653583294329, 0.0058393887980865717, 0.0058313764233345914, 0.0058235490583593156, 0.0058159421277636019, 0.0058085513155227359, 0.0058013519687783004, 0.0057943529050428584, 0.005787516213133794, 0.0057808820870330017, 0.0057744280547911064, 0.0057681050428063981, 0.0057619783796081531, 0.0057560185765585395]}
[2017-10-20 01:40:39,664 AE_UNIGRAMA_4L_UNDER_02.py:94]: done!
[2017-10-20 01:40:39,664 AE_UNIGRAMA_4L_UNDER_02.py:154]: >> Executing classifier part ... 
[2017-10-20 01:40:39,664 AE_UNIGRAMA_4L_UNDER_02.py:99]: =======================================
[2017-10-20 01:40:39,664 AE_UNIGRAMA_4L_UNDER_02.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7efd6659a898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:40:39,699 AE_UNIGRAMA_4L_UNDER_02.py:112]: training ... 
[2017-10-20 01:41:37,286 AE_UNIGRAMA_4L_UNDER_02.py:124]: trained!
[2017-10-20 01:41:37,287 AE_UNIGRAMA_4L_UNDER_02.py:127]: Training history: 
{'val_loss': [0.010172667092605595, 0.010085315505894366, 0.010002835643335789, 0.0099252716890885929, 0.0098510173921469869, 0.0097810637870574969, 0.0097147941582431136, 0.0096519813357011097, 0.0095702507273470599, 0.009406660489571804, 0.0092517932786928235, 0.0091003094311651236, 0.0089534496279177166, 0.0088129615494254351, 0.0086804128643194547, 0.0085553657159652408, 0.0084369453154919758, 0.0083250810122152026, 0.0082191022833096056, 0.0081182670810685722, 0.0080220871726154833, 0.0079301051868188119, 0.0078420914643786872, 0.007758076207497638, 0.0076778157679952656, 0.0076010178300278562, 0.0075274879652937549, 0.0074571563020957889, 0.0073900233684142287, 0.007325977625387641, 0.0072648143707376434, 0.0072063696085991249, 0.0071504706669197208, 0.0070969917617572063, 0.0070457656826256156, 0.0069965271358845621, 0.006949218402038498, 0.0069038919727127572, 0.0068604253409049543, 0.0068187920954840111, 0.0067788490776291123, 0.0067404889930939805, 0.0067037038512001695, 0.0066683557711984809, 0.00663437006725033, 0.0066016791873095646, 0.0065702372040170277, 0.0065400020416729069, 0.0065108635307023072, 0.0064827719751787008, 0.0064556489103096346, 0.0064294749739334045, 0.0064041918579862906, 0.0063797765096379475, 0.0063561452241081284, 0.0063332355647005116, 0.0063107732551857887, 0.0062890838135767823, 0.0062681377093311138, 0.0062478939330960076, 0.006228347487235269, 0.0062094530035295007, 0.006191209493530395, 0.0061735723541571745, 0.0061564910083621409, 0.0061399908130469151, 0.0061240307969425466, 0.0061085739979679704, 0.0060936143019385495, 0.0060791278562636625, 0.0060651063811740244, 0.0060515345063849894, 0.0060383817475275258, 0.0060256414416637342, 0.0060132945953525578, 0.006001320137853516, 0.0059897157218182619, 0.0059784835439909345, 0.0059676054747408204, 0.0059570523453218562, 0.0059468114790143132, 0.005936900745786477, 0.0059272841183420225, 0.0059179493267656922, 0.0059088927427078265, 0.0059000894212645223, 0.0058915398661808895, 0.0058832391282910533, 0.0058751663947858778, 0.0058673333158529599, 0.0058597031007884383, 0.0058522898890770499, 0.0058450884043782618, 0.0058380773474486563, 0.0058312597113304868, 0.0058246132585334292, 0.0058181658491049115, 0.0058118813968917916, 0.0058057466366061711, 0.0057997956463450833, 0.0057940125590031028, 0.0057883693604664291], 'loss': [0.010215595333660095, 0.010127183984101881, 0.010043109464902744, 0.0099638990631994474, 0.0098888241138123771, 0.009817422847890311, 0.0097501864256114047, 0.0096865398815037945, 0.0096233637480279306, 0.0094930478076884987, 0.0093334594926926789, 0.0091801212434259091, 0.0090295795846980047, 0.008885463388875978, 0.0087482770383999105, 0.008618874601291673, 0.0084966308183707043, 0.0083810342344115985, 0.0082716640702047515, 0.0081678410286808497, 0.0080688552886302584, 0.0079742800581744638, 0.0078838326122220234, 0.0077973337427294544, 0.0077147156929742652, 0.0076357351522148573, 0.0075600837965821592, 0.007487629288114887, 0.0074184189190528256, 0.0073523147846786758, 0.0072892147987009418, 0.0072289051470296947, 0.0071712415954458732, 0.007116051193283208, 0.0070631888082002521, 0.0070124462595496833, 0.0069636652096144317, 0.0069168301187020617, 0.0068719428886682915, 0.0068288827884527862, 0.0067876045899517195, 0.0067479607910169697, 0.0067098851916142675, 0.0066733364620862488, 0.0066381779744918903, 0.0066043453905834477, 0.0065717786137236729, 0.006540434549779579, 0.0065102726684742422, 0.0064811617815460649, 0.0064530459801610913, 0.0064258921906333727, 0.0063996926266596992, 0.0063743395968406166, 0.0063498267450569669, 0.0063260821345105956, 0.0063029175807997242, 0.0062803678888857326, 0.00625860181705226, 0.0062375589234945628, 0.0062172060209019055, 0.0061975602345620117, 0.0061785481007541878, 0.0061601694345877226, 0.0061423864244805684, 0.0061251676710667091, 0.0061085094398971749, 0.0060923909797083037, 0.0060767707175654762, 0.0060616363848536086, 0.006046972232661825, 0.0060327657619771704, 0.0060190066506888105, 0.0060056625217423717, 0.00599273012781581, 0.0059801838875902201, 0.0059680116552339787, 0.0059562266312571631, 0.00594479871911501, 0.0059337237218455548, 0.0059229864423479784, 0.0059125547560038346, 0.0059024549424808561, 0.0058926557918830783, 0.0058831305314054607, 0.0058738799455456013, 0.0058648930390301883, 0.0058561540746828967, 0.005847653583294329, 0.0058393887980865717, 0.0058313764233345914, 0.0058235490583593156, 0.0058159421277636019, 0.0058085513155227359, 0.0058013519687783004, 0.0057943529050428584, 0.005787516213133794, 0.0057808820870330017, 0.0057744280547911064, 0.0057681050428063981, 0.0057619783796081531, 0.0057560185765585395]}
[2017-10-20 01:41:37,287 AE_UNIGRAMA_4L_UNDER_02.py:131]: evaluating model ... 
[2017-10-20 01:41:37,338 AE_UNIGRAMA_4L_UNDER_02.py:135]: evaluated! 
[2017-10-20 01:41:37,338 AE_UNIGRAMA_4L_UNDER_02.py:137]: generating reports ... 
[2017-10-20 01:41:37,955 AE_UNIGRAMA_4L_UNDER_02.py:140]: done!
[2017-10-20 01:41:37,956 AE_UNIGRAMA_4L_UNDER_02.py:156]: >> experiment AE_UNIGRAMA_4L_UNDER_02 finished!
