[2017-11-13 15:14:31,959 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_UNDER_02 was already executed!
[2017-11-14 07:03:52,500 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_UNDER_02 was already executed!
[2017-11-18 14:55:42,775 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_UNDER_02 was already executed!
[2017-11-18 16:22:13,264 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:145]: The experiment AE_UNIGRAMA_4L_FULLDS_UNDER_02 was already executed!
[2017-11-18 16:45:28,058 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_FULLDS_UNDER_02
[2017-11-18 16:45:28,058 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:148]: >> Printing header log
[2017-11-18 16:45:28,058 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_FULLDS_UNDER_02
	layers = 96,76,69,63,56
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2c78fd0be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2c78fd0470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:45:28,058 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:150]: >> Loading dataset... 
[2017-11-18 16:45:30,185 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:45:30,186 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:152]: >> Executing autoencoder part ... 
[2017-11-18 16:45:30,186 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:59]: =======================================
[2017-11-18 16:45:30,186 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2c78fd0be0>, 'discard_decoder_function': True}
[2017-11-18 16:45:30,278 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:75]: training and evaluate autoencoder
[2017-11-18 16:47:06,284 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:87]: trained and evaluated!
[2017-11-18 16:47:06,285 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:90]: Training history: 
{'val_loss': [0.0092739785108571539, 0.0086090250717026258, 0.0080484072318405334, 0.0075827186536324542, 0.0072205042555854295, 0.0069336478149354761, 0.0067006162936275211, 0.0065091618421278382, 0.0063512810900908691, 0.0062196260485531145, 0.0061090632305178996, 0.0060153801953546681, 0.0059353575796348918, 0.0058660016052708309, 0.0058051257655921283, 0.0057517102549351599, 0.0057037169334007371, 0.0056606195135454852, 0.005622650511293798, 0.0055892669720022789, 0.0055590364235757585, 0.0055313710833857577, 0.005506111769630645, 0.0054838832707213804, 0.0054644078817369145, 0.0054472148266457672, 0.0054319715188102212, 0.0054184200991908935, 0.0054062596638301897, 0.0053953277343320727, 0.0053854759126930381, 0.0053765496200731643, 0.0053684267560954492, 0.0053610467402115929, 0.0053542726405357852, 0.0053480197831259979, 0.0053422554050055731, 0.0053368829974020909, 0.0053318830720227358, 0.0053271974650174322, 0.0053227702717035625, 0.0053185662931534341, 0.0053145556921328982, 0.0053107110756589393, 0.005306984139544748, 0.005303356494533445, 0.0052998174641292316, 0.0052963760027710518, 0.0052929898000567688, 0.0052895982181074943, 0.0052860733526370373, 0.0052822993676192188, 0.0052783189334409319, 0.0052741898720223531, 0.0052700703375784903, 0.0052660135055136777, 0.0052620372019615055, 0.0052581504219201712, 0.0052543382395848831, 0.0052506616096929925, 0.0052472691475908325, 0.0052439319573100475, 0.0052405947894480888, 0.0052372979977226668, 0.0052339822899834972, 0.0052305731580287044, 0.005227197414895233, 0.0052239053119562682, 0.0052206075737627278, 0.0052172909929728197, 0.0052139400474580664, 0.0052105499579865886, 0.0052071189082055483, 0.0052036050401966186, 0.0052000111483553619, 0.0051963490954073516, 0.0051926331123448733, 0.0051888939571142116, 0.0051851560429624398, 0.0051813869770802488, 0.0051776025705593982, 0.0051737835963463043, 0.005169949621370816, 0.0051660903543644596, 0.0051622032788566745, 0.0051582887343814519, 0.0051543615198461771, 0.0051504067764458344, 0.0051464309602036653, 0.0051424239351571931, 0.0051383961332487531, 0.0051343451619103074, 0.0051302586776094542, 0.0051261717334659396, 0.0051220434248749986, 0.0051178864786282962, 0.005113698879684, 0.0051094822985014356, 0.0051052407404351043, 0.0051009573938461273, 0.0050966585369370621], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096736579682580592, 0.0089398662398389919, 0.008337333012494343, 0.0078229042054973053, 0.0074129530299663895, 0.0070923772276776645, 0.0068355934394675995, 0.0066251263774156832, 0.0064523323965824187, 0.0063089485350176387, 0.0061889736989964124, 0.0060878217716318263, 0.0060017529831143173, 0.0059277056874708486, 0.0058630608136299141, 0.0058062573903089028, 0.0057559027954980843, 0.0057104785328316431, 0.0056700228298604454, 0.0056345119209402477, 0.005602844457740036, 0.0055739266505368656, 0.0055473764598249799, 0.0055235365460092585, 0.0055026475528061457, 0.0054842739950029182, 0.0054680164068332806, 0.0054535428770261449, 0.0054406343276926939, 0.0054290340033045347, 0.0054185845623597843, 0.0054091387442632647, 0.0054005433723437494, 0.0053927352060603303, 0.0053855999472582029, 0.0053790479198731946, 0.0053730048633045552, 0.0053674005794132999, 0.0053621878321860423, 0.0053573210113943065, 0.0053527340997909902, 0.0053483824488779249, 0.0053442402189976786, 0.0053402816293077757, 0.0053364601243107625, 0.0053327582943789014, 0.0053291421457809605, 0.0053256019970832633, 0.005322128457383165, 0.0053186869821807859, 0.0053151881818276538, 0.0053115108889362208, 0.0053076235314197147, 0.0053035552094790987, 0.0052994364080716271, 0.0052953728863232574, 0.005291390181014391, 0.0052875059007376534, 0.0052837263278908246, 0.0052800402378477542, 0.0052765791601742263, 0.0052732845256888124, 0.0052699853417606376, 0.0052667077057698252, 0.0052634339559102178, 0.0052600954773597951, 0.0052567240058469479, 0.0052534251475444462, 0.0052501614137750556, 0.0052468780045445253, 0.0052435654547027541, 0.0052402146016337307, 0.0052368202200656702, 0.005233358516118578, 0.0052298093649598846, 0.0052261685015048643, 0.0052224818358868382, 0.0052187634677488669, 0.0052150218151747535, 0.0052112635069932432, 0.0052074993650994923, 0.0052037125277765413, 0.0051999044072692773, 0.0051960719558883034, 0.0051922220505254578, 0.0051883411660837995, 0.005184449723185415, 0.0051805316648894477, 0.00517658850226592, 0.0051726228368907667, 0.0051686296102203214, 0.00516461839211703, 0.0051605758547341183, 0.0051565121124153655, 0.0051524244872225575, 0.0051483082852761984, 0.0051441690227792087, 0.0051400008123485543, 0.0051357997201266058, 0.0051315745576686646, 0.0051273181049099024], 'acc': [0.37535289066385402, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822264767316, 0.59383822262206665, 0.59383822265133124, 0.59383822264767316, 0.59383822262938279, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822267327968, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316]}
[2017-11-18 16:47:06,285 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:94]: done!
[2017-11-18 16:47:06,285 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:154]: >> Executing classifier part ... 
[2017-11-18 16:47:06,285 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:99]: =======================================
[2017-11-18 16:47:06,285 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2c78fd0470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:47:06,316 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:112]: training ... 
[2017-11-18 16:51:09,762 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:124]: trained!
[2017-11-18 16:51:09,762 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:127]: Training history: 
{'val_loss': [0.0092739785108571539, 0.0086090250717026258, 0.0080484072318405334, 0.0075827186536324542, 0.0072205042555854295, 0.0069336478149354761, 0.0067006162936275211, 0.0065091618421278382, 0.0063512810900908691, 0.0062196260485531145, 0.0061090632305178996, 0.0060153801953546681, 0.0059353575796348918, 0.0058660016052708309, 0.0058051257655921283, 0.0057517102549351599, 0.0057037169334007371, 0.0056606195135454852, 0.005622650511293798, 0.0055892669720022789, 0.0055590364235757585, 0.0055313710833857577, 0.005506111769630645, 0.0054838832707213804, 0.0054644078817369145, 0.0054472148266457672, 0.0054319715188102212, 0.0054184200991908935, 0.0054062596638301897, 0.0053953277343320727, 0.0053854759126930381, 0.0053765496200731643, 0.0053684267560954492, 0.0053610467402115929, 0.0053542726405357852, 0.0053480197831259979, 0.0053422554050055731, 0.0053368829974020909, 0.0053318830720227358, 0.0053271974650174322, 0.0053227702717035625, 0.0053185662931534341, 0.0053145556921328982, 0.0053107110756589393, 0.005306984139544748, 0.005303356494533445, 0.0052998174641292316, 0.0052963760027710518, 0.0052929898000567688, 0.0052895982181074943, 0.0052860733526370373, 0.0052822993676192188, 0.0052783189334409319, 0.0052741898720223531, 0.0052700703375784903, 0.0052660135055136777, 0.0052620372019615055, 0.0052581504219201712, 0.0052543382395848831, 0.0052506616096929925, 0.0052472691475908325, 0.0052439319573100475, 0.0052405947894480888, 0.0052372979977226668, 0.0052339822899834972, 0.0052305731580287044, 0.005227197414895233, 0.0052239053119562682, 0.0052206075737627278, 0.0052172909929728197, 0.0052139400474580664, 0.0052105499579865886, 0.0052071189082055483, 0.0052036050401966186, 0.0052000111483553619, 0.0051963490954073516, 0.0051926331123448733, 0.0051888939571142116, 0.0051851560429624398, 0.0051813869770802488, 0.0051776025705593982, 0.0051737835963463043, 0.005169949621370816, 0.0051660903543644596, 0.0051622032788566745, 0.0051582887343814519, 0.0051543615198461771, 0.0051504067764458344, 0.0051464309602036653, 0.0051424239351571931, 0.0051383961332487531, 0.0051343451619103074, 0.0051302586776094542, 0.0051261717334659396, 0.0051220434248749986, 0.0051178864786282962, 0.005113698879684, 0.0051094822985014356, 0.0051052407404351043, 0.0051009573938461273, 0.0050966585369370621], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096736579682580592, 0.0089398662398389919, 0.008337333012494343, 0.0078229042054973053, 0.0074129530299663895, 0.0070923772276776645, 0.0068355934394675995, 0.0066251263774156832, 0.0064523323965824187, 0.0063089485350176387, 0.0061889736989964124, 0.0060878217716318263, 0.0060017529831143173, 0.0059277056874708486, 0.0058630608136299141, 0.0058062573903089028, 0.0057559027954980843, 0.0057104785328316431, 0.0056700228298604454, 0.0056345119209402477, 0.005602844457740036, 0.0055739266505368656, 0.0055473764598249799, 0.0055235365460092585, 0.0055026475528061457, 0.0054842739950029182, 0.0054680164068332806, 0.0054535428770261449, 0.0054406343276926939, 0.0054290340033045347, 0.0054185845623597843, 0.0054091387442632647, 0.0054005433723437494, 0.0053927352060603303, 0.0053855999472582029, 0.0053790479198731946, 0.0053730048633045552, 0.0053674005794132999, 0.0053621878321860423, 0.0053573210113943065, 0.0053527340997909902, 0.0053483824488779249, 0.0053442402189976786, 0.0053402816293077757, 0.0053364601243107625, 0.0053327582943789014, 0.0053291421457809605, 0.0053256019970832633, 0.005322128457383165, 0.0053186869821807859, 0.0053151881818276538, 0.0053115108889362208, 0.0053076235314197147, 0.0053035552094790987, 0.0052994364080716271, 0.0052953728863232574, 0.005291390181014391, 0.0052875059007376534, 0.0052837263278908246, 0.0052800402378477542, 0.0052765791601742263, 0.0052732845256888124, 0.0052699853417606376, 0.0052667077057698252, 0.0052634339559102178, 0.0052600954773597951, 0.0052567240058469479, 0.0052534251475444462, 0.0052501614137750556, 0.0052468780045445253, 0.0052435654547027541, 0.0052402146016337307, 0.0052368202200656702, 0.005233358516118578, 0.0052298093649598846, 0.0052261685015048643, 0.0052224818358868382, 0.0052187634677488669, 0.0052150218151747535, 0.0052112635069932432, 0.0052074993650994923, 0.0052037125277765413, 0.0051999044072692773, 0.0051960719558883034, 0.0051922220505254578, 0.0051883411660837995, 0.005184449723185415, 0.0051805316648894477, 0.00517658850226592, 0.0051726228368907667, 0.0051686296102203214, 0.00516461839211703, 0.0051605758547341183, 0.0051565121124153655, 0.0051524244872225575, 0.0051483082852761984, 0.0051441690227792087, 0.0051400008123485543, 0.0051357997201266058, 0.0051315745576686646, 0.0051273181049099024], 'acc': [0.37535289066385402, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822264767316, 0.59383822262206665, 0.59383822265133124, 0.59383822264767316, 0.59383822262938279, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822267327968, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316]}
[2017-11-18 16:51:09,763 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:131]: evaluating model ... 
[2017-11-18 16:51:09,846 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:135]: evaluated! 
[2017-11-18 16:51:09,847 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:137]: generating reports ... 
[2017-11-18 16:51:10,671 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:140]: done!
[2017-11-18 16:51:10,671 AE_UNIGRAMA_4L_FULLDS_UNDER_02.py:156]: >> experiment AE_UNIGRAMA_4L_FULLDS_UNDER_02 finished!
