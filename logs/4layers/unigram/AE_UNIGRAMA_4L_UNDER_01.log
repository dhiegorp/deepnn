[2017-10-20 01:36:26,129 AE_UNIGRAMA_4L_UNDER_01.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_4L_UNDER_01
[2017-10-20 01:36:26,129 AE_UNIGRAMA_4L_UNDER_01.py:148]: >> Printing header log
[2017-10-20 01:36:26,129 AE_UNIGRAMA_4L_UNDER_01.py:37]: 
	=======================================
	network_name = AE_UNIGRAMA_4L_UNDER_01
	layers = 96,28,26,24,22,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/4layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/4layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/4layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/4layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/4layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2e16c2eb70>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2e16c2ecf8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:36:26,129 AE_UNIGRAMA_4L_UNDER_01.py:150]: >> Loading dataset... 
[2017-10-20 01:36:26,696 AE_UNIGRAMA_4L_UNDER_01.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:36:26,696 AE_UNIGRAMA_4L_UNDER_01.py:152]: >> Executing autoencoder part ... 
[2017-10-20 01:36:26,696 AE_UNIGRAMA_4L_UNDER_01.py:59]: =======================================
[2017-10-20 01:36:26,696 AE_UNIGRAMA_4L_UNDER_01.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2e16c2eb70>, 'discard_decoder_function': True}
[2017-10-20 01:36:26,804 AE_UNIGRAMA_4L_UNDER_01.py:75]: training and evaluate autoencoder
[2017-10-20 01:36:53,061 AE_UNIGRAMA_4L_UNDER_01.py:87]: trained and evaluated!
[2017-10-20 01:36:53,062 AE_UNIGRAMA_4L_UNDER_01.py:90]: Training history: 
{'val_loss': [0.010282348010508988, 0.010217308122179986, 0.010152969762101271, 0.010090651153327142, 0.01003088627952293, 0.0099738409438042391, 0.0099192565535524083, 0.009866983196992413, 0.0098173401446590633, 0.0097703671006686629, 0.009725883540777025, 0.0096836311458765797, 0.0096436487026097164, 0.009605813044431484, 0.0095699592026082109, 0.0095359791921915613, 0.0095037047415417811, 0.0094730531949148294, 0.0094439869878128122, 0.009416313474949407, 0.0093899785322881547, 0.0093648941377281695, 0.0093410284808909585, 0.0093182526238013378, 0.0092965177187633776, 0.0092757631259447575, 0.009255915862892419, 0.009236912932039194, 0.0092187485688791839, 0.0092013698749825856, 0.0091846985153881591, 0.0091687311525681641, 0.0091534055402453952, 0.009138700597292871, 0.0091245634391294538, 0.009110990319691847, 0.0090979368332427223, 0.0090853829926994655, 0.0090733147659044725, 0.009061697043035331, 0.0090504822193136006, 0.0090396738642321197, 0.0090292494910246372, 0.0090192201682349118, 0.0090095207275178793, 0.009000166790165201, 0.0089911196803237874, 0.0089823701886328627, 0.0089739018871161577, 0.0089657123799550039, 0.0089577904739676795, 0.0089501206690383219, 0.0089426956322999698, 0.0089354917794798386, 0.0089285068947918805, 0.0089217255092797227, 0.0089151298931927931, 0.0089086794041678807, 0.0089022821528650133, 0.0088959451467075755, 0.0088896525601361315, 0.0088834890673373263, 0.0088774937596241346, 0.0088716826737480978, 0.0088660348913040306, 0.0088605486223522611, 0.0088552189713904852, 0.0088500335923357969, 0.0088449891788199494, 0.008840091699616616, 0.008835315652413217, 0.0088306772436074158, 0.0088261599794417951, 0.0088217619176413926, 0.0088174799180219168, 0.0088133098606061767, 0.0088092499658409991, 0.0088052968373418302, 0.0088014482108522973, 0.0087976964280618609, 0.0087940398929121331, 0.0087904726262429383, 0.0087869962344991667, 0.0087836051297453706, 0.00878029878573236, 0.0087770714206434099, 0.0087739190027865555, 0.0087708508142280532, 0.0087678531499849593, 0.0087649284335732675, 0.0087620776724831994, 0.0087592919481758961, 0.0087565741706016331, 0.0087539229860536232, 0.0087513322024484995, 0.0087488048976515752, 0.008746331408758367, 0.0087439162850546127, 0.0087415557008472082, 0.0087392503122165517, 0.0087369984763650196, 0.008734799410843163], 'loss': [0.010310491996908306, 0.010247275026626175, 0.01018355006137983, 0.010120953583761309, 0.010060629134822566, 0.010002927139135835, 0.0099478514610887598, 0.0098950965684903268, 0.0098448384028860005, 0.0097972549350397609, 0.0097522639412462673, 0.0097096350465311031, 0.00966928338491173, 0.0096311226255903232, 0.0095950347911188706, 0.009560859519427329, 0.0095284592163346633, 0.0094977034239834557, 0.0094685320963953708, 0.0094408600825241686, 0.0094145381274806546, 0.0093894762221149088, 0.0093656194412917101, 0.0093429368991031561, 0.009321288551423142, 0.009300638964490137, 0.0092809261129075723, 0.0092620906553425222, 0.0092440527636550949, 0.0092268297065234879, 0.0092103407714234295, 0.0091945420156136267, 0.0091794080672798241, 0.0091648880150752999, 0.0091509621249215318, 0.0091375871009085168, 0.0091247389141124458, 0.0091123971498508951, 0.0091005303761300758, 0.0090891189241270095, 0.0090781415336992598, 0.0090675509088863314, 0.0090573492351765997, 0.0090475113388121167, 0.0090380492829102346, 0.0090288994971207109, 0.0090200882130282451, 0.0090115610012108001, 0.0090033178668201298, 0.0089953455875943101, 0.0089876414010485548, 0.0089801842685658367, 0.0089729720132440318, 0.0089659902731388276, 0.0089592175328097757, 0.0089526496565435366, 0.0089462724821693564, 0.0089400607180113653, 0.0089339312548350168, 0.0089278629670158875, 0.0089218399344903974, 0.0089158850236032809, 0.008910084376827148, 0.0089044475443684108, 0.0088989871514579891, 0.008893681251625379, 0.0088885352238737957, 0.0088835312259631354, 0.0088786634060736801, 0.0088739355204062523, 0.0088693452249129414, 0.0088648711661473336, 0.0088605273379895617, 0.0088562963074777269, 0.0088521812326368115, 0.0088481732123813599, 0.0088442771981190379, 0.0088404835778223868, 0.0088367868992188046, 0.008833192618587813, 0.0088296853499309595, 0.0088262736297040241, 0.0088229419551354715, 0.0088196946565604461, 0.0088165374335357222, 0.0088134533591160916, 0.0088104418494361417, 0.0088075097683489728, 0.008804651644119801, 0.0088018667721032149, 0.0087991363403845876, 0.0087964847316414803, 0.0087938916828819921, 0.0087913642686087076, 0.0087889024813802025, 0.0087864923261715064, 0.0087841462873989411, 0.0087818505686662572, 0.0087796061190409599, 0.0087774154388408163, 0.0087752734896507662, 0.0087731812085175553]}
[2017-10-20 01:36:53,062 AE_UNIGRAMA_4L_UNDER_01.py:94]: done!
[2017-10-20 01:36:53,062 AE_UNIGRAMA_4L_UNDER_01.py:154]: >> Executing classifier part ... 
[2017-10-20 01:36:53,062 AE_UNIGRAMA_4L_UNDER_01.py:99]: =======================================
[2017-10-20 01:36:53,062 AE_UNIGRAMA_4L_UNDER_01.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2e16c2ecf8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:36:53,096 AE_UNIGRAMA_4L_UNDER_01.py:112]: training ... 
[2017-10-20 01:37:42,180 AE_UNIGRAMA_4L_UNDER_01.py:124]: trained!
[2017-10-20 01:37:42,181 AE_UNIGRAMA_4L_UNDER_01.py:127]: Training history: 
{'val_loss': [0.010282348010508988, 0.010217308122179986, 0.010152969762101271, 0.010090651153327142, 0.01003088627952293, 0.0099738409438042391, 0.0099192565535524083, 0.009866983196992413, 0.0098173401446590633, 0.0097703671006686629, 0.009725883540777025, 0.0096836311458765797, 0.0096436487026097164, 0.009605813044431484, 0.0095699592026082109, 0.0095359791921915613, 0.0095037047415417811, 0.0094730531949148294, 0.0094439869878128122, 0.009416313474949407, 0.0093899785322881547, 0.0093648941377281695, 0.0093410284808909585, 0.0093182526238013378, 0.0092965177187633776, 0.0092757631259447575, 0.009255915862892419, 0.009236912932039194, 0.0092187485688791839, 0.0092013698749825856, 0.0091846985153881591, 0.0091687311525681641, 0.0091534055402453952, 0.009138700597292871, 0.0091245634391294538, 0.009110990319691847, 0.0090979368332427223, 0.0090853829926994655, 0.0090733147659044725, 0.009061697043035331, 0.0090504822193136006, 0.0090396738642321197, 0.0090292494910246372, 0.0090192201682349118, 0.0090095207275178793, 0.009000166790165201, 0.0089911196803237874, 0.0089823701886328627, 0.0089739018871161577, 0.0089657123799550039, 0.0089577904739676795, 0.0089501206690383219, 0.0089426956322999698, 0.0089354917794798386, 0.0089285068947918805, 0.0089217255092797227, 0.0089151298931927931, 0.0089086794041678807, 0.0089022821528650133, 0.0088959451467075755, 0.0088896525601361315, 0.0088834890673373263, 0.0088774937596241346, 0.0088716826737480978, 0.0088660348913040306, 0.0088605486223522611, 0.0088552189713904852, 0.0088500335923357969, 0.0088449891788199494, 0.008840091699616616, 0.008835315652413217, 0.0088306772436074158, 0.0088261599794417951, 0.0088217619176413926, 0.0088174799180219168, 0.0088133098606061767, 0.0088092499658409991, 0.0088052968373418302, 0.0088014482108522973, 0.0087976964280618609, 0.0087940398929121331, 0.0087904726262429383, 0.0087869962344991667, 0.0087836051297453706, 0.00878029878573236, 0.0087770714206434099, 0.0087739190027865555, 0.0087708508142280532, 0.0087678531499849593, 0.0087649284335732675, 0.0087620776724831994, 0.0087592919481758961, 0.0087565741706016331, 0.0087539229860536232, 0.0087513322024484995, 0.0087488048976515752, 0.008746331408758367, 0.0087439162850546127, 0.0087415557008472082, 0.0087392503122165517, 0.0087369984763650196, 0.008734799410843163], 'loss': [0.010310491996908306, 0.010247275026626175, 0.01018355006137983, 0.010120953583761309, 0.010060629134822566, 0.010002927139135835, 0.0099478514610887598, 0.0098950965684903268, 0.0098448384028860005, 0.0097972549350397609, 0.0097522639412462673, 0.0097096350465311031, 0.00966928338491173, 0.0096311226255903232, 0.0095950347911188706, 0.009560859519427329, 0.0095284592163346633, 0.0094977034239834557, 0.0094685320963953708, 0.0094408600825241686, 0.0094145381274806546, 0.0093894762221149088, 0.0093656194412917101, 0.0093429368991031561, 0.009321288551423142, 0.009300638964490137, 0.0092809261129075723, 0.0092620906553425222, 0.0092440527636550949, 0.0092268297065234879, 0.0092103407714234295, 0.0091945420156136267, 0.0091794080672798241, 0.0091648880150752999, 0.0091509621249215318, 0.0091375871009085168, 0.0091247389141124458, 0.0091123971498508951, 0.0091005303761300758, 0.0090891189241270095, 0.0090781415336992598, 0.0090675509088863314, 0.0090573492351765997, 0.0090475113388121167, 0.0090380492829102346, 0.0090288994971207109, 0.0090200882130282451, 0.0090115610012108001, 0.0090033178668201298, 0.0089953455875943101, 0.0089876414010485548, 0.0089801842685658367, 0.0089729720132440318, 0.0089659902731388276, 0.0089592175328097757, 0.0089526496565435366, 0.0089462724821693564, 0.0089400607180113653, 0.0089339312548350168, 0.0089278629670158875, 0.0089218399344903974, 0.0089158850236032809, 0.008910084376827148, 0.0089044475443684108, 0.0088989871514579891, 0.008893681251625379, 0.0088885352238737957, 0.0088835312259631354, 0.0088786634060736801, 0.0088739355204062523, 0.0088693452249129414, 0.0088648711661473336, 0.0088605273379895617, 0.0088562963074777269, 0.0088521812326368115, 0.0088481732123813599, 0.0088442771981190379, 0.0088404835778223868, 0.0088367868992188046, 0.008833192618587813, 0.0088296853499309595, 0.0088262736297040241, 0.0088229419551354715, 0.0088196946565604461, 0.0088165374335357222, 0.0088134533591160916, 0.0088104418494361417, 0.0088075097683489728, 0.008804651644119801, 0.0088018667721032149, 0.0087991363403845876, 0.0087964847316414803, 0.0087938916828819921, 0.0087913642686087076, 0.0087889024813802025, 0.0087864923261715064, 0.0087841462873989411, 0.0087818505686662572, 0.0087796061190409599, 0.0087774154388408163, 0.0087752734896507662, 0.0087731812085175553]}
[2017-10-20 01:37:42,181 AE_UNIGRAMA_4L_UNDER_01.py:131]: evaluating model ... 
[2017-10-20 01:37:42,226 AE_UNIGRAMA_4L_UNDER_01.py:135]: evaluated! 
[2017-10-20 01:37:42,227 AE_UNIGRAMA_4L_UNDER_01.py:137]: generating reports ... 
[2017-10-20 01:37:42,853 AE_UNIGRAMA_4L_UNDER_01.py:140]: done!
[2017-10-20 01:37:42,854 AE_UNIGRAMA_4L_UNDER_01.py:156]: >> experiment AE_UNIGRAMA_4L_UNDER_01 finished!
