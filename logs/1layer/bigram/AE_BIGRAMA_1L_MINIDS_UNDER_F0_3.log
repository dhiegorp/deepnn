[2017-12-14 09:31:57,846 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_3
[2017-12-14 09:31:57,846 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:146]: >> Printing header log
[2017-12-14 09:31:57,846 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_3
	layers = 9216,2765
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0715bf4eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0715bd7400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 09:31:57,846 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:148]: >> Loading dataset... 
[2017-12-14 09:32:19,791 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 09:32:19,791 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:150]: >> Executing autoencoder part ... 
[2017-12-14 09:32:19,792 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:57]: =======================================
[2017-12-14 09:32:19,792 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0715bf4eb8>, 'discard_decoder_function': True}
[2017-12-14 09:32:19,836 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:73]: training and evaluate autoencoder
[2017-12-14 10:18:55,066 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_3
[2017-12-14 10:18:55,067 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:146]: >> Printing header log
[2017-12-14 10:18:55,067 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_3
	layers = 9216,2765
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f18f820aeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f18f81ed400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 10:18:55,067 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:148]: >> Loading dataset... 
[2017-12-14 10:19:17,911 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 10:19:17,912 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:150]: >> Executing autoencoder part ... 
[2017-12-14 10:19:17,912 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:57]: =======================================
[2017-12-14 10:19:17,912 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f18f820aeb8>, 'discard_decoder_function': True}
[2017-12-14 10:19:17,963 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:73]: training and evaluate autoencoder
[2017-12-14 15:13:18,988 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:85]: trained and evaluated!
[2017-12-14 15:13:19,084 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:88]: Training history: 
{'val_loss': [0.00011415445513314515, 0.0001141504307062404, 0.00011414641764913674, 0.00011414238546359414, 0.00011413833021666255, 0.00011413427203789545, 0.00011413021646917704, 0.0001141261130078531, 0.00011412197701030591, 0.00011411785874678811, 0.00011411371865539745, 0.00011410954904900429, 0.00011410538321466778, 0.00011410116988102075, 0.00011409696235741358, 0.00011409268804516355, 0.00011408841307146283, 0.00011408413148325518, 0.00011407984049172147, 0.00011407554361863972, 0.00011407123725284669, 0.00011406692091166213, 0.00011406252937962322, 0.00011405812892693847, 0.00011405372185974681, 0.00011404929067642045, 0.00011404479940834339, 0.00011404031083970022, 0.00011403583437381702, 0.00011403136582746507, 0.0001140268215181933, 0.00011402224998218087, 0.0001140176840953149, 0.00011401309702414974, 0.00011400850816527999, 0.00011400387818920506, 0.00011399926095946373, 0.00011399462494094735, 0.00011398998000178514, 0.0001139852901018529, 0.0001139806301996034, 0.00011397595132980839, 0.00011397123388134868, 0.00011396652583621502, 0.00011396176580463237, 0.00011395700650600859, 0.00011395222015941461, 0.00011394740855255501, 0.00011394253759390356, 0.00011393763190015226, 0.00011393272432931115, 0.00011392782836067273, 0.00011392292479428986, 0.00011391795504708369, 0.00011391294797260603, 0.00011390792053617327, 0.00011390288289194739, 0.00011389782694162668, 0.00011389268752337944, 0.00011388755743695006, 0.00011388240414611533, 0.00011387718390574432, 0.00011387194609223734, 0.00011386670491784577, 0.00011386141527878322, 0.0001138560653046913, 0.00011385069931276642, 0.00011384534107947938, 0.00011383993616922591, 0.00011383450517636273, 0.0001138290601321416, 0.00011382356825006064, 0.00011381803868316727, 0.00011381250250176698, 0.00011380694474277249, 0.00011380137783073059, 0.00011379576488529591, 0.00011379015914431066, 0.00011378455789046389, 0.00011377894315732464, 0.00011377329302763484, 0.00011376758756848849, 0.00011376188316408782, 0.00011375615718209297, 0.00011375044927379135, 0.00011374471757114186, 0.00011373896674005342, 0.00011373319007663391, 0.00011372738014403228, 0.00011372156563490693, 0.00011371575480845301, 0.00011370994716411323, 0.0001137041211242934, 0.00011369826991359317, 0.00011369237186503311, 0.0001136864775885297, 0.00011368058518911609, 0.00011367468379754847, 0.00011366878691099639, 0.00011366284375864994, 0.00011365692838723257, 0.00011365095727518658, 0.00011364495755986743, 0.00011363895752276145, 0.00011363294472144482, 0.00011362688754930067, 0.00011362080479510408, 0.0001136147318554056, 0.00011360863635487538, 0.00011360256790231538, 0.00011359645629456696, 0.00011359037312919832, 0.00011358428865880534, 0.0001135781956074304, 0.00011357207107457792, 0.00011356600221084586, 0.00011355990858740547, 0.00011355381029805613, 0.0001135477165852305, 0.00011354162802099403, 0.00011353551968474499, 0.0001135294425618178, 0.00011352333569148652, 0.00011351721982900123, 0.00011351115922446429, 0.00011350505676976329, 0.00011349896223459356, 0.00011349285749163071, 0.00011348677171621338, 0.00011348069623797441, 0.00011347458911736447, 0.0001134685199318456, 0.00011346241191738337, 0.00011345631992075413, 0.00011345021231746398, 0.00011344407437682719, 0.00011343794723392604, 0.0001134318132977475, 0.00011342567576828278, 0.00011341957020297583, 0.00011341352726096008, 0.00011340742087330903, 0.00011340129650134996, 0.00011339518750365023, 0.0001133890830824742, 0.00011338297310153695, 0.00011337689574620817, 0.00011337083187017188, 0.00011336475083217167, 0.00011335865188137163, 0.00011335254787136767, 0.0001133464674769411, 0.00011334037033172269, 0.00011333429412052483, 0.00011332817048152465, 0.00011332206892067594, 0.00011331598101789017, 0.00011330985991743047, 0.00011330371094665648, 0.00011329763995555598, 0.00011329155548516299, 0.00011328546602707425, 0.00011327940999906103, 0.00011327335184367937, 0.00011326724799456881, 0.00011326117782581241, 0.00011325510479672869, 0.00011324903258998908, 0.00011324296642569092, 0.00011323687280225053, 0.00011323080508264939, 0.00011322474587252203, 0.00011321865682560534, 0.00011321257848703905, 0.00011320650472499646, 0.00011320042441995513, 0.0001131943593997879, 0.00011318826282663496, 0.00011318218865342031, 0.00011317613491366894, 0.00011317007799180343, 0.00011316398256278141, 0.00011315793879842157, 0.00011315185236155355, 0.00011314581955582274, 0.00011313978265624846, 0.0001131337414304291, 0.00011312766913430427, 0.00011312159676667124, 0.00011311555332409821, 0.00011310951912395784, 0.00011310349302211919, 0.00011309743184551679, 0.00011309138988673857, 0.00011308535511453272, 0.00011307931004514854, 0.00011307326685285415, 0.00011306724589960467, 0.00011306118758332959, 0.00011305515420553332], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011487284310542028, 0.00011486871033779524, 0.00011486455368038103, 0.00011486041178818373, 0.00011485625638687947, 0.00011485207358815825, 0.00011484789512657138, 0.00011484371649908321, 0.00011483951016607563, 0.00011483526408785336, 0.00011483103033372865, 0.00011482675417996822, 0.0001148224514582974, 0.00011481817340852195, 0.00011481384307613251, 0.00011480949307258729, 0.00011480508339196953, 0.00011480065610211234, 0.00011479622191550052, 0.00011479178275184931, 0.00011478732159442393, 0.0001147828440127685, 0.0001147783369480796, 0.00011477378141650693, 0.0001147692183008742, 0.00011476464023042307, 0.00011476004026099852, 0.00011475538170471004, 0.00011475073386090641, 0.00011474608926402848, 0.00011474144807997757, 0.00011473676909412734, 0.00011473204014828149, 0.00011472730935382102, 0.00011472254955033084, 0.00011471779958241852, 0.0001147130223829906, 0.00011470824947329662, 0.00011470345497273169, 0.00011469864613355323, 0.00011469377866011046, 0.00011468892573858293, 0.00011468404565664032, 0.00011467914223001287, 0.0001146742532367997, 0.00011466930748163707, 0.00011466436957123655, 0.00011465941177637859, 0.00011465441890524288, 0.00011464937650071493, 0.00011464430226683496, 0.00011463922139690242, 0.00011463414538550837, 0.00011462905515400172, 0.00011462389647635306, 0.00011461872360229201, 0.00011461352890035812, 0.00011460833571523622, 0.00011460312563188052, 0.00011459785899987705, 0.00011459260068663944, 0.0001145873299782037, 0.00011458201066068304, 0.00011457665749929438, 0.00011457128040071619, 0.00011456586346212253, 0.00011456038170351558, 0.00011455487058037613, 0.00011454934293820586, 0.00011454375497905798, 0.00011453813232283535, 0.00011453252656484654, 0.00011452685620014614, 0.00011452116682789522, 0.00011451548532410661, 0.00011450977737090857, 0.00011450404604932549, 0.00011449826929448263, 0.00011449250398683043, 0.00011448673896358049, 0.00011448094410179426, 0.00011447513288687853, 0.00011446928043363628, 0.0001144634284069974, 0.00011445754997834946, 0.00011445168697852369, 0.00011444579705528472, 0.00011443987042045505, 0.00011443391579570376, 0.00011442792611837491, 0.00011442192869108468, 0.00011441593529282635, 0.00011440993151388582, 0.00011440390282604807, 0.00011439785565206393, 0.00011439179724419083, 0.00011438574222544457, 0.00011437971121498842, 0.00011437366150508419, 0.0001143676151843068, 0.00011436153554106555, 0.00011435548173102887, 0.00011434936964223071, 0.00011434322084184184, 0.00011433708962699223, 0.00011433095819884092, 0.00011432481681661079, 0.00011431867185565233, 0.00011431253111332728, 0.00011430636458519804, 0.00011430021689871799, 0.00011429401842273578, 0.00011428785744045045, 0.00011428169273723566, 0.0001142755012528088, 0.00011426928658959841, 0.00011426312548881215, 0.00011425693966873014, 0.00011425075809098174, 0.00011424457217609898, 0.00011423839057465038, 0.00011423218901764377, 0.00011422601981139332, 0.00011421982154871279, 0.00011421361335565363, 0.00011420745991002799, 0.0001142012700135137, 0.00011419508521253977, 0.00011418888517234517, 0.00011418270916414086, 0.00011417654130880111, 0.00011417033766617798, 0.00011416415466641832, 0.0001141579344810642, 0.00011415173299515814, 0.00011414551008428244, 0.0001141392426407541, 0.0001141329929960667, 0.00011412673102728173, 0.00011412047230542246, 0.00011411424517591336, 0.00011410808170510832, 0.00011410185531030503, 0.00011409560184988742, 0.00011408937372497043, 0.00011408314180802341, 0.00011407690100350603, 0.0001140706984984919, 0.00011406449890860086, 0.000114058278628446, 0.00011405204299056952, 0.00011404580360806338, 0.00011403958849454942, 0.00011403335269077162, 0.00011402713963917399, 0.00011402087970860515, 0.00011401464186661121, 0.00011400841625391412, 0.0001140021566551479, 0.00011399586719414522, 0.00011398965824268006, 0.00011398343201377809, 0.0001139772034859579, 0.00011397100982111378, 0.00011396481380995108, 0.00011395858333871552, 0.00011395237611736404, 0.00011394617339904824, 0.00011393997098883486, 0.000113933768768223, 0.00011392754841696755, 0.00011392134930108027, 0.00011391515812475587, 0.00011390894071232369, 0.00011390272749482475, 0.00011389652503721101, 0.00011389031902456911, 0.0001138841203352852, 0.00011387789097795845, 0.00011387168664802988, 0.00011386550341126834, 0.00011385932095661298, 0.00011385309302129749, 0.00011384691924091083, 0.00011384069912665726, 0.00011383453532404961, 0.00011382837156884233, 0.00011382219852316147, 0.00011381599528344154, 0.00011380979161711822, 0.00011380361861883775, 0.00011379745626194154, 0.00011379130286371627, 0.00011378510834566539, 0.00011377893767000331, 0.00011377276983836375, 0.00011376659283475155, 0.00011376042033417503, 0.00011375426911636702, 0.00011374807926725312], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-14 15:13:19,084 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:92]: done!
[2017-12-14 15:13:19,084 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:152]: >> Executing classifier part ... 
[2017-12-14 15:13:19,085 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:97]: =======================================
[2017-12-14 15:13:19,085 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f18f81ed400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-14 15:13:19,502 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:110]: training ... 
[2017-12-14 17:57:31,968 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:122]: trained!
[2017-12-14 17:57:31,970 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:125]: Training history: 
{'val_loss': [0.00011415445513314515, 0.0001141504307062404, 0.00011414641764913674, 0.00011414238546359414, 0.00011413833021666255, 0.00011413427203789545, 0.00011413021646917704, 0.0001141261130078531, 0.00011412197701030591, 0.00011411785874678811, 0.00011411371865539745, 0.00011410954904900429, 0.00011410538321466778, 0.00011410116988102075, 0.00011409696235741358, 0.00011409268804516355, 0.00011408841307146283, 0.00011408413148325518, 0.00011407984049172147, 0.00011407554361863972, 0.00011407123725284669, 0.00011406692091166213, 0.00011406252937962322, 0.00011405812892693847, 0.00011405372185974681, 0.00011404929067642045, 0.00011404479940834339, 0.00011404031083970022, 0.00011403583437381702, 0.00011403136582746507, 0.0001140268215181933, 0.00011402224998218087, 0.0001140176840953149, 0.00011401309702414974, 0.00011400850816527999, 0.00011400387818920506, 0.00011399926095946373, 0.00011399462494094735, 0.00011398998000178514, 0.0001139852901018529, 0.0001139806301996034, 0.00011397595132980839, 0.00011397123388134868, 0.00011396652583621502, 0.00011396176580463237, 0.00011395700650600859, 0.00011395222015941461, 0.00011394740855255501, 0.00011394253759390356, 0.00011393763190015226, 0.00011393272432931115, 0.00011392782836067273, 0.00011392292479428986, 0.00011391795504708369, 0.00011391294797260603, 0.00011390792053617327, 0.00011390288289194739, 0.00011389782694162668, 0.00011389268752337944, 0.00011388755743695006, 0.00011388240414611533, 0.00011387718390574432, 0.00011387194609223734, 0.00011386670491784577, 0.00011386141527878322, 0.0001138560653046913, 0.00011385069931276642, 0.00011384534107947938, 0.00011383993616922591, 0.00011383450517636273, 0.0001138290601321416, 0.00011382356825006064, 0.00011381803868316727, 0.00011381250250176698, 0.00011380694474277249, 0.00011380137783073059, 0.00011379576488529591, 0.00011379015914431066, 0.00011378455789046389, 0.00011377894315732464, 0.00011377329302763484, 0.00011376758756848849, 0.00011376188316408782, 0.00011375615718209297, 0.00011375044927379135, 0.00011374471757114186, 0.00011373896674005342, 0.00011373319007663391, 0.00011372738014403228, 0.00011372156563490693, 0.00011371575480845301, 0.00011370994716411323, 0.0001137041211242934, 0.00011369826991359317, 0.00011369237186503311, 0.0001136864775885297, 0.00011368058518911609, 0.00011367468379754847, 0.00011366878691099639, 0.00011366284375864994, 0.00011365692838723257, 0.00011365095727518658, 0.00011364495755986743, 0.00011363895752276145, 0.00011363294472144482, 0.00011362688754930067, 0.00011362080479510408, 0.0001136147318554056, 0.00011360863635487538, 0.00011360256790231538, 0.00011359645629456696, 0.00011359037312919832, 0.00011358428865880534, 0.0001135781956074304, 0.00011357207107457792, 0.00011356600221084586, 0.00011355990858740547, 0.00011355381029805613, 0.0001135477165852305, 0.00011354162802099403, 0.00011353551968474499, 0.0001135294425618178, 0.00011352333569148652, 0.00011351721982900123, 0.00011351115922446429, 0.00011350505676976329, 0.00011349896223459356, 0.00011349285749163071, 0.00011348677171621338, 0.00011348069623797441, 0.00011347458911736447, 0.0001134685199318456, 0.00011346241191738337, 0.00011345631992075413, 0.00011345021231746398, 0.00011344407437682719, 0.00011343794723392604, 0.0001134318132977475, 0.00011342567576828278, 0.00011341957020297583, 0.00011341352726096008, 0.00011340742087330903, 0.00011340129650134996, 0.00011339518750365023, 0.0001133890830824742, 0.00011338297310153695, 0.00011337689574620817, 0.00011337083187017188, 0.00011336475083217167, 0.00011335865188137163, 0.00011335254787136767, 0.0001133464674769411, 0.00011334037033172269, 0.00011333429412052483, 0.00011332817048152465, 0.00011332206892067594, 0.00011331598101789017, 0.00011330985991743047, 0.00011330371094665648, 0.00011329763995555598, 0.00011329155548516299, 0.00011328546602707425, 0.00011327940999906103, 0.00011327335184367937, 0.00011326724799456881, 0.00011326117782581241, 0.00011325510479672869, 0.00011324903258998908, 0.00011324296642569092, 0.00011323687280225053, 0.00011323080508264939, 0.00011322474587252203, 0.00011321865682560534, 0.00011321257848703905, 0.00011320650472499646, 0.00011320042441995513, 0.0001131943593997879, 0.00011318826282663496, 0.00011318218865342031, 0.00011317613491366894, 0.00011317007799180343, 0.00011316398256278141, 0.00011315793879842157, 0.00011315185236155355, 0.00011314581955582274, 0.00011313978265624846, 0.0001131337414304291, 0.00011312766913430427, 0.00011312159676667124, 0.00011311555332409821, 0.00011310951912395784, 0.00011310349302211919, 0.00011309743184551679, 0.00011309138988673857, 0.00011308535511453272, 0.00011307931004514854, 0.00011307326685285415, 0.00011306724589960467, 0.00011306118758332959, 0.00011305515420553332], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011487284310542028, 0.00011486871033779524, 0.00011486455368038103, 0.00011486041178818373, 0.00011485625638687947, 0.00011485207358815825, 0.00011484789512657138, 0.00011484371649908321, 0.00011483951016607563, 0.00011483526408785336, 0.00011483103033372865, 0.00011482675417996822, 0.0001148224514582974, 0.00011481817340852195, 0.00011481384307613251, 0.00011480949307258729, 0.00011480508339196953, 0.00011480065610211234, 0.00011479622191550052, 0.00011479178275184931, 0.00011478732159442393, 0.0001147828440127685, 0.0001147783369480796, 0.00011477378141650693, 0.0001147692183008742, 0.00011476464023042307, 0.00011476004026099852, 0.00011475538170471004, 0.00011475073386090641, 0.00011474608926402848, 0.00011474144807997757, 0.00011473676909412734, 0.00011473204014828149, 0.00011472730935382102, 0.00011472254955033084, 0.00011471779958241852, 0.0001147130223829906, 0.00011470824947329662, 0.00011470345497273169, 0.00011469864613355323, 0.00011469377866011046, 0.00011468892573858293, 0.00011468404565664032, 0.00011467914223001287, 0.0001146742532367997, 0.00011466930748163707, 0.00011466436957123655, 0.00011465941177637859, 0.00011465441890524288, 0.00011464937650071493, 0.00011464430226683496, 0.00011463922139690242, 0.00011463414538550837, 0.00011462905515400172, 0.00011462389647635306, 0.00011461872360229201, 0.00011461352890035812, 0.00011460833571523622, 0.00011460312563188052, 0.00011459785899987705, 0.00011459260068663944, 0.0001145873299782037, 0.00011458201066068304, 0.00011457665749929438, 0.00011457128040071619, 0.00011456586346212253, 0.00011456038170351558, 0.00011455487058037613, 0.00011454934293820586, 0.00011454375497905798, 0.00011453813232283535, 0.00011453252656484654, 0.00011452685620014614, 0.00011452116682789522, 0.00011451548532410661, 0.00011450977737090857, 0.00011450404604932549, 0.00011449826929448263, 0.00011449250398683043, 0.00011448673896358049, 0.00011448094410179426, 0.00011447513288687853, 0.00011446928043363628, 0.0001144634284069974, 0.00011445754997834946, 0.00011445168697852369, 0.00011444579705528472, 0.00011443987042045505, 0.00011443391579570376, 0.00011442792611837491, 0.00011442192869108468, 0.00011441593529282635, 0.00011440993151388582, 0.00011440390282604807, 0.00011439785565206393, 0.00011439179724419083, 0.00011438574222544457, 0.00011437971121498842, 0.00011437366150508419, 0.0001143676151843068, 0.00011436153554106555, 0.00011435548173102887, 0.00011434936964223071, 0.00011434322084184184, 0.00011433708962699223, 0.00011433095819884092, 0.00011432481681661079, 0.00011431867185565233, 0.00011431253111332728, 0.00011430636458519804, 0.00011430021689871799, 0.00011429401842273578, 0.00011428785744045045, 0.00011428169273723566, 0.0001142755012528088, 0.00011426928658959841, 0.00011426312548881215, 0.00011425693966873014, 0.00011425075809098174, 0.00011424457217609898, 0.00011423839057465038, 0.00011423218901764377, 0.00011422601981139332, 0.00011421982154871279, 0.00011421361335565363, 0.00011420745991002799, 0.0001142012700135137, 0.00011419508521253977, 0.00011418888517234517, 0.00011418270916414086, 0.00011417654130880111, 0.00011417033766617798, 0.00011416415466641832, 0.0001141579344810642, 0.00011415173299515814, 0.00011414551008428244, 0.0001141392426407541, 0.0001141329929960667, 0.00011412673102728173, 0.00011412047230542246, 0.00011411424517591336, 0.00011410808170510832, 0.00011410185531030503, 0.00011409560184988742, 0.00011408937372497043, 0.00011408314180802341, 0.00011407690100350603, 0.0001140706984984919, 0.00011406449890860086, 0.000114058278628446, 0.00011405204299056952, 0.00011404580360806338, 0.00011403958849454942, 0.00011403335269077162, 0.00011402713963917399, 0.00011402087970860515, 0.00011401464186661121, 0.00011400841625391412, 0.0001140021566551479, 0.00011399586719414522, 0.00011398965824268006, 0.00011398343201377809, 0.0001139772034859579, 0.00011397100982111378, 0.00011396481380995108, 0.00011395858333871552, 0.00011395237611736404, 0.00011394617339904824, 0.00011393997098883486, 0.000113933768768223, 0.00011392754841696755, 0.00011392134930108027, 0.00011391515812475587, 0.00011390894071232369, 0.00011390272749482475, 0.00011389652503721101, 0.00011389031902456911, 0.0001138841203352852, 0.00011387789097795845, 0.00011387168664802988, 0.00011386550341126834, 0.00011385932095661298, 0.00011385309302129749, 0.00011384691924091083, 0.00011384069912665726, 0.00011383453532404961, 0.00011382837156884233, 0.00011382219852316147, 0.00011381599528344154, 0.00011380979161711822, 0.00011380361861883775, 0.00011379745626194154, 0.00011379130286371627, 0.00011378510834566539, 0.00011377893767000331, 0.00011377276983836375, 0.00011376659283475155, 0.00011376042033417503, 0.00011375426911636702, 0.00011374807926725312], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-14 17:57:31,970 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:129]: evaluating model ... 
[2017-12-14 17:57:37,808 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:133]: evaluated! 
[2017-12-14 17:57:37,810 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:135]: generating reports ... 
[2017-12-14 17:57:44,007 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:138]: done!
[2017-12-14 17:57:44,007 AE_BIGRAMA_1L_MINIDS_UNDER_F0_3.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_3 finished!
