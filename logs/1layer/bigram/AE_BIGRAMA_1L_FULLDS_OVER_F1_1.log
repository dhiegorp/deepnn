[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_1
[2018-01-18 00:19:28,523 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:146]: >> Printing header log
[2018-01-18 00:19:28,523 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_1
	layers = 9216,10138
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f208c6e5b70>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f208c6e5400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,523 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:148]: >> Loading dataset... 
[2018-01-18 00:21:58,220 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:21:58,220 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:21:58,220 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:57]: =======================================
[2018-01-18 00:21:58,220 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f208c6e5b70>, 'discard_decoder_function': True}
[2018-01-18 00:21:58,264 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:73]: training and evaluate autoencoder
[2018-01-19 22:17:10,319 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:85]: trained and evaluated!
[2018-01-19 22:17:10,322 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:88]: Training history: 
{'val_loss': [0.00011928203545742829, 0.0001192510882453279, 0.00011921950100566158, 0.00011918720103233323, 0.00011915407657347933, 0.00011912008120843682, 0.00011908485014994452, 0.00011904846661827173, 0.0001190110687202391, 0.00011897259047218982, 0.00011893286644970572, 0.00011889172026496319, 0.00011884927297535036, 0.00011880549336992374, 0.00011875985930179195, 0.00011871188594242616, 0.00011866218762758754, 0.00011861108737128853, 0.00011855904013881113, 0.00011850633462068674, 0.00011845292589904104, 0.00011839894634763581, 0.00011834467358663692, 0.00011829016612319344, 0.00011823547607893929, 0.00011818059077910814, 0.00011812562436612069, 0.00011807056752910433, 0.0001180154914285824, 0.00011796040620971594, 0.00011790531475507838, 0.00011785022255706847, 0.00011779513172814722, 0.00011774006710443898, 0.00011768507470015864, 0.00011763011659796732, 0.0001175751868776261, 0.00011752032715729165, 0.00011746551182537925, 0.0001174107637980803, 0.00011735615317701359, 0.00011730157963899729, 0.00011724710066971197, 0.00011719267912193119, 0.00011713835505219481, 0.00011708414241344179, 0.00011703000005279167, 0.00011697596962048916, 0.00011692199047553212, 0.00011686812735014472, 0.00011681436094873336, 0.00011676066292153596, 0.00011670704748889158, 0.00011665353439562604, 0.00011660010219090069, 0.00011654675842609526, 0.00011649349726653887, 0.00011644032773698599, 0.00011638725703584821, 0.00011633424051532532, 0.00011628131139453587, 0.00011622849033816208, 0.00011617574458968771, 0.0001161230770691222, 0.00011607050292735706, 0.00011601801912672681, 0.00011596563658785286, 0.00011591333946727733, 0.00011586113477623171, 0.00011580899127970649, 0.00011575697520736657, 0.00011570504180979971, 0.0001156532095616811, 0.00011560145170160545, 0.00011554976194299561, 0.00011549816478505177, 0.00011544667983355168, 0.00011539526403172593, 0.00011534394169961661, 0.00011529268968304621, 0.00011524151721801534, 0.00011519043177568369, 0.00011513944664583787, 0.00011508853501626655, 0.00011503773405291421, 0.00011498700308154663, 0.00011493636135497339, 0.00011488579240134629, 0.00011483533285180954, 0.00011478494110425047, 0.00011473464439872061, 0.00011468438686998421, 0.0001146342622123738, 0.00011458418824045858, 0.00011453421304347842, 0.00011448432790151499, 0.00011443451806745098, 0.00011438480459102482, 0.00011433515563022871, 0.00011428556634512025, 0.00011423606460414127], 'val_acc': [0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00073502388827636903, 0.00073502388827636903, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0014700477765527381, 0.0025725836089672913, 0.0036751194413818448, 0.0058801911062109522, 0.0084527747151782427, 0.0099228224917309819, 0.013965453877251011, 0.020213156927600145, 0.024255788313120176, 0.031606027195883866, 0.038221242190371187, 0.048511576626240352, 0.062844542447629548, 0.073502388827636891, 0.086732818816611545, 0.10290334435869165, 0.11613377434766629, 0.12421903711870635, 0.13340683572216097, 0.14332965821389196, 0.15876515986769571, 0.17456817346563763, 0.18632855567805953, 0.19625137816979052, 0.2105843439911797, 0.22528482175670708, 0.23778022785740535, 0.25505328923190002, 0.27048879088570377, 0.2884968761484748, 0.30981256890848952, 0.33186328555678057, 0.34913634693127527, 0.36567438441749356, 0.37706725468577729, 0.38772510106578462, 0.3980154355016538, 0.40610069827269385, 0.41271591326718116, 0.4211686879823594, 0.42815141492098491, 0.43292907019478133, 0.43660418963616315, 0.43844174935685409, 0.44321940463065052, 0.44652701212789414, 0.45093715545755236, 0.45571481073134879, 0.45828739434031607, 0.46306504961411243, 0.46527012127894157, 0.46821021683204705, 0.4693127526644616, 0.47115031238515254, 0.47372289599411982], 'loss': [0.00011939273690636797, 0.00011936184935529891, 0.00011933029832030952, 0.000119297998308228, 0.00011926486231031857, 0.00011923080154239387, 0.00011919572665673038, 0.00011915945951159329, 0.00011912211971954617, 0.00011908369101305886, 0.00011904413758570343, 0.00011900326898189905, 0.00011896093868849061, 0.00011891723292383434, 0.00011887214134154888, 0.00011882508271881367, 0.00011877601343828562, 0.00011872554349796077, 0.00011867397788522701, 0.00011862166260683316, 0.00011856867576835784, 0.00011851511866609912, 0.00011846117717590167, 0.000118407009800577, 0.0001183526385689419, 0.00011829812519669235, 0.00011824348362933933, 0.00011818876344020499, 0.00011813397392451046, 0.00011807921027700205, 0.00011802442598674362, 0.00011796965318601445, 0.00011791487210907327, 0.00011786009201899021, 0.00011780534300020227, 0.00011775066926931206, 0.00011769604935032196, 0.00011764146903515416, 0.00011758694872542595, 0.0001175325040072441, 0.00011747811515684237, 0.00011742385327087395, 0.00011736962522476193, 0.0001173154882830702, 0.00011726141012239949, 0.00011720742407354815, 0.00011715355023359168, 0.00011709975169939462, 0.00011704606573579158, 0.00011699243690904141, 0.00011693891344658821, 0.00011688548828234917, 0.00011683213416564369, 0.00011677886370592873, 0.0001167256959884153, 0.00011667260842968125, 0.00011661960979713495, 0.00011656669203337004, 0.0001165138668869102, 0.00011646113444259842, 0.00011640847023349784, 0.00011635590359474772, 0.00011630343446472527, 0.00011625103972862318, 0.00011619873140646277, 0.00011614651291339831, 0.00011609438278209232, 0.00011604235378543618, 0.00011599040621305983, 0.00011593855969227648, 0.00011588677003416911, 0.00011583510519798588, 0.00011578352234604631, 0.00011573203616601442, 0.00011568062990988076, 0.00011562929080564705, 0.00011557803065988747, 0.00011552688765195489, 0.00011547581311679391, 0.00011542483099620787, 0.00011537391685630399, 0.00011532307675933838, 0.0001152723275256603, 0.00011522167493531121, 0.00011517110141060637, 0.00011512062900447582, 0.00011507022498716697, 0.00011501991117226328, 0.00011496966900861816, 0.00011491953286658003, 0.000114869467078149, 0.00011481949233251545, 0.00011476955768993832, 0.00011471975742260787, 0.00011467001565765613, 0.00011462036335652888, 0.00011457080453810535, 0.00011452131692529133, 0.00011447192839035404, 0.0001144226047353103, 0.00011437333812155942], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00024548913710568308, 0.00024548913710568308, 0.0003682337056585246, 0.00049097827421136617, 0.00049097827421136617, 0.00061372284276420773, 0.00085921197986989076, 0.00085921197986989076, 0.00098195654842273233, 0.001104701117890092, 0.0013501902540812569, 0.0015956793911869401, 0.001841168528292623, 0.0019639130968454647, 0.0033141033509267214, 0.0041733153307966127, 0.0056462501534307111, 0.0089603535043574316, 0.013624647109365411, 0.017429728734503498, 0.023198723457401569, 0.03314103351018173, 0.042960598993494539, 0.053639376457591752, 0.067264023567871686, 0.078433779306180257, 0.091076469851576122, 0.10519209525069971, 0.11857125322295944, 0.13145943292375137, 0.14361114520865365, 0.1553946237732651, 0.16975573831223792, 0.18301215171320126, 0.19553209770833463, 0.20964772311020177, 0.22302688106234211, 0.23591506074392915, 0.2506444089885605, 0.26476003435750495, 0.27948938258384598, 0.29470970908439831, 0.30894807905116023, 0.32699153064671832, 0.34442125933000878, 0.35792316188911172, 0.36872468395834251, 0.38222658646257435, 0.39155517369088066, 0.39941082609655287, 0.40824843503235747, 0.41634957652026428, 0.42187308210514213, 0.42801031058765532, 0.4337793052364774, 0.43770713143016832, 0.44138946852333433, 0.44568552844463222, 0.44924512090705809, 0.45194550141887868, 0.45476862647730365, 0.45746900698546616, 0.46127408862889463, 0.46520191483721784, 0.46962071930877824, 0.47207561068349313, 0.47563520318615782]}
[2018-01-19 22:17:10,322 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:92]: done!
[2018-01-19 22:17:10,323 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:152]: >> Executing classifier part ... 
[2018-01-19 22:17:10,323 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:97]: =======================================
[2018-01-19 22:17:10,323 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f208c6e5400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-19 22:17:10,743 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:110]: training ... 
[2018-01-23 06:26:37,227 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:122]: trained!
[2018-01-23 06:26:37,230 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:125]: Training history: 
{'val_loss': [0.00011928203545742829, 0.0001192510882453279, 0.00011921950100566158, 0.00011918720103233323, 0.00011915407657347933, 0.00011912008120843682, 0.00011908485014994452, 0.00011904846661827173, 0.0001190110687202391, 0.00011897259047218982, 0.00011893286644970572, 0.00011889172026496319, 0.00011884927297535036, 0.00011880549336992374, 0.00011875985930179195, 0.00011871188594242616, 0.00011866218762758754, 0.00011861108737128853, 0.00011855904013881113, 0.00011850633462068674, 0.00011845292589904104, 0.00011839894634763581, 0.00011834467358663692, 0.00011829016612319344, 0.00011823547607893929, 0.00011818059077910814, 0.00011812562436612069, 0.00011807056752910433, 0.0001180154914285824, 0.00011796040620971594, 0.00011790531475507838, 0.00011785022255706847, 0.00011779513172814722, 0.00011774006710443898, 0.00011768507470015864, 0.00011763011659796732, 0.0001175751868776261, 0.00011752032715729165, 0.00011746551182537925, 0.0001174107637980803, 0.00011735615317701359, 0.00011730157963899729, 0.00011724710066971197, 0.00011719267912193119, 0.00011713835505219481, 0.00011708414241344179, 0.00011703000005279167, 0.00011697596962048916, 0.00011692199047553212, 0.00011686812735014472, 0.00011681436094873336, 0.00011676066292153596, 0.00011670704748889158, 0.00011665353439562604, 0.00011660010219090069, 0.00011654675842609526, 0.00011649349726653887, 0.00011644032773698599, 0.00011638725703584821, 0.00011633424051532532, 0.00011628131139453587, 0.00011622849033816208, 0.00011617574458968771, 0.0001161230770691222, 0.00011607050292735706, 0.00011601801912672681, 0.00011596563658785286, 0.00011591333946727733, 0.00011586113477623171, 0.00011580899127970649, 0.00011575697520736657, 0.00011570504180979971, 0.0001156532095616811, 0.00011560145170160545, 0.00011554976194299561, 0.00011549816478505177, 0.00011544667983355168, 0.00011539526403172593, 0.00011534394169961661, 0.00011529268968304621, 0.00011524151721801534, 0.00011519043177568369, 0.00011513944664583787, 0.00011508853501626655, 0.00011503773405291421, 0.00011498700308154663, 0.00011493636135497339, 0.00011488579240134629, 0.00011483533285180954, 0.00011478494110425047, 0.00011473464439872061, 0.00011468438686998421, 0.0001146342622123738, 0.00011458418824045858, 0.00011453421304347842, 0.00011448432790151499, 0.00011443451806745098, 0.00011438480459102482, 0.00011433515563022871, 0.00011428556634512025, 0.00011423606460414127], 'val_acc': [0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00073502388827636903, 0.00073502388827636903, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0014700477765527381, 0.0025725836089672913, 0.0036751194413818448, 0.0058801911062109522, 0.0084527747151782427, 0.0099228224917309819, 0.013965453877251011, 0.020213156927600145, 0.024255788313120176, 0.031606027195883866, 0.038221242190371187, 0.048511576626240352, 0.062844542447629548, 0.073502388827636891, 0.086732818816611545, 0.10290334435869165, 0.11613377434766629, 0.12421903711870635, 0.13340683572216097, 0.14332965821389196, 0.15876515986769571, 0.17456817346563763, 0.18632855567805953, 0.19625137816979052, 0.2105843439911797, 0.22528482175670708, 0.23778022785740535, 0.25505328923190002, 0.27048879088570377, 0.2884968761484748, 0.30981256890848952, 0.33186328555678057, 0.34913634693127527, 0.36567438441749356, 0.37706725468577729, 0.38772510106578462, 0.3980154355016538, 0.40610069827269385, 0.41271591326718116, 0.4211686879823594, 0.42815141492098491, 0.43292907019478133, 0.43660418963616315, 0.43844174935685409, 0.44321940463065052, 0.44652701212789414, 0.45093715545755236, 0.45571481073134879, 0.45828739434031607, 0.46306504961411243, 0.46527012127894157, 0.46821021683204705, 0.4693127526644616, 0.47115031238515254, 0.47372289599411982], 'loss': [0.00011939273690636797, 0.00011936184935529891, 0.00011933029832030952, 0.000119297998308228, 0.00011926486231031857, 0.00011923080154239387, 0.00011919572665673038, 0.00011915945951159329, 0.00011912211971954617, 0.00011908369101305886, 0.00011904413758570343, 0.00011900326898189905, 0.00011896093868849061, 0.00011891723292383434, 0.00011887214134154888, 0.00011882508271881367, 0.00011877601343828562, 0.00011872554349796077, 0.00011867397788522701, 0.00011862166260683316, 0.00011856867576835784, 0.00011851511866609912, 0.00011846117717590167, 0.000118407009800577, 0.0001183526385689419, 0.00011829812519669235, 0.00011824348362933933, 0.00011818876344020499, 0.00011813397392451046, 0.00011807921027700205, 0.00011802442598674362, 0.00011796965318601445, 0.00011791487210907327, 0.00011786009201899021, 0.00011780534300020227, 0.00011775066926931206, 0.00011769604935032196, 0.00011764146903515416, 0.00011758694872542595, 0.0001175325040072441, 0.00011747811515684237, 0.00011742385327087395, 0.00011736962522476193, 0.0001173154882830702, 0.00011726141012239949, 0.00011720742407354815, 0.00011715355023359168, 0.00011709975169939462, 0.00011704606573579158, 0.00011699243690904141, 0.00011693891344658821, 0.00011688548828234917, 0.00011683213416564369, 0.00011677886370592873, 0.0001167256959884153, 0.00011667260842968125, 0.00011661960979713495, 0.00011656669203337004, 0.0001165138668869102, 0.00011646113444259842, 0.00011640847023349784, 0.00011635590359474772, 0.00011630343446472527, 0.00011625103972862318, 0.00011619873140646277, 0.00011614651291339831, 0.00011609438278209232, 0.00011604235378543618, 0.00011599040621305983, 0.00011593855969227648, 0.00011588677003416911, 0.00011583510519798588, 0.00011578352234604631, 0.00011573203616601442, 0.00011568062990988076, 0.00011562929080564705, 0.00011557803065988747, 0.00011552688765195489, 0.00011547581311679391, 0.00011542483099620787, 0.00011537391685630399, 0.00011532307675933838, 0.0001152723275256603, 0.00011522167493531121, 0.00011517110141060637, 0.00011512062900447582, 0.00011507022498716697, 0.00011501991117226328, 0.00011496966900861816, 0.00011491953286658003, 0.000114869467078149, 0.00011481949233251545, 0.00011476955768993832, 0.00011471975742260787, 0.00011467001565765613, 0.00011462036335652888, 0.00011457080453810535, 0.00011452131692529133, 0.00011447192839035404, 0.0001144226047353103, 0.00011437333812155942], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00024548913710568308, 0.00024548913710568308, 0.0003682337056585246, 0.00049097827421136617, 0.00049097827421136617, 0.00061372284276420773, 0.00085921197986989076, 0.00085921197986989076, 0.00098195654842273233, 0.001104701117890092, 0.0013501902540812569, 0.0015956793911869401, 0.001841168528292623, 0.0019639130968454647, 0.0033141033509267214, 0.0041733153307966127, 0.0056462501534307111, 0.0089603535043574316, 0.013624647109365411, 0.017429728734503498, 0.023198723457401569, 0.03314103351018173, 0.042960598993494539, 0.053639376457591752, 0.067264023567871686, 0.078433779306180257, 0.091076469851576122, 0.10519209525069971, 0.11857125322295944, 0.13145943292375137, 0.14361114520865365, 0.1553946237732651, 0.16975573831223792, 0.18301215171320126, 0.19553209770833463, 0.20964772311020177, 0.22302688106234211, 0.23591506074392915, 0.2506444089885605, 0.26476003435750495, 0.27948938258384598, 0.29470970908439831, 0.30894807905116023, 0.32699153064671832, 0.34442125933000878, 0.35792316188911172, 0.36872468395834251, 0.38222658646257435, 0.39155517369088066, 0.39941082609655287, 0.40824843503235747, 0.41634957652026428, 0.42187308210514213, 0.42801031058765532, 0.4337793052364774, 0.43770713143016832, 0.44138946852333433, 0.44568552844463222, 0.44924512090705809, 0.45194550141887868, 0.45476862647730365, 0.45746900698546616, 0.46127408862889463, 0.46520191483721784, 0.46962071930877824, 0.47207561068349313, 0.47563520318615782]}
[2018-01-23 06:26:37,231 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:129]: evaluating model ... 
[2018-01-23 06:27:19,335 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:133]: evaluated! 
[2018-01-23 06:27:19,336 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:135]: generating reports ... 
[2018-01-23 06:27:24,379 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:138]: done!
[2018-01-23 06:27:24,379 AE_BIGRAMA_1L_FULLDS_OVER_F1_1.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_1 finished!
