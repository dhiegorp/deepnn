[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_9
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:146]: >> Printing header log
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_UNDER_F0_9
	layers = 9216,8294
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fae68cc5be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fae68cc5470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,512 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:148]: >> Loading dataset... 
[2018-01-18 00:21:56,607 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:21:56,607 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:21:56,607 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:57]: =======================================
[2018-01-18 00:21:56,607 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fae68cc5be0>, 'discard_decoder_function': True}
[2018-01-18 00:21:56,649 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:73]: training and evaluate autoencoder
[2018-01-19 16:15:49,983 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:85]: trained and evaluated!
[2018-01-19 16:15:49,984 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:88]: Training history: 
{'val_loss': [0.00011990574939047746, 0.00011985833877469121, 0.00011980991292616865, 0.00011976059811660052, 0.00011971058157955984, 0.00011965989502335433, 0.00011960873744716283, 0.00011955716734743845, 0.00011950526044655075, 0.00011945314984024187, 0.00011940081314712068, 0.00011934822457377038, 0.00011929548431502073, 0.0001192426826772446, 0.00011918972320921407, 0.00011913661285798458, 0.0001190832174314735, 0.00011902964032261617, 0.00011897583504122549, 0.00011892179503599821, 0.00011886758168061284, 0.00011881328575741445, 0.0001187588542302607, 0.00011870433509747544, 0.00011864972774403834, 0.00011859506018278735, 0.00011854038263681539, 0.00011848569344824166, 0.00011843101747458248, 0.00011837636583433539, 0.00011832173977358501, 0.0001182671780653506, 0.00011821266840387803, 0.00011815823351817862, 0.00011810381734514049, 0.00011804947825821266, 0.00011799522353067873, 0.00011794108099354454, 0.00011788694124271971, 0.00011783291453797506, 0.00011777891276027078, 0.00011772504126525921, 0.00011767123272693492, 0.00011761751729198888, 0.00011756385450812898, 0.00011751030786684278, 0.00011745686271995099, 0.00011740347656152851, 0.00011735017910775209, 0.00011729696233126974, 0.00011724385453905952, 0.00011719081020357484, 0.00011713785305925145, 0.00011708495924062753, 0.00011703213945707839, 0.00011697943357796381, 0.00011692681332037177, 0.00011687430067261519, 0.00011682186561368114, 0.00011676953449317873, 0.00011671726944457513, 0.00011666511731369963, 0.00011661303252219956, 0.00011656105273605767, 0.00011650917355921575, 0.00011645736784788632, 0.00011640565936057118, 0.00011635405501758577, 0.00011630252111849136, 0.00011625106317707869, 0.00011619970943614976, 0.00011614840765374065, 0.00011609725578119401, 0.00011604616074454558, 0.00011599513881241948, 0.0001159442352930942, 0.00011589340163472762, 0.00011584263780255771, 0.00011579198123260309, 0.00011574141498773935, 0.00011569093136416863, 0.00011564051618968393, 0.0001155902183423555, 0.00011554001267320086, 0.00011548985612812462, 0.00011543976726737, 0.0001153897913938675, 0.00011533989587945293, 0.00011529006934357662, 0.00011524033272901696, 0.00011519069584668485, 0.00011514113471346238, 0.00011509165827923196, 0.00011504227375310122, 0.00011499297485116699, 0.00011494373513557816, 0.00011489458523167195, 0.00011484553282720218, 0.00011479654964460478, 0.00011474763726421455, 0.00011469886219646653], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.0011025358324145535, 0.0011025358324145535, 0.002205071664829107, 0.0058801911062109522, 0.010290334435869165, 0.016538037486218304, 0.022418228592429253, 0.025725836089672913, 0.029400955531054759, 0.036383682469680267, 0.044101433296582136, 0.054024255788313123, 0.066519661889011386, 0.077912532157295114, 0.088570378537302458, 0.10400588019110621, 0.11833884601249541, 0.13744946710768099, 0.15729511209114297, 0.17420066152149946, 0.19955898566703417, 0.22234472620360163, 0.24108783535464903, 0.2657111356119074, 0.28518926865123118, 0.30834252113193678, 0.32451304667401693, 0.34105108416023522, 0.35170893054024255, 0.36530687247335536, 0.37522969496508635, 0.38552002940095553, 0.39654538772510106, 0.40463065049614111, 0.41234840132304301, 0.41712605659683938, 0.42337375964718854, 0.42704887908857037, 0.43072399852995225, 0.43403160602719587, 0.43844174935685409, 0.44395442851892686, 0.45020213156927602, 0.45497978684307239, 0.45902241822859241, 0.46196251378169789, 0.46490260933480337, 0.46747519294377066, 0.4696802646085998, 0.47225284821756708, 0.47409040793825802, 0.47519294377067256, 0.47886806321205438, 0.48070562293274532, 0.48217567070929807, 0.48474825431826535, 0.48621830209481809, 0.48695332598309443, 0.48805586181550903], 'loss': [0.00012001816876244141, 0.00011997164121137911, 0.00011992400105770926, 0.00011987543992963231, 0.00011982614723603433, 0.00011977620215866051, 0.00011972561989512599, 0.00011967460464379249, 0.00011962316625537958, 0.00011957136601690276, 0.00011951932759820748, 0.00011946703370650284, 0.000119414514035948, 0.00011936184260268868, 0.00011930909130983322, 0.0001192561879979581, 0.00011920313775675062, 0.00011914990241310947, 0.00011909647031585717, 0.00011904278603750416, 0.00011898892473109246, 0.00011893489779952211, 0.00011888074021686655, 0.00011882645129455779, 0.00011877212239868981, 0.00011871771359589221, 0.00011866326606181564, 0.00011860877831215404, 0.00011855431565994681, 0.00011849985801258388, 0.00011844543719601657, 0.0001183910648614224, 0.00011833673454912275, 0.00011828246154425508, 0.00011822826650921722, 0.00011817409258490553, 0.00011811998690652205, 0.00011806595400557639, 0.00011801202603488874, 0.00011795811045753161, 0.00011790430765617789, 0.00011785053716572026, 0.00011779689474176194, 0.00011774331342441611, 0.00011768982524057807, 0.00011763637725714262, 0.0001175830387595881, 0.0001175297934669881, 0.0001174766067178487, 0.00011742351805258323, 0.00011737050686595124, 0.00011731759984420401, 0.00011726476457820622, 0.00011721202578942373, 0.00011715935176443385, 0.00011710675234145296, 0.0001170542699303742, 0.00011700186662155613, 0.00011694957144470321, 0.00011689735247115941, 0.00011684524156170634, 0.0001167931892403681, 0.00011674125594840937, 0.00011668938529470264, 0.00011663761856117562, 0.0001165859518673771, 0.00011653436612363063, 0.00011648287624265749, 0.00011643148710427019, 0.00011638017129524679, 0.00011632893111974474, 0.00011627779498588185, 0.00011622671199678511, 0.00011617577602007755, 0.00011612489472870652, 0.00011607408581109921, 0.00011602339377500373, 0.00011597276776552202, 0.00011592221244098167, 0.00011587176133223191, 0.00011582140460730792, 0.00011577112132695571, 0.00011572091082046898, 0.00011567081202364304, 0.00011562080825187737, 0.0001155708556493754, 0.00011552096067402959, 0.00011547118342237406, 0.00011542149032605006, 0.00011537185813450149, 0.00011532232082154739, 0.00011527288539343391, 0.00011522352437442323, 0.00011517424504493839, 0.00011512505853191641, 0.00011507595606794894, 0.00011502691877591356, 0.00011497797312772141, 0.00011492912356200131, 0.00011488033663364015, 0.00011483162370981462], 'acc': [0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00024548913710568308, 0.0003682337056585246, 0.00061372284276420773, 0.00061372284276420773, 0.00073646741131704919, 0.0014729348226340984, 0.0028231250767153555, 0.0049097827421136619, 0.0063827175647477603, 0.0090830980729102746, 0.013870136247385612, 0.019148152694243279, 0.024794402849503027, 0.032404566098864683, 0.040137473917693699, 0.04811587085808159, 0.058917392906278454, 0.068859702959973138, 0.080643181542874962, 0.092794893825948202, 0.10556032894081142, 0.11869399779151228, 0.1346507917042962, 0.15281698785011674, 0.17392905364120551, 0.19356818459685687, 0.21247084816862677, 0.23272370197801659, 0.25138087639804851, 0.27457959987465497, 0.2969191113146914, 0.31422609553917119, 0.32821897631761443, 0.34122990058055752, 0.35362710200805264, 0.36430587946849174, 0.37228427640979417, 0.38149011903296692, 0.38995949429603566, 0.39793789123733803, 0.40382963056445514, 0.4092303915624898, 0.41524487542157906, 0.42040014729714031, 0.42555541921659851, 0.43034245734809146, 0.43574321836624552, 0.44053025656175476, 0.44433533815397019, 0.44912237632753105, 0.45415490361624911, 0.45697802871491289, 0.46090585495981684, 0.46372897998166113, 0.46704308335087819, 0.46876150734719868, 0.47219835523009751, 0.47403952377668052, 0.47600343684060331, 0.4791947956558999, 0.48201792073261523, 0.48361360014209254, 0.48422732297022447, 0.4857002577343294]}
[2018-01-19 16:15:49,984 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:92]: done!
[2018-01-19 16:15:49,984 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:152]: >> Executing classifier part ... 
[2018-01-19 16:15:49,985 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:97]: =======================================
[2018-01-19 16:15:49,985 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fae68cc5470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-19 16:15:50,461 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:110]: training ... 
[2018-01-22 13:20:22,378 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:122]: trained!
[2018-01-22 13:20:22,381 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:125]: Training history: 
{'val_loss': [0.00011990574939047746, 0.00011985833877469121, 0.00011980991292616865, 0.00011976059811660052, 0.00011971058157955984, 0.00011965989502335433, 0.00011960873744716283, 0.00011955716734743845, 0.00011950526044655075, 0.00011945314984024187, 0.00011940081314712068, 0.00011934822457377038, 0.00011929548431502073, 0.0001192426826772446, 0.00011918972320921407, 0.00011913661285798458, 0.0001190832174314735, 0.00011902964032261617, 0.00011897583504122549, 0.00011892179503599821, 0.00011886758168061284, 0.00011881328575741445, 0.0001187588542302607, 0.00011870433509747544, 0.00011864972774403834, 0.00011859506018278735, 0.00011854038263681539, 0.00011848569344824166, 0.00011843101747458248, 0.00011837636583433539, 0.00011832173977358501, 0.0001182671780653506, 0.00011821266840387803, 0.00011815823351817862, 0.00011810381734514049, 0.00011804947825821266, 0.00011799522353067873, 0.00011794108099354454, 0.00011788694124271971, 0.00011783291453797506, 0.00011777891276027078, 0.00011772504126525921, 0.00011767123272693492, 0.00011761751729198888, 0.00011756385450812898, 0.00011751030786684278, 0.00011745686271995099, 0.00011740347656152851, 0.00011735017910775209, 0.00011729696233126974, 0.00011724385453905952, 0.00011719081020357484, 0.00011713785305925145, 0.00011708495924062753, 0.00011703213945707839, 0.00011697943357796381, 0.00011692681332037177, 0.00011687430067261519, 0.00011682186561368114, 0.00011676953449317873, 0.00011671726944457513, 0.00011666511731369963, 0.00011661303252219956, 0.00011656105273605767, 0.00011650917355921575, 0.00011645736784788632, 0.00011640565936057118, 0.00011635405501758577, 0.00011630252111849136, 0.00011625106317707869, 0.00011619970943614976, 0.00011614840765374065, 0.00011609725578119401, 0.00011604616074454558, 0.00011599513881241948, 0.0001159442352930942, 0.00011589340163472762, 0.00011584263780255771, 0.00011579198123260309, 0.00011574141498773935, 0.00011569093136416863, 0.00011564051618968393, 0.0001155902183423555, 0.00011554001267320086, 0.00011548985612812462, 0.00011543976726737, 0.0001153897913938675, 0.00011533989587945293, 0.00011529006934357662, 0.00011524033272901696, 0.00011519069584668485, 0.00011514113471346238, 0.00011509165827923196, 0.00011504227375310122, 0.00011499297485116699, 0.00011494373513557816, 0.00011489458523167195, 0.00011484553282720218, 0.00011479654964460478, 0.00011474763726421455, 0.00011469886219646653], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.0011025358324145535, 0.0011025358324145535, 0.002205071664829107, 0.0058801911062109522, 0.010290334435869165, 0.016538037486218304, 0.022418228592429253, 0.025725836089672913, 0.029400955531054759, 0.036383682469680267, 0.044101433296582136, 0.054024255788313123, 0.066519661889011386, 0.077912532157295114, 0.088570378537302458, 0.10400588019110621, 0.11833884601249541, 0.13744946710768099, 0.15729511209114297, 0.17420066152149946, 0.19955898566703417, 0.22234472620360163, 0.24108783535464903, 0.2657111356119074, 0.28518926865123118, 0.30834252113193678, 0.32451304667401693, 0.34105108416023522, 0.35170893054024255, 0.36530687247335536, 0.37522969496508635, 0.38552002940095553, 0.39654538772510106, 0.40463065049614111, 0.41234840132304301, 0.41712605659683938, 0.42337375964718854, 0.42704887908857037, 0.43072399852995225, 0.43403160602719587, 0.43844174935685409, 0.44395442851892686, 0.45020213156927602, 0.45497978684307239, 0.45902241822859241, 0.46196251378169789, 0.46490260933480337, 0.46747519294377066, 0.4696802646085998, 0.47225284821756708, 0.47409040793825802, 0.47519294377067256, 0.47886806321205438, 0.48070562293274532, 0.48217567070929807, 0.48474825431826535, 0.48621830209481809, 0.48695332598309443, 0.48805586181550903], 'loss': [0.00012001816876244141, 0.00011997164121137911, 0.00011992400105770926, 0.00011987543992963231, 0.00011982614723603433, 0.00011977620215866051, 0.00011972561989512599, 0.00011967460464379249, 0.00011962316625537958, 0.00011957136601690276, 0.00011951932759820748, 0.00011946703370650284, 0.000119414514035948, 0.00011936184260268868, 0.00011930909130983322, 0.0001192561879979581, 0.00011920313775675062, 0.00011914990241310947, 0.00011909647031585717, 0.00011904278603750416, 0.00011898892473109246, 0.00011893489779952211, 0.00011888074021686655, 0.00011882645129455779, 0.00011877212239868981, 0.00011871771359589221, 0.00011866326606181564, 0.00011860877831215404, 0.00011855431565994681, 0.00011849985801258388, 0.00011844543719601657, 0.0001183910648614224, 0.00011833673454912275, 0.00011828246154425508, 0.00011822826650921722, 0.00011817409258490553, 0.00011811998690652205, 0.00011806595400557639, 0.00011801202603488874, 0.00011795811045753161, 0.00011790430765617789, 0.00011785053716572026, 0.00011779689474176194, 0.00011774331342441611, 0.00011768982524057807, 0.00011763637725714262, 0.0001175830387595881, 0.0001175297934669881, 0.0001174766067178487, 0.00011742351805258323, 0.00011737050686595124, 0.00011731759984420401, 0.00011726476457820622, 0.00011721202578942373, 0.00011715935176443385, 0.00011710675234145296, 0.0001170542699303742, 0.00011700186662155613, 0.00011694957144470321, 0.00011689735247115941, 0.00011684524156170634, 0.0001167931892403681, 0.00011674125594840937, 0.00011668938529470264, 0.00011663761856117562, 0.0001165859518673771, 0.00011653436612363063, 0.00011648287624265749, 0.00011643148710427019, 0.00011638017129524679, 0.00011632893111974474, 0.00011627779498588185, 0.00011622671199678511, 0.00011617577602007755, 0.00011612489472870652, 0.00011607408581109921, 0.00011602339377500373, 0.00011597276776552202, 0.00011592221244098167, 0.00011587176133223191, 0.00011582140460730792, 0.00011577112132695571, 0.00011572091082046898, 0.00011567081202364304, 0.00011562080825187737, 0.0001155708556493754, 0.00011552096067402959, 0.00011547118342237406, 0.00011542149032605006, 0.00011537185813450149, 0.00011532232082154739, 0.00011527288539343391, 0.00011522352437442323, 0.00011517424504493839, 0.00011512505853191641, 0.00011507595606794894, 0.00011502691877591356, 0.00011497797312772141, 0.00011492912356200131, 0.00011488033663364015, 0.00011483162370981462], 'acc': [0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00024548913710568308, 0.0003682337056585246, 0.00061372284276420773, 0.00061372284276420773, 0.00073646741131704919, 0.0014729348226340984, 0.0028231250767153555, 0.0049097827421136619, 0.0063827175647477603, 0.0090830980729102746, 0.013870136247385612, 0.019148152694243279, 0.024794402849503027, 0.032404566098864683, 0.040137473917693699, 0.04811587085808159, 0.058917392906278454, 0.068859702959973138, 0.080643181542874962, 0.092794893825948202, 0.10556032894081142, 0.11869399779151228, 0.1346507917042962, 0.15281698785011674, 0.17392905364120551, 0.19356818459685687, 0.21247084816862677, 0.23272370197801659, 0.25138087639804851, 0.27457959987465497, 0.2969191113146914, 0.31422609553917119, 0.32821897631761443, 0.34122990058055752, 0.35362710200805264, 0.36430587946849174, 0.37228427640979417, 0.38149011903296692, 0.38995949429603566, 0.39793789123733803, 0.40382963056445514, 0.4092303915624898, 0.41524487542157906, 0.42040014729714031, 0.42555541921659851, 0.43034245734809146, 0.43574321836624552, 0.44053025656175476, 0.44433533815397019, 0.44912237632753105, 0.45415490361624911, 0.45697802871491289, 0.46090585495981684, 0.46372897998166113, 0.46704308335087819, 0.46876150734719868, 0.47219835523009751, 0.47403952377668052, 0.47600343684060331, 0.4791947956558999, 0.48201792073261523, 0.48361360014209254, 0.48422732297022447, 0.4857002577343294]}
[2018-01-22 13:20:22,382 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:129]: evaluating model ... 
[2018-01-22 13:21:11,462 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:133]: evaluated! 
[2018-01-22 13:21:11,463 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:135]: generating reports ... 
[2018-01-22 13:21:15,580 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:138]: done!
[2018-01-22 13:21:15,581 AE_BIGRAMA_1L_FULLDS_UNDER_F0_9.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_9 finished!
