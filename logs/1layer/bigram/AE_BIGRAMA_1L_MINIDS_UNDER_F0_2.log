[2017-12-14 09:31:58,009 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_2
[2017-12-14 09:31:58,009 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:146]: >> Printing header log
[2017-12-14 09:31:58,009 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_2
	layers = 9216,1843
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8e6b2beb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff8e6b0e400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 09:31:58,009 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:148]: >> Loading dataset... 
[2017-12-14 09:32:19,909 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 09:32:19,909 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:150]: >> Executing autoencoder part ... 
[2017-12-14 09:32:19,909 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:57]: =======================================
[2017-12-14 09:32:19,910 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8e6b2beb8>, 'discard_decoder_function': True}
[2017-12-14 09:32:19,961 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:73]: training and evaluate autoencoder
[2017-12-14 10:18:54,911 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_2
[2017-12-14 10:18:54,911 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:146]: >> Printing header log
[2017-12-14 10:18:54,911 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_2
	layers = 9216,1843
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fcef588aeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fcef586d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 10:18:54,911 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:148]: >> Loading dataset... 
[2017-12-14 10:19:18,505 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 10:19:18,505 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:150]: >> Executing autoencoder part ... 
[2017-12-14 10:19:18,505 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:57]: =======================================
[2017-12-14 10:19:18,505 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fcef588aeb8>, 'discard_decoder_function': True}
[2017-12-14 10:19:18,549 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:73]: training and evaluate autoencoder
[2017-12-14 14:11:27,980 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:85]: trained and evaluated!
[2017-12-14 14:11:27,992 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:88]: Training history: 
{'val_loss': [0.0001114186469630821, 0.00011141480363065066, 0.00011141090668495905, 0.00011140694631150917, 0.00011140297531909413, 0.00011139898494796149, 0.00011139497087186623, 0.00011139098132307772, 0.00011138690137006891, 0.00011138281798466733, 0.00011137866055254231, 0.00011137445424457427, 0.00011137028234991924, 0.0001113660275772802, 0.00011136169328754173, 0.00011135732270740042, 0.00011135294844458768, 0.00011134852834502968, 0.00011134407086456904, 0.00011133956475854401, 0.000111335052020135, 0.00011133049923714356, 0.00011132590991347063, 0.0001113212767731586, 0.00011131666783836649, 0.0001113120035562408, 0.00011130735745507061, 0.00011130266569592562, 0.00011129795359270258, 0.00011129318549857231, 0.00011128839500450371, 0.00011128358219988205, 0.00011127879186670688, 0.00011127398624865759, 0.00011126913886982948, 0.00011126423852131485, 0.00011125933647448087, 0.0001112544128142986, 0.00011124941918335933, 0.00011124443756579479, 0.00011123942391256428, 0.00011123443886260697, 0.00011122942864176924, 0.00011122440549582746, 0.00011121933756788611, 0.00011121429922645546, 0.00011120927200454725, 0.00011120421380171878, 0.00011119916671841275, 0.0001111940447302851, 0.00011118892790862366, 0.00011118374998321991, 0.00011117858028125718, 0.00011117337886541533, 0.00011116820753664144, 0.0001111629847040988, 0.00011115777944469212, 0.00011115256544341005, 0.00011114731073609487, 0.00011114206543210574, 0.00011113676617519257, 0.00011113149462770029, 0.00011112620820650597, 0.00011112088696082656, 0.00011111559342456803, 0.00011111027030179881, 0.00011110491407074089, 0.00011109957795135942, 0.00011109423300071736, 0.00011108884387589529, 0.0001110834984068189, 0.00011107815016680042, 0.00011107275271127503, 0.00011106734610270224, 0.00011106194473210384, 0.00011105655194248739, 0.00011105116233498509, 0.00011104578769057006, 0.00011104040144395235, 0.00011103499705213321, 0.00011102960066923057, 0.0001110241853187824, 0.00011101877422307112, 0.00011101336443238417, 0.00011100794230653567, 0.00011100253054937371, 0.00011099715443904092, 0.00011099173680033091, 0.00011098633428560158, 0.00011098092490608669, 0.00011097551168300696, 0.0001109700934007233, 0.00011096464274310981, 0.0001109592097480175, 0.00011095377494734357, 0.00011094834563492268, 0.00011094292799621267, 0.00011093748486483543, 0.00011093204802617829, 0.0001109266082378086, 0.0001109211485880411, 0.00011091567422546497, 0.00011091021899132776, 0.00011090477593145871, 0.00011089930941690565, 0.00011089383930906639, 0.00011088837434981631, 0.00011088292467544034, 0.00011087744214305429, 0.00011087194464758099, 0.0001108664716794144, 0.00011086101015255711, 0.0001108555413497422, 0.00011085010123958568, 0.00011084465353168474, 0.00011083919273778632, 0.00011083373979191097, 0.00011082824108079854, 0.00011082275731489634, 0.00011081731050084768, 0.00011081182739639618, 0.00011080638172647845, 0.00011080090900859052, 0.00011079544633760229, 0.00011078998824313777, 0.0001107845385687618, 0.00011077907999161704, 0.00011077361919771862, 0.00011076813298266116, 0.00011076263271624575, 0.00011075718974576192, 0.00011075172094294701, 0.00011074623358375862, 0.00011074077459544181, 0.00011073532206073851, 0.00011072986593274903, 0.00011072442451756819, 0.00011071897999178138, 0.0001107135265632258, 0.00011070804133140585, 0.00011070257138446001, 0.00011069714264410459, 0.00011069168340550915, 0.00011068623601939502, 0.00011068078716736314, 0.00011067533030641478, 0.00011066988717503754, 0.00011066447461340851, 0.00011065900933237161, 0.00011065356652278119, 0.00011064810410207161, 0.00011064262868474977, 0.00011063717468412873, 0.00011063175043091178, 0.00011062630084592103, 0.00011062085362070032, 0.00011061544458084929, 0.00011061002483264787, 0.00011060458366774567, 0.0001105991545162182, 0.00011059371415578304, 0.00011058830136175243, 0.00011058289575429418, 0.00011057745033465509, 0.00011057198333742179, 0.00011056656301715491, 0.00011056117326663624, 0.00011055573725032321, 0.00011055032649427579, 0.00011054491548794973, 0.00011053951486818726, 0.00011053409470881379, 0.00011052867022319526, 0.00011052323567279997, 0.00011051778919841518, 0.00011051240100319948, 0.00011050697528406479, 0.0001105015763804987, 0.00011049616210267328, 0.00011049073221818693, 0.0001104852999560535, 0.00011047989425921003, 0.00011047447279481223, 0.00011046912759389152, 0.00011046373081769387, 0.00011045833722361036, 0.00011045295868199936, 0.00011044755797285166, 0.00011044217394298762, 0.00011043678533659987, 0.00011043139084866408, 0.00011042598082557554, 0.0001104205985119079, 0.00011041519445975263, 0.00011040981100195406, 0.00011040441724697713, 0.00011039904671428263, 0.00011039367192685123, 0.0001103882861807908, 0.00011038293141565064], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011203407230980373, 0.00011202993674555654, 0.00011202578880981139, 0.00011202160063114758, 0.00011201734059351476, 0.0001120130798448763, 0.0001120087736392779, 0.00011200444899493348, 0.00011200012136436544, 0.00011199568241401591, 0.00011199126522043866, 0.00011198678218774006, 0.00011198226322555696, 0.00011197779026543812, 0.00011197326805632931, 0.00011196868557764326, 0.00011196408034677706, 0.00011195947627722003, 0.00011195486590341311, 0.00011195023446013933, 0.00011194556919669775, 0.00011194088904953832, 0.00011193616707154766, 0.00011193139875969009, 0.00011192657953982943, 0.00011192175811585129, 0.00011191689047650722, 0.00011191202748239992, 0.00011190713163983252, 0.00011190223020402083, 0.00011189725088939246, 0.00011189225022089501, 0.00011188721798374757, 0.00011188220283443546, 0.00011187716877237357, 0.00011187207564944401, 0.00011186692220953685, 0.00011186176903033174, 0.00011185661250940017, 0.00011185138977014426, 0.00011184618219900846, 0.00011184094981377617, 0.00011183573894831428, 0.0001118304813460823, 0.00011182523037990288, 0.0001118199255194967, 0.00011181464445407894, 0.00011180937997879254, 0.00011180406134857733, 0.00011179877032908075, 0.00011179341444217052, 0.00011178808069123556, 0.00011178269925552303, 0.00011177733180292121, 0.0001117719403183291, 0.00011176657857747251, 0.00011176116332159217, 0.00011175575666887995, 0.00011175033416074219, 0.00011174488238287264, 0.00011173945380748684, 0.00011173397446629904, 0.00011172851093313641, 0.0001117230043367328, 0.00011171746854169798, 0.0001117119645760152, 0.00011170644624801868, 0.00011170089319924724, 0.00011169535813891823, 0.00011168982675211831, 0.00011168426227985641, 0.0001116787554938513, 0.00011167325226287434, 0.00011166770959478508, 0.00011166215829982753, 0.0001116566132854197, 0.00011165107651867718, 0.00011164554589028327, 0.0001116400277044879, 0.00011163451487493492, 0.00011162898597665471, 0.00011162347115628597, 0.00011161793555085265, 0.00011161240105932815, 0.00011160686860601979, 0.0001116013143011384, 0.00011159576845722401, 0.00011159026316433071, 0.00011158471241447748, 0.00011157916469824825, 0.00011157360728864228, 0.0001115680546664742, 0.00011156250484092828, 0.00011155693548642773, 0.00011155138016243826, 0.00011154582761137076, 0.00011154027570020832, 0.000111534741232384, 0.00011152917820583355, 0.00011152361487118066, 0.00011151805248453527, 0.00011151246959722756, 0.00011150686367333742, 0.00011150127391297528, 0.00011149569875192874, 0.00011149010389602625, 0.00011148452062951552, 0.00011147893812141081, 0.00011147337374394966, 0.00011146777606772484, 0.00011146215800933862, 0.00011145656758537121, 0.00011145098801608977, 0.00011144540401487323, 0.00011143984869088377, 0.00011143427919418209, 0.00011142870012260458, 0.00011142312882468862, 0.0001114175069505722, 0.0001114119019272892, 0.00011140633198028394, 0.00011140072887671614, 0.00011139515819500507, 0.00011138956011587705, 0.00011138397331803836, 0.00011137838813181245, 0.00011137281557778654, 0.00011136723048636138, 0.00011136164852336098, 0.00011135603954214664, 0.00011135041821313452, 0.00011134485288766586, 0.0001113392618000932, 0.0001113336517997708, 0.00011132807196978728, 0.00011132249910765895, 0.00011131692209799777, 0.00011131135575342104, 0.00011130579118635839, 0.00011130021443739928, 0.0001112946078262037, 0.00011128901493741679, 0.00011128346219674778, 0.00011127787881173612, 0.00011127231054744419, 0.00011126673704541079, 0.00011126115681252408, 0.00011125558902223591, 0.00011125005583422173, 0.00011124446320613688, 0.0001112388971696626, 0.00011123331238633987, 0.00011122771212679458, 0.00011122213672874616, 0.00011121658441468054, 0.00011121101050974394, 0.00011120543601230267, 0.00011119990640301681, 0.00011119435970589568, 0.00011118879283991482, 0.00011118323817953061, 0.00011117767458417565, 0.00011117213549481475, 0.00011116659941537767, 0.00011116103003717692, 0.00011115543359336186, 0.0001111498892188591, 0.00011114437555979956, 0.00011113881279395117, 0.00011113327673821428, 0.00011112774243629127, 0.00011112221709303922, 0.00011111667316884003, 0.00011111111708644456, 0.0001111055610040491, 0.0001110999863170063, 0.00011109447460136216, 0.00011108892174219221, 0.00011108339696774465, 0.00011107785562686592, 0.00011107230357350235, 0.00011106674820211251, 0.00011106121330768483, 0.00011105566744007024, 0.00011105019518523857, 0.00011104467199870358, 0.00011103915085038473, 0.00011103364567599239, 0.00011102811931363225, 0.00011102260728988566, 0.00011101709483953569, 0.00011101157020728926, 0.00011100603317984468, 0.00011100052693894388, 0.00011099499749555935, 0.0001109894861591182, 0.00011098396666981249, 0.00011097847045409108, 0.00011097296544560003, 0.0001109674563843769], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433227182599538, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329]}
[2017-12-14 14:11:27,992 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:92]: done!
[2017-12-14 14:11:28,035 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:152]: >> Executing classifier part ... 
[2017-12-14 14:11:28,035 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:97]: =======================================
[2017-12-14 14:11:28,035 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fcef586d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-14 14:11:28,418 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:110]: training ... 
[2017-12-14 16:00:21,130 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:122]: trained!
[2017-12-14 16:00:21,141 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:125]: Training history: 
{'val_loss': [0.0001114186469630821, 0.00011141480363065066, 0.00011141090668495905, 0.00011140694631150917, 0.00011140297531909413, 0.00011139898494796149, 0.00011139497087186623, 0.00011139098132307772, 0.00011138690137006891, 0.00011138281798466733, 0.00011137866055254231, 0.00011137445424457427, 0.00011137028234991924, 0.0001113660275772802, 0.00011136169328754173, 0.00011135732270740042, 0.00011135294844458768, 0.00011134852834502968, 0.00011134407086456904, 0.00011133956475854401, 0.000111335052020135, 0.00011133049923714356, 0.00011132590991347063, 0.0001113212767731586, 0.00011131666783836649, 0.0001113120035562408, 0.00011130735745507061, 0.00011130266569592562, 0.00011129795359270258, 0.00011129318549857231, 0.00011128839500450371, 0.00011128358219988205, 0.00011127879186670688, 0.00011127398624865759, 0.00011126913886982948, 0.00011126423852131485, 0.00011125933647448087, 0.0001112544128142986, 0.00011124941918335933, 0.00011124443756579479, 0.00011123942391256428, 0.00011123443886260697, 0.00011122942864176924, 0.00011122440549582746, 0.00011121933756788611, 0.00011121429922645546, 0.00011120927200454725, 0.00011120421380171878, 0.00011119916671841275, 0.0001111940447302851, 0.00011118892790862366, 0.00011118374998321991, 0.00011117858028125718, 0.00011117337886541533, 0.00011116820753664144, 0.0001111629847040988, 0.00011115777944469212, 0.00011115256544341005, 0.00011114731073609487, 0.00011114206543210574, 0.00011113676617519257, 0.00011113149462770029, 0.00011112620820650597, 0.00011112088696082656, 0.00011111559342456803, 0.00011111027030179881, 0.00011110491407074089, 0.00011109957795135942, 0.00011109423300071736, 0.00011108884387589529, 0.0001110834984068189, 0.00011107815016680042, 0.00011107275271127503, 0.00011106734610270224, 0.00011106194473210384, 0.00011105655194248739, 0.00011105116233498509, 0.00011104578769057006, 0.00011104040144395235, 0.00011103499705213321, 0.00011102960066923057, 0.0001110241853187824, 0.00011101877422307112, 0.00011101336443238417, 0.00011100794230653567, 0.00011100253054937371, 0.00011099715443904092, 0.00011099173680033091, 0.00011098633428560158, 0.00011098092490608669, 0.00011097551168300696, 0.0001109700934007233, 0.00011096464274310981, 0.0001109592097480175, 0.00011095377494734357, 0.00011094834563492268, 0.00011094292799621267, 0.00011093748486483543, 0.00011093204802617829, 0.0001109266082378086, 0.0001109211485880411, 0.00011091567422546497, 0.00011091021899132776, 0.00011090477593145871, 0.00011089930941690565, 0.00011089383930906639, 0.00011088837434981631, 0.00011088292467544034, 0.00011087744214305429, 0.00011087194464758099, 0.0001108664716794144, 0.00011086101015255711, 0.0001108555413497422, 0.00011085010123958568, 0.00011084465353168474, 0.00011083919273778632, 0.00011083373979191097, 0.00011082824108079854, 0.00011082275731489634, 0.00011081731050084768, 0.00011081182739639618, 0.00011080638172647845, 0.00011080090900859052, 0.00011079544633760229, 0.00011078998824313777, 0.0001107845385687618, 0.00011077907999161704, 0.00011077361919771862, 0.00011076813298266116, 0.00011076263271624575, 0.00011075718974576192, 0.00011075172094294701, 0.00011074623358375862, 0.00011074077459544181, 0.00011073532206073851, 0.00011072986593274903, 0.00011072442451756819, 0.00011071897999178138, 0.0001107135265632258, 0.00011070804133140585, 0.00011070257138446001, 0.00011069714264410459, 0.00011069168340550915, 0.00011068623601939502, 0.00011068078716736314, 0.00011067533030641478, 0.00011066988717503754, 0.00011066447461340851, 0.00011065900933237161, 0.00011065356652278119, 0.00011064810410207161, 0.00011064262868474977, 0.00011063717468412873, 0.00011063175043091178, 0.00011062630084592103, 0.00011062085362070032, 0.00011061544458084929, 0.00011061002483264787, 0.00011060458366774567, 0.0001105991545162182, 0.00011059371415578304, 0.00011058830136175243, 0.00011058289575429418, 0.00011057745033465509, 0.00011057198333742179, 0.00011056656301715491, 0.00011056117326663624, 0.00011055573725032321, 0.00011055032649427579, 0.00011054491548794973, 0.00011053951486818726, 0.00011053409470881379, 0.00011052867022319526, 0.00011052323567279997, 0.00011051778919841518, 0.00011051240100319948, 0.00011050697528406479, 0.0001105015763804987, 0.00011049616210267328, 0.00011049073221818693, 0.0001104852999560535, 0.00011047989425921003, 0.00011047447279481223, 0.00011046912759389152, 0.00011046373081769387, 0.00011045833722361036, 0.00011045295868199936, 0.00011044755797285166, 0.00011044217394298762, 0.00011043678533659987, 0.00011043139084866408, 0.00011042598082557554, 0.0001104205985119079, 0.00011041519445975263, 0.00011040981100195406, 0.00011040441724697713, 0.00011039904671428263, 0.00011039367192685123, 0.0001103882861807908, 0.00011038293141565064], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011203407230980373, 0.00011202993674555654, 0.00011202578880981139, 0.00011202160063114758, 0.00011201734059351476, 0.0001120130798448763, 0.0001120087736392779, 0.00011200444899493348, 0.00011200012136436544, 0.00011199568241401591, 0.00011199126522043866, 0.00011198678218774006, 0.00011198226322555696, 0.00011197779026543812, 0.00011197326805632931, 0.00011196868557764326, 0.00011196408034677706, 0.00011195947627722003, 0.00011195486590341311, 0.00011195023446013933, 0.00011194556919669775, 0.00011194088904953832, 0.00011193616707154766, 0.00011193139875969009, 0.00011192657953982943, 0.00011192175811585129, 0.00011191689047650722, 0.00011191202748239992, 0.00011190713163983252, 0.00011190223020402083, 0.00011189725088939246, 0.00011189225022089501, 0.00011188721798374757, 0.00011188220283443546, 0.00011187716877237357, 0.00011187207564944401, 0.00011186692220953685, 0.00011186176903033174, 0.00011185661250940017, 0.00011185138977014426, 0.00011184618219900846, 0.00011184094981377617, 0.00011183573894831428, 0.0001118304813460823, 0.00011182523037990288, 0.0001118199255194967, 0.00011181464445407894, 0.00011180937997879254, 0.00011180406134857733, 0.00011179877032908075, 0.00011179341444217052, 0.00011178808069123556, 0.00011178269925552303, 0.00011177733180292121, 0.0001117719403183291, 0.00011176657857747251, 0.00011176116332159217, 0.00011175575666887995, 0.00011175033416074219, 0.00011174488238287264, 0.00011173945380748684, 0.00011173397446629904, 0.00011172851093313641, 0.0001117230043367328, 0.00011171746854169798, 0.0001117119645760152, 0.00011170644624801868, 0.00011170089319924724, 0.00011169535813891823, 0.00011168982675211831, 0.00011168426227985641, 0.0001116787554938513, 0.00011167325226287434, 0.00011166770959478508, 0.00011166215829982753, 0.0001116566132854197, 0.00011165107651867718, 0.00011164554589028327, 0.0001116400277044879, 0.00011163451487493492, 0.00011162898597665471, 0.00011162347115628597, 0.00011161793555085265, 0.00011161240105932815, 0.00011160686860601979, 0.0001116013143011384, 0.00011159576845722401, 0.00011159026316433071, 0.00011158471241447748, 0.00011157916469824825, 0.00011157360728864228, 0.0001115680546664742, 0.00011156250484092828, 0.00011155693548642773, 0.00011155138016243826, 0.00011154582761137076, 0.00011154027570020832, 0.000111534741232384, 0.00011152917820583355, 0.00011152361487118066, 0.00011151805248453527, 0.00011151246959722756, 0.00011150686367333742, 0.00011150127391297528, 0.00011149569875192874, 0.00011149010389602625, 0.00011148452062951552, 0.00011147893812141081, 0.00011147337374394966, 0.00011146777606772484, 0.00011146215800933862, 0.00011145656758537121, 0.00011145098801608977, 0.00011144540401487323, 0.00011143984869088377, 0.00011143427919418209, 0.00011142870012260458, 0.00011142312882468862, 0.0001114175069505722, 0.0001114119019272892, 0.00011140633198028394, 0.00011140072887671614, 0.00011139515819500507, 0.00011138956011587705, 0.00011138397331803836, 0.00011137838813181245, 0.00011137281557778654, 0.00011136723048636138, 0.00011136164852336098, 0.00011135603954214664, 0.00011135041821313452, 0.00011134485288766586, 0.0001113392618000932, 0.0001113336517997708, 0.00011132807196978728, 0.00011132249910765895, 0.00011131692209799777, 0.00011131135575342104, 0.00011130579118635839, 0.00011130021443739928, 0.0001112946078262037, 0.00011128901493741679, 0.00011128346219674778, 0.00011127787881173612, 0.00011127231054744419, 0.00011126673704541079, 0.00011126115681252408, 0.00011125558902223591, 0.00011125005583422173, 0.00011124446320613688, 0.0001112388971696626, 0.00011123331238633987, 0.00011122771212679458, 0.00011122213672874616, 0.00011121658441468054, 0.00011121101050974394, 0.00011120543601230267, 0.00011119990640301681, 0.00011119435970589568, 0.00011118879283991482, 0.00011118323817953061, 0.00011117767458417565, 0.00011117213549481475, 0.00011116659941537767, 0.00011116103003717692, 0.00011115543359336186, 0.0001111498892188591, 0.00011114437555979956, 0.00011113881279395117, 0.00011113327673821428, 0.00011112774243629127, 0.00011112221709303922, 0.00011111667316884003, 0.00011111111708644456, 0.0001111055610040491, 0.0001110999863170063, 0.00011109447460136216, 0.00011108892174219221, 0.00011108339696774465, 0.00011107785562686592, 0.00011107230357350235, 0.00011106674820211251, 0.00011106121330768483, 0.00011105566744007024, 0.00011105019518523857, 0.00011104467199870358, 0.00011103915085038473, 0.00011103364567599239, 0.00011102811931363225, 0.00011102260728988566, 0.00011101709483953569, 0.00011101157020728926, 0.00011100603317984468, 0.00011100052693894388, 0.00011099499749555935, 0.0001109894861591182, 0.00011098396666981249, 0.00011097847045409108, 0.00011097296544560003, 0.0001109674563843769], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433227182599538, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329]}
[2017-12-14 16:00:21,142 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:129]: evaluating model ... 
[2017-12-14 16:00:23,419 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:133]: evaluated! 
[2017-12-14 16:00:23,419 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:135]: generating reports ... 
[2017-12-14 16:00:27,964 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:138]: done!
[2017-12-14 16:00:27,964 AE_BIGRAMA_1L_MINIDS_UNDER_F0_2.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_2 finished!
