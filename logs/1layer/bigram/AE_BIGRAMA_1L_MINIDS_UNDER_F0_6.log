[2017-12-14 09:31:57,667 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_6
[2017-12-14 09:31:57,667 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:146]: >> Printing header log
[2017-12-14 09:31:57,668 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_6
	layers = 9216,5530
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fee2e954be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fee2e954470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 09:31:57,668 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:148]: >> Loading dataset... 
[2017-12-14 09:32:21,320 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 09:32:21,321 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:150]: >> Executing autoencoder part ... 
[2017-12-14 09:32:21,321 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:57]: =======================================
[2017-12-14 09:32:21,321 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fee2e954be0>, 'discard_decoder_function': True}
[2017-12-14 09:32:21,363 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:73]: training and evaluate autoencoder
[2017-12-14 10:18:55,056 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_6
[2017-12-14 10:18:55,056 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:146]: >> Printing header log
[2017-12-14 10:18:55,056 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_6
	layers = 9216,5530
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8f45177eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8f4515a400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 10:18:55,056 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:148]: >> Loading dataset... 
[2017-12-14 10:19:17,447 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 10:19:17,448 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:150]: >> Executing autoencoder part ... 
[2017-12-14 10:19:17,448 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:57]: =======================================
[2017-12-14 10:19:17,448 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8f45177eb8>, 'discard_decoder_function': True}
[2017-12-14 10:19:17,496 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:73]: training and evaluate autoencoder
[2017-12-14 19:45:22,683 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:85]: trained and evaluated!
[2017-12-14 19:45:22,685 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:88]: Training history: 
{'val_loss': [0.00011872587433695239, 0.00011872292825344639, 0.0001187199734995732, 0.00011871702830991948, 0.00011871409824424645, 0.00011871114635070058, 0.00011870821228056931, 0.00011870526896800539, 0.00011870232762191651, 0.00011869939158531021, 0.0001186964429632637, 0.00011869350832106697, 0.00011869056500850305, 0.00011868763379869909, 0.00011868470618218133, 0.00011868176099252762, 0.00011867882994361706, 0.00011867590184441907, 0.00011867297807146615, 0.00011867005544264414, 0.00011866715111991698, 0.00011866421803302321, 0.00011866127986904846, 0.00011865834465478627, 0.00011865542186507085, 0.00011865249866418339, 0.00011864958003981964, 0.00011864665896630061, 0.00011864373061682397, 0.00011864080872096085, 0.00011863787677819801, 0.00011863494671252499, 0.00011863203479205338, 0.00011862912884251505, 0.00011862621250641315, 0.00011862329273791847, 0.00011862038408894622, 0.00011861745459533866, 0.00011861453352181965, 0.00011861162642815038, 0.00011860870780378662, 0.00011860579212913542, 0.0001186028793863197, 0.00011859996428373395, 0.0001185970437822804, 0.00011859413211208743, 0.00011859121618715758, 0.00011858830728790671, 0.00011858538564232221, 0.00011858248083691481, 0.00011857957177677052, 0.00011857666296690487, 0.00011857374189338585, 0.00011857083537178205, 0.00011856794486801124, 0.00011856503564697353, 0.00011856213640132736, 0.00011855922635794556, 0.00011855633177820831, 0.00011855342525660452, 0.00011855051390819837, 0.00011854761670053541, 0.00011854471033982503, 0.00011854180635676172, 0.000118538904161403, 0.00011853600205542949, 0.00011853310608128269, 0.00011853020781887403, 0.00011852731388271043, 0.00011852441225941716, 0.00011852152658244869, 0.0001185186378842595, 0.00011851573863861331, 0.00011851283710470529, 0.00011850993719760841, 0.000118507051931812, 0.00011850415129175625, 0.00011850125719469924, 0.00011849836129206062, 0.00011849546016932463, 0.00011849258536159997, 0.000118489691675715, 0.00011848679872278893, 0.00011848391231286159, 0.00011848102810181087, 0.00011847814741253816, 0.00011847524963280974, 0.00011847237123179888, 0.00011846948923750184, 0.00011846661973925976, 0.00011846372760867778, 0.000118460839071382, 0.0001184579604200925, 0.0001184550932994975, 0.00011845219732535069, 0.00011844931091542335, 0.00011844643267530591, 0.00011844356212231814, 0.00011844069614585407, 0.00011843779934936315, 0.00011843492691928557, 0.00011843204524677535, 0.00011842918000327016, 0.00011842631558210908, 0.00011842342647274782, 0.00011842055722478439, 0.00011841767850198671, 0.00011841480541045844, 0.00011841193854014209, 0.00011840907240278461, 0.00011840619718388789, 0.00011840333349568568, 0.00011840046793039367, 0.00011839759966566775, 0.00011839474840201231, 0.00011839187327250083, 0.00011838901269490457, 0.00011838616788486266, 0.0001183832964380226, 0.00011838044746262902, 0.00011837759832634204, 0.00011837475360568534, 0.00011837188394654986, 0.0001183690233689536, 0.00011836615837572705, 0.0001183632969757867, 0.00011836044374565624, 0.00011835758872782121, 0.00011835474146862402, 0.00011835189404853343, 0.00011834903861952635, 0.00011834618858938708, 0.00011834333863075598, 0.00011834050004192598, 0.0001183376401972886, 0.00011833480062522109, 0.00011833194977273771, 0.00011832911363306297, 0.00011832626776827536, 0.0001183234151995956, 0.00011832055674936778, 0.0001183176996041643, 0.00011831486158739977, 0.00011831202618068391, 0.00011830918743096049, 0.00011830634246002517, 0.0001183034917684352, 0.00011830065219636769, 0.00011829781131927584, 0.00011829497199748695, 0.00011829214157846686, 0.00011828930413376778, 0.00011828645998517655, 0.00011828360881090636, 0.00011828077193827274, 0.00011827794021422831, 0.00011827508789582717, 0.00011827224905671854, 0.00011826941472262542, 0.00011826657776060658, 0.00011826376017730532, 0.00011826093041973591, 0.00011825808487673512, 0.00011825525143649429, 0.00011825242527221107, 0.00011824959640849396, 0.00011824677555369332, 0.00011824395707653978, 0.00011824112976812563, 0.00011823829518375388, 0.00011823545570107159, 0.00011823263770659828, 0.00011822981236465917, 0.00011822698807746574, 0.00011822417294331975, 0.00011822135888179649, 0.00011821853525605378, 0.00011821571154092582, 0.00011821289395762456, 0.00011821006975981638, 0.00011820725462567038, 0.00011820442928373127, 0.00011820161513282279, 0.00011819879379534193, 0.00011819597522880315, 0.00011819315478517457, 0.00011819032159521238, 0.00011818751144876214, 0.00011818468839508488, 0.0001181818696676527, 0.00011817905176256461, 0.00011817624301052394, 0.00011817343736908922, 0.00011817062992207289, 0.00011816782933984213, 0.00011816501829953961, 0.00011816221993406251, 0.0001181594243395275, 0.00011815661860870755, 0.00011815380740751162], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011951018317548728, 0.00011950714862715841, 0.00011950412163918942, 0.00011950108360693296, 0.00011949805472294894, 0.00011949504129148729, 0.00011949201032188675, 0.00011948899255329076, 0.00011948596532831988, 0.0001194829442416976, 0.00011947992874831962, 0.00011947690479397464, 0.00011947388261714373, 0.0001194708597293072, 0.00011946785366860392, 0.00011946483677691486, 0.00011946181317807269, 0.0001194588005761176, 0.00011945579034418128, 0.00011945278489968288, 0.00011944978120899836, 0.00011944679555415664, 0.00011944377854396666, 0.00011944076411709711, 0.00011943775092263733, 0.0001194347420416117, 0.00011943173925153431, 0.0001194287413199954, 0.00011942573371877991, 0.00011942272929338956, 0.00011941972536570316, 0.00011941671411465877, 0.00011941370530473371, 0.00011941071230283383, 0.00011940772494157861, 0.00011940472712854063, 0.0001194017299791079, 0.00011939873534189507, 0.0001193957317460113, 0.00011939273322196768, 0.00011938973976976424, 0.00011938674138792174, 0.00011938374603970329, 0.00011938075438871409, 0.00011937775503516391, 0.00011937475155778108, 0.00011937176647174388, 0.00011936876778179895, 0.0001193657762493107, 0.00011936277613735451, 0.00011935978962930605, 0.00011935680587047936, 0.0001193538101193577, 0.00011935080998370133, 0.00011934782338085211, 0.00011934484820149335, 0.00011934185738001073, 0.0001193388792855289, 0.00011933588739753783, 0.0001193329123603802, 0.00011932992736914374, 0.00011932693863327763, 0.00011932395556175639, 0.00011932097111562425, 0.0001193179882337045, 0.00011931500094354984, 0.00011931202111895429, 0.00011930904437538315, 0.0001193060666838045, 0.00011930309373226339, 0.0001193001147608746, 0.00011929714671527233, 0.00011929417888297175, 0.00011929119962718071, 0.00011928821695856265, 0.00011928523748946992, 0.00011928226892246352, 0.00011927928589834265, 0.00011927631458211447, 0.00011927333978195872, 0.00011927035735034253, 0.00011926740428325887, 0.0001192644325878277, 0.00011926146022879127, 0.00011925849372370119, 0.00011925553205344942, 0.0001192525698617935, 0.00011924959354482573, 0.00011924663554810303, 0.00011924367764618108, 0.00011924072761272143, 0.00011923775442417844, 0.00011923478718438256, 0.00011923183165247937, 0.00011922888780476871, 0.0001192259127202107, 0.00011922294559891576, 0.00011921999220002946, 0.00011921704465508953, 0.00011921409594884039, 0.00011921111825726174, 0.00011920816639888764, 0.00011920520764375894, 0.00011920226026472031, 0.00011919932177325207, 0.00011919635308774473, 0.00011919339983105957, 0.00011919044707207835, 0.00011918749182457741, 0.00011918454691035831, 0.00011918159962612044, 0.00011917865331359025, 0.0001191757098450826, 0.00011917276339035129, 0.00011916981546620835, 0.00011916687908405681, 0.00011916393307962906, 0.00011916098551098894, 0.0001191580618084378, 0.0001191551130310881, 0.00011915218565500787, 0.00011914925752052164, 0.00011914632834322715, 0.00011914337930517538, 0.00011914043882289137, 0.00011913749220225875, 0.0001191345527390828, 0.00011913162213977705, 0.0001191286767515542, 0.00011912575093968635, 0.0001191228259099247, 0.00011911989433891125, 0.00011911696288639874, 0.00011911403330620106, 0.00011911110991175235, 0.00011910817144398429, 0.000119105253026575, 0.00011910231609931914, 0.00011909940180574249, 0.00011909647561467164, 0.00011909353816601165, 0.00011909060209196255, 0.0001190876647618035, 0.00011908474281306624, 0.00011908182688417666, 0.00011907890770836136, 0.00011907598270229989, 0.00011907305056248194, 0.00011907013534459798, 0.00011906721567107874, 0.00011906429654266382, 0.00011906138305489357, 0.00011905846186456231, 0.00011905553263986744, 0.0001190525993387403, 0.00011904968604057154, 0.00011904677504132098, 0.00011904384010488089, 0.00011904092230367648, 0.00011903800504757638, 0.00011903508864468304, 0.00011903219053833458, 0.00011902927866217708, 0.00011902635164159966, 0.00011902343455140087, 0.00011902052990380062, 0.00011901761933115345, 0.00011901472046639898, 0.0001190118223837507, 0.00011900890631265999, 0.00011900599417580043, 0.00011900307952672097, 0.00011900017755724192, 0.00011899727582476475, 0.00011899437148526694, 0.00011899147013199276, 0.00011898858261962818, 0.00011898567621821405, 0.00011898277005380178, 0.00011897987270585932, 0.0001189769699068737, 0.00011897407547405432, 0.00011897117528208935, 0.00011896828174987711, 0.00011896537741037929, 0.00011896248127114641, 0.00011895958480011089, 0.00011895667285285284, 0.00011895377557601094, 0.00011895087806216717, 0.00011894798298944273, 0.00011894508933872955, 0.00011894219886384152, 0.00011893931258388671, 0.00011893642931385572, 0.00011893354962255308, 0.00011893066609182003, 0.00011892778500220633, 0.00011892491225505866, 0.00011892202640170723], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-14 19:45:22,686 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:92]: done!
[2017-12-14 19:45:22,686 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:152]: >> Executing classifier part ... 
[2017-12-14 19:45:22,686 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:97]: =======================================
[2017-12-14 19:45:22,686 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8f4515a400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-14 19:45:22,753 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:110]: training ... 
[2017-12-14 23:36:45,571 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:122]: trained!
[2017-12-14 23:36:45,573 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:125]: Training history: 
{'val_loss': [0.00011872587433695239, 0.00011872292825344639, 0.0001187199734995732, 0.00011871702830991948, 0.00011871409824424645, 0.00011871114635070058, 0.00011870821228056931, 0.00011870526896800539, 0.00011870232762191651, 0.00011869939158531021, 0.0001186964429632637, 0.00011869350832106697, 0.00011869056500850305, 0.00011868763379869909, 0.00011868470618218133, 0.00011868176099252762, 0.00011867882994361706, 0.00011867590184441907, 0.00011867297807146615, 0.00011867005544264414, 0.00011866715111991698, 0.00011866421803302321, 0.00011866127986904846, 0.00011865834465478627, 0.00011865542186507085, 0.00011865249866418339, 0.00011864958003981964, 0.00011864665896630061, 0.00011864373061682397, 0.00011864080872096085, 0.00011863787677819801, 0.00011863494671252499, 0.00011863203479205338, 0.00011862912884251505, 0.00011862621250641315, 0.00011862329273791847, 0.00011862038408894622, 0.00011861745459533866, 0.00011861453352181965, 0.00011861162642815038, 0.00011860870780378662, 0.00011860579212913542, 0.0001186028793863197, 0.00011859996428373395, 0.0001185970437822804, 0.00011859413211208743, 0.00011859121618715758, 0.00011858830728790671, 0.00011858538564232221, 0.00011858248083691481, 0.00011857957177677052, 0.00011857666296690487, 0.00011857374189338585, 0.00011857083537178205, 0.00011856794486801124, 0.00011856503564697353, 0.00011856213640132736, 0.00011855922635794556, 0.00011855633177820831, 0.00011855342525660452, 0.00011855051390819837, 0.00011854761670053541, 0.00011854471033982503, 0.00011854180635676172, 0.000118538904161403, 0.00011853600205542949, 0.00011853310608128269, 0.00011853020781887403, 0.00011852731388271043, 0.00011852441225941716, 0.00011852152658244869, 0.0001185186378842595, 0.00011851573863861331, 0.00011851283710470529, 0.00011850993719760841, 0.000118507051931812, 0.00011850415129175625, 0.00011850125719469924, 0.00011849836129206062, 0.00011849546016932463, 0.00011849258536159997, 0.000118489691675715, 0.00011848679872278893, 0.00011848391231286159, 0.00011848102810181087, 0.00011847814741253816, 0.00011847524963280974, 0.00011847237123179888, 0.00011846948923750184, 0.00011846661973925976, 0.00011846372760867778, 0.000118460839071382, 0.0001184579604200925, 0.0001184550932994975, 0.00011845219732535069, 0.00011844931091542335, 0.00011844643267530591, 0.00011844356212231814, 0.00011844069614585407, 0.00011843779934936315, 0.00011843492691928557, 0.00011843204524677535, 0.00011842918000327016, 0.00011842631558210908, 0.00011842342647274782, 0.00011842055722478439, 0.00011841767850198671, 0.00011841480541045844, 0.00011841193854014209, 0.00011840907240278461, 0.00011840619718388789, 0.00011840333349568568, 0.00011840046793039367, 0.00011839759966566775, 0.00011839474840201231, 0.00011839187327250083, 0.00011838901269490457, 0.00011838616788486266, 0.0001183832964380226, 0.00011838044746262902, 0.00011837759832634204, 0.00011837475360568534, 0.00011837188394654986, 0.0001183690233689536, 0.00011836615837572705, 0.0001183632969757867, 0.00011836044374565624, 0.00011835758872782121, 0.00011835474146862402, 0.00011835189404853343, 0.00011834903861952635, 0.00011834618858938708, 0.00011834333863075598, 0.00011834050004192598, 0.0001183376401972886, 0.00011833480062522109, 0.00011833194977273771, 0.00011832911363306297, 0.00011832626776827536, 0.0001183234151995956, 0.00011832055674936778, 0.0001183176996041643, 0.00011831486158739977, 0.00011831202618068391, 0.00011830918743096049, 0.00011830634246002517, 0.0001183034917684352, 0.00011830065219636769, 0.00011829781131927584, 0.00011829497199748695, 0.00011829214157846686, 0.00011828930413376778, 0.00011828645998517655, 0.00011828360881090636, 0.00011828077193827274, 0.00011827794021422831, 0.00011827508789582717, 0.00011827224905671854, 0.00011826941472262542, 0.00011826657776060658, 0.00011826376017730532, 0.00011826093041973591, 0.00011825808487673512, 0.00011825525143649429, 0.00011825242527221107, 0.00011824959640849396, 0.00011824677555369332, 0.00011824395707653978, 0.00011824112976812563, 0.00011823829518375388, 0.00011823545570107159, 0.00011823263770659828, 0.00011822981236465917, 0.00011822698807746574, 0.00011822417294331975, 0.00011822135888179649, 0.00011821853525605378, 0.00011821571154092582, 0.00011821289395762456, 0.00011821006975981638, 0.00011820725462567038, 0.00011820442928373127, 0.00011820161513282279, 0.00011819879379534193, 0.00011819597522880315, 0.00011819315478517457, 0.00011819032159521238, 0.00011818751144876214, 0.00011818468839508488, 0.0001181818696676527, 0.00011817905176256461, 0.00011817624301052394, 0.00011817343736908922, 0.00011817062992207289, 0.00011816782933984213, 0.00011816501829953961, 0.00011816221993406251, 0.0001181594243395275, 0.00011815661860870755, 0.00011815380740751162], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011951018317548728, 0.00011950714862715841, 0.00011950412163918942, 0.00011950108360693296, 0.00011949805472294894, 0.00011949504129148729, 0.00011949201032188675, 0.00011948899255329076, 0.00011948596532831988, 0.0001194829442416976, 0.00011947992874831962, 0.00011947690479397464, 0.00011947388261714373, 0.0001194708597293072, 0.00011946785366860392, 0.00011946483677691486, 0.00011946181317807269, 0.0001194588005761176, 0.00011945579034418128, 0.00011945278489968288, 0.00011944978120899836, 0.00011944679555415664, 0.00011944377854396666, 0.00011944076411709711, 0.00011943775092263733, 0.0001194347420416117, 0.00011943173925153431, 0.0001194287413199954, 0.00011942573371877991, 0.00011942272929338956, 0.00011941972536570316, 0.00011941671411465877, 0.00011941370530473371, 0.00011941071230283383, 0.00011940772494157861, 0.00011940472712854063, 0.0001194017299791079, 0.00011939873534189507, 0.0001193957317460113, 0.00011939273322196768, 0.00011938973976976424, 0.00011938674138792174, 0.00011938374603970329, 0.00011938075438871409, 0.00011937775503516391, 0.00011937475155778108, 0.00011937176647174388, 0.00011936876778179895, 0.0001193657762493107, 0.00011936277613735451, 0.00011935978962930605, 0.00011935680587047936, 0.0001193538101193577, 0.00011935080998370133, 0.00011934782338085211, 0.00011934484820149335, 0.00011934185738001073, 0.0001193388792855289, 0.00011933588739753783, 0.0001193329123603802, 0.00011932992736914374, 0.00011932693863327763, 0.00011932395556175639, 0.00011932097111562425, 0.0001193179882337045, 0.00011931500094354984, 0.00011931202111895429, 0.00011930904437538315, 0.0001193060666838045, 0.00011930309373226339, 0.0001193001147608746, 0.00011929714671527233, 0.00011929417888297175, 0.00011929119962718071, 0.00011928821695856265, 0.00011928523748946992, 0.00011928226892246352, 0.00011927928589834265, 0.00011927631458211447, 0.00011927333978195872, 0.00011927035735034253, 0.00011926740428325887, 0.0001192644325878277, 0.00011926146022879127, 0.00011925849372370119, 0.00011925553205344942, 0.0001192525698617935, 0.00011924959354482573, 0.00011924663554810303, 0.00011924367764618108, 0.00011924072761272143, 0.00011923775442417844, 0.00011923478718438256, 0.00011923183165247937, 0.00011922888780476871, 0.0001192259127202107, 0.00011922294559891576, 0.00011921999220002946, 0.00011921704465508953, 0.00011921409594884039, 0.00011921111825726174, 0.00011920816639888764, 0.00011920520764375894, 0.00011920226026472031, 0.00011919932177325207, 0.00011919635308774473, 0.00011919339983105957, 0.00011919044707207835, 0.00011918749182457741, 0.00011918454691035831, 0.00011918159962612044, 0.00011917865331359025, 0.0001191757098450826, 0.00011917276339035129, 0.00011916981546620835, 0.00011916687908405681, 0.00011916393307962906, 0.00011916098551098894, 0.0001191580618084378, 0.0001191551130310881, 0.00011915218565500787, 0.00011914925752052164, 0.00011914632834322715, 0.00011914337930517538, 0.00011914043882289137, 0.00011913749220225875, 0.0001191345527390828, 0.00011913162213977705, 0.0001191286767515542, 0.00011912575093968635, 0.0001191228259099247, 0.00011911989433891125, 0.00011911696288639874, 0.00011911403330620106, 0.00011911110991175235, 0.00011910817144398429, 0.000119105253026575, 0.00011910231609931914, 0.00011909940180574249, 0.00011909647561467164, 0.00011909353816601165, 0.00011909060209196255, 0.0001190876647618035, 0.00011908474281306624, 0.00011908182688417666, 0.00011907890770836136, 0.00011907598270229989, 0.00011907305056248194, 0.00011907013534459798, 0.00011906721567107874, 0.00011906429654266382, 0.00011906138305489357, 0.00011905846186456231, 0.00011905553263986744, 0.0001190525993387403, 0.00011904968604057154, 0.00011904677504132098, 0.00011904384010488089, 0.00011904092230367648, 0.00011903800504757638, 0.00011903508864468304, 0.00011903219053833458, 0.00011902927866217708, 0.00011902635164159966, 0.00011902343455140087, 0.00011902052990380062, 0.00011901761933115345, 0.00011901472046639898, 0.0001190118223837507, 0.00011900890631265999, 0.00011900599417580043, 0.00011900307952672097, 0.00011900017755724192, 0.00011899727582476475, 0.00011899437148526694, 0.00011899147013199276, 0.00011898858261962818, 0.00011898567621821405, 0.00011898277005380178, 0.00011897987270585932, 0.0001189769699068737, 0.00011897407547405432, 0.00011897117528208935, 0.00011896828174987711, 0.00011896537741037929, 0.00011896248127114641, 0.00011895958480011089, 0.00011895667285285284, 0.00011895377557601094, 0.00011895087806216717, 0.00011894798298944273, 0.00011894508933872955, 0.00011894219886384152, 0.00011893931258388671, 0.00011893642931385572, 0.00011893354962255308, 0.00011893066609182003, 0.00011892778500220633, 0.00011892491225505866, 0.00011892202640170723], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-14 23:36:45,574 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:129]: evaluating model ... 
[2017-12-14 23:36:52,541 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:133]: evaluated! 
[2017-12-14 23:36:52,542 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:135]: generating reports ... 
[2017-12-14 23:36:55,324 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:138]: done!
[2017-12-14 23:36:55,324 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_6 finished!
