[2018-01-18 00:19:28,510 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_0
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:146]: >> Printing header log
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_0
	layers = 9216,9216
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f197dc41be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f197dc41470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:148]: >> Loading dataset... 
[2018-01-18 00:22:11,989 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:22:11,990 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:22:11,990 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:57]: =======================================
[2018-01-18 00:22:11,990 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f197dc41be0>, 'discard_decoder_function': True}
[2018-01-18 00:22:12,033 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:73]: training and evaluate autoencoder
[2018-01-19 21:08:07,057 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:85]: trained and evaluated!
[2018-01-19 21:08:07,060 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:88]: Training history: 
{'val_loss': [0.00011931074907087119, 0.00011925571597363862, 0.000119200316340348, 0.00011914461734191265, 0.00011908878692700804, 0.0001190328062974048, 0.00011897664874517768, 0.000118920399469357, 0.00011886408780908533, 0.00011880774620534678, 0.00011875138263201333, 0.00011869500255474368, 0.00011863864013657881, 0.00011858224006312721, 0.00011852587087973898, 0.00011846950134873056, 0.00011841317224862223, 0.00011835686928955088, 0.00011830059913512784, 0.000118244395868174, 0.00011818822761459357, 0.00011813207946415513, 0.00011807596608108195, 0.00011801991277747061, 0.00011796397614053724, 0.00011790804395314207, 0.00011785221541538637, 0.00011779646725811062, 0.00011774080458330931, 0.00011768518409355298, 0.00011762969704715892, 0.00011757424876308811, 0.00011751889411719582, 0.00011746368325770296, 0.00011740855881123701, 0.00011735348993051867, 0.00011729853027740658, 0.0001172436710704804, 0.00011718892455131817, 0.00011713423705806128, 0.00011707966936006389, 0.00011702515960767529, 0.00011697076673053673, 0.00011691646699421244, 0.00011686227724491079, 0.00011680816314310671, 0.00011675416233873893, 0.00011670022094533263, 0.00011664638223357736, 0.0001165926548939774, 0.00011653899897695292, 0.00011648546291936397, 0.00011643200360026515, 0.00011637866137568449, 0.00011632540791725192, 0.00011627220621144106, 0.00011621910523526022, 0.0001161661042934691, 0.00011611320334328362, 0.00011606037207757277, 0.00011600766486413154, 0.00011595503742684593, 0.00011590249323656969, 0.00011585002781702456, 0.00011579764560170476, 0.00011574533242375126, 0.00011569316644957087, 0.000115641078010733, 0.00011558905506888366, 0.00011553713738642262, 0.00011548531631028155, 0.00011543358219266368, 0.00011538192757310532, 0.00011533036062870249, 0.00011527889789013142, 0.00011522752100304701, 0.00011517622758224004, 0.00011512499633196396, 0.00011507384332831475, 0.00011502279737028671, 0.00011497182288296617, 0.00011492092395222718, 0.00011487010805992542, 0.00011481939013768432, 0.0001147687617517037, 0.00011471821568217998, 0.00011466777080221451, 0.00011461738006542795, 0.00011456708648045763, 0.00011451685870266, 0.00011446670531557934, 0.00011441665557813816, 0.0001143666898417747, 0.00011431682983007576, 0.00011426704007508771, 0.00011421733322483684, 0.00011416773345764316, 0.00011411819418705555, 0.00011406872400196624, 0.00011401935462137901, 0.00011397006867498122], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.0018375597206909224, 0.0029400955531054761, 0.0036751194413818448, 0.0058801911062109522, 0.0084527747151782427, 0.012127894156560088, 0.016538037486218304, 0.021315692760014701, 0.026828371922087469, 0.034546122748989341, 0.041528849687614847, 0.049981624402793093, 0.060271958838662258, 0.071664829106945979, 0.082690187431091508, 0.097390665196618889, 0.11723631018008085, 0.13561190738699008, 0.14847482543182652, 0.16207276736493936, 0.17750826901874311, 0.19147372289599413, 0.20543917677324514, 0.22454979786843071, 0.24292539507533994, 0.2587284086732819, 0.27489893421536199, 0.29143697170158028, 0.30613744946710769, 0.31863285556780596, 0.33443586916574791, 0.34509371554575524, 0.35722160970231531, 0.3667769202499081, 0.37816979051819183, 0.38441749356854099, 0.39544285189268652, 0.40352811466372657, 0.4141859610437339, 0.42521131936787948, 0.43403160602719587, 0.44248438074237412, 0.44652701212789414, 0.45350973906651965, 0.45681734656376333, 0.46233002572583609, 0.46674016905549431, 0.47115031238515254, 0.47482543182653436, 0.47739801543550164, 0.47923557515619258, 0.48144064682102167, 0.48291069459757441, 0.48327820654171261, 0.48401323042998895, 0.48401323042998895, 0.48438074237412715, 0.48548327820654169, 0.48585079015067989, 0.48585079015067989, 0.48658581403895629, 0.48732083792723263, 0.48768834987137083, 0.48915839764792357, 0.48989342153619991, 0.49026093348033811, 0.49026093348033811, 0.49026093348033811, 0.49026093348033811, 0.49062844542447631, 0.49062844542447631, 0.49099595736861446, 0.49136346931275265, 0.49173098125689085, 0.49209849320102905, 0.49209849320102905, 0.4924660051451672], 'loss': [0.00011947258170500778, 0.00011941840015911486, 0.00011936370894163448, 0.0001193085867600841, 0.00011925316241954372, 0.00011919755598715678, 0.00011914175117663838, 0.00011908580619832869, 0.000119029763156686, 0.0001189736369304944, 0.00011891745801590272, 0.00011886123427026645, 0.00011880500887778277, 0.00011874880848630036, 0.00011869257996444937, 0.00011863636363409187, 0.00011858013263035966, 0.0001185239652231589, 0.00011846781676809962, 0.000118411715020455, 0.00011835569869185616, 0.0001182997394483113, 0.00011824379950789001, 0.00011818791964256888, 0.00011813208893528568, 0.00011807637784949685, 0.00011802067393696094, 0.00011796506492356042, 0.00011790955530597466, 0.00011785411755577384, 0.00011779871814478799, 0.00011774345603657908, 0.00011768823362507323, 0.0001176331043908363, 0.00011757811024631345, 0.00011752320995869665, 0.0001174683667748886, 0.00011741363030036244, 0.00011735899557046266, 0.00011730447236535521, 0.00011725000538972699, 0.00011719565371395832, 0.00011714136655459792, 0.00011708718612327418, 0.00011703310517350127, 0.0001169791300104542, 0.00011692523228853104, 0.00011687144908680489, 0.00011681772293173008, 0.00011676410025207899, 0.00011671058572761323, 0.00011665714096017428, 0.00011660381599106041, 0.00011655056448259383, 0.00011649742757380874, 0.0001164443732512061, 0.00011639136890649276, 0.00011633846213570222, 0.00011628566133114747, 0.00011623295707793402, 0.00011618032426342506, 0.00011612781795787645, 0.00011607539002225941, 0.00011602304629109353, 0.00011597077628671407, 0.00011591859474679779, 0.00011586648647462261, 0.00011581452037253365, 0.00011576262823479153, 0.00011571079625252714, 0.00011565905900417756, 0.00011560742255110578, 0.00011555587293529762, 0.00011550439720524488, 0.00011545300519916394, 0.00011540172775882731, 0.00011535053016647673, 0.00011529941861654477, 0.00011524836927439819, 0.00011519739562114419, 0.0001151465277108549, 0.00011509573001842389, 0.00011504501392174487, 0.00011499437520546005, 0.00011494383875714901, 0.00011489338407070363, 0.00011484300629221086, 0.00011479273486844552, 0.00011474251952412128, 0.00011469239684264939, 0.00011464233818906865, 0.00011459235902802643, 0.00011454248600647834, 0.00011449269368134636, 0.00011444300187106373, 0.00011439338119405076, 0.00011434384531360384, 0.00011429441196637672, 0.0001142450434454581, 0.00011419574354913542, 0.00011414654670223525], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00024548913710568308, 0.00073646741131704919, 0.0020866576653983063, 0.0033141033509267214, 0.005523505584877869, 0.0083466306625077421, 0.011660734012519946, 0.017429728735418017, 0.023198723458316087, 0.029826930158340495, 0.036700625997299618, 0.045292745797827563, 0.054130354732717635, 0.063949920216030437, 0.07291027372130239, 0.083834540321590767, 0.098932122255419322, 0.1147661716005649, 0.12937277525652402, 0.14459310177719578, 0.15846323800263296, 0.17392905366132488, 0.18927212471213972, 0.20473794031687509, 0.22118571250295585, 0.24021112065973993, 0.25444949058077593, 0.2713882410922811, 0.2863630784593858, 0.30416104086296714, 0.31852215537999151, 0.33312875909630879, 0.3455259604835651, 0.35522278141387187, 0.36639253711925779, 0.3755983797973016, 0.38689088010050499, 0.39830612492470618, 0.40665275565946091, 0.41377194058065458, 0.42162759295706226, 0.4297287344815498, 0.43635694120900975, 0.4440898489949161, 0.44936786549755936, 0.45513686023783329, 0.45906468635836278, 0.46262427884639518, 0.46667484963058736, 0.46863876274206512, 0.47158463236904297, 0.4735485454841788, 0.47600343685157753, 0.47759911624642254, 0.47907205100321137, 0.48054498587340039, 0.48177243159550953, 0.48324536633400794, 0.48447281210733012, 0.48594574684217046, 0.48680495890617603, 0.48680495890617603, 0.48729593716209707, 0.48778691545459879, 0.48852338286591585, 0.48864612743812674, 0.48876887191888585, 0.48913710562454438, 0.48938259481286306, 0.48987357303586138, 0.49011906225710278, 0.49036455137591811, 0.49073278507791851, 0.49073278508157658, 0.49073278506694434, 0.49073278511815732, 0.49073278506694434]}
[2018-01-19 21:08:07,061 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:92]: done!
[2018-01-19 21:08:07,062 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:152]: >> Executing classifier part ... 
[2018-01-19 21:08:07,062 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:97]: =======================================
[2018-01-19 21:08:07,062 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f197dc41470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-19 21:08:07,736 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:110]: training ... 
[2018-01-23 03:34:12,224 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:122]: trained!
[2018-01-23 03:34:12,227 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:125]: Training history: 
{'val_loss': [0.00011931074907087119, 0.00011925571597363862, 0.000119200316340348, 0.00011914461734191265, 0.00011908878692700804, 0.0001190328062974048, 0.00011897664874517768, 0.000118920399469357, 0.00011886408780908533, 0.00011880774620534678, 0.00011875138263201333, 0.00011869500255474368, 0.00011863864013657881, 0.00011858224006312721, 0.00011852587087973898, 0.00011846950134873056, 0.00011841317224862223, 0.00011835686928955088, 0.00011830059913512784, 0.000118244395868174, 0.00011818822761459357, 0.00011813207946415513, 0.00011807596608108195, 0.00011801991277747061, 0.00011796397614053724, 0.00011790804395314207, 0.00011785221541538637, 0.00011779646725811062, 0.00011774080458330931, 0.00011768518409355298, 0.00011762969704715892, 0.00011757424876308811, 0.00011751889411719582, 0.00011746368325770296, 0.00011740855881123701, 0.00011735348993051867, 0.00011729853027740658, 0.0001172436710704804, 0.00011718892455131817, 0.00011713423705806128, 0.00011707966936006389, 0.00011702515960767529, 0.00011697076673053673, 0.00011691646699421244, 0.00011686227724491079, 0.00011680816314310671, 0.00011675416233873893, 0.00011670022094533263, 0.00011664638223357736, 0.0001165926548939774, 0.00011653899897695292, 0.00011648546291936397, 0.00011643200360026515, 0.00011637866137568449, 0.00011632540791725192, 0.00011627220621144106, 0.00011621910523526022, 0.0001161661042934691, 0.00011611320334328362, 0.00011606037207757277, 0.00011600766486413154, 0.00011595503742684593, 0.00011590249323656969, 0.00011585002781702456, 0.00011579764560170476, 0.00011574533242375126, 0.00011569316644957087, 0.000115641078010733, 0.00011558905506888366, 0.00011553713738642262, 0.00011548531631028155, 0.00011543358219266368, 0.00011538192757310532, 0.00011533036062870249, 0.00011527889789013142, 0.00011522752100304701, 0.00011517622758224004, 0.00011512499633196396, 0.00011507384332831475, 0.00011502279737028671, 0.00011497182288296617, 0.00011492092395222718, 0.00011487010805992542, 0.00011481939013768432, 0.0001147687617517037, 0.00011471821568217998, 0.00011466777080221451, 0.00011461738006542795, 0.00011456708648045763, 0.00011451685870266, 0.00011446670531557934, 0.00011441665557813816, 0.0001143666898417747, 0.00011431682983007576, 0.00011426704007508771, 0.00011421733322483684, 0.00011416773345764316, 0.00011411819418705555, 0.00011406872400196624, 0.00011401935462137901, 0.00011397006867498122], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.0018375597206909224, 0.0029400955531054761, 0.0036751194413818448, 0.0058801911062109522, 0.0084527747151782427, 0.012127894156560088, 0.016538037486218304, 0.021315692760014701, 0.026828371922087469, 0.034546122748989341, 0.041528849687614847, 0.049981624402793093, 0.060271958838662258, 0.071664829106945979, 0.082690187431091508, 0.097390665196618889, 0.11723631018008085, 0.13561190738699008, 0.14847482543182652, 0.16207276736493936, 0.17750826901874311, 0.19147372289599413, 0.20543917677324514, 0.22454979786843071, 0.24292539507533994, 0.2587284086732819, 0.27489893421536199, 0.29143697170158028, 0.30613744946710769, 0.31863285556780596, 0.33443586916574791, 0.34509371554575524, 0.35722160970231531, 0.3667769202499081, 0.37816979051819183, 0.38441749356854099, 0.39544285189268652, 0.40352811466372657, 0.4141859610437339, 0.42521131936787948, 0.43403160602719587, 0.44248438074237412, 0.44652701212789414, 0.45350973906651965, 0.45681734656376333, 0.46233002572583609, 0.46674016905549431, 0.47115031238515254, 0.47482543182653436, 0.47739801543550164, 0.47923557515619258, 0.48144064682102167, 0.48291069459757441, 0.48327820654171261, 0.48401323042998895, 0.48401323042998895, 0.48438074237412715, 0.48548327820654169, 0.48585079015067989, 0.48585079015067989, 0.48658581403895629, 0.48732083792723263, 0.48768834987137083, 0.48915839764792357, 0.48989342153619991, 0.49026093348033811, 0.49026093348033811, 0.49026093348033811, 0.49026093348033811, 0.49062844542447631, 0.49062844542447631, 0.49099595736861446, 0.49136346931275265, 0.49173098125689085, 0.49209849320102905, 0.49209849320102905, 0.4924660051451672], 'loss': [0.00011947258170500778, 0.00011941840015911486, 0.00011936370894163448, 0.0001193085867600841, 0.00011925316241954372, 0.00011919755598715678, 0.00011914175117663838, 0.00011908580619832869, 0.000119029763156686, 0.0001189736369304944, 0.00011891745801590272, 0.00011886123427026645, 0.00011880500887778277, 0.00011874880848630036, 0.00011869257996444937, 0.00011863636363409187, 0.00011858013263035966, 0.0001185239652231589, 0.00011846781676809962, 0.000118411715020455, 0.00011835569869185616, 0.0001182997394483113, 0.00011824379950789001, 0.00011818791964256888, 0.00011813208893528568, 0.00011807637784949685, 0.00011802067393696094, 0.00011796506492356042, 0.00011790955530597466, 0.00011785411755577384, 0.00011779871814478799, 0.00011774345603657908, 0.00011768823362507323, 0.0001176331043908363, 0.00011757811024631345, 0.00011752320995869665, 0.0001174683667748886, 0.00011741363030036244, 0.00011735899557046266, 0.00011730447236535521, 0.00011725000538972699, 0.00011719565371395832, 0.00011714136655459792, 0.00011708718612327418, 0.00011703310517350127, 0.0001169791300104542, 0.00011692523228853104, 0.00011687144908680489, 0.00011681772293173008, 0.00011676410025207899, 0.00011671058572761323, 0.00011665714096017428, 0.00011660381599106041, 0.00011655056448259383, 0.00011649742757380874, 0.0001164443732512061, 0.00011639136890649276, 0.00011633846213570222, 0.00011628566133114747, 0.00011623295707793402, 0.00011618032426342506, 0.00011612781795787645, 0.00011607539002225941, 0.00011602304629109353, 0.00011597077628671407, 0.00011591859474679779, 0.00011586648647462261, 0.00011581452037253365, 0.00011576262823479153, 0.00011571079625252714, 0.00011565905900417756, 0.00011560742255110578, 0.00011555587293529762, 0.00011550439720524488, 0.00011545300519916394, 0.00011540172775882731, 0.00011535053016647673, 0.00011529941861654477, 0.00011524836927439819, 0.00011519739562114419, 0.0001151465277108549, 0.00011509573001842389, 0.00011504501392174487, 0.00011499437520546005, 0.00011494383875714901, 0.00011489338407070363, 0.00011484300629221086, 0.00011479273486844552, 0.00011474251952412128, 0.00011469239684264939, 0.00011464233818906865, 0.00011459235902802643, 0.00011454248600647834, 0.00011449269368134636, 0.00011444300187106373, 0.00011439338119405076, 0.00011434384531360384, 0.00011429441196637672, 0.0001142450434454581, 0.00011419574354913542, 0.00011414654670223525], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00024548913710568308, 0.00073646741131704919, 0.0020866576653983063, 0.0033141033509267214, 0.005523505584877869, 0.0083466306625077421, 0.011660734012519946, 0.017429728735418017, 0.023198723458316087, 0.029826930158340495, 0.036700625997299618, 0.045292745797827563, 0.054130354732717635, 0.063949920216030437, 0.07291027372130239, 0.083834540321590767, 0.098932122255419322, 0.1147661716005649, 0.12937277525652402, 0.14459310177719578, 0.15846323800263296, 0.17392905366132488, 0.18927212471213972, 0.20473794031687509, 0.22118571250295585, 0.24021112065973993, 0.25444949058077593, 0.2713882410922811, 0.2863630784593858, 0.30416104086296714, 0.31852215537999151, 0.33312875909630879, 0.3455259604835651, 0.35522278141387187, 0.36639253711925779, 0.3755983797973016, 0.38689088010050499, 0.39830612492470618, 0.40665275565946091, 0.41377194058065458, 0.42162759295706226, 0.4297287344815498, 0.43635694120900975, 0.4440898489949161, 0.44936786549755936, 0.45513686023783329, 0.45906468635836278, 0.46262427884639518, 0.46667484963058736, 0.46863876274206512, 0.47158463236904297, 0.4735485454841788, 0.47600343685157753, 0.47759911624642254, 0.47907205100321137, 0.48054498587340039, 0.48177243159550953, 0.48324536633400794, 0.48447281210733012, 0.48594574684217046, 0.48680495890617603, 0.48680495890617603, 0.48729593716209707, 0.48778691545459879, 0.48852338286591585, 0.48864612743812674, 0.48876887191888585, 0.48913710562454438, 0.48938259481286306, 0.48987357303586138, 0.49011906225710278, 0.49036455137591811, 0.49073278507791851, 0.49073278508157658, 0.49073278506694434, 0.49073278511815732, 0.49073278506694434]}
[2018-01-23 03:34:12,227 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:129]: evaluating model ... 
[2018-01-23 03:35:04,780 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:133]: evaluated! 
[2018-01-23 03:35:04,781 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:135]: generating reports ... 
[2018-01-23 03:35:09,094 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:138]: done!
[2018-01-23 03:35:09,097 AE_BIGRAMA_1L_FULLDS_OVER_F1_0.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_0 finished!
