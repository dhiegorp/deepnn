[2017-12-14 09:31:57,903 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_5
[2017-12-14 09:31:57,903 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:146]: >> Printing header log
[2017-12-14 09:31:57,903 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_5
	layers = 9216,4608
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3752bb0eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f3752b93400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 09:31:57,903 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:148]: >> Loading dataset... 
[2017-12-14 09:32:21,808 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 09:32:21,809 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:150]: >> Executing autoencoder part ... 
[2017-12-14 09:32:21,809 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:57]: =======================================
[2017-12-14 09:32:21,809 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3752bb0eb8>, 'discard_decoder_function': True}
[2017-12-14 09:32:21,852 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:73]: training and evaluate autoencoder
[2017-12-14 10:18:55,066 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_5
[2017-12-14 10:18:55,066 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:146]: >> Printing header log
[2017-12-14 10:18:55,066 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_5
	layers = 9216,4608
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5bd5d43eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5bd5d26400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 10:18:55,067 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:148]: >> Loading dataset... 
[2017-12-14 10:19:17,196 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 10:19:17,197 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:150]: >> Executing autoencoder part ... 
[2017-12-14 10:19:17,197 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:57]: =======================================
[2017-12-14 10:19:17,197 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5bd5d43eb8>, 'discard_decoder_function': True}
[2017-12-14 10:19:17,240 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:73]: training and evaluate autoencoder
[2017-12-14 17:31:35,218 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:85]: trained and evaluated!
[2017-12-14 17:31:35,219 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:88]: Training history: 
{'val_loss': [0.00011775317376680301, 0.00011775037808288278, 0.00011774756041019629, 0.00011774473628389628, 0.0001177419123184897, 0.00011773911123570164, 0.00011773630271606257, 0.00011773347900093463, 0.00011773066860420575, 0.00011772784921532287, 0.00011772503325883276, 0.00011772220643309885, 0.000117719389010691, 0.00011771657321509431, 0.00011771376666193027, 0.00011771094670098193, 0.00011770814472434159, 0.00011770533588291569, 0.00011770254003810204, 0.00011769972563691492, 0.00011769692938092922, 0.00011769412887020664, 0.00011769132803769722, 0.00011768854347329943, 0.0001176857414966591, 0.00011768293412115096, 0.00011768013157244516, 0.00011767732918463276, 0.00011767452263146873, 0.00011767173079111333, 0.00011766892963681708, 0.00011766613223670045, 0.00011766333115391241, 0.0001176605320375994, 0.00011765772720063174, 0.00011765491975361541, 0.00011765211834904053, 0.00011764931964389956, 0.00011764651325162893, 0.00011764371626268436, 0.00011764091755754339, 0.00011763812097977087, 0.00011763532227462991, 0.00011763251171700762, 0.00011762970916830182, 0.00011762690114922003, 0.00011762410587647184, 0.00011762130440038878, 0.0001176184938427665, 0.00011761568745049587, 0.00011761288842356807, 0.00011761008456983793, 0.00011760727499545317, 0.0001176044664043059, 0.00011760167595836006, 0.00011759886581190983, 0.00011759607854807813, 0.0001175932648083417, 0.00011759046594230732, 0.00011758767091983778, 0.00011758486960464814, 0.00011758206991626966, 0.00011757927130051392, 0.00011757647275626636, 0.00011757366155507043, 0.00011757086097283967, 0.00011756807281515568, 0.00011756527934798911, 0.00011756248636350279, 0.00011755968733657499, 0.0001175568767789527, 0.00011755407072634594, 0.00011755127373740137, 0.00011754848493614374, 0.00011754569865554955, 0.00011754288704318156, 0.00011754010419498017, 0.00011753732127527058, 0.00011753452151538393, 0.00011753172820911077, 0.00011752894160672977, 0.00011752614976637436, 0.00011752336471929634, 0.00011752056381527874, 0.00011751777737379116, 0.00011751497704183902, 0.00011751218643499977, 0.00011750939884938126, 0.00011750660604366539, 0.00011750381690274388, 0.00011750103013946946, 0.00011749824639741578, 0.00011749545995592819, 0.00011749268635015944, 0.0001174899028583844, 0.00011748711126830763, 0.00011748433766253887, 0.00011748154819983055, 0.00011747877042871014, 0.00011747598840285285, 0.00011747322150097624, 0.00011747043661479163, 0.00011746766129282649, 0.00011746487665692052, 0.00011746210330143041, 0.00011745931424989413, 0.00011745654293238724, 0.00011745376646629115, 0.00011745097585945192, 0.00011744821108494375, 0.00011744541532951533, 0.00011744264327904955, 0.00011743984605770339, 0.00011743706526536224, 0.00011743428381157041, 0.00011743150359129473, 0.00011742869982694982, 0.00011742591617428137, 0.00011742313700875139, 0.00011742035907673757, 0.00011741757917824871, 0.00011741481007749549, 0.00011741202356449971, 0.00011740923295766046, 0.00011740644170724757, 0.00011740365306688335, 0.00011740086589243689, 0.00011739807439174536, 0.00011739527913687422, 0.00011739249310655867, 0.00011738970716562837, 0.00011738692751741815, 0.00011738414427592175, 0.00011738135849588484, 0.0001173785758264539, 0.00011737579004641701, 0.00011737298923178464, 0.00011737020271878887, 0.00011736742478677504, 0.00011736466083461099, 0.00011736189663216828, 0.00011735912098841632, 0.00011735633358156826, 0.0001173535491065557, 0.00011735076668740339, 0.00011734799218778236, 0.0001173452255361844, 0.00011734245389689067, 0.0001173396656676985, 0.00011733689542281435, 0.0001173341209231933, 0.00011733132926160835, 0.00011732855043574225, 0.00011732576449481194, 0.00011732298608011788, 0.00011732020242744942, 0.00011731742630101722, 0.00011731465834439492, 0.00011731188343360183, 0.0001173091124557588, 0.00011730633035839332, 0.00011730354597276598, 0.00011730076886309627, 0.0001172980003344085, 0.00011729522150854239, 0.0001172924499586339, 0.00011728967079310392, 0.0001172868899292546, 0.00011728413080389289, 0.00011728136014783667, 0.00011727858303816696, 0.0001172758208021993, 0.00011727304884111874, 0.00011727028873251952, 0.0001172675179155699, 0.00011726474922598873, 0.00011726197939227663, 0.00011725921381330141, 0.00011725644757287549, 0.00011725366604757547, 0.00011725090406188645, 0.00011724813136784703, 0.00011724536954305141, 0.00011724259153952941, 0.00011723982186671072, 0.00011723705365980978, 0.00011723429592885764, 0.00011723153181580017, 0.00011722875756645776, 0.00011722600727235665, 0.00011722322256494249, 0.00011722043817931516, 0.00011721766205288296, 0.00011721488780354056, 0.00011721212892845748, 0.00011720936481540003, 0.00011720658084094473, 0.00011720380700277439, 0.00011720104567853606, 0.00011719828099341312], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011850850363125485, 0.00011850558075821027, 0.00011850269620836915, 0.00011849979058906121, 0.00011849686856922339, 0.00011849396119610155, 0.00011849106221284614, 0.0001184881655996095, 0.00011848524941001785, 0.0001184823501423602, 0.00011847943639388788, 0.0001184765256316392, 0.00011847360839923929, 0.00011847070067061464, 0.00011846778976616484, 0.0001184648887209931, 0.00011846197753214104, 0.00011845908525603875, 0.00011845617515739533, 0.0001184532890907422, 0.00011845038079331304, 0.00011844748875421262, 0.00011844459560120339, 0.00011844170740153337, 0.0001184388241078022, 0.00011843592721016332, 0.00011843302915121522, 0.00011843012919625213, 0.00011842722962049204, 0.00011842432587349891, 0.00011842143750792757, 0.00011841854290920689, 0.00011841565236321829, 0.00011841275774079743, 0.00011840986491959081, 0.00011840696081709486, 0.00011840406221304247, 0.00011840116676111503, 0.00011839826716165474, 0.00011839537332134006, 0.0001183924727027717, 0.00011838958490600488, 0.00011838669357791009, 0.00011838379682247232, 0.00011838090236595277, 0.0001183780131234745, 0.00011837511534892866, 0.00011837223094128867, 0.00011836933916289032, 0.00011836643956343003, 0.00011836354683702417, 0.00011836065531932788, 0.00011835776010440232, 0.00011835486214025498, 0.00011835197088326076, 0.0001183490962163979, 0.0001183462005037684, 0.00011834333223595621, 0.00011834043173588879, 0.0001183375430859152, 0.00011833466372641519, 0.00011833177322782697, 0.000118328890716202, 0.00011832600227953011, 0.00011832312036040983, 0.00011832022291766662, 0.0001183173397187362, 0.00011831446308475776, 0.00011831158557387239, 0.00011830870621437237, 0.00011830582251773801, 0.00011830292836932089, 0.00011830003907944224, 0.00011829715737362365, 0.00011829428254085947, 0.00011829140692598912, 0.00011828851704360577, 0.000118285644912663, 0.00011828277865936677, 0.00011827989692984798, 0.00011827700818507365, 0.00011827414050976615, 0.00011827126705161287, 0.00011826839442296614, 0.00011826550899621809, 0.00011826263762368133, 0.0001182597546143524, 0.00011825688482972821, 0.00011825401030506648, 0.00011825113343408616, 0.00011824825909902594, 0.00011824538711028429, 0.00011824251784706422, 0.0001182396434883038, 0.00011823678778159107, 0.00011823391721486068, 0.00011823104873374682, 0.00011822819075181607, 0.00011822532030358662, 0.00011822246016493881, 0.00011821959929158516, 0.00011821674505428408, 0.00011821388064960248, 0.00011821102089015767, 0.00011820815515826557, 0.00011820529184379261, 0.00011820242596969936, 0.0001181995711161934, 0.00011819671014803901, 0.00011819383453316866, 0.00011819098200228108, 0.00011818810574750564, 0.00011818524558515765, 0.00011818236006360884, 0.00011817949535082479, 0.00011817662703561224, 0.00011817375800939404, 0.00011817087341215255, 0.00011816800407783191, 0.00011816514083445952, 0.0001181622759083738, 0.00011815940704805691, 0.00011815654809441848, 0.0001181536771247849, 0.00011815080030120497, 0.00011814792153420964, 0.00011814504402332427, 0.00011814216433202162, 0.00011813929461849799, 0.00011813641464279309, 0.00011813354684898466, 0.00011813067410183701, 0.00011812781242267699, 0.00011812494981920965, 0.00011812208413471793, 0.00011811922191045359, 0.00011811635568085755, 0.00011811347385653802, 0.00011811060930965529, 0.00011810775383994445, 0.00011810490652309816, 0.00011810206295088152, 0.00011809920769447236, 0.0001180963364878369, 0.00011809347144325024, 0.0001180906078917754, 0.0001180877469710214, 0.00011808490079178412, 0.00011808205288243313, 0.00011807918371401382, 0.0001180763314438283, 0.0001180734782019351, 0.00011807060287146698, 0.00011806774842086422, 0.00011806488200166666, 0.00011806203025288528, 0.00011805916399958904, 0.00011805631049699378, 0.00011805346341714937, 0.00011805060768673646, 0.00011804775887677834, 0.00011804489606000932, 0.00011804202648868681, 0.00011803917815273245, 0.0001180363236547293, 0.00011803346332647998, 0.00011803061515642694, 0.0001180277566056917, 0.00011802489217730992, 0.00011802205403243626, 0.00011801920287615957, 0.00011801634543933315, 0.00011801349601317015, 0.00011801064476209271, 0.00011800780699642205, 0.00011800495235621778, 0.00011800210487347018, 0.00011799925412009668, 0.00011799640438583124, 0.00011799355581287501, 0.00011799068944107784, 0.00011798785212571074, 0.00011798499494958638, 0.000117982151661772, 0.0001179792916890255, 0.00011797643735692366, 0.00011797358821516293, 0.00011797074687076392, 0.00011796790156843359, 0.00011796504673862781, 0.00011796220691104082, 0.00011795934471047669, 0.00011795647788837595, 0.00011795361341259379, 0.00011795075547806342, 0.00011794791453656761, 0.0001179450593986594, 0.00011794219677149187, 0.00011793934040117391, 0.00011793648943449871], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-14 17:31:35,220 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:92]: done!
[2017-12-14 17:31:35,220 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:152]: >> Executing classifier part ... 
[2017-12-14 17:31:35,220 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:97]: =======================================
[2017-12-14 17:31:35,220 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5bd5d26400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-14 17:31:35,449 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:110]: training ... 
[2017-12-14 20:57:20,696 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:122]: trained!
[2017-12-14 20:57:20,699 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:125]: Training history: 
{'val_loss': [0.00011775317376680301, 0.00011775037808288278, 0.00011774756041019629, 0.00011774473628389628, 0.0001177419123184897, 0.00011773911123570164, 0.00011773630271606257, 0.00011773347900093463, 0.00011773066860420575, 0.00011772784921532287, 0.00011772503325883276, 0.00011772220643309885, 0.000117719389010691, 0.00011771657321509431, 0.00011771376666193027, 0.00011771094670098193, 0.00011770814472434159, 0.00011770533588291569, 0.00011770254003810204, 0.00011769972563691492, 0.00011769692938092922, 0.00011769412887020664, 0.00011769132803769722, 0.00011768854347329943, 0.0001176857414966591, 0.00011768293412115096, 0.00011768013157244516, 0.00011767732918463276, 0.00011767452263146873, 0.00011767173079111333, 0.00011766892963681708, 0.00011766613223670045, 0.00011766333115391241, 0.0001176605320375994, 0.00011765772720063174, 0.00011765491975361541, 0.00011765211834904053, 0.00011764931964389956, 0.00011764651325162893, 0.00011764371626268436, 0.00011764091755754339, 0.00011763812097977087, 0.00011763532227462991, 0.00011763251171700762, 0.00011762970916830182, 0.00011762690114922003, 0.00011762410587647184, 0.00011762130440038878, 0.0001176184938427665, 0.00011761568745049587, 0.00011761288842356807, 0.00011761008456983793, 0.00011760727499545317, 0.0001176044664043059, 0.00011760167595836006, 0.00011759886581190983, 0.00011759607854807813, 0.0001175932648083417, 0.00011759046594230732, 0.00011758767091983778, 0.00011758486960464814, 0.00011758206991626966, 0.00011757927130051392, 0.00011757647275626636, 0.00011757366155507043, 0.00011757086097283967, 0.00011756807281515568, 0.00011756527934798911, 0.00011756248636350279, 0.00011755968733657499, 0.0001175568767789527, 0.00011755407072634594, 0.00011755127373740137, 0.00011754848493614374, 0.00011754569865554955, 0.00011754288704318156, 0.00011754010419498017, 0.00011753732127527058, 0.00011753452151538393, 0.00011753172820911077, 0.00011752894160672977, 0.00011752614976637436, 0.00011752336471929634, 0.00011752056381527874, 0.00011751777737379116, 0.00011751497704183902, 0.00011751218643499977, 0.00011750939884938126, 0.00011750660604366539, 0.00011750381690274388, 0.00011750103013946946, 0.00011749824639741578, 0.00011749545995592819, 0.00011749268635015944, 0.0001174899028583844, 0.00011748711126830763, 0.00011748433766253887, 0.00011748154819983055, 0.00011747877042871014, 0.00011747598840285285, 0.00011747322150097624, 0.00011747043661479163, 0.00011746766129282649, 0.00011746487665692052, 0.00011746210330143041, 0.00011745931424989413, 0.00011745654293238724, 0.00011745376646629115, 0.00011745097585945192, 0.00011744821108494375, 0.00011744541532951533, 0.00011744264327904955, 0.00011743984605770339, 0.00011743706526536224, 0.00011743428381157041, 0.00011743150359129473, 0.00011742869982694982, 0.00011742591617428137, 0.00011742313700875139, 0.00011742035907673757, 0.00011741757917824871, 0.00011741481007749549, 0.00011741202356449971, 0.00011740923295766046, 0.00011740644170724757, 0.00011740365306688335, 0.00011740086589243689, 0.00011739807439174536, 0.00011739527913687422, 0.00011739249310655867, 0.00011738970716562837, 0.00011738692751741815, 0.00011738414427592175, 0.00011738135849588484, 0.0001173785758264539, 0.00011737579004641701, 0.00011737298923178464, 0.00011737020271878887, 0.00011736742478677504, 0.00011736466083461099, 0.00011736189663216828, 0.00011735912098841632, 0.00011735633358156826, 0.0001173535491065557, 0.00011735076668740339, 0.00011734799218778236, 0.0001173452255361844, 0.00011734245389689067, 0.0001173396656676985, 0.00011733689542281435, 0.0001173341209231933, 0.00011733132926160835, 0.00011732855043574225, 0.00011732576449481194, 0.00011732298608011788, 0.00011732020242744942, 0.00011731742630101722, 0.00011731465834439492, 0.00011731188343360183, 0.0001173091124557588, 0.00011730633035839332, 0.00011730354597276598, 0.00011730076886309627, 0.0001172980003344085, 0.00011729522150854239, 0.0001172924499586339, 0.00011728967079310392, 0.0001172868899292546, 0.00011728413080389289, 0.00011728136014783667, 0.00011727858303816696, 0.0001172758208021993, 0.00011727304884111874, 0.00011727028873251952, 0.0001172675179155699, 0.00011726474922598873, 0.00011726197939227663, 0.00011725921381330141, 0.00011725644757287549, 0.00011725366604757547, 0.00011725090406188645, 0.00011724813136784703, 0.00011724536954305141, 0.00011724259153952941, 0.00011723982186671072, 0.00011723705365980978, 0.00011723429592885764, 0.00011723153181580017, 0.00011722875756645776, 0.00011722600727235665, 0.00011722322256494249, 0.00011722043817931516, 0.00011721766205288296, 0.00011721488780354056, 0.00011721212892845748, 0.00011720936481540003, 0.00011720658084094473, 0.00011720380700277439, 0.00011720104567853606, 0.00011719828099341312], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011850850363125485, 0.00011850558075821027, 0.00011850269620836915, 0.00011849979058906121, 0.00011849686856922339, 0.00011849396119610155, 0.00011849106221284614, 0.0001184881655996095, 0.00011848524941001785, 0.0001184823501423602, 0.00011847943639388788, 0.0001184765256316392, 0.00011847360839923929, 0.00011847070067061464, 0.00011846778976616484, 0.0001184648887209931, 0.00011846197753214104, 0.00011845908525603875, 0.00011845617515739533, 0.0001184532890907422, 0.00011845038079331304, 0.00011844748875421262, 0.00011844459560120339, 0.00011844170740153337, 0.0001184388241078022, 0.00011843592721016332, 0.00011843302915121522, 0.00011843012919625213, 0.00011842722962049204, 0.00011842432587349891, 0.00011842143750792757, 0.00011841854290920689, 0.00011841565236321829, 0.00011841275774079743, 0.00011840986491959081, 0.00011840696081709486, 0.00011840406221304247, 0.00011840116676111503, 0.00011839826716165474, 0.00011839537332134006, 0.0001183924727027717, 0.00011838958490600488, 0.00011838669357791009, 0.00011838379682247232, 0.00011838090236595277, 0.0001183780131234745, 0.00011837511534892866, 0.00011837223094128867, 0.00011836933916289032, 0.00011836643956343003, 0.00011836354683702417, 0.00011836065531932788, 0.00011835776010440232, 0.00011835486214025498, 0.00011835197088326076, 0.0001183490962163979, 0.0001183462005037684, 0.00011834333223595621, 0.00011834043173588879, 0.0001183375430859152, 0.00011833466372641519, 0.00011833177322782697, 0.000118328890716202, 0.00011832600227953011, 0.00011832312036040983, 0.00011832022291766662, 0.0001183173397187362, 0.00011831446308475776, 0.00011831158557387239, 0.00011830870621437237, 0.00011830582251773801, 0.00011830292836932089, 0.00011830003907944224, 0.00011829715737362365, 0.00011829428254085947, 0.00011829140692598912, 0.00011828851704360577, 0.000118285644912663, 0.00011828277865936677, 0.00011827989692984798, 0.00011827700818507365, 0.00011827414050976615, 0.00011827126705161287, 0.00011826839442296614, 0.00011826550899621809, 0.00011826263762368133, 0.0001182597546143524, 0.00011825688482972821, 0.00011825401030506648, 0.00011825113343408616, 0.00011824825909902594, 0.00011824538711028429, 0.00011824251784706422, 0.0001182396434883038, 0.00011823678778159107, 0.00011823391721486068, 0.00011823104873374682, 0.00011822819075181607, 0.00011822532030358662, 0.00011822246016493881, 0.00011821959929158516, 0.00011821674505428408, 0.00011821388064960248, 0.00011821102089015767, 0.00011820815515826557, 0.00011820529184379261, 0.00011820242596969936, 0.0001181995711161934, 0.00011819671014803901, 0.00011819383453316866, 0.00011819098200228108, 0.00011818810574750564, 0.00011818524558515765, 0.00011818236006360884, 0.00011817949535082479, 0.00011817662703561224, 0.00011817375800939404, 0.00011817087341215255, 0.00011816800407783191, 0.00011816514083445952, 0.0001181622759083738, 0.00011815940704805691, 0.00011815654809441848, 0.0001181536771247849, 0.00011815080030120497, 0.00011814792153420964, 0.00011814504402332427, 0.00011814216433202162, 0.00011813929461849799, 0.00011813641464279309, 0.00011813354684898466, 0.00011813067410183701, 0.00011812781242267699, 0.00011812494981920965, 0.00011812208413471793, 0.00011811922191045359, 0.00011811635568085755, 0.00011811347385653802, 0.00011811060930965529, 0.00011810775383994445, 0.00011810490652309816, 0.00011810206295088152, 0.00011809920769447236, 0.0001180963364878369, 0.00011809347144325024, 0.0001180906078917754, 0.0001180877469710214, 0.00011808490079178412, 0.00011808205288243313, 0.00011807918371401382, 0.0001180763314438283, 0.0001180734782019351, 0.00011807060287146698, 0.00011806774842086422, 0.00011806488200166666, 0.00011806203025288528, 0.00011805916399958904, 0.00011805631049699378, 0.00011805346341714937, 0.00011805060768673646, 0.00011804775887677834, 0.00011804489606000932, 0.00011804202648868681, 0.00011803917815273245, 0.0001180363236547293, 0.00011803346332647998, 0.00011803061515642694, 0.0001180277566056917, 0.00011802489217730992, 0.00011802205403243626, 0.00011801920287615957, 0.00011801634543933315, 0.00011801349601317015, 0.00011801064476209271, 0.00011800780699642205, 0.00011800495235621778, 0.00011800210487347018, 0.00011799925412009668, 0.00011799640438583124, 0.00011799355581287501, 0.00011799068944107784, 0.00011798785212571074, 0.00011798499494958638, 0.000117982151661772, 0.0001179792916890255, 0.00011797643735692366, 0.00011797358821516293, 0.00011797074687076392, 0.00011796790156843359, 0.00011796504673862781, 0.00011796220691104082, 0.00011795934471047669, 0.00011795647788837595, 0.00011795361341259379, 0.00011795075547806342, 0.00011794791453656761, 0.0001179450593986594, 0.00011794219677149187, 0.00011793934040117391, 0.00011793648943449871], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-14 20:57:20,699 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:129]: evaluating model ... 
[2017-12-14 20:57:28,353 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:133]: evaluated! 
[2017-12-14 20:57:28,354 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:135]: generating reports ... 
[2017-12-14 20:57:31,768 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:138]: done!
[2017-12-14 20:57:31,768 AE_BIGRAMA_1L_MINIDS_UNDER_F0_5.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_5 finished!
