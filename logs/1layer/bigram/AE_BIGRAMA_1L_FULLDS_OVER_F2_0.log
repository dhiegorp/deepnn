[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F2_0
[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:146]: >> Printing header log
[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F2_0
	layers = 9216,18432
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9577fcabe0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9577fca470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:148]: >> Loading dataset... 
[2018-01-18 00:21:59,650 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:21:59,651 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:21:59,651 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:57]: =======================================
[2018-01-18 00:21:59,651 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9577fcabe0>, 'discard_decoder_function': True}
[2018-01-18 00:21:59,690 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:73]: training and evaluate autoencoder
[2018-01-21 01:34:13,971 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:85]: trained and evaluated!
[2018-01-21 01:34:13,972 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:88]: Training history: 
{'val_loss': [0.00011793092356418705, 0.00011790972983878149, 0.00011788853517747548, 0.0001178673287345196, 0.00011784612217925568, 0.00011782489579894591, 0.00011780367474524679, 0.00011778245965189663, 0.00011776123901801571, 0.00011774000051645791, 0.000117718775868901, 0.00011769753943434624, 0.00011767629487617544, 0.00011765505674630383, 0.00011763379208766505, 0.00011761253369688538, 0.00011759127399049704, 0.00011757000302388912, 0.00011754871708822178, 0.00011752740840749912, 0.00011750611008050962, 0.00011748478803512832, 0.00011746344949650684, 0.00011744210454295617, 0.00011742075953325148, 0.00011739935093579519, 0.00011737793038822696, 0.00011735647405984698, 0.0001173349964223504, 0.00011731347740200926, 0.00011729193244652925, 0.00011727034035107982, 0.00011724874072296864, 0.00011722711657426529, 0.00011720544533372454, 0.00011718376083013721, 0.00011716202570235672, 0.00011714022889873561, 0.00011711839474733794, 0.00011709648742189392, 0.00011707451931907372, 0.00011705251920043561, 0.00011703044921014278, 0.00011700828585709359, 0.00011698603864736274, 0.00011696371924494404, 0.00011694132487155009, 0.00011691883913287876, 0.00011689619782883215, 0.00011687340629136892, 0.00011685044823047297, 0.00011682732367021031, 0.00011680402078347309, 0.00011678045744633249, 0.00011675667434371871, 0.00011673255158678222, 0.00011670798736827044, 0.00011668294243116989, 0.00011665729692674101, 0.00011663094308738228, 0.00011660389923267679, 0.00011657609508986966, 0.00011654733272403453, 0.00011651771268831739, 0.00011648717547014465, 0.00011645558747640995, 0.00011642264564917277, 0.00011638837651185228, 0.00011635262580933385, 0.00011631534997411383, 0.00011627616506773354, 0.00011623490641182114, 0.00011619152633160697, 0.0001161458685638014, 0.00011609780606392734, 0.00011604733773831822, 0.00011599460788143375, 0.00011594024672329895, 0.00011588424699330423, 0.00011582710042959784, 0.0001157688038447702, 0.00011570958195119693, 0.00011564969707108235, 0.0001155894553722305, 0.00011552900285511396, 0.0001154684647646069, 0.00011540786109421725, 0.0001153472537444018, 0.00011528668199891401, 0.00011522615692811942, 0.00011516565811066987, 0.0001151052103880377, 0.00011504483903488346, 0.00011498455643450731, 0.00011492437825923103, 0.00011486429948728013, 0.00011480426987416964, 0.00011474435543029637, 0.00011468453225008842, 0.00011462477804039674, 0.0001145650797039628], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00073502388827636903, 0.002205071664829107], 'loss': [0.00011805013842967949, 0.00011802891975820176, 0.00011800769258902714, 0.00011798645298276086, 0.00011796518226322449, 0.00011794391520533366, 0.00011792263457792031, 0.00011790136659211492, 0.00011788010270913871, 0.00011785882723214239, 0.00011783753093467229, 0.00011781624901050057, 0.00011779494673472433, 0.0001177736274215793, 0.00011775231728576832, 0.00011773098068787017, 0.00011770964653077136, 0.00011768830228628562, 0.00011766693768662302, 0.00011764555651131621, 0.00011762414617323539, 0.00011760272066433194, 0.00011758127124666926, 0.00011755980563738863, 0.00011753832895654221, 0.00011751683389244899, 0.00011749530658890643, 0.00011747376573906153, 0.00011745219558980073, 0.00011743060890597759, 0.00011740897625867898, 0.00011738731559889892, 0.00011736563837776401, 0.00011734393668076136, 0.00011732219596758585, 0.00011730040269461441, 0.00011727856326436821, 0.00011725666737512012, 0.00011723470575308299, 0.0001172127126015985, 0.00011719064504547662, 0.00011716851753124866, 0.00011714635343718174, 0.00011712410974965778, 0.00011710177890246678, 0.0001170793583306707, 0.00011705685360890158, 0.0001170342663920446, 0.00011701157631688515, 0.0001169887230904105, 0.00011696570996434053, 0.00011694249833689347, 0.00011691911507650983, 0.00011689552598520644, 0.00011687169380529337, 0.00011684757761832825, 0.00011682303314743905, 0.00011679797845482247, 0.00011677244115821674, 0.00011674633536345525, 0.00011671959784285034, 0.00011669219929519994, 0.00011666400675186512, 0.00011663491979712891, 0.00011660490179310187, 0.00011657391164629712, 0.0001165416263861817, 0.00011650804930287812, 0.00011647304853695814, 0.00011643655328202089, 0.00011639831072734128, 0.00011635809721425119, 0.00011631561326212035, 0.00011627110975350496, 0.00011622433310248271, 0.00011617521664299152, 0.00011612380013425033, 0.00011607061105594714, 0.00011601572301966047, 0.00011595951353032852, 0.00011590207135606314, 0.00011584365303532323, 0.00011578451770544292, 0.00011572490420841617, 0.00011566496012820609, 0.00011560482552722004, 0.00011554457260685648, 0.00011548421141788588, 0.00011542384990026026, 0.00011536352260830343, 0.00011530321353080047, 0.00011524297629121067, 0.00011518278824448907, 0.00011512265903773206, 0.00011506262986355887, 0.00011500271767628146, 0.00011494289984157186, 0.00011488314595526891, 0.00011482350470386204, 0.00011476396515064118, 0.00011470449800601435], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00024548913710568308, 0.00085921197986989076, 0.0015956793911869401]}
[2018-01-21 01:34:13,973 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:92]: done!
[2018-01-21 01:34:13,973 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:152]: >> Executing classifier part ... 
[2018-01-21 01:34:13,973 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:97]: =======================================
[2018-01-21 01:34:13,973 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9577fca470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-21 01:34:14,279 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:110]: training ... 
[2018-01-24 11:39:32,182 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:122]: trained!
[2018-01-24 11:39:32,184 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:125]: Training history: 
{'val_loss': [0.00011793092356418705, 0.00011790972983878149, 0.00011788853517747548, 0.0001178673287345196, 0.00011784612217925568, 0.00011782489579894591, 0.00011780367474524679, 0.00011778245965189663, 0.00011776123901801571, 0.00011774000051645791, 0.000117718775868901, 0.00011769753943434624, 0.00011767629487617544, 0.00011765505674630383, 0.00011763379208766505, 0.00011761253369688538, 0.00011759127399049704, 0.00011757000302388912, 0.00011754871708822178, 0.00011752740840749912, 0.00011750611008050962, 0.00011748478803512832, 0.00011746344949650684, 0.00011744210454295617, 0.00011742075953325148, 0.00011739935093579519, 0.00011737793038822696, 0.00011735647405984698, 0.0001173349964223504, 0.00011731347740200926, 0.00011729193244652925, 0.00011727034035107982, 0.00011724874072296864, 0.00011722711657426529, 0.00011720544533372454, 0.00011718376083013721, 0.00011716202570235672, 0.00011714022889873561, 0.00011711839474733794, 0.00011709648742189392, 0.00011707451931907372, 0.00011705251920043561, 0.00011703044921014278, 0.00011700828585709359, 0.00011698603864736274, 0.00011696371924494404, 0.00011694132487155009, 0.00011691883913287876, 0.00011689619782883215, 0.00011687340629136892, 0.00011685044823047297, 0.00011682732367021031, 0.00011680402078347309, 0.00011678045744633249, 0.00011675667434371871, 0.00011673255158678222, 0.00011670798736827044, 0.00011668294243116989, 0.00011665729692674101, 0.00011663094308738228, 0.00011660389923267679, 0.00011657609508986966, 0.00011654733272403453, 0.00011651771268831739, 0.00011648717547014465, 0.00011645558747640995, 0.00011642264564917277, 0.00011638837651185228, 0.00011635262580933385, 0.00011631534997411383, 0.00011627616506773354, 0.00011623490641182114, 0.00011619152633160697, 0.0001161458685638014, 0.00011609780606392734, 0.00011604733773831822, 0.00011599460788143375, 0.00011594024672329895, 0.00011588424699330423, 0.00011582710042959784, 0.0001157688038447702, 0.00011570958195119693, 0.00011564969707108235, 0.0001155894553722305, 0.00011552900285511396, 0.0001154684647646069, 0.00011540786109421725, 0.0001153472537444018, 0.00011528668199891401, 0.00011522615692811942, 0.00011516565811066987, 0.0001151052103880377, 0.00011504483903488346, 0.00011498455643450731, 0.00011492437825923103, 0.00011486429948728013, 0.00011480426987416964, 0.00011474435543029637, 0.00011468453225008842, 0.00011462477804039674, 0.0001145650797039628], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00073502388827636903, 0.002205071664829107], 'loss': [0.00011805013842967949, 0.00011802891975820176, 0.00011800769258902714, 0.00011798645298276086, 0.00011796518226322449, 0.00011794391520533366, 0.00011792263457792031, 0.00011790136659211492, 0.00011788010270913871, 0.00011785882723214239, 0.00011783753093467229, 0.00011781624901050057, 0.00011779494673472433, 0.0001177736274215793, 0.00011775231728576832, 0.00011773098068787017, 0.00011770964653077136, 0.00011768830228628562, 0.00011766693768662302, 0.00011764555651131621, 0.00011762414617323539, 0.00011760272066433194, 0.00011758127124666926, 0.00011755980563738863, 0.00011753832895654221, 0.00011751683389244899, 0.00011749530658890643, 0.00011747376573906153, 0.00011745219558980073, 0.00011743060890597759, 0.00011740897625867898, 0.00011738731559889892, 0.00011736563837776401, 0.00011734393668076136, 0.00011732219596758585, 0.00011730040269461441, 0.00011727856326436821, 0.00011725666737512012, 0.00011723470575308299, 0.0001172127126015985, 0.00011719064504547662, 0.00011716851753124866, 0.00011714635343718174, 0.00011712410974965778, 0.00011710177890246678, 0.0001170793583306707, 0.00011705685360890158, 0.0001170342663920446, 0.00011701157631688515, 0.0001169887230904105, 0.00011696570996434053, 0.00011694249833689347, 0.00011691911507650983, 0.00011689552598520644, 0.00011687169380529337, 0.00011684757761832825, 0.00011682303314743905, 0.00011679797845482247, 0.00011677244115821674, 0.00011674633536345525, 0.00011671959784285034, 0.00011669219929519994, 0.00011666400675186512, 0.00011663491979712891, 0.00011660490179310187, 0.00011657391164629712, 0.0001165416263861817, 0.00011650804930287812, 0.00011647304853695814, 0.00011643655328202089, 0.00011639831072734128, 0.00011635809721425119, 0.00011631561326212035, 0.00011627110975350496, 0.00011622433310248271, 0.00011617521664299152, 0.00011612380013425033, 0.00011607061105594714, 0.00011601572301966047, 0.00011595951353032852, 0.00011590207135606314, 0.00011584365303532323, 0.00011578451770544292, 0.00011572490420841617, 0.00011566496012820609, 0.00011560482552722004, 0.00011554457260685648, 0.00011548421141788588, 0.00011542384990026026, 0.00011536352260830343, 0.00011530321353080047, 0.00011524297629121067, 0.00011518278824448907, 0.00011512265903773206, 0.00011506262986355887, 0.00011500271767628146, 0.00011494289984157186, 0.00011488314595526891, 0.00011482350470386204, 0.00011476396515064118, 0.00011470449800601435], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00024548913710568308, 0.00085921197986989076, 0.0015956793911869401]}
[2018-01-24 11:39:32,185 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:129]: evaluating model ... 
[2018-01-24 11:39:40,460 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:133]: evaluated! 
[2018-01-24 11:39:40,460 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:135]: generating reports ... 
[2018-01-24 11:39:41,330 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:138]: done!
[2018-01-24 11:39:41,330 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F2_0 finished!
[2018-05-03 21:43:55,207 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F2_0
[2018-05-03 21:43:55,208 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:146]: >> Printing header log
[2018-05-03 21:43:55,208 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F2_0
	layers = 9216,18432
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff6cf158630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff6cf158e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-05-03 21:43:55,208 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:148]: >> Loading dataset... 
[2018-05-03 21:46:26,773 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-03 21:46:26,775 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:150]: >> Executing autoencoder part ... 
[2018-05-03 21:46:26,775 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:57]: =======================================
[2018-05-03 21:46:26,775 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff6cf158630>, 'discard_decoder_function': True}
[2018-05-03 21:46:26,966 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:73]: training and evaluate autoencoder
[2018-05-06 02:23:43,921 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F2_0
[2018-05-06 02:23:43,921 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:146]: >> Printing header log
[2018-05-06 02:23:43,921 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F2_0
	layers = 9216,18432
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7feb0bc975c0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7feb0bc97da0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-05-06 02:23:43,921 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:148]: >> Loading dataset... 
[2018-05-06 02:27:49,410 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-06 02:27:49,410 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:150]: >> Executing autoencoder part ... 
[2018-05-06 02:27:49,410 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:57]: =======================================
[2018-05-06 02:27:49,411 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7feb0bc975c0>, 'discard_decoder_function': True}
[2018-05-06 02:27:49,788 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:73]: training and evaluate autoencoder
[2018-05-06 11:36:00,862 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:85]: trained and evaluated!
[2018-05-06 11:36:00,863 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:88]: Training history: 
{'val_loss': [0.00011738677865594817, 0.00011734380528331402, 0.00011729943113508407, 0.00011725374885470833, 0.00011720668883525822, 0.00011715800713294058, 0.00011710755097671151, 0.0001170554175371053, 0.00011700176089810045, 0.00011694671839105721, 0.0001168905014653046, 0.00011683330189486989, 0.00011677530774761447, 0.00011671665184118435, 0.00011665746978488287, 0.00011659781350514183, 0.00011653769766618452, 0.0001164772281183535, 0.00011641649894905952, 0.00011635566775324488, 0.00011629466771029035, 0.00011623368819831802, 0.00011617265788032045, 0.00011611174400171073, 0.0001160509033880634, 0.00011599008612914366, 0.00011592937524734477, 0.00011586870778063145, 0.00011580810537504444, 0.00011574760239952282, 0.00011568715619572341, 0.00011562680880696907, 0.00011556652503805433, 0.0001155063316370145, 0.00011544622613842032, 0.00011538618869583394, 0.00011532623022185479, 0.00011526636003002949, 0.00011520659318300754, 0.00011514686843813649, 0.0001150872541241723, 0.00011502771373564882, 0.00011496824841971263, 0.00011490889187145449, 0.00011484959809002951, 0.00011479035572430207, 0.00011473121580491353, 0.00011467217775962758, 0.00011461322655520878, 0.00011455436991684694, 0.00011449558158584904, 0.00011443692207486512, 0.00011437832003886575, 0.00011431985804298996, 0.0001142614537360188, 0.00011420312934157736, 0.00011414491178418498, 0.0001140867767892576, 0.00011402870548904186, 0.0001139707653860273, 0.00011391291162384163, 0.0001138551614310754, 0.00011379750946239996, 0.00011373992658457083, 0.00011368244015796963, 0.00011362508681908852, 0.0001135678401060104, 0.0001135106762227974, 0.00011345358013888809, 0.00011339657435332962, 0.00011333966269529192, 0.00011328286597652731, 0.00011322618750477544, 0.00011316958078450121, 0.0001131130896853704, 0.00011305668183324896, 0.00011300038365261798, 0.00011294418180288486, 0.00011288808351722319, 0.00011283206355038641, 0.0001127761719463094, 0.00011272032981393096, 0.00011266460465306662, 0.00011260901754019486, 0.00011255353305549406, 0.0001124981226753921, 0.00011244280018703978, 0.00011238758202217528, 0.000112332452861445, 0.00011227745076390982, 0.00011222253267814839, 0.00011216771100885284, 0.00011211299740664698, 0.00011205842607200778, 0.0001120039262562081, 0.00011194948296077452, 0.00011189518838527279, 0.00011184100703233531, 0.00011178688102855132, 0.00011173287246690568, 0.00011167897771075655], 'val_acc': [0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.0011025358324145535, 0.0011025358324145535, 0.0018375597206909224, 0.002205071664829107, 0.002205071664829107, 0.0025725836089672913, 0.003675119441381845, 0.005880191106210952, 0.007717750826901874, 0.009187798603454611, 0.010290334435869165, 0.016538037486218304, 0.021683204704152886, 0.02719588386622565, 0.03491363469312753, 0.04630650496141125, 0.0591694230062477, 0.0782800441014333, 0.10363836824696802, 0.13120176405733186, 0.15692760014700477, 0.18779860345461227, 0.21021683204704153, 0.24072032341051083, 0.2653436236677692, 0.2914369717015803, 0.3094450569643513, 0.3237780227857405, 0.3410510841602352, 0.3572216097023153, 0.3737596471885336, 0.384417493568541, 0.39911797133406834, 0.4079382579933848, 0.42263873575891214, 0.43256155825064313, 0.4410143329658214, 0.4476295479603087, 0.45387725101065785, 0.4597574421168688, 0.46380007350238883, 0.4663726571113561, 0.4696802646085998, 0.4726203601617053, 0.47482543182653436, 0.47703050349136344, 0.4788680632120544, 0.48144064682102167, 0.48438074237412715, 0.48695332598309443, 0.48879088570378537, 0.4898934215361999, 0.49099595736861446, 0.49136346931275265, 0.49136346931275265, 0.49209849320102905, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818], 'loss': [0.00011751943859864571, 0.0001174769537078833, 0.00011743304448791145, 0.0001173877945260601, 0.00011734116366479468, 0.00011729310204768536, 0.00011724335730429755, 0.00011719197164090117, 0.00011713877727375288, 0.00011708414049779702, 0.00011702814777877415, 0.0001169711645105066, 0.00011691350161224805, 0.00011685529833012679, 0.00011679651660089092, 0.00011673723054874933, 0.00011667748264611105, 0.00011661733745493162, 0.00011655688096940311, 0.00011649616449989656, 0.00011643540256257634, 0.00011637453439288122, 0.00011631371722901538, 0.00011625289260878892, 0.00011619216732900596, 0.00011613151444531385, 0.00011607090783767669, 0.00011601039257916493, 0.0001159499454683421, 0.00011588956681064302, 0.00011582928906878812, 0.00011576906395013814, 0.00011570893239635564, 0.000115648863245944, 0.00011558887832052446, 0.00011552898049493532, 0.00011546914433949484, 0.00011540938921894942, 0.00011534972193145659, 0.00011529015754870663, 0.00011523065006792835, 0.00011517125617764636, 0.00011511194249079795, 0.00011505270559044269, 0.00011499358672903648, 0.00011493451990229264, 0.00011487549690098051, 0.00011481659030516629, 0.00011475777669282167, 0.00011469905293636554, 0.0001146404253633, 0.0001145818700729036, 0.00011452345389913829, 0.00011446508813640813, 0.00011440686204670059, 0.0001143486958775896, 0.00011429060167856825, 0.0001142326259078807, 0.00011417473716021829, 0.00011411690339528946, 0.00011405920135046774, 0.00011400158809697804, 0.0001139440733229986, 0.00011388666946026258, 0.00011382933077124485, 0.00011377209012680535, 0.00011371498231704212, 0.00011365797898206393, 0.00011360105468147201, 0.00011354420073627336, 0.0001134874346232342, 0.0001134307612873622, 0.00011337420407745273, 0.00011331776604070934, 0.00011326139680539257, 0.00011320514910544977, 0.00011314898553672525, 0.00011309292671339029, 0.00011303695875334286, 0.00011298109466256934, 0.00011292529726911587, 0.00011286963550033396, 0.00011281401657994957, 0.00011275850794207724, 0.00011270314900656397, 0.00011264788621157324, 0.00011259270392545094, 0.00011253760754242609, 0.00011248261757843075, 0.00011242771364345775, 0.00011237293800182748, 0.00011231824326202273, 0.00011226365796969626, 0.00011220916877770353, 0.00011215482321152442, 0.00011210055146590557, 0.00011204633750730495, 0.00011199227687073395, 0.00011193831866735731, 0.0001118844118654463, 0.00011183062249340087], 'acc': [0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0007364674113170492, 0.0007364674113170492, 0.0008592119798698908, 0.0008592119798698908, 0.0012274456855284155, 0.001841168528292623, 0.0022094022339511476, 0.002700380508162514, 0.0035595924880324047, 0.005032527310666503, 0.0065054621333006015, 0.00883760893580459, 0.012397201423836995, 0.01816619614582055, 0.0254081256904382, 0.03277279980360869, 0.040628452190990545, 0.054375843870737836, 0.0702098932140544, 0.09144470357369598, 0.1178347857814633, 0.144102123482865, 0.17405179819695507, 0.20191481529137276, 0.22744568555036382, 0.25764084939607246, 0.2852583773241199, 0.30710691048994493, 0.328832699178669, 0.3450349821947214, 0.36099177612122313, 0.37793052656322484, 0.3929053639303296, 0.4037068859593216, 0.41512213085302624, 0.42408248435738366, 0.4314471584668961, 0.4401620228597543, 0.4465447404391344, 0.4535411807734849, 0.45906468637665315, 0.46323800168915935, 0.4672885725245646, 0.4701116975829896, 0.472934822663363, 0.47538971399783914, 0.47698539341829066, 0.4784583282628732, 0.48115870875274536, 0.4837363446594323, 0.48520927949669873, 0.4866822143376232, 0.4895053393960482, 0.490732785103525, 0.49097827423697266, 0.4918374862205006, 0.4920829753063933, 0.49232846443618283, 0.4924512090413164, 0.49245120905960676, 0.49245120906326484, 0.4925739536281596, 0.4926966981491575, 0.4926966982150028, 0.4926966981637898, 0.49269669811257677, 0.4929421873521085, 0.4929421872972374, 0.49294218730089545, 0.493064931906029, 0.49306493186579026, 0.4931876764709238, 0.4931876764745819, 0.4931876764160527, 0.4931876764160527]}
[2018-05-06 11:36:00,863 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:92]: done!
[2018-05-06 11:36:00,864 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:152]: >> Executing classifier part ... 
[2018-05-06 11:36:00,864 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:97]: =======================================
[2018-05-06 11:36:00,864 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff6cf158e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-05-06 11:36:01,196 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:110]: training ... 
[2018-05-08 18:03:19,582 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:122]: trained!
[2018-05-08 18:03:19,584 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:125]: Training history: 
{'val_loss': [0.00011738677865594817, 0.00011734380528331402, 0.00011729943113508407, 0.00011725374885470833, 0.00011720668883525822, 0.00011715800713294058, 0.00011710755097671151, 0.0001170554175371053, 0.00011700176089810045, 0.00011694671839105721, 0.0001168905014653046, 0.00011683330189486989, 0.00011677530774761447, 0.00011671665184118435, 0.00011665746978488287, 0.00011659781350514183, 0.00011653769766618452, 0.0001164772281183535, 0.00011641649894905952, 0.00011635566775324488, 0.00011629466771029035, 0.00011623368819831802, 0.00011617265788032045, 0.00011611174400171073, 0.0001160509033880634, 0.00011599008612914366, 0.00011592937524734477, 0.00011586870778063145, 0.00011580810537504444, 0.00011574760239952282, 0.00011568715619572341, 0.00011562680880696907, 0.00011556652503805433, 0.0001155063316370145, 0.00011544622613842032, 0.00011538618869583394, 0.00011532623022185479, 0.00011526636003002949, 0.00011520659318300754, 0.00011514686843813649, 0.0001150872541241723, 0.00011502771373564882, 0.00011496824841971263, 0.00011490889187145449, 0.00011484959809002951, 0.00011479035572430207, 0.00011473121580491353, 0.00011467217775962758, 0.00011461322655520878, 0.00011455436991684694, 0.00011449558158584904, 0.00011443692207486512, 0.00011437832003886575, 0.00011431985804298996, 0.0001142614537360188, 0.00011420312934157736, 0.00011414491178418498, 0.0001140867767892576, 0.00011402870548904186, 0.0001139707653860273, 0.00011391291162384163, 0.0001138551614310754, 0.00011379750946239996, 0.00011373992658457083, 0.00011368244015796963, 0.00011362508681908852, 0.0001135678401060104, 0.0001135106762227974, 0.00011345358013888809, 0.00011339657435332962, 0.00011333966269529192, 0.00011328286597652731, 0.00011322618750477544, 0.00011316958078450121, 0.0001131130896853704, 0.00011305668183324896, 0.00011300038365261798, 0.00011294418180288486, 0.00011288808351722319, 0.00011283206355038641, 0.0001127761719463094, 0.00011272032981393096, 0.00011266460465306662, 0.00011260901754019486, 0.00011255353305549406, 0.0001124981226753921, 0.00011244280018703978, 0.00011238758202217528, 0.000112332452861445, 0.00011227745076390982, 0.00011222253267814839, 0.00011216771100885284, 0.00011211299740664698, 0.00011205842607200778, 0.0001120039262562081, 0.00011194948296077452, 0.00011189518838527279, 0.00011184100703233531, 0.00011178688102855132, 0.00011173287246690568, 0.00011167897771075655], 'val_acc': [0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.0011025358324145535, 0.0011025358324145535, 0.0018375597206909224, 0.002205071664829107, 0.002205071664829107, 0.0025725836089672913, 0.003675119441381845, 0.005880191106210952, 0.007717750826901874, 0.009187798603454611, 0.010290334435869165, 0.016538037486218304, 0.021683204704152886, 0.02719588386622565, 0.03491363469312753, 0.04630650496141125, 0.0591694230062477, 0.0782800441014333, 0.10363836824696802, 0.13120176405733186, 0.15692760014700477, 0.18779860345461227, 0.21021683204704153, 0.24072032341051083, 0.2653436236677692, 0.2914369717015803, 0.3094450569643513, 0.3237780227857405, 0.3410510841602352, 0.3572216097023153, 0.3737596471885336, 0.384417493568541, 0.39911797133406834, 0.4079382579933848, 0.42263873575891214, 0.43256155825064313, 0.4410143329658214, 0.4476295479603087, 0.45387725101065785, 0.4597574421168688, 0.46380007350238883, 0.4663726571113561, 0.4696802646085998, 0.4726203601617053, 0.47482543182653436, 0.47703050349136344, 0.4788680632120544, 0.48144064682102167, 0.48438074237412715, 0.48695332598309443, 0.48879088570378537, 0.4898934215361999, 0.49099595736861446, 0.49136346931275265, 0.49136346931275265, 0.49209849320102905, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818], 'loss': [0.00011751943859864571, 0.0001174769537078833, 0.00011743304448791145, 0.0001173877945260601, 0.00011734116366479468, 0.00011729310204768536, 0.00011724335730429755, 0.00011719197164090117, 0.00011713877727375288, 0.00011708414049779702, 0.00011702814777877415, 0.0001169711645105066, 0.00011691350161224805, 0.00011685529833012679, 0.00011679651660089092, 0.00011673723054874933, 0.00011667748264611105, 0.00011661733745493162, 0.00011655688096940311, 0.00011649616449989656, 0.00011643540256257634, 0.00011637453439288122, 0.00011631371722901538, 0.00011625289260878892, 0.00011619216732900596, 0.00011613151444531385, 0.00011607090783767669, 0.00011601039257916493, 0.0001159499454683421, 0.00011588956681064302, 0.00011582928906878812, 0.00011576906395013814, 0.00011570893239635564, 0.000115648863245944, 0.00011558887832052446, 0.00011552898049493532, 0.00011546914433949484, 0.00011540938921894942, 0.00011534972193145659, 0.00011529015754870663, 0.00011523065006792835, 0.00011517125617764636, 0.00011511194249079795, 0.00011505270559044269, 0.00011499358672903648, 0.00011493451990229264, 0.00011487549690098051, 0.00011481659030516629, 0.00011475777669282167, 0.00011469905293636554, 0.0001146404253633, 0.0001145818700729036, 0.00011452345389913829, 0.00011446508813640813, 0.00011440686204670059, 0.0001143486958775896, 0.00011429060167856825, 0.0001142326259078807, 0.00011417473716021829, 0.00011411690339528946, 0.00011405920135046774, 0.00011400158809697804, 0.0001139440733229986, 0.00011388666946026258, 0.00011382933077124485, 0.00011377209012680535, 0.00011371498231704212, 0.00011365797898206393, 0.00011360105468147201, 0.00011354420073627336, 0.0001134874346232342, 0.0001134307612873622, 0.00011337420407745273, 0.00011331776604070934, 0.00011326139680539257, 0.00011320514910544977, 0.00011314898553672525, 0.00011309292671339029, 0.00011303695875334286, 0.00011298109466256934, 0.00011292529726911587, 0.00011286963550033396, 0.00011281401657994957, 0.00011275850794207724, 0.00011270314900656397, 0.00011264788621157324, 0.00011259270392545094, 0.00011253760754242609, 0.00011248261757843075, 0.00011242771364345775, 0.00011237293800182748, 0.00011231824326202273, 0.00011226365796969626, 0.00011220916877770353, 0.00011215482321152442, 0.00011210055146590557, 0.00011204633750730495, 0.00011199227687073395, 0.00011193831866735731, 0.0001118844118654463, 0.00011183062249340087], 'acc': [0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0004909782742113662, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0007364674113170492, 0.0007364674113170492, 0.0008592119798698908, 0.0008592119798698908, 0.0012274456855284155, 0.001841168528292623, 0.0022094022339511476, 0.002700380508162514, 0.0035595924880324047, 0.005032527310666503, 0.0065054621333006015, 0.00883760893580459, 0.012397201423836995, 0.01816619614582055, 0.0254081256904382, 0.03277279980360869, 0.040628452190990545, 0.054375843870737836, 0.0702098932140544, 0.09144470357369598, 0.1178347857814633, 0.144102123482865, 0.17405179819695507, 0.20191481529137276, 0.22744568555036382, 0.25764084939607246, 0.2852583773241199, 0.30710691048994493, 0.328832699178669, 0.3450349821947214, 0.36099177612122313, 0.37793052656322484, 0.3929053639303296, 0.4037068859593216, 0.41512213085302624, 0.42408248435738366, 0.4314471584668961, 0.4401620228597543, 0.4465447404391344, 0.4535411807734849, 0.45906468637665315, 0.46323800168915935, 0.4672885725245646, 0.4701116975829896, 0.472934822663363, 0.47538971399783914, 0.47698539341829066, 0.4784583282628732, 0.48115870875274536, 0.4837363446594323, 0.48520927949669873, 0.4866822143376232, 0.4895053393960482, 0.490732785103525, 0.49097827423697266, 0.4918374862205006, 0.4920829753063933, 0.49232846443618283, 0.4924512090413164, 0.49245120905960676, 0.49245120906326484, 0.4925739536281596, 0.4926966981491575, 0.4926966982150028, 0.4926966981637898, 0.49269669811257677, 0.4929421873521085, 0.4929421872972374, 0.49294218730089545, 0.493064931906029, 0.49306493186579026, 0.4931876764709238, 0.4931876764745819, 0.4931876764160527, 0.4931876764160527]}
[2018-05-08 18:03:19,584 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:129]: evaluating model ... 
[2018-05-08 18:03:43,263 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:133]: evaluated! 
[2018-05-08 18:03:43,272 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:135]: generating reports ... 
[2018-05-08 18:03:45,351 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:138]: done!
[2018-05-08 18:03:45,352 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F2_0 finished!
[2018-05-09 09:52:35,031 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:85]: trained and evaluated!
[2018-05-09 09:52:35,051 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:88]: Training history: 
{'val_loss': [0.00011779330851916958, 0.0001177370858229221, 0.00011768083484108858, 0.00011762443326484824, 0.0001175678766714029, 0.00011751137657425764, 0.00011745491241034222, 0.00011739853514344796, 0.00011734218716221626, 0.00011728583292382144, 0.00011722959000944992, 0.0001171733903844859, 0.00011711724926667094, 0.00011706117406298872, 0.00011700517765945165, 0.00011694925246991796, 0.00011689344035587844, 0.0001168376489466312, 0.00011678193523316654, 0.00011672632452490706, 0.00011667077290940292, 0.00011661529850568715, 0.00011655990155976785, 0.00011650462443852207, 0.00011644944830093645, 0.00011639435278983887, 0.00011633936745829204, 0.00011628447568737767, 0.00011622963843400238, 0.0001161749348887155, 0.000116120306547042, 0.00011606579494157046, 0.00011601136676761438, 0.00011595705133757631, 0.00011590282600266498, 0.00011584868699788652, 0.00011579466484964013, 0.00011574072516759469, 0.00011568690265493946, 0.00011563317992799179, 0.00011557952885090972, 0.0001155260101609594, 0.00011547261291345341, 0.00011541930105215783, 0.0001153661052398459, 0.00011531299709199351, 0.0001152599585724617, 0.00011520703716616607, 0.00011515422445267643, 0.00011510148718346028, 0.0001150488702630219, 0.0001149963427103819, 0.00011494391122926163, 0.0001148915915427889, 0.00011483937094410938, 0.000114787247229846, 0.00011473522386550444, 0.00011468331032239746, 0.00011463149700086025, 0.00011457976588347187, 0.0001145281130982784, 0.00011447657773650526, 0.00011442513239498684, 0.00011437380481381291, 0.0001143225267899056, 0.00011427136684989694, 0.00011422028226324572, 0.00011416928428214951, 0.00011411840975434663, 0.00011406763306825235, 0.00011401692782879955, 0.00011396632828459726, 0.00011391582528788694, 0.00011386539340089391, 0.0001138150782501029, 0.00011376485887936545, 0.00011371475297185237, 0.00011366474205288846, 0.00011361481200374673, 0.00011356500400939561, 0.00011351527138979395, 0.00011346563697021708, 0.00011341606475058509, 0.0001133665958222764, 0.00011331723343955065, 0.00011326791711114977, 0.00011321872189361705, 0.00011316960564736555, 0.00011312059535841669, 0.0001130716584895223, 0.00011302282698965025, 0.00011297408591113311, 0.00011292545114823478, 0.00011287691523246956, 0.00011282844403021048, 0.00011278008085493107, 0.00011273180245618976, 0.00011268363556330384, 0.00011263553404440239, 0.00011258754291897178, 0.00011253961401487807], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0011025358324145535, 0.002205071664829107, 0.005145167217934583, 0.006982726938625505, 0.012127894156560088, 0.019110621095185593, 0.025725836089672913, 0.0356486585814039, 0.04005880191106211, 0.04961411245865491, 0.06174200661521499, 0.08342521131936788, 0.10804851157662625, 0.12605659683939727, 0.14884233737596472, 0.16942300624770304, 0.18779860345461227, 0.20801176038221242, 0.22418228592429254, 0.2366776920249908, 0.25101065784638, 0.26607864755604554, 0.28041161337743475, 0.2914369717015803, 0.30025725836089673, 0.3090775450202132, 0.32120543917677324, 0.33112826166850423, 0.3403160602719588, 0.3502388827636898, 0.360529217199559, 0.3708195516354281, 0.3836824696802646, 0.3914002205071665, 0.39985299522234474, 0.4079382579933848, 0.4141859610437339, 0.4219037118706358, 0.432194046306505, 0.4391767732451305, 0.4432194046306505, 0.44689452407203234, 0.450202131569276, 0.4549797868430724, 0.4590224182285924, 0.46085997794928335, 0.4645350973906652, 0.4663726571113561, 0.4696802646085998, 0.47078280044101434, 0.4733553840499816, 0.4762954796030871, 0.47813303932377804, 0.4792355751561926, 0.48144064682102167, 0.4836457184858508, 0.48511576626240355, 0.48768834987137083, 0.48879088570378537, 0.4895259095920617, 0.4906284454244763, 0.4906284454244763, 0.49099595736861446, 0.49136346931275265, 0.49136346931275265, 0.49173098125689085, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.0001179627756082904, 0.00011790694255487479, 0.00011785110116094509, 0.00011779517839096215, 0.0001177390816383379, 0.0001176829634436532, 0.0001176269055777046, 0.00011757086246193591, 0.00011751491611542111, 0.00011745901266463727, 0.00011740310698739433, 0.00011734732223554882, 0.00011729161878116514, 0.0001172359608204946, 0.00011718037016533451, 0.00011712485808283614, 0.00011706941232166935, 0.0001170140727955567, 0.00011695875581624972, 0.0001169035076758789, 0.00011684835553670949, 0.00011679327334300766, 0.00011673825561480828, 0.00011668331695582547, 0.00011662850227301598, 0.00011657378183917654, 0.0001165191383418684, 0.00011646459756443469, 0.00011641014560423244, 0.00011635575876327033, 0.00011630150590549089, 0.0001162473321347897, 0.00011619326734001829, 0.00011613927399734765, 0.000116085400377983, 0.00011603161672257003, 0.00011597791583552869, 0.00011592432820764936, 0.00011587081628831045, 0.00011581742584629505, 0.00011576412648815902, 0.00011571089435694202, 0.0001156577925383313, 0.00011560480849074435, 0.00011555191386500691, 0.00011549913196168782, 0.00011544644801095926, 0.00011539383572667169, 0.00011534133297202616, 0.00011528893763755761, 0.00011523662173043243, 0.00011518441978264731, 0.00011513230980825348, 0.00011508028994695641, 0.00011502838878370458, 0.000114976591207512, 0.00011492488307996148, 0.0001148732733595814, 0.0001148217714621593, 0.00011477037014924711, 0.0001147190472518138, 0.00011466780196161809, 0.00011461668221942405, 0.00011456564689870063, 0.00011451472674744649, 0.00011446386128242195, 0.00011441311266497203, 0.00011436243783414516, 0.00011431185818020291, 0.00011426139268743777, 0.00011421103266703278, 0.00011416074044780004, 0.00011411054635173693, 0.0001140604557739656, 0.00011401043042974918, 0.00011396051862155088, 0.00011391070068544106, 0.0001138609956807313, 0.00011381137954683806, 0.0001137618522685789, 0.00011371243613287199, 0.00011366310063910308, 0.0001136138609330884, 0.00011356468217382411, 0.00011351560843055394, 0.00011346662834771128, 0.00011341769921621976, 0.00011336888721094515, 0.00011332015485092647, 0.00011327152023987511, 0.00011322295961728388, 0.00011317450314528806, 0.00011312613467424468, 0.00011307787059492951, 0.00011302970705547002, 0.00011298160330978912, 0.00011293361007435681, 0.00011288570477200252, 0.00011283790557073974, 0.00011279017333204304, 0.00011274255860001715], 'acc': [0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0006137228427642077, 0.00159567939118694, 0.0029458696452681968, 0.004050570762243771, 0.005768994721983552, 0.009083098072910275, 0.014483859089235301, 0.02246225604517, 0.031054375845697944, 0.03915551736927097, 0.04676568061863263, 0.0583036700662578, 0.07045538235116008, 0.09193568183144601, 0.1104701116984719, 0.12679513931599984, 0.14434761258887707, 0.1644777218617222, 0.18203019516752209, 0.20031913586726316, 0.2168896526182387, 0.22990057690313026, 0.24303424575657467, 0.2565361482461742, 0.26684669205582595, 0.27678900210860613, 0.2872222903843846, 0.2952006873915323, 0.3026881060586234, 0.3116484595629808, 0.3231864489703672, 0.3333742482334145, 0.3450349822093537, 0.35669571618529294, 0.3666380262892861, 0.37731680375338333, 0.3894685160401146, 0.3976924021368131, 0.40481158713116827, 0.4125444948768358, 0.42052289180350594, 0.4262918865913348, 0.43156990305739734, 0.4366024303351412, 0.44224868048491384, 0.4462992512837383, 0.45157726771322015, 0.4546458819270412, 0.45832821894704573, 0.4617650668665253, 0.46409721368731965, 0.4670430833874589, 0.46949797474022537, 0.4721983552483879, 0.47391677917154695, 0.47637167049504886, 0.4784583282080021, 0.4802994966887398, 0.4841045784016716, 0.48692770345643854, 0.48815514912733465, 0.4888916165386517, 0.4895053393302029, 0.4903645513759181, 0.49085552963549717, 0.49134650796092155, 0.4915919970614465, 0.49208297535394824, 0.4922057199042107, 0.49232846449105394, 0.4924512090376583, 0.4925739536098692, 0.4925739535732885, 0.49257395363181766, 0.49269669816013173, 0.49269669814184136, 0.4926966981637898, 0.4926966982150028, 0.49269669811257677, 0.4926966981637898, 0.4926966981491575, 0.49269669816013173, 0.49269669819671247, 0.4928194427323426, 0.4928194427469749, 0.49281944278355566, 0.49281944272868455, 0.4930649319206613, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115]}
[2018-05-09 09:52:35,052 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:92]: done!
[2018-05-09 09:52:35,052 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:152]: >> Executing classifier part ... 
[2018-05-09 09:52:35,052 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:97]: =======================================
[2018-05-09 09:52:35,053 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7feb0bc97da0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-05-09 09:52:35,146 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:110]: training ... 
[2018-05-10 16:12:11,535 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:122]: trained!
[2018-05-10 16:12:11,536 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:125]: Training history: 
{'val_loss': [0.00011779330851916958, 0.0001177370858229221, 0.00011768083484108858, 0.00011762443326484824, 0.0001175678766714029, 0.00011751137657425764, 0.00011745491241034222, 0.00011739853514344796, 0.00011734218716221626, 0.00011728583292382144, 0.00011722959000944992, 0.0001171733903844859, 0.00011711724926667094, 0.00011706117406298872, 0.00011700517765945165, 0.00011694925246991796, 0.00011689344035587844, 0.0001168376489466312, 0.00011678193523316654, 0.00011672632452490706, 0.00011667077290940292, 0.00011661529850568715, 0.00011655990155976785, 0.00011650462443852207, 0.00011644944830093645, 0.00011639435278983887, 0.00011633936745829204, 0.00011628447568737767, 0.00011622963843400238, 0.0001161749348887155, 0.000116120306547042, 0.00011606579494157046, 0.00011601136676761438, 0.00011595705133757631, 0.00011590282600266498, 0.00011584868699788652, 0.00011579466484964013, 0.00011574072516759469, 0.00011568690265493946, 0.00011563317992799179, 0.00011557952885090972, 0.0001155260101609594, 0.00011547261291345341, 0.00011541930105215783, 0.0001153661052398459, 0.00011531299709199351, 0.0001152599585724617, 0.00011520703716616607, 0.00011515422445267643, 0.00011510148718346028, 0.0001150488702630219, 0.0001149963427103819, 0.00011494391122926163, 0.0001148915915427889, 0.00011483937094410938, 0.000114787247229846, 0.00011473522386550444, 0.00011468331032239746, 0.00011463149700086025, 0.00011457976588347187, 0.0001145281130982784, 0.00011447657773650526, 0.00011442513239498684, 0.00011437380481381291, 0.0001143225267899056, 0.00011427136684989694, 0.00011422028226324572, 0.00011416928428214951, 0.00011411840975434663, 0.00011406763306825235, 0.00011401692782879955, 0.00011396632828459726, 0.00011391582528788694, 0.00011386539340089391, 0.0001138150782501029, 0.00011376485887936545, 0.00011371475297185237, 0.00011366474205288846, 0.00011361481200374673, 0.00011356500400939561, 0.00011351527138979395, 0.00011346563697021708, 0.00011341606475058509, 0.0001133665958222764, 0.00011331723343955065, 0.00011326791711114977, 0.00011321872189361705, 0.00011316960564736555, 0.00011312059535841669, 0.0001130716584895223, 0.00011302282698965025, 0.00011297408591113311, 0.00011292545114823478, 0.00011287691523246956, 0.00011282844403021048, 0.00011278008085493107, 0.00011273180245618976, 0.00011268363556330384, 0.00011263553404440239, 0.00011258754291897178, 0.00011253961401487807], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0011025358324145535, 0.002205071664829107, 0.005145167217934583, 0.006982726938625505, 0.012127894156560088, 0.019110621095185593, 0.025725836089672913, 0.0356486585814039, 0.04005880191106211, 0.04961411245865491, 0.06174200661521499, 0.08342521131936788, 0.10804851157662625, 0.12605659683939727, 0.14884233737596472, 0.16942300624770304, 0.18779860345461227, 0.20801176038221242, 0.22418228592429254, 0.2366776920249908, 0.25101065784638, 0.26607864755604554, 0.28041161337743475, 0.2914369717015803, 0.30025725836089673, 0.3090775450202132, 0.32120543917677324, 0.33112826166850423, 0.3403160602719588, 0.3502388827636898, 0.360529217199559, 0.3708195516354281, 0.3836824696802646, 0.3914002205071665, 0.39985299522234474, 0.4079382579933848, 0.4141859610437339, 0.4219037118706358, 0.432194046306505, 0.4391767732451305, 0.4432194046306505, 0.44689452407203234, 0.450202131569276, 0.4549797868430724, 0.4590224182285924, 0.46085997794928335, 0.4645350973906652, 0.4663726571113561, 0.4696802646085998, 0.47078280044101434, 0.4733553840499816, 0.4762954796030871, 0.47813303932377804, 0.4792355751561926, 0.48144064682102167, 0.4836457184858508, 0.48511576626240355, 0.48768834987137083, 0.48879088570378537, 0.4895259095920617, 0.4906284454244763, 0.4906284454244763, 0.49099595736861446, 0.49136346931275265, 0.49136346931275265, 0.49173098125689085, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.0001179627756082904, 0.00011790694255487479, 0.00011785110116094509, 0.00011779517839096215, 0.0001177390816383379, 0.0001176829634436532, 0.0001176269055777046, 0.00011757086246193591, 0.00011751491611542111, 0.00011745901266463727, 0.00011740310698739433, 0.00011734732223554882, 0.00011729161878116514, 0.0001172359608204946, 0.00011718037016533451, 0.00011712485808283614, 0.00011706941232166935, 0.0001170140727955567, 0.00011695875581624972, 0.0001169035076758789, 0.00011684835553670949, 0.00011679327334300766, 0.00011673825561480828, 0.00011668331695582547, 0.00011662850227301598, 0.00011657378183917654, 0.0001165191383418684, 0.00011646459756443469, 0.00011641014560423244, 0.00011635575876327033, 0.00011630150590549089, 0.0001162473321347897, 0.00011619326734001829, 0.00011613927399734765, 0.000116085400377983, 0.00011603161672257003, 0.00011597791583552869, 0.00011592432820764936, 0.00011587081628831045, 0.00011581742584629505, 0.00011576412648815902, 0.00011571089435694202, 0.0001156577925383313, 0.00011560480849074435, 0.00011555191386500691, 0.00011549913196168782, 0.00011544644801095926, 0.00011539383572667169, 0.00011534133297202616, 0.00011528893763755761, 0.00011523662173043243, 0.00011518441978264731, 0.00011513230980825348, 0.00011508028994695641, 0.00011502838878370458, 0.000114976591207512, 0.00011492488307996148, 0.0001148732733595814, 0.0001148217714621593, 0.00011477037014924711, 0.0001147190472518138, 0.00011466780196161809, 0.00011461668221942405, 0.00011456564689870063, 0.00011451472674744649, 0.00011446386128242195, 0.00011441311266497203, 0.00011436243783414516, 0.00011431185818020291, 0.00011426139268743777, 0.00011421103266703278, 0.00011416074044780004, 0.00011411054635173693, 0.0001140604557739656, 0.00011401043042974918, 0.00011396051862155088, 0.00011391070068544106, 0.0001138609956807313, 0.00011381137954683806, 0.0001137618522685789, 0.00011371243613287199, 0.00011366310063910308, 0.0001136138609330884, 0.00011356468217382411, 0.00011351560843055394, 0.00011346662834771128, 0.00011341769921621976, 0.00011336888721094515, 0.00011332015485092647, 0.00011327152023987511, 0.00011322295961728388, 0.00011317450314528806, 0.00011312613467424468, 0.00011307787059492951, 0.00011302970705547002, 0.00011298160330978912, 0.00011293361007435681, 0.00011288570477200252, 0.00011283790557073974, 0.00011279017333204304, 0.00011274255860001715], 'acc': [0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0006137228427642077, 0.00159567939118694, 0.0029458696452681968, 0.004050570762243771, 0.005768994721983552, 0.009083098072910275, 0.014483859089235301, 0.02246225604517, 0.031054375845697944, 0.03915551736927097, 0.04676568061863263, 0.0583036700662578, 0.07045538235116008, 0.09193568183144601, 0.1104701116984719, 0.12679513931599984, 0.14434761258887707, 0.1644777218617222, 0.18203019516752209, 0.20031913586726316, 0.2168896526182387, 0.22990057690313026, 0.24303424575657467, 0.2565361482461742, 0.26684669205582595, 0.27678900210860613, 0.2872222903843846, 0.2952006873915323, 0.3026881060586234, 0.3116484595629808, 0.3231864489703672, 0.3333742482334145, 0.3450349822093537, 0.35669571618529294, 0.3666380262892861, 0.37731680375338333, 0.3894685160401146, 0.3976924021368131, 0.40481158713116827, 0.4125444948768358, 0.42052289180350594, 0.4262918865913348, 0.43156990305739734, 0.4366024303351412, 0.44224868048491384, 0.4462992512837383, 0.45157726771322015, 0.4546458819270412, 0.45832821894704573, 0.4617650668665253, 0.46409721368731965, 0.4670430833874589, 0.46949797474022537, 0.4721983552483879, 0.47391677917154695, 0.47637167049504886, 0.4784583282080021, 0.4802994966887398, 0.4841045784016716, 0.48692770345643854, 0.48815514912733465, 0.4888916165386517, 0.4895053393302029, 0.4903645513759181, 0.49085552963549717, 0.49134650796092155, 0.4915919970614465, 0.49208297535394824, 0.4922057199042107, 0.49232846449105394, 0.4924512090376583, 0.4925739536098692, 0.4925739535732885, 0.49257395363181766, 0.49269669816013173, 0.49269669814184136, 0.4926966981637898, 0.4926966982150028, 0.49269669811257677, 0.4926966981637898, 0.4926966981491575, 0.49269669816013173, 0.49269669819671247, 0.4928194427323426, 0.4928194427469749, 0.49281944278355566, 0.49281944272868455, 0.4930649319206613, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115]}
[2018-05-10 16:12:11,536 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:129]: evaluating model ... 
[2018-05-10 16:12:17,080 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:133]: evaluated! 
[2018-05-10 16:12:17,081 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:135]: generating reports ... 
[2018-05-10 16:12:18,059 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:138]: done!
[2018-05-10 16:12:18,059 AE_BIGRAMA_1L_FULLDS_OVER_F2_0.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F2_0 finished!
