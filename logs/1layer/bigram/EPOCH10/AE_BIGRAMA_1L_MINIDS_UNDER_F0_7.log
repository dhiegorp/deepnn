[2017-12-13 22:14:58,841 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_7
[2017-12-13 22:14:58,841 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:146]: >> Printing header log
[2017-12-13 22:14:58,841 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_7
	layers = 9216,6451
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 50, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f1e6b13eeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f1e6b121400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-13 22:14:58,841 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:148]: >> Loading dataset... 
[2017-12-13 22:15:21,301 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-13 22:15:21,301 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:150]: >> Executing autoencoder part ... 
[2017-12-13 22:15:21,301 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:57]: =======================================
[2017-12-13 22:15:21,302 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f1e6b13eeb8>, 'discard_decoder_function': True}
[2017-12-13 22:15:21,349 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:73]: training and evaluate autoencoder
[2017-12-14 00:35:20,027 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:85]: trained and evaluated!
[2017-12-14 00:35:20,028 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:88]: Training history: 
{'val_loss': [0.00011919865419236367, 0.00011919243725306178, 0.00011918623248802805, 0.00011917997296560322, 0.00011917366177851623, 0.00011916732345407381, 0.0001191609747430678, 0.00011915464982640969, 0.00011914823171671215, 0.00011914178117805364, 0.00011913529695904098, 0.00011912878233117351, 0.00011912223786651671, 0.00011911568081641972, 0.00011910911536411124, 0.00011910254460232016, 0.00011909593140042252, 0.00011908928321314637, 0.00011908257821261888, 0.00011907591416840316, 0.00011906921488853029, 0.00011906254512365995, 0.00011905575919374641, 0.00011904897751856975, 0.00011904215079323784, 0.00011903526684348255, 0.00011902835854519095, 0.00011902145809492243, 0.00011901448350854525, 0.00011900750826071738, 0.00011900051315149168, 0.00011899353456065626, 0.00011898653480339868, 0.00011897953946177141, 0.00011897246033043077, 0.00011896543025370362, 0.00011895837940384933, 0.00011895132340540588, 0.00011894424420255705, 0.00011893713450146821, 0.00011892998155580572, 0.00011892288665691075, 0.00011891574279278751, 0.0001189085455478057, 0.00011890133661123596, 0.00011889410479204771, 0.00011888692781963575, 0.00011887967867759017, 0.00011887240860152404, 0.00011886512627968157], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00012001669019572922, 0.00012001041509704028, 0.0001200040785437647, 0.00011999774817623811, 0.00011999138569495722, 0.0001199849904363168, 0.00011997855692557347, 0.00011997210739350329, 0.00011996568075581438, 0.00011995917905963114, 0.00011995269577849372, 0.00011994617808468379, 0.00011993964060121716, 0.00011993306410724164, 0.00011992647680598054, 0.00011991989926919675, 0.00011991330907651274, 0.00011990667866461028, 0.00011989999288906941, 0.00011989322802600229, 0.00011988650094103432, 0.00011987974889976873, 0.00011987300795019097, 0.00011986615947286176, 0.00011985928793524996, 0.00011985236065479675, 0.000119845365236304, 0.00011983833820176089, 0.0001198313330661912, 0.00011982424012142618, 0.00011981716556800681, 0.00011981005925633596, 0.00011980297569684526, 0.00011979588493249752, 0.00011978880687145036, 0.00011978164664185257, 0.00011977452253134078, 0.00011976736979100228, 0.00011976020439476357, 0.00011975302210029106, 0.00011974580747876255, 0.00011973853825200167, 0.00011973131787132756, 0.00011972403504065897, 0.00011971670153898912, 0.00011970938166492719, 0.0001197020253636768, 0.00011969471921202354, 0.0001196873562984208, 0.00011967999269751262], 'acc': [0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329]}
[2017-12-14 00:35:20,029 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:92]: done!
[2017-12-14 00:35:20,029 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:152]: >> Executing classifier part ... 
[2017-12-14 00:35:20,029 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:97]: =======================================
[2017-12-14 00:35:20,029 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f1e6b121400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-14 00:35:20,508 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:110]: training ... 
[2017-12-14 01:40:29,982 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:122]: trained!
[2017-12-14 01:40:29,983 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:125]: Training history: 
{'val_loss': [0.00011919865419236367, 0.00011919243725306178, 0.00011918623248802805, 0.00011917997296560322, 0.00011917366177851623, 0.00011916732345407381, 0.0001191609747430678, 0.00011915464982640969, 0.00011914823171671215, 0.00011914178117805364, 0.00011913529695904098, 0.00011912878233117351, 0.00011912223786651671, 0.00011911568081641972, 0.00011910911536411124, 0.00011910254460232016, 0.00011909593140042252, 0.00011908928321314637, 0.00011908257821261888, 0.00011907591416840316, 0.00011906921488853029, 0.00011906254512365995, 0.00011905575919374641, 0.00011904897751856975, 0.00011904215079323784, 0.00011903526684348255, 0.00011902835854519095, 0.00011902145809492243, 0.00011901448350854525, 0.00011900750826071738, 0.00011900051315149168, 0.00011899353456065626, 0.00011898653480339868, 0.00011897953946177141, 0.00011897246033043077, 0.00011896543025370362, 0.00011895837940384933, 0.00011895132340540588, 0.00011894424420255705, 0.00011893713450146821, 0.00011892998155580572, 0.00011892288665691075, 0.00011891574279278751, 0.0001189085455478057, 0.00011890133661123596, 0.00011889410479204771, 0.00011888692781963575, 0.00011887967867759017, 0.00011887240860152404, 0.00011886512627968157], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00012001669019572922, 0.00012001041509704028, 0.0001200040785437647, 0.00011999774817623811, 0.00011999138569495722, 0.0001199849904363168, 0.00011997855692557347, 0.00011997210739350329, 0.00011996568075581438, 0.00011995917905963114, 0.00011995269577849372, 0.00011994617808468379, 0.00011993964060121716, 0.00011993306410724164, 0.00011992647680598054, 0.00011991989926919675, 0.00011991330907651274, 0.00011990667866461028, 0.00011989999288906941, 0.00011989322802600229, 0.00011988650094103432, 0.00011987974889976873, 0.00011987300795019097, 0.00011986615947286176, 0.00011985928793524996, 0.00011985236065479675, 0.000119845365236304, 0.00011983833820176089, 0.0001198313330661912, 0.00011982424012142618, 0.00011981716556800681, 0.00011981005925633596, 0.00011980297569684526, 0.00011979588493249752, 0.00011978880687145036, 0.00011978164664185257, 0.00011977452253134078, 0.00011976736979100228, 0.00011976020439476357, 0.00011975302210029106, 0.00011974580747876255, 0.00011973853825200167, 0.00011973131787132756, 0.00011972403504065897, 0.00011971670153898912, 0.00011970938166492719, 0.0001197020253636768, 0.00011969471921202354, 0.0001196873562984208, 0.00011967999269751262], 'acc': [0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329]}
[2017-12-14 01:40:29,984 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:129]: evaluating model ... 
[2017-12-14 01:40:38,148 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:133]: evaluated! 
[2017-12-14 01:40:38,150 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:135]: generating reports ... 
[2017-12-14 01:40:41,984 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:138]: done!
[2017-12-14 01:40:41,984 AE_BIGRAMA_1L_MINIDS_UNDER_F0_7.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_7 finished!
