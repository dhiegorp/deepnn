[2017-12-13 22:14:58,905 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_4
[2017-12-13 22:14:58,905 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:146]: >> Printing header log
[2017-12-13 22:14:58,905 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_OVER_F1_4
	layers = 9216,12902
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 50, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f93d2025eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f93d2008400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-13 22:14:58,905 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:148]: >> Loading dataset... 
[2017-12-13 22:15:21,853 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-13 22:15:21,853 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:150]: >> Executing autoencoder part ... 
[2017-12-13 22:15:21,853 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:57]: =======================================
[2017-12-13 22:15:21,854 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f93d2025eb8>, 'discard_decoder_function': True}
[2017-12-13 22:15:21,900 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:73]: training and evaluate autoencoder
[2017-12-14 02:07:29,935 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:85]: trained and evaluated!
[2017-12-14 02:07:29,936 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:88]: Training history: 
{'val_loss': [0.00011804976720243912, 0.0001180407640361742, 0.0001180317110823369, 0.00011802270571719535, 0.00011801379043448726, 0.00011800471434775278, 0.00011799567619610934, 0.00011798663861653138, 0.00011797771001542422, 0.00011796873741890751, 0.00011795973630850283, 0.00011795072316684639, 0.00011794174697704348, 0.00011793275689677603, 0.00011792372185573856, 0.00011791473054195496, 0.00011790575256444748, 0.00011789674482165884, 0.00011788777297597804, 0.00011787881559282724, 0.00011786984823428493, 0.0001178608933002894, 0.00011785195610032323, 0.00011784296668150648, 0.00011783399115315426, 0.00011782500400472231, 0.00011781603230205788, 0.00011780702364753992, 0.00011779809452799842, 0.0001177891435090759, 0.00011778019240076816, 0.00011777125387790062, 0.00011776232533042459, 0.0001177533182312096, 0.00011774435069389683, 0.00011773538626719001, 0.00011772639927965147, 0.00011771743910768154, 0.0001177084925758975, 0.00011769958667863842, 0.00011769059699166599, 0.00011768166075706029, 0.00011767273074366651, 0.00011766380873918923, 0.00011765492892453986, 0.0001176459998943836, 0.00011763708729323237, 0.00011762818196803876, 0.00011761924795018674, 0.00011761031622059658], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002502767694, 0.004914004959770151, 0.004914004959770151, 0.004914004959770151], 'loss': [0.00011887957953149453, 0.0001188703333298791, 0.00011886112189643899, 0.00011885185623696947, 0.00011884264629664118, 0.00011883351843006277, 0.00011882422670038684, 0.00011881497260660892, 0.00011880572277886478, 0.00011879657806145295, 0.00011878739535264027, 0.00011877818297119265, 0.00011876895904775363, 0.00011875976624266102, 0.00011875056891083256, 0.00011874131320544188, 0.00011873211300589071, 0.00011872291659836957, 0.00011871369530565139, 0.00011870450150515089, 0.00011869532747060692, 0.00011868614689481114, 0.00011867697496958387, 0.00011866781738297013, 0.00011865861531110414, 0.00011864941861918075, 0.00011864021676061644, 0.00011863103033087432, 0.00011862180702364018, 0.00011861266446294542, 0.00011860349663785061, 0.00011859433187008001, 0.00011858517857320024, 0.0001185760321493749, 0.00011856681329777604, 0.00011855763047046244, 0.00011854844304531242, 0.00011853924239545769, 0.00011853006409487994, 0.00011852090176822866, 0.00011851177771738048, 0.00011850257391540078, 0.00011849341552298067, 0.00011848426928875683, 0.00011847513398031949, 0.00011846604047901322, 0.00011845689893742654, 0.00011844777609528792, 0.00011843865417745662, 0.00011842950699522528], 'acc': [0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.0016286644951140066, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0032573289902280132, 0.0032573289902280132, 0.0032573289902280132, 0.0040716612377850164, 0.0040716612620540086, 0.0040716612377850164, 0.0040716612377850164, 0.0040716612377850164, 0.0040716612377850164, 0.0040716612377850164, 0.0048859934853420191, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0065146579804560263, 0.0065146579804560263, 0.0065146579804560263, 0.0065146579804560263, 0.0081433224755700327, 0.0081433224755700327, 0.0081433224755700327, 0.0081433224755700327, 0.0081433224755700327, 0.0089576547231270363, 0.0097719869706840382, 0.0097719869706840382, 0.0097719869949530313, 0.010586319266779026]}
[2017-12-14 02:07:29,936 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:92]: done!
[2017-12-14 02:07:29,936 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:152]: >> Executing classifier part ... 
[2017-12-14 02:07:29,936 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:97]: =======================================
[2017-12-14 02:07:29,936 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f93d2008400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-14 02:07:30,151 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:110]: training ... 
[2017-12-14 03:26:34,243 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:122]: trained!
[2017-12-14 03:26:34,244 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:125]: Training history: 
{'val_loss': [0.00011804976720243912, 0.0001180407640361742, 0.0001180317110823369, 0.00011802270571719535, 0.00011801379043448726, 0.00011800471434775278, 0.00011799567619610934, 0.00011798663861653138, 0.00011797771001542422, 0.00011796873741890751, 0.00011795973630850283, 0.00011795072316684639, 0.00011794174697704348, 0.00011793275689677603, 0.00011792372185573856, 0.00011791473054195496, 0.00011790575256444748, 0.00011789674482165884, 0.00011788777297597804, 0.00011787881559282724, 0.00011786984823428493, 0.0001178608933002894, 0.00011785195610032323, 0.00011784296668150648, 0.00011783399115315426, 0.00011782500400472231, 0.00011781603230205788, 0.00011780702364753992, 0.00011779809452799842, 0.0001177891435090759, 0.00011778019240076816, 0.00011777125387790062, 0.00011776232533042459, 0.0001177533182312096, 0.00011774435069389683, 0.00011773538626719001, 0.00011772639927965147, 0.00011771743910768154, 0.0001177084925758975, 0.00011769958667863842, 0.00011769059699166599, 0.00011768166075706029, 0.00011767273074366651, 0.00011766380873918923, 0.00011765492892453986, 0.0001176459998943836, 0.00011763708729323237, 0.00011762818196803876, 0.00011761924795018674, 0.00011761031622059658], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002502767694, 0.004914004959770151, 0.004914004959770151, 0.004914004959770151], 'loss': [0.00011887957953149453, 0.0001188703333298791, 0.00011886112189643899, 0.00011885185623696947, 0.00011884264629664118, 0.00011883351843006277, 0.00011882422670038684, 0.00011881497260660892, 0.00011880572277886478, 0.00011879657806145295, 0.00011878739535264027, 0.00011877818297119265, 0.00011876895904775363, 0.00011875976624266102, 0.00011875056891083256, 0.00011874131320544188, 0.00011873211300589071, 0.00011872291659836957, 0.00011871369530565139, 0.00011870450150515089, 0.00011869532747060692, 0.00011868614689481114, 0.00011867697496958387, 0.00011866781738297013, 0.00011865861531110414, 0.00011864941861918075, 0.00011864021676061644, 0.00011863103033087432, 0.00011862180702364018, 0.00011861266446294542, 0.00011860349663785061, 0.00011859433187008001, 0.00011858517857320024, 0.0001185760321493749, 0.00011856681329777604, 0.00011855763047046244, 0.00011854844304531242, 0.00011853924239545769, 0.00011853006409487994, 0.00011852090176822866, 0.00011851177771738048, 0.00011850257391540078, 0.00011849341552298067, 0.00011848426928875683, 0.00011847513398031949, 0.00011846604047901322, 0.00011845689893742654, 0.00011844777609528792, 0.00011843865417745662, 0.00011842950699522528], 'acc': [0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.0016286644951140066, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0032573289902280132, 0.0032573289902280132, 0.0032573289902280132, 0.0040716612377850164, 0.0040716612620540086, 0.0040716612377850164, 0.0040716612377850164, 0.0040716612377850164, 0.0040716612377850164, 0.0040716612377850164, 0.0048859934853420191, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0057003257328990227, 0.0065146579804560263, 0.0065146579804560263, 0.0065146579804560263, 0.0065146579804560263, 0.0081433224755700327, 0.0081433224755700327, 0.0081433224755700327, 0.0081433224755700327, 0.0081433224755700327, 0.0089576547231270363, 0.0097719869706840382, 0.0097719869706840382, 0.0097719869949530313, 0.010586319266779026]}
[2017-12-14 03:26:34,245 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:129]: evaluating model ... 
[2017-12-14 03:26:38,922 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:133]: evaluated! 
[2017-12-14 03:26:38,923 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:135]: generating reports ... 
[2017-12-14 03:26:40,481 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:138]: done!
[2017-12-14 03:26:40,481 AE_BIGRAMA_1L_MINIDS_OVER_F1_4.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_4 finished!
