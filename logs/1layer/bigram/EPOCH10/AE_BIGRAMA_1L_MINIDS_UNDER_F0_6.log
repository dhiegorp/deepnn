[2017-12-13 22:14:58,791 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_6
[2017-12-13 22:14:58,791 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:146]: >> Printing header log
[2017-12-13 22:14:58,791 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_UNDER_F0_6
	layers = 9216,5530
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 50, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f287519ceb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f287517f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-13 22:14:58,791 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:148]: >> Loading dataset... 
[2017-12-13 22:15:20,757 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-13 22:15:20,758 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:150]: >> Executing autoencoder part ... 
[2017-12-13 22:15:20,758 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:57]: =======================================
[2017-12-13 22:15:20,758 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f287519ceb8>, 'discard_decoder_function': True}
[2017-12-13 22:15:20,803 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:73]: training and evaluate autoencoder
[2017-12-14 00:29:55,090 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:85]: trained and evaluated!
[2017-12-14 00:29:55,092 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:88]: Training history: 
{'val_loss': [0.00011740032883022891, 0.0001173930685329068, 0.00011738580782441262, 0.00011737848106023445, 0.00011737117408594592, 0.00011736387912503212, 0.00011735658972387954, 0.00011734930800985664, 0.00011734200798973889, 0.00011733468612387126, 0.00011732739958304601, 0.00011732011361428621, 0.00011731283132819784, 0.00011730554201643049, 0.00011729824419518938, 0.0001172909235628379, 0.00011728363555609489, 0.00011727631336844043, 0.00011726902046338689, 0.00011726169230479917, 0.00011725440102655678, 0.00011724712258403324, 0.0001172397779249323, 0.00011723245795403151, 0.00011722514583115381, 0.00011721784997638772, 0.00011721061656614239, 0.00011720332355382658, 0.00011719600660414652, 0.00011718874907776649, 0.00011718147864415944, 0.00011717418327207358, 0.00011716692590658697, 0.00011715967206287837, 0.00011715237678017774, 0.0001171451280850583, 0.00011713777990417935, 0.00011713049565161594, 0.00011712320371192287, 0.00011711588021924408, 0.00011710855983717124, 0.00011710126961367457, 0.00011709396925389295, 0.00011708666104608827, 0.00011707937033991135, 0.00011707209491860854, 0.00011706482055205143, 0.00011705746999352538, 0.00011705014920028051, 0.00011704283371651819], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011816382478673849, 0.00011815641707978106, 0.00011814905101405336, 0.00011814167980538494, 0.00011813424207028972, 0.0001181268205224227, 0.00011811941608609116, 0.00011811202032402832, 0.00011810461659870241, 0.00011809720275339637, 0.00011808975970945912, 0.00011808235868595462, 0.0001180749536334182, 0.00011806755310761763, 0.00011806014990369587, 0.00011805272909053465, 0.00011804529389135952, 0.00011803789123254207, 0.0001180304512933294, 0.00011802304417887667, 0.0001180155981013154, 0.00011800819155566716, 0.00011800079645720957, 0.00011799333703644264, 0.00011798589920654668, 0.00011797847035902185, 0.00011797106132485391, 0.0001179637093133375, 0.00011795629634493841, 0.00011794887223745111, 0.00011794149275741719, 0.00011793411211607407, 0.00011792670770344273, 0.00011791933647107411, 0.00011791196192067924, 0.00011790454703256495, 0.00011789718231774793, 0.00011788972228077613, 0.00011788231964565887, 0.00011787491269710744, 0.00011786746851556119, 0.00011786003717951664, 0.00011785262222030179, 0.00011784520252104939, 0.00011783777369722475, 0.00011783035582288681, 0.00011782296084293016, 0.00011781555730720575, 0.00011780808150960916, 0.00011780063344123212], 'acc': [0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329]}
[2017-12-14 00:29:55,093 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:92]: done!
[2017-12-14 00:29:55,094 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:152]: >> Executing classifier part ... 
[2017-12-14 00:29:55,094 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:97]: =======================================
[2017-12-14 00:29:55,094 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f287517f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-14 00:29:55,768 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:110]: training ... 
[2017-12-14 01:38:03,197 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:122]: trained!
[2017-12-14 01:38:03,198 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:125]: Training history: 
{'val_loss': [0.00011740032883022891, 0.0001173930685329068, 0.00011738580782441262, 0.00011737848106023445, 0.00011737117408594592, 0.00011736387912503212, 0.00011735658972387954, 0.00011734930800985664, 0.00011734200798973889, 0.00011733468612387126, 0.00011732739958304601, 0.00011732011361428621, 0.00011731283132819784, 0.00011730554201643049, 0.00011729824419518938, 0.0001172909235628379, 0.00011728363555609489, 0.00011727631336844043, 0.00011726902046338689, 0.00011726169230479917, 0.00011725440102655678, 0.00011724712258403324, 0.0001172397779249323, 0.00011723245795403151, 0.00011722514583115381, 0.00011721784997638772, 0.00011721061656614239, 0.00011720332355382658, 0.00011719600660414652, 0.00011718874907776649, 0.00011718147864415944, 0.00011717418327207358, 0.00011716692590658697, 0.00011715967206287837, 0.00011715237678017774, 0.0001171451280850583, 0.00011713777990417935, 0.00011713049565161594, 0.00011712320371192287, 0.00011711588021924408, 0.00011710855983717124, 0.00011710126961367457, 0.00011709396925389295, 0.00011708666104608827, 0.00011707937033991135, 0.00011707209491860854, 0.00011706482055205143, 0.00011705746999352538, 0.00011705014920028051, 0.00011704283371651819], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011816382478673849, 0.00011815641707978106, 0.00011814905101405336, 0.00011814167980538494, 0.00011813424207028972, 0.0001181268205224227, 0.00011811941608609116, 0.00011811202032402832, 0.00011810461659870241, 0.00011809720275339637, 0.00011808975970945912, 0.00011808235868595462, 0.0001180749536334182, 0.00011806755310761763, 0.00011806014990369587, 0.00011805272909053465, 0.00011804529389135952, 0.00011803789123254207, 0.0001180304512933294, 0.00011802304417887667, 0.0001180155981013154, 0.00011800819155566716, 0.00011800079645720957, 0.00011799333703644264, 0.00011798589920654668, 0.00011797847035902185, 0.00011797106132485391, 0.0001179637093133375, 0.00011795629634493841, 0.00011794887223745111, 0.00011794149275741719, 0.00011793411211607407, 0.00011792670770344273, 0.00011791933647107411, 0.00011791196192067924, 0.00011790454703256495, 0.00011789718231774793, 0.00011788972228077613, 0.00011788231964565887, 0.00011787491269710744, 0.00011786746851556119, 0.00011786003717951664, 0.00011785262222030179, 0.00011784520252104939, 0.00011783777369722475, 0.00011783035582288681, 0.00011782296084293016, 0.00011781555730720575, 0.00011780808150960916, 0.00011780063344123212], 'acc': [0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329, 0.00081433224755700329]}
[2017-12-14 01:38:03,199 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:129]: evaluating model ... 
[2017-12-14 01:38:11,066 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:133]: evaluated! 
[2017-12-14 01:38:11,110 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:135]: generating reports ... 
[2017-12-14 01:38:15,139 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:138]: done!
[2017-12-14 01:38:15,140 AE_BIGRAMA_1L_MINIDS_UNDER_F0_6.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_UNDER_F0_6 finished!
