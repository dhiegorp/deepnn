[2018-01-18 00:19:28,515 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_5
[2018-01-18 00:19:28,516 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:146]: >> Printing header log
[2018-01-18 00:19:28,516 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_5
	layers = 9216,13824
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd8c14a4be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd8c14a4470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,516 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:148]: >> Loading dataset... 
[2018-01-18 00:21:57,185 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:21:57,186 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:21:57,186 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:57]: =======================================
[2018-01-18 00:21:57,186 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd8c14a4be0>, 'discard_decoder_function': True}
[2018-01-18 00:21:57,231 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:73]: training and evaluate autoencoder
[2018-01-20 12:17:54,429 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:85]: trained and evaluated!
[2018-01-20 12:17:54,431 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:88]: Training history: 
{'val_loss': [0.00011825555423505671, 0.00011820036965564889, 0.00011814506871974727, 0.00011808968092158652, 0.00011803426082683771, 0.00011797879954712046, 0.0001179233324220363, 0.00011786785177720141, 0.00011781237560864476, 0.00011775687865240179, 0.00011770142491871628, 0.00011764598549628587, 0.00011759053567733831, 0.00011753505768511274, 0.00011747947607533572, 0.00011742382474899606, 0.00011736817650845392, 0.00011731258322398709, 0.00011725703278236954, 0.00011720150082344918, 0.00011714609340881468, 0.00011709072885842147, 0.00011703541322620856, 0.0001169801999868545, 0.00011692504689113833, 0.00011686996032457521, 0.00011681493200845702, 0.00011675999514318424, 0.00011670511170445802, 0.00011665032111775392, 0.00011659564057690047, 0.0001165410201689889, 0.0001164864766011795, 0.00011643200825837546, 0.00011637761994843117, 0.00011632333318636133, 0.00011626912123750065, 0.00011621496024440929, 0.00011616094078086022, 0.00011610697054032761, 0.00011605308110811513, 0.00011599929810650352, 0.00011594561194117601, 0.00011589198617619051, 0.00011583842134634728, 0.00011578495981317535, 0.00011573158167675686, 0.00011567830935057092, 0.00011562509765469109, 0.00011557197985904191, 0.00011551894924118403, 0.00011546597526402228, 0.00011541309973289345, 0.00011536028902490481, 0.00011530757447400393, 0.00011525494852881107, 0.00011520236468309511, 0.00011514990004970637, 0.0001150975237225375, 0.00011504516445549711, 0.00011499293826815482, 0.00011494078105935079, 0.00011488871619985662, 0.00011483674006372655, 0.00011478479828316553, 0.00011473292731015967, 0.00011468113913493096, 0.00011462942432895068, 0.00011457778327727504, 0.00011452619795713509, 0.000114474721078445, 0.00011442331479873798, 0.00011437195634621872, 0.00011432068855838849, 0.00011426950310305916, 0.00011421838275966218, 0.0001141673363096179, 0.0001141163605013407, 0.00011406547692471733, 0.00011401463037766434, 0.00011396385922675281, 0.00011391315443920623, 0.00011386251789217357, 0.00011381196717523553, 0.00011376151030504811, 0.00011371111156230156, 0.00011366081386471722, 0.00011361059532826817, 0.00011356044102667905, 0.00011351035761821313, 0.00011346034270696525, 0.00011341044066531343, 0.00011336061935176172, 0.00011331087532754439, 0.00011326122111768366, 0.00011321163620189337, 0.00011316214907433165, 0.00011311270901454132, 0.00011306338270141948, 0.00011301414194029613, 0.00011296499860373719], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.00073502388827636903, 0.0014700477765527381, 0.002205071664829107, 0.0073502388827636897, 0.011392870268283719, 0.018743109151047408, 0.027563395810363836, 0.036383682469680267, 0.059536934950385888, 0.076074972436604188, 0.092613009922822495, 0.11576626240352811, 0.13708195516354282, 0.1565600882028666, 0.17714075707460492, 0.1988239617787578, 0.22124219037118706, 0.23851525174568172, 0.25431826534362367, 0.264976111723631, 0.27673649393605293, 0.29033443586916574, 0.29841969864020579, 0.30760749724366043, 0.31422271223814774, 0.32414553472987873, 0.33443586916574791, 0.34141859610437342, 0.34987137081955161, 0.35869165747886805, 0.36604189636163176, 0.37192208746784272, 0.37963983829474457, 0.38699007717750827, 0.39029768467475195, 0.39544285189268652, 0.39911797133406834, 0.40463065049614111, 0.40757074604924659, 0.41087835354649027, 0.41749356854097758, 0.4215361999264976, 0.42704887908857037, 0.43035648658581405, 0.43292907019478133, 0.43623667769202501, 0.44211686879823592, 0.44689452407203234, 0.45056964351341416, 0.45387725101065785, 0.45755237045203967, 0.46269753766997429, 0.46821021683204705, 0.47225284821756708, 0.4766629915472253, 0.47923557515619258, 0.48180815876515987, 0.48291069459757441, 0.48438074237412715, 0.48511576626240355, 0.48621830209481809, 0.48658581403895629, 0.48768834987137083, 0.48879088570378537, 0.48915839764792357, 0.48952590959206171, 0.49026093348033811, 0.49062844542447631, 0.49136346931275265, 0.49173098125689085, 0.49173098125689085, 0.49173098125689085, 0.49209849320102905, 0.49209849320102905, 0.49209849320102905, 0.49209849320102905, 0.49209849320102905, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359], 'loss': [0.00011840542408835924, 0.00011835077703032409, 0.0001182960158182565, 0.00011824112805971905, 0.00011818615953867721, 0.00011813116713031021, 0.00011807617574184545, 0.00011802111577254587, 0.00011796604213459143, 0.00011791097387211125, 0.00011785588020316952, 0.00011780083600305906, 0.00011774582346903784, 0.00011769076617988419, 0.00011763564608189943, 0.00011758043965928142, 0.00011752521482126559, 0.00011747001194419216, 0.0001174148720438497, 0.00011735979477282841, 0.00011730473323527285, 0.00011724978619201484, 0.00011719488657421124, 0.000117140042116865, 0.00011708530084736935, 0.00011703061948775325, 0.00011697601191833253, 0.00011692145274514885, 0.00011686698183905673, 0.00011681256825825824, 0.0001167582457863455, 0.00011670404103008527, 0.00011664990717310664, 0.00011659585743484307, 0.00011654187181735145, 0.0001164879756681497, 0.00011643417218983809, 0.00011638043994750084, 0.00011632676527605541, 0.00011627322912555387, 0.00011621972868502719, 0.0001161663188496867, 0.00011611301136269756, 0.0001160597947202412, 0.00011600663600144495, 0.00011595354004414636, 0.00011590054441861482, 0.00011584763604295183, 0.00011579483437389149, 0.0001157420902399996, 0.00011568943721945885, 0.00011563686964118407, 0.00011558436501374081, 0.00011553195559354703, 0.00011547961551063044, 0.0001154273682504283, 0.00011537521669581664, 0.00011532310319641918, 0.00011527111310697961, 0.00011521921250547778, 0.00011516732812238646, 0.00011511557923179023, 0.0001150639000178432, 0.00011501230675343403, 0.00011496080053080477, 0.00011490933372445013, 0.00011485793877833576, 0.000114806630499799, 0.00011475539834776612, 0.00011470423701731648, 0.00011465312613451847, 0.00011460212736148298, 0.00011455119095341571, 0.00011450029586478567, 0.00011444949329790067, 0.00011439877581426178, 0.00011434812025440746, 0.0001142975449122761, 0.00011424703801880308, 0.0001141966281857294, 0.00011414625342675457, 0.0001140959570966549, 0.0001140457305530538, 0.00011399556685490027, 0.00011394549122914591, 0.00011389549113063587, 0.00011384553998386129, 0.00011379568629312239, 0.00011374590772238138, 0.00011369619390382288, 0.00011364655194550464, 0.00011359697201724805, 0.00011354749672631781, 0.00011349809815043398, 0.0001134487701460698, 0.00011339953665592172, 0.0001133503636132899, 0.00011330129391033299, 0.0001132522631190581, 0.00011320335221720287, 0.00011315452596812711], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00049097827421136617, 0.0011047011169755738, 0.0024548913710568309, 0.0050325273106665031, 0.0089603535043574316, 0.012765435129495521, 0.018534429852393591, 0.026512826807413771, 0.039646495644396852, 0.054744077575481845, 0.073892230272468676, 0.096354486314895127, 0.11636185098809378, 0.13673744935689125, 0.15662206947525484, 0.17552473301958918, 0.19221799432448525, 0.21013870134783241, 0.23235546824126443, 0.24953970788987528, 0.26426905611621626, 0.2748250889934703, 0.28673131212846359, 0.29765557872966653, 0.30747514421023575, 0.31619000859577789, 0.32478212837618642, 0.33239229161183032, 0.34086166684197639, 0.35006750948343945, 0.35706394992753215, 0.36406039026919884, 0.37019761872610552, 0.3771940592067789, 0.38271756477336644, 0.38922302687008631, 0.39388732045680391, 0.39818338037444373, 0.40309316312021548, 0.40738922307077796, 0.411930772052362, 0.4161040873648682, 0.41917270163356035, 0.42371425061514439, 0.4265373757101501, 0.4309561801817105, 0.43598870747042856, 0.43991653371899059, 0.44335338162017979, 0.44838590889426555, 0.45280471338411626, 0.45611881671309457, 0.46004664293970815, 0.46532465936187384, 0.46839327356837873, 0.47158463242391407, 0.47514422483878499, 0.47723088253710599, 0.47968577384597555, 0.48079047501416416, 0.48312262184959082, 0.48435006750219656, 0.48606849149485898, 0.48680495887325337, 0.48766417084946523, 0.48803240459170444, 0.48876887197009883, 0.48950533939604818, 0.48999631767025958, 0.49085552963549717, 0.49110101880552548, 0.49122376331920725, 0.49159199705778844, 0.49159199707973689, 0.49183748621684253, 0.49196023078539541, 0.4922057198895784, 0.49232846447276357, 0.49257395359157885, 0.49269669821500278, 0.4926966981784221, 0.49269669819671247, 0.49294218733381812, 0.49294218724968242, 0.49294218737405693, 0.49294218731552775, 0.49306493190237094, 0.49306493192066131, 0.49306493186944833, 0.49306493192066131, 0.49306493192066131, 0.49306493190602901, 0.49306493190237094, 0.49306493188408063, 0.49306493186944833]}
[2018-01-20 12:17:54,431 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:92]: done!
[2018-01-20 12:17:54,431 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:152]: >> Executing classifier part ... 
[2018-01-20 12:17:54,432 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:97]: =======================================
[2018-01-20 12:17:54,432 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd8c14a4470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-20 12:17:54,673 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:110]: training ... 
[2018-01-24 06:18:46,821 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:122]: trained!
[2018-01-24 06:18:46,823 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:125]: Training history: 
{'val_loss': [0.00011825555423505671, 0.00011820036965564889, 0.00011814506871974727, 0.00011808968092158652, 0.00011803426082683771, 0.00011797879954712046, 0.0001179233324220363, 0.00011786785177720141, 0.00011781237560864476, 0.00011775687865240179, 0.00011770142491871628, 0.00011764598549628587, 0.00011759053567733831, 0.00011753505768511274, 0.00011747947607533572, 0.00011742382474899606, 0.00011736817650845392, 0.00011731258322398709, 0.00011725703278236954, 0.00011720150082344918, 0.00011714609340881468, 0.00011709072885842147, 0.00011703541322620856, 0.0001169801999868545, 0.00011692504689113833, 0.00011686996032457521, 0.00011681493200845702, 0.00011675999514318424, 0.00011670511170445802, 0.00011665032111775392, 0.00011659564057690047, 0.0001165410201689889, 0.0001164864766011795, 0.00011643200825837546, 0.00011637761994843117, 0.00011632333318636133, 0.00011626912123750065, 0.00011621496024440929, 0.00011616094078086022, 0.00011610697054032761, 0.00011605308110811513, 0.00011599929810650352, 0.00011594561194117601, 0.00011589198617619051, 0.00011583842134634728, 0.00011578495981317535, 0.00011573158167675686, 0.00011567830935057092, 0.00011562509765469109, 0.00011557197985904191, 0.00011551894924118403, 0.00011546597526402228, 0.00011541309973289345, 0.00011536028902490481, 0.00011530757447400393, 0.00011525494852881107, 0.00011520236468309511, 0.00011514990004970637, 0.0001150975237225375, 0.00011504516445549711, 0.00011499293826815482, 0.00011494078105935079, 0.00011488871619985662, 0.00011483674006372655, 0.00011478479828316553, 0.00011473292731015967, 0.00011468113913493096, 0.00011462942432895068, 0.00011457778327727504, 0.00011452619795713509, 0.000114474721078445, 0.00011442331479873798, 0.00011437195634621872, 0.00011432068855838849, 0.00011426950310305916, 0.00011421838275966218, 0.0001141673363096179, 0.0001141163605013407, 0.00011406547692471733, 0.00011401463037766434, 0.00011396385922675281, 0.00011391315443920623, 0.00011386251789217357, 0.00011381196717523553, 0.00011376151030504811, 0.00011371111156230156, 0.00011366081386471722, 0.00011361059532826817, 0.00011356044102667905, 0.00011351035761821313, 0.00011346034270696525, 0.00011341044066531343, 0.00011336061935176172, 0.00011331087532754439, 0.00011326122111768366, 0.00011321163620189337, 0.00011316214907433165, 0.00011311270901454132, 0.00011306338270141948, 0.00011301414194029613, 0.00011296499860373719], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.00073502388827636903, 0.0014700477765527381, 0.002205071664829107, 0.0073502388827636897, 0.011392870268283719, 0.018743109151047408, 0.027563395810363836, 0.036383682469680267, 0.059536934950385888, 0.076074972436604188, 0.092613009922822495, 0.11576626240352811, 0.13708195516354282, 0.1565600882028666, 0.17714075707460492, 0.1988239617787578, 0.22124219037118706, 0.23851525174568172, 0.25431826534362367, 0.264976111723631, 0.27673649393605293, 0.29033443586916574, 0.29841969864020579, 0.30760749724366043, 0.31422271223814774, 0.32414553472987873, 0.33443586916574791, 0.34141859610437342, 0.34987137081955161, 0.35869165747886805, 0.36604189636163176, 0.37192208746784272, 0.37963983829474457, 0.38699007717750827, 0.39029768467475195, 0.39544285189268652, 0.39911797133406834, 0.40463065049614111, 0.40757074604924659, 0.41087835354649027, 0.41749356854097758, 0.4215361999264976, 0.42704887908857037, 0.43035648658581405, 0.43292907019478133, 0.43623667769202501, 0.44211686879823592, 0.44689452407203234, 0.45056964351341416, 0.45387725101065785, 0.45755237045203967, 0.46269753766997429, 0.46821021683204705, 0.47225284821756708, 0.4766629915472253, 0.47923557515619258, 0.48180815876515987, 0.48291069459757441, 0.48438074237412715, 0.48511576626240355, 0.48621830209481809, 0.48658581403895629, 0.48768834987137083, 0.48879088570378537, 0.48915839764792357, 0.48952590959206171, 0.49026093348033811, 0.49062844542447631, 0.49136346931275265, 0.49173098125689085, 0.49173098125689085, 0.49173098125689085, 0.49209849320102905, 0.49209849320102905, 0.49209849320102905, 0.49209849320102905, 0.49209849320102905, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359], 'loss': [0.00011840542408835924, 0.00011835077703032409, 0.0001182960158182565, 0.00011824112805971905, 0.00011818615953867721, 0.00011813116713031021, 0.00011807617574184545, 0.00011802111577254587, 0.00011796604213459143, 0.00011791097387211125, 0.00011785588020316952, 0.00011780083600305906, 0.00011774582346903784, 0.00011769076617988419, 0.00011763564608189943, 0.00011758043965928142, 0.00011752521482126559, 0.00011747001194419216, 0.0001174148720438497, 0.00011735979477282841, 0.00011730473323527285, 0.00011724978619201484, 0.00011719488657421124, 0.000117140042116865, 0.00011708530084736935, 0.00011703061948775325, 0.00011697601191833253, 0.00011692145274514885, 0.00011686698183905673, 0.00011681256825825824, 0.0001167582457863455, 0.00011670404103008527, 0.00011664990717310664, 0.00011659585743484307, 0.00011654187181735145, 0.0001164879756681497, 0.00011643417218983809, 0.00011638043994750084, 0.00011632676527605541, 0.00011627322912555387, 0.00011621972868502719, 0.0001161663188496867, 0.00011611301136269756, 0.0001160597947202412, 0.00011600663600144495, 0.00011595354004414636, 0.00011590054441861482, 0.00011584763604295183, 0.00011579483437389149, 0.0001157420902399996, 0.00011568943721945885, 0.00011563686964118407, 0.00011558436501374081, 0.00011553195559354703, 0.00011547961551063044, 0.0001154273682504283, 0.00011537521669581664, 0.00011532310319641918, 0.00011527111310697961, 0.00011521921250547778, 0.00011516732812238646, 0.00011511557923179023, 0.0001150639000178432, 0.00011501230675343403, 0.00011496080053080477, 0.00011490933372445013, 0.00011485793877833576, 0.000114806630499799, 0.00011475539834776612, 0.00011470423701731648, 0.00011465312613451847, 0.00011460212736148298, 0.00011455119095341571, 0.00011450029586478567, 0.00011444949329790067, 0.00011439877581426178, 0.00011434812025440746, 0.0001142975449122761, 0.00011424703801880308, 0.0001141966281857294, 0.00011414625342675457, 0.0001140959570966549, 0.0001140457305530538, 0.00011399556685490027, 0.00011394549122914591, 0.00011389549113063587, 0.00011384553998386129, 0.00011379568629312239, 0.00011374590772238138, 0.00011369619390382288, 0.00011364655194550464, 0.00011359697201724805, 0.00011354749672631781, 0.00011349809815043398, 0.0001134487701460698, 0.00011339953665592172, 0.0001133503636132899, 0.00011330129391033299, 0.0001132522631190581, 0.00011320335221720287, 0.00011315452596812711], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00049097827421136617, 0.0011047011169755738, 0.0024548913710568309, 0.0050325273106665031, 0.0089603535043574316, 0.012765435129495521, 0.018534429852393591, 0.026512826807413771, 0.039646495644396852, 0.054744077575481845, 0.073892230272468676, 0.096354486314895127, 0.11636185098809378, 0.13673744935689125, 0.15662206947525484, 0.17552473301958918, 0.19221799432448525, 0.21013870134783241, 0.23235546824126443, 0.24953970788987528, 0.26426905611621626, 0.2748250889934703, 0.28673131212846359, 0.29765557872966653, 0.30747514421023575, 0.31619000859577789, 0.32478212837618642, 0.33239229161183032, 0.34086166684197639, 0.35006750948343945, 0.35706394992753215, 0.36406039026919884, 0.37019761872610552, 0.3771940592067789, 0.38271756477336644, 0.38922302687008631, 0.39388732045680391, 0.39818338037444373, 0.40309316312021548, 0.40738922307077796, 0.411930772052362, 0.4161040873648682, 0.41917270163356035, 0.42371425061514439, 0.4265373757101501, 0.4309561801817105, 0.43598870747042856, 0.43991653371899059, 0.44335338162017979, 0.44838590889426555, 0.45280471338411626, 0.45611881671309457, 0.46004664293970815, 0.46532465936187384, 0.46839327356837873, 0.47158463242391407, 0.47514422483878499, 0.47723088253710599, 0.47968577384597555, 0.48079047501416416, 0.48312262184959082, 0.48435006750219656, 0.48606849149485898, 0.48680495887325337, 0.48766417084946523, 0.48803240459170444, 0.48876887197009883, 0.48950533939604818, 0.48999631767025958, 0.49085552963549717, 0.49110101880552548, 0.49122376331920725, 0.49159199705778844, 0.49159199707973689, 0.49183748621684253, 0.49196023078539541, 0.4922057198895784, 0.49232846447276357, 0.49257395359157885, 0.49269669821500278, 0.4926966981784221, 0.49269669819671247, 0.49294218733381812, 0.49294218724968242, 0.49294218737405693, 0.49294218731552775, 0.49306493190237094, 0.49306493192066131, 0.49306493186944833, 0.49306493192066131, 0.49306493192066131, 0.49306493190602901, 0.49306493190237094, 0.49306493188408063, 0.49306493186944833]}
[2018-01-24 06:18:46,824 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:129]: evaluating model ... 
[2018-01-24 06:19:15,750 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:133]: evaluated! 
[2018-01-24 06:19:15,752 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:135]: generating reports ... 
[2018-01-24 06:19:18,008 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:138]: done!
[2018-01-24 06:19:18,008 AE_BIGRAMA_1L_FULLDS_OVER_F1_5.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_5 finished!
