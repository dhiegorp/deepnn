[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6
[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:146]: >> Printing header log
[2018-01-18 00:19:28,523 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_6
	layers = 9216,14746
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,523 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:148]: >> Loading dataset... 
[2018-01-18 00:22:02,837 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:22:02,837 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:22:02,837 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:57]: =======================================
[2018-01-18 00:22:02,838 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843be0>, 'discard_decoder_function': True}
[2018-01-18 00:22:02,880 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:73]: training and evaluate autoencoder
[2018-01-20 15:59:56,043 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:85]: trained and evaluated!
[2018-01-20 15:59:56,044 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:88]: Training history: 
{'val_loss': [0.00011881631711228021, 0.00011878693500385326, 0.00011875619542795599, 0.00011872395244294395, 0.00011869031339392644, 0.00011865539354907872, 0.00011861904240223603, 0.00011858128412369637, 0.00011854227144171962, 0.00011850202833942367, 0.0001184603467393952, 0.00011841738325789196, 0.00011837322736432443, 0.00011832790441089918, 0.00011828159106353597, 0.00011823408318095139, 0.00011818553901856608, 0.00011813605055132968, 0.00011808557264209981, 0.00011803426534055195, 0.00011798230571905407, 0.00011792938165747513, 0.00011787568825897403, 0.0001178214441953574, 0.00011776668522871901, 0.00011771150414957892, 0.0001176559396694544, 0.00011759999909104306, 0.00011754373109721309, 0.00011748718235196165, 0.00011743043348445081, 0.00011737350365924809, 0.00011731645669941716, 0.00011725931354773648, 0.00011720215376644152, 0.00011714495737004637, 0.00011708770417786302, 0.00011703043849541947, 0.00011697316506639406, 0.00011691589648265905, 0.0001168585987817236, 0.00011680130511585613, 0.00011674402411405897, 0.00011668678513954068, 0.00011662964972641983, 0.00011657252150101454, 0.00011651546544423111, 0.00011645846827163093, 0.00011640156431204304, 0.00011634472505526531, 0.0001162879786478357, 0.00011623131347924043, 0.00011617475587502258, 0.00011611825568161327, 0.00011606183139775366, 0.00011600550593428714, 0.00011594927320251268, 0.00011589312425522183, 0.00011583708169842183, 0.00011578113784970686, 0.00011572529066881392, 0.00011566951112143656, 0.0001156138323839093, 0.00011555824853866715, 0.00011550277324183493, 0.00011544735278876995, 0.00011539205651900066, 0.00011533685456393221, 0.00011528174315857076, 0.00011522672837022528, 0.00011517184915374714, 0.0001151170546683491, 0.0001150623846764309, 0.0001150077815211759, 0.00011495327527707703, 0.00011489886512588991, 0.00011484455403308197, 0.00011479033255942857, 0.0001147362184736685, 0.00011468219106566149, 0.00011462831473338152, 0.00011457450866048644, 0.00011452079386462673, 0.00011446721235436319, 0.00011441368722274368, 0.00011436026819549687, 0.00011430695376716002, 0.00011425374776422903, 0.00011420062861553517, 0.00011414761656059451, 0.00011409467217125747, 0.00011404184395925613, 0.00011398910481823905, 0.00011393643742602559, 0.0001138838748519902, 0.00011383140854467663, 0.00011377903245549388, 0.00011372673356205548, 0.00011367454497651985, 0.00011362247082219708, 0.00011357048224393882], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.0011025358324145535, 0.0014700477765527381, 0.0025725836089672913, 0.0033076074972436605, 0.0036751194413818448, 0.0051451672179345827, 0.006615214994487321, 0.010657846380007351, 0.016905549430356485, 0.022418228592429253, 0.030871003307607496, 0.038221242190371187, 0.046306504961411248, 0.060639470782800443, 0.071664829106945979, 0.087835354649026087, 0.1018008085262771, 0.12238147739801543, 0.13928702682837193, 0.15545755237045203, 0.16648291069459759, 0.18118338846012497, 0.1988239617787578, 0.22050716648291069, 0.23778022785740535, 0.25284821756707093, 0.26828371922087468, 0.27820654171260567, 0.28629180448364572, 0.30062477030503493, 0.31128261668504226, 0.32267548695332599, 0.33112826166850423, 0.336640940830577, 0.3439911797133407, 0.35023888276368981, 0.35501653803748623, 0.36089672914369719, 0.36530687247335536, 0.37008452774715178, 0.37596471885336274, 0.37963983829474457, 0.38221242190371185, 0.38809261300992282, 0.39360529217199558, 0.3980154355016538, 0.40132304299889748, 0.40463065049614111, 0.40720323410510839, 0.41161337743476661, 0.41639103270856304, 0.42374127159132674, 0.42778390297684676, 0.42998897464167585, 0.43366409408305767, 0.43770672546857775, 0.44174935685409777, 0.4454244762954796, 0.44799705990444688, 0.44983461962513782, 0.45350973906651965, 0.45534729878721059], 'loss': [0.00011894635547869605, 0.00011891733849175452, 0.00011888728734804918, 0.00011885581693534991, 0.00011882306809036814, 0.00011878894310432534, 0.00011875345987909584, 0.00011871675839849559, 0.00011867888733651083, 0.00011863973338575302, 0.00011859920439332092, 0.00011855722777111056, 0.00011851390745984258, 0.00011846941255341495, 0.00011842382160930694, 0.00011837711792773565, 0.00011832920885477954, 0.00011828018637633309, 0.00011823027370184305, 0.00011817940304264034, 0.00011812777280632822, 0.00011807526476998228, 0.00011802187855582785, 0.00011796782567747998, 0.00011791327467958978, 0.0001178582429942693, 0.00011780279517186399, 0.0001177469185019984, 0.00011769077737737487, 0.00011763441150005498, 0.00011757787003254208, 0.00011752119831583187, 0.00011746442023457031, 0.00011740759773040368, 0.00011735066045508337, 0.00011729371938951338, 0.00011723677668513374, 0.00011717979976490924, 0.00011712280944395514, 0.00011706583613447037, 0.00011700887366167025, 0.00011695194922354334, 0.00011689508901871698, 0.00011683825525543685, 0.00011678145034503049, 0.00011672472454492257, 0.00011666800763636173, 0.00011661134756904285, 0.00011655474825288893, 0.00011649824094049115, 0.00011644179161069706, 0.00011638544023260042, 0.00011632917396722167, 0.00011627301903104977, 0.00011621692767801306, 0.0001161609017844816, 0.00011610496574505245, 0.00011604911631693661, 0.00011599334742001628, 0.00011593768495820098, 0.00011588211581833424, 0.00011582664140255837, 0.00011577123584804578, 0.00011571594295075638, 0.00011566073860366623, 0.00011560564212686754, 0.00011555060215819038, 0.00011549568413302672, 0.00011544085879393563, 0.0001153861273840904, 0.00011533149258363698, 0.00011527700461427663, 0.00011522259551676122, 0.00011516831362123955, 0.00011511410029315643, 0.00011505997974759897, 0.00011500595676435421, 0.00011495203404500212, 0.00011489821207448744, 0.00011484448169780325, 0.00011479084497082956, 0.00011473735305211305, 0.00011468393849414289, 0.00011463060850589536, 0.00011457741356717314, 0.00011452426864474282, 0.00011447123025208446, 0.00011441829167588352, 0.00011436546029569541, 0.0001143127205932877, 0.00011426008398406366, 0.00011420751791599439, 0.00011415506709955815, 0.00011410269889163147, 0.00011405040304228609, 0.00011399821695389157, 0.000113946115639736, 0.00011389411775813609, 0.00011384219183858808, 0.0001137903769758562, 0.00011373867767733686], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.0003682337056585246, 0.00049097827421136617, 0.0011047011169755738, 0.0020866576653983063, 0.0044188044679022952, 0.0069964404075119674, 0.010187799190800366, 0.015220326500552351, 0.020130109243580531, 0.026021848533202406, 0.033877500921498785, 0.043819810973364431, 0.054375843868908799, 0.066282067020363461, 0.080397692402111212, 0.094022339513305658, 0.11145206823134782, 0.12716337302165834, 0.14459310174061504, 0.16140910764790115, 0.17969804836136, 0.19369092919833239, 0.21161163618875689, 0.23075978890129054, 0.24389345769986384, 0.25395851232485495, 0.26647845829895439, 0.27740272495137031, 0.28930894804978291, 0.30109242670401715, 0.30968454646247728, 0.31901313365786094, 0.32821897629566599, 0.33570639501397004, 0.34245734623316332, 0.34957653122751847, 0.35694120534068896, 0.36185098810109301, 0.36761998280478619, 0.37105683077913687, 0.37645759177351346, 0.38161286365273278, 0.3872591138281119, 0.392782619372751, 0.39744691296312668, 0.40100650548773981, 0.40554805452053688, 0.41008960355699203, 0.41450840799197164, 0.41929544614724212, 0.42334601692777624, 0.42788756594594102, 0.43120166931515808, 0.43451577261852986, 0.43746164234793378, 0.44065300113030764, 0.44384435989439114, 0.44629925125081565, 0.44863139806795194, 0.45071805569676954, 0.45292745794901107]}
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:92]: done!
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:152]: >> Executing classifier part ... 
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:97]: =======================================
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-20 15:59:56,187 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:110]: training ... 
[2018-01-24 10:20:45,708 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:122]: trained!
[2018-01-24 10:20:45,710 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:125]: Training history: 
{'val_loss': [0.00011881631711228021, 0.00011878693500385326, 0.00011875619542795599, 0.00011872395244294395, 0.00011869031339392644, 0.00011865539354907872, 0.00011861904240223603, 0.00011858128412369637, 0.00011854227144171962, 0.00011850202833942367, 0.0001184603467393952, 0.00011841738325789196, 0.00011837322736432443, 0.00011832790441089918, 0.00011828159106353597, 0.00011823408318095139, 0.00011818553901856608, 0.00011813605055132968, 0.00011808557264209981, 0.00011803426534055195, 0.00011798230571905407, 0.00011792938165747513, 0.00011787568825897403, 0.0001178214441953574, 0.00011776668522871901, 0.00011771150414957892, 0.0001176559396694544, 0.00011759999909104306, 0.00011754373109721309, 0.00011748718235196165, 0.00011743043348445081, 0.00011737350365924809, 0.00011731645669941716, 0.00011725931354773648, 0.00011720215376644152, 0.00011714495737004637, 0.00011708770417786302, 0.00011703043849541947, 0.00011697316506639406, 0.00011691589648265905, 0.0001168585987817236, 0.00011680130511585613, 0.00011674402411405897, 0.00011668678513954068, 0.00011662964972641983, 0.00011657252150101454, 0.00011651546544423111, 0.00011645846827163093, 0.00011640156431204304, 0.00011634472505526531, 0.0001162879786478357, 0.00011623131347924043, 0.00011617475587502258, 0.00011611825568161327, 0.00011606183139775366, 0.00011600550593428714, 0.00011594927320251268, 0.00011589312425522183, 0.00011583708169842183, 0.00011578113784970686, 0.00011572529066881392, 0.00011566951112143656, 0.0001156138323839093, 0.00011555824853866715, 0.00011550277324183493, 0.00011544735278876995, 0.00011539205651900066, 0.00011533685456393221, 0.00011528174315857076, 0.00011522672837022528, 0.00011517184915374714, 0.0001151170546683491, 0.0001150623846764309, 0.0001150077815211759, 0.00011495327527707703, 0.00011489886512588991, 0.00011484455403308197, 0.00011479033255942857, 0.0001147362184736685, 0.00011468219106566149, 0.00011462831473338152, 0.00011457450866048644, 0.00011452079386462673, 0.00011446721235436319, 0.00011441368722274368, 0.00011436026819549687, 0.00011430695376716002, 0.00011425374776422903, 0.00011420062861553517, 0.00011414761656059451, 0.00011409467217125747, 0.00011404184395925613, 0.00011398910481823905, 0.00011393643742602559, 0.0001138838748519902, 0.00011383140854467663, 0.00011377903245549388, 0.00011372673356205548, 0.00011367454497651985, 0.00011362247082219708, 0.00011357048224393882], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.0011025358324145535, 0.0014700477765527381, 0.0025725836089672913, 0.0033076074972436605, 0.0036751194413818448, 0.0051451672179345827, 0.006615214994487321, 0.010657846380007351, 0.016905549430356485, 0.022418228592429253, 0.030871003307607496, 0.038221242190371187, 0.046306504961411248, 0.060639470782800443, 0.071664829106945979, 0.087835354649026087, 0.1018008085262771, 0.12238147739801543, 0.13928702682837193, 0.15545755237045203, 0.16648291069459759, 0.18118338846012497, 0.1988239617787578, 0.22050716648291069, 0.23778022785740535, 0.25284821756707093, 0.26828371922087468, 0.27820654171260567, 0.28629180448364572, 0.30062477030503493, 0.31128261668504226, 0.32267548695332599, 0.33112826166850423, 0.336640940830577, 0.3439911797133407, 0.35023888276368981, 0.35501653803748623, 0.36089672914369719, 0.36530687247335536, 0.37008452774715178, 0.37596471885336274, 0.37963983829474457, 0.38221242190371185, 0.38809261300992282, 0.39360529217199558, 0.3980154355016538, 0.40132304299889748, 0.40463065049614111, 0.40720323410510839, 0.41161337743476661, 0.41639103270856304, 0.42374127159132674, 0.42778390297684676, 0.42998897464167585, 0.43366409408305767, 0.43770672546857775, 0.44174935685409777, 0.4454244762954796, 0.44799705990444688, 0.44983461962513782, 0.45350973906651965, 0.45534729878721059], 'loss': [0.00011894635547869605, 0.00011891733849175452, 0.00011888728734804918, 0.00011885581693534991, 0.00011882306809036814, 0.00011878894310432534, 0.00011875345987909584, 0.00011871675839849559, 0.00011867888733651083, 0.00011863973338575302, 0.00011859920439332092, 0.00011855722777111056, 0.00011851390745984258, 0.00011846941255341495, 0.00011842382160930694, 0.00011837711792773565, 0.00011832920885477954, 0.00011828018637633309, 0.00011823027370184305, 0.00011817940304264034, 0.00011812777280632822, 0.00011807526476998228, 0.00011802187855582785, 0.00011796782567747998, 0.00011791327467958978, 0.0001178582429942693, 0.00011780279517186399, 0.0001177469185019984, 0.00011769077737737487, 0.00011763441150005498, 0.00011757787003254208, 0.00011752119831583187, 0.00011746442023457031, 0.00011740759773040368, 0.00011735066045508337, 0.00011729371938951338, 0.00011723677668513374, 0.00011717979976490924, 0.00011712280944395514, 0.00011706583613447037, 0.00011700887366167025, 0.00011695194922354334, 0.00011689508901871698, 0.00011683825525543685, 0.00011678145034503049, 0.00011672472454492257, 0.00011666800763636173, 0.00011661134756904285, 0.00011655474825288893, 0.00011649824094049115, 0.00011644179161069706, 0.00011638544023260042, 0.00011632917396722167, 0.00011627301903104977, 0.00011621692767801306, 0.0001161609017844816, 0.00011610496574505245, 0.00011604911631693661, 0.00011599334742001628, 0.00011593768495820098, 0.00011588211581833424, 0.00011582664140255837, 0.00011577123584804578, 0.00011571594295075638, 0.00011566073860366623, 0.00011560564212686754, 0.00011555060215819038, 0.00011549568413302672, 0.00011544085879393563, 0.0001153861273840904, 0.00011533149258363698, 0.00011527700461427663, 0.00011522259551676122, 0.00011516831362123955, 0.00011511410029315643, 0.00011505997974759897, 0.00011500595676435421, 0.00011495203404500212, 0.00011489821207448744, 0.00011484448169780325, 0.00011479084497082956, 0.00011473735305211305, 0.00011468393849414289, 0.00011463060850589536, 0.00011457741356717314, 0.00011452426864474282, 0.00011447123025208446, 0.00011441829167588352, 0.00011436546029569541, 0.0001143127205932877, 0.00011426008398406366, 0.00011420751791599439, 0.00011415506709955815, 0.00011410269889163147, 0.00011405040304228609, 0.00011399821695389157, 0.000113946115639736, 0.00011389411775813609, 0.00011384219183858808, 0.0001137903769758562, 0.00011373867767733686], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.0003682337056585246, 0.00049097827421136617, 0.0011047011169755738, 0.0020866576653983063, 0.0044188044679022952, 0.0069964404075119674, 0.010187799190800366, 0.015220326500552351, 0.020130109243580531, 0.026021848533202406, 0.033877500921498785, 0.043819810973364431, 0.054375843868908799, 0.066282067020363461, 0.080397692402111212, 0.094022339513305658, 0.11145206823134782, 0.12716337302165834, 0.14459310174061504, 0.16140910764790115, 0.17969804836136, 0.19369092919833239, 0.21161163618875689, 0.23075978890129054, 0.24389345769986384, 0.25395851232485495, 0.26647845829895439, 0.27740272495137031, 0.28930894804978291, 0.30109242670401715, 0.30968454646247728, 0.31901313365786094, 0.32821897629566599, 0.33570639501397004, 0.34245734623316332, 0.34957653122751847, 0.35694120534068896, 0.36185098810109301, 0.36761998280478619, 0.37105683077913687, 0.37645759177351346, 0.38161286365273278, 0.3872591138281119, 0.392782619372751, 0.39744691296312668, 0.40100650548773981, 0.40554805452053688, 0.41008960355699203, 0.41450840799197164, 0.41929544614724212, 0.42334601692777624, 0.42788756594594102, 0.43120166931515808, 0.43451577261852986, 0.43746164234793378, 0.44065300113030764, 0.44384435989439114, 0.44629925125081565, 0.44863139806795194, 0.45071805569676954, 0.45292745794901107]}
[2018-01-24 10:20:45,710 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:129]: evaluating model ... 
[2018-01-24 10:21:01,188 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:133]: evaluated! 
[2018-01-24 10:21:01,189 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:135]: generating reports ... 
[2018-01-24 10:21:02,585 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:138]: done!
[2018-01-24 10:21:02,586 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6 finished!
[2018-05-03 21:43:55,263 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6
[2018-05-03 21:43:55,264 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:146]: >> Printing header log
[2018-05-03 21:43:55,264 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_6
	layers = 9216,14746
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9af0962630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9af0962e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-05-03 21:43:55,264 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:148]: >> Loading dataset... 
[2018-05-03 21:46:31,392 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-03 21:46:31,393 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:150]: >> Executing autoencoder part ... 
[2018-05-03 21:46:31,394 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:57]: =======================================
[2018-05-03 21:46:31,394 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9af0962630>, 'discard_decoder_function': True}
[2018-05-03 21:46:31,543 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:73]: training and evaluate autoencoder
[2018-05-06 02:23:43,789 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6
[2018-05-06 02:23:43,790 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:146]: >> Printing header log
[2018-05-06 02:23:43,790 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_6
	layers = 9216,14746
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9c94a0b630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9c94a0be10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-05-06 02:23:43,790 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:148]: >> Loading dataset... 
[2018-05-06 02:28:54,657 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-06 02:28:54,657 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:150]: >> Executing autoencoder part ... 
[2018-05-06 02:28:54,657 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:57]: =======================================
[2018-05-06 02:28:54,658 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f9c94a0b630>, 'discard_decoder_function': True}
[2018-05-06 02:28:54,879 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:73]: training and evaluate autoencoder
[2018-05-06 05:28:34,700 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:85]: trained and evaluated!
[2018-05-06 05:28:34,702 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:88]: Training history: 
{'val_loss': [0.00011922769037806349, 0.00011920508724805985, 0.000119182485735827, 0.00011915988348022179, 0.0001191372891022245, 0.00011911467968564373, 0.00011909207685780223, 0.00011906947975499759, 0.00011904688121625422, 0.00011902429680960789, 0.00011900169754888415, 0.00011897908382181325, 0.00011895647776645215, 0.00011893386397253122, 0.00011891125810702421, 0.0001188886622823922, 0.00011886607347433967, 0.00011884349254924305, 0.00011882093634796272, 0.00011879837402321935, 0.00011877581236162831, 0.00011875326939665454, 0.00011873074822479161, 0.0001187082286974395, 0.00011868573366661355, 0.00011866325607295026, 0.00011864078722861933, 0.00011861834191817408, 0.00011859591184151439, 0.00011857349134312747, 0.00011855108561057588, 0.00011852869986618421, 0.00011850633476240881, 0.00011848399444662571, 0.00011846167134873717, 0.00011843937548555215, 0.0001184171119644132, 0.00011839486348987973, 0.00011837263635922486, 0.00011835043498455077, 0.00011832825345096655, 0.00011830609728028493, 0.0001182839632530083, 0.00011826185626790711, 0.0001182397663589784, 0.00011821769508249094, 0.00011819565026257262, 0.00011817363764565231, 0.0001181516462014745, 0.00011812969264254752, 0.00011810774085915743, 0.00011808581946311842, 0.00011806393436129944, 0.00011804207863071105, 0.00011802024059666345, 0.0001179984352629781, 0.00011797664362017954, 0.00011795488631155804, 0.00011793315630716411, 0.00011791144171303983, 0.0001178897634692896, 0.00011786809971327857, 0.00011784647422490056, 0.00011782488576341893, 0.0001178033196458924, 0.00011778177545785077, 0.00011776024650894269, 0.00011773874478136815, 0.00011771725861380734, 0.00011769581722507276, 0.0001176743985947635, 0.00011765300469629252, 0.00011763162913879664, 0.00011761028444729811, 0.00011758895468207498, 0.0001175676546089626, 0.0001175463868992883, 0.00011752513302489687, 0.00011750391466659109, 0.00011748270412439118, 0.00011746152421555049, 0.00011744036598483857, 0.0001174192376574835, 0.00011739812665230905, 0.00011737704783943658, 0.00011735598339397324, 0.00011733494136466304, 0.0001173139320517591, 0.00011729292655732905, 0.00011727194309666994, 0.0001172509846967513, 0.00011723004883598983, 0.00011720913535929348, 0.00011718823423380927, 0.0001171673523076546, 0.00011714648568480954, 0.00011712564591695981, 0.00011710480986062392, 0.00011708399671780542, 0.00011706318370333897, 0.00011704237743805189], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011934511291037886, 0.00011932243217509479, 0.00011929975589719435, 0.00011927708508050426, 0.00011925442063418434, 0.00011923175581812751, 0.00011920906406664887, 0.00011918638550513192, 0.00011916370990329627, 0.00011914102532685672, 0.00011911834375653885, 0.0001190956413657472, 0.00011907293647253339, 0.00011905022414975149, 0.00011902750387494716, 0.00011900478081639914, 0.0001189820718471487, 0.00011895937338235552, 0.00011893668273919447, 0.00011891401305940067, 0.00011889134574181479, 0.00011886867495459649, 0.0001188460262471008, 0.00011882338185588141, 0.00011880073989920979, 0.00011877811783688353, 0.00011875551308342367, 0.00011873291487805774, 0.00011871035090639836, 0.00011868779711768591, 0.00011866525558744828, 0.00011864273207607903, 0.00011862022843851424, 0.00011859774599383935, 0.00011857528339171096, 0.00011855283763404515, 0.00011853041510103599, 0.00011850802213983343, 0.00011848563472736351, 0.00011846326698328865, 0.0001184409243625676, 0.00011841859980536918, 0.00011839629892830039, 0.00011837402374973169, 0.00011835176625155246, 0.00011832953096795156, 0.00011830731724876364, 0.00011828513377208863, 0.00011826298426566032, 0.00011824085791690733, 0.00011821876769073414, 0.00011819669238799925, 0.00011817464237919728, 0.00011815263138835432, 0.00011813065714792942, 0.00011810870069327792, 0.00011808676958882367, 0.00011806486848842881, 0.00011804299255872125, 0.00011802114621689584, 0.00011799931787429096, 0.00011797752776105168, 0.00011795574953565723, 0.00011793401038091379, 0.00011791230791585867, 0.00011789061898192344, 0.00011786895527136748, 0.00011784730359512217, 0.00011782567977238933, 0.00011780407347822161, 0.00011778252029220357, 0.00011776098412837189, 0.00011773947560192627, 0.00011771798547390987, 0.0001176965275013929, 0.00011767508876591128, 0.00011765367737309793, 0.0001176322926826114, 0.00011761092493125438, 0.00011758958056262993, 0.0001175682484801659, 0.0001175469439350625, 0.00011752566269945876, 0.00011750440948973275, 0.00011748317043271328, 0.00011746196959970095, 0.00011744077663476109, 0.00011741960765092027, 0.00011739847746623283, 0.00011737733752549274, 0.00011735622503727026, 0.00011733514074014613, 0.00011731407371795117, 0.00011729302859061039, 0.00011727198974522441, 0.0001172509790945091, 0.00011722997415685391, 0.00011720900318765925, 0.00011718803320264346, 0.00011716707544930994, 0.00011714612501212283], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831]}
[2018-05-06 05:28:34,702 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:92]: done!
[2018-05-06 05:28:34,702 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:152]: >> Executing classifier part ... 
[2018-05-06 05:28:34,702 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:97]: =======================================
[2018-05-06 05:28:34,702 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9af0962e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-05-06 05:28:34,990 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:110]: training ... 
[2018-05-08 13:24:37,728 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:122]: trained!
[2018-05-08 13:24:37,731 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:125]: Training history: 
{'val_loss': [0.00011922769037806349, 0.00011920508724805985, 0.000119182485735827, 0.00011915988348022179, 0.0001191372891022245, 0.00011911467968564373, 0.00011909207685780223, 0.00011906947975499759, 0.00011904688121625422, 0.00011902429680960789, 0.00011900169754888415, 0.00011897908382181325, 0.00011895647776645215, 0.00011893386397253122, 0.00011891125810702421, 0.0001188886622823922, 0.00011886607347433967, 0.00011884349254924305, 0.00011882093634796272, 0.00011879837402321935, 0.00011877581236162831, 0.00011875326939665454, 0.00011873074822479161, 0.0001187082286974395, 0.00011868573366661355, 0.00011866325607295026, 0.00011864078722861933, 0.00011861834191817408, 0.00011859591184151439, 0.00011857349134312747, 0.00011855108561057588, 0.00011852869986618421, 0.00011850633476240881, 0.00011848399444662571, 0.00011846167134873717, 0.00011843937548555215, 0.0001184171119644132, 0.00011839486348987973, 0.00011837263635922486, 0.00011835043498455077, 0.00011832825345096655, 0.00011830609728028493, 0.0001182839632530083, 0.00011826185626790711, 0.0001182397663589784, 0.00011821769508249094, 0.00011819565026257262, 0.00011817363764565231, 0.0001181516462014745, 0.00011812969264254752, 0.00011810774085915743, 0.00011808581946311842, 0.00011806393436129944, 0.00011804207863071105, 0.00011802024059666345, 0.0001179984352629781, 0.00011797664362017954, 0.00011795488631155804, 0.00011793315630716411, 0.00011791144171303983, 0.0001178897634692896, 0.00011786809971327857, 0.00011784647422490056, 0.00011782488576341893, 0.0001178033196458924, 0.00011778177545785077, 0.00011776024650894269, 0.00011773874478136815, 0.00011771725861380734, 0.00011769581722507276, 0.0001176743985947635, 0.00011765300469629252, 0.00011763162913879664, 0.00011761028444729811, 0.00011758895468207498, 0.0001175676546089626, 0.0001175463868992883, 0.00011752513302489687, 0.00011750391466659109, 0.00011748270412439118, 0.00011746152421555049, 0.00011744036598483857, 0.0001174192376574835, 0.00011739812665230905, 0.00011737704783943658, 0.00011735598339397324, 0.00011733494136466304, 0.0001173139320517591, 0.00011729292655732905, 0.00011727194309666994, 0.0001172509846967513, 0.00011723004883598983, 0.00011720913535929348, 0.00011718823423380927, 0.0001171673523076546, 0.00011714648568480954, 0.00011712564591695981, 0.00011710480986062392, 0.00011708399671780542, 0.00011706318370333897, 0.00011704237743805189], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011934511291037886, 0.00011932243217509479, 0.00011929975589719435, 0.00011927708508050426, 0.00011925442063418434, 0.00011923175581812751, 0.00011920906406664887, 0.00011918638550513192, 0.00011916370990329627, 0.00011914102532685672, 0.00011911834375653885, 0.0001190956413657472, 0.00011907293647253339, 0.00011905022414975149, 0.00011902750387494716, 0.00011900478081639914, 0.0001189820718471487, 0.00011895937338235552, 0.00011893668273919447, 0.00011891401305940067, 0.00011889134574181479, 0.00011886867495459649, 0.0001188460262471008, 0.00011882338185588141, 0.00011880073989920979, 0.00011877811783688353, 0.00011875551308342367, 0.00011873291487805774, 0.00011871035090639836, 0.00011868779711768591, 0.00011866525558744828, 0.00011864273207607903, 0.00011862022843851424, 0.00011859774599383935, 0.00011857528339171096, 0.00011855283763404515, 0.00011853041510103599, 0.00011850802213983343, 0.00011848563472736351, 0.00011846326698328865, 0.0001184409243625676, 0.00011841859980536918, 0.00011839629892830039, 0.00011837402374973169, 0.00011835176625155246, 0.00011832953096795156, 0.00011830731724876364, 0.00011828513377208863, 0.00011826298426566032, 0.00011824085791690733, 0.00011821876769073414, 0.00011819669238799925, 0.00011817464237919728, 0.00011815263138835432, 0.00011813065714792942, 0.00011810870069327792, 0.00011808676958882367, 0.00011806486848842881, 0.00011804299255872125, 0.00011802114621689584, 0.00011799931787429096, 0.00011797752776105168, 0.00011795574953565723, 0.00011793401038091379, 0.00011791230791585867, 0.00011789061898192344, 0.00011786895527136748, 0.00011784730359512217, 0.00011782567977238933, 0.00011780407347822161, 0.00011778252029220357, 0.00011776098412837189, 0.00011773947560192627, 0.00011771798547390987, 0.0001176965275013929, 0.00011767508876591128, 0.00011765367737309793, 0.0001176322926826114, 0.00011761092493125438, 0.00011758958056262993, 0.0001175682484801659, 0.0001175469439350625, 0.00011752566269945876, 0.00011750440948973275, 0.00011748317043271328, 0.00011746196959970095, 0.00011744077663476109, 0.00011741960765092027, 0.00011739847746623283, 0.00011737733752549274, 0.00011735622503727026, 0.00011733514074014613, 0.00011731407371795117, 0.00011729302859061039, 0.00011727198974522441, 0.0001172509790945091, 0.00011722997415685391, 0.00011720900318765925, 0.00011718803320264346, 0.00011716707544930994, 0.00011714612501212283], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831]}
[2018-05-08 13:24:37,731 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:129]: evaluating model ... 
[2018-05-08 13:25:31,265 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:133]: evaluated! 
[2018-05-08 13:25:31,266 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:135]: generating reports ... 
[2018-05-08 13:25:34,521 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:138]: done!
[2018-05-08 13:25:34,522 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6 finished!
[2018-05-09 05:30:31,350 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:85]: trained and evaluated!
[2018-05-09 05:30:31,351 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:88]: Training history: 
{'val_loss': [0.00011848799904705891, 0.00011846568621198747, 0.00011844314098480859, 0.00011842033255567897, 0.00011839725615952824, 0.00011837382898788326, 0.00011835001465293398, 0.00011832568323565186, 0.0001183009173305899, 0.00011827555054534145, 0.00011824952154366409, 0.00011822278083514118, 0.00011819524047186906, 0.00011816660358087227, 0.00011813628887704607, 0.00011810414720994435, 0.00011807013771013083, 0.00011803425614733539, 0.00011799628755324327, 0.00011795628883595072, 0.00011791430844836182, 0.00011787020860453612, 0.00011782440341101533, 0.00011777695704383132, 0.00011772799810105595, 0.00011767785738874158, 0.00011762682880637417, 0.00011757494962953226, 0.00011752213313500473, 0.00011746884318180204, 0.00011741490003959889, 0.00011736056198483557, 0.0001173058010741982, 0.00011725076087481811, 0.00011719551316758693, 0.00011714005047064897, 0.0001170845422515124, 0.00011702902163570567, 0.00011697349838868162, 0.00011691797741990672, 0.00011686253198097333, 0.00011680714600113347, 0.00011675180893412592, 0.0001166965532851108, 0.00011664132723194239, 0.00011658616803415518, 0.00011653111146988695, 0.00011647615029259411, 0.00011642123538087225, 0.00011636638326004958, 0.00011631165141045865, 0.0001162570266064889, 0.00011620251268265822, 0.00011614804809950005, 0.00011609371470284704, 0.00011603945995926911, 0.0001159852495613292, 0.00011593115383526225, 0.00011587717134245555, 0.0001158232785516974, 0.00011576949672664638, 0.00011571576541882844, 0.00011566216845818526, 0.00011560866196970299, 0.00011555523456748402, 0.0001155018968459216, 0.00011544867772701409, 0.00011539555370628982, 0.00011534250054125274, 0.00011528954795610162, 0.00011523669276877489, 0.00011518393407011208, 0.00011513125184253926, 0.00011507867022159242, 0.00011502619184383686, 0.00011497379476641767, 0.00011492149952031707, 0.00011486930057570032, 0.00011481719465424176, 0.00011476516232129977, 0.00011471322249810772, 0.00011466138445810223, 0.00011460965833040033, 0.00011455799572092598, 0.00011450642194177577, 0.00011445495280699351, 0.00011440357038472634, 0.00011435228407943693, 0.00011430110266719761, 0.00011424998427314759, 0.0001141989561587304, 0.00011414804270816419, 0.00011409720452806136, 0.00011404649963622874, 0.0001139958130024772, 0.00011394524241770929, 0.00011389476477320554, 0.00011384439939932157, 0.0001137941211711409, 0.00011374390163996337, 0.00011369376142768724], 'val_acc': [0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.001470047776552738, 0.0018375597206909224, 0.002205071664829107, 0.0033076074972436605, 0.003675119441381845, 0.004410143329658214, 0.005512679162072767, 0.00808526277104006, 0.009922822491730982, 0.012127894156560088, 0.016538037486218304, 0.02058066887173833, 0.02388827636898199, 0.028298419698640206, 0.030871003307607496, 0.0356486585814039, 0.040793825799338476, 0.04961411245865491, 0.05622932745314223, 0.06504961411245866, 0.07460492466005145, 0.08379272326350606, 0.0970231532524807, 0.1065784638000735, 0.11723631018008085, 0.12936420433664095, 0.14553472987872107, 0.16060271958838662, 0.17567070929805217, 0.1969864020580669, 0.22418228592429254, 0.2517456817346564, 0.27600147004777653, 0.30687247335538403, 0.3340683572216097, 0.3528114663726571, 0.37045203969129, 0.3862550532892319, 0.39654538772510106, 0.40683572216097025, 0.4152884968761485, 0.4241087835354649, 0.43072399852995225, 0.4358691657478868, 0.4410143329658214, 0.4483645718485851, 0.4553472987872106, 0.4593899301727306, 0.4649026093348034, 0.47004777655273794, 0.4737228959941198, 0.47813303932377804, 0.48180815876515987, 0.48401323042998895, 0.4854832782065417, 0.4865858140389563, 0.48768834987137083, 0.48915839764792357], 'loss': [0.00011862949583028215, 0.00011860728272732239, 0.00011858484497883637, 0.00011856216437572876, 0.00011853918941293617, 0.00011851594769301435, 0.00011849236627955649, 0.000118468342683997, 0.0001184437974057596, 0.00011841876177692003, 0.00011839305722081144, 0.00011836654216750022, 0.00011833922503877113, 0.00011831089764506881, 0.00011828129610320928, 0.0001182499909155669, 0.00011821686658580356, 0.0001181819371478456, 0.00011814513750299384, 0.00011810635835380813, 0.00011806561972413108, 0.00011802278238748221, 0.00011797805080657619, 0.00011793163006839357, 0.00011788370892718961, 0.00011783454120287468, 0.00011778429913746882, 0.00011773317087435767, 0.00011768113789365255, 0.00011762856405217773, 0.00011757546290873874, 0.00011752183791510628, 0.00011746781809784529, 0.00011741350992689109, 0.0001173589460105368, 0.00011730412530030152, 0.00011724915263624174, 0.00011719411855924156, 0.00011713906381180577, 0.00011708401769781569, 0.00011702898480593834, 0.00011697402409402545, 0.0001169190921796151, 0.0001168642037816293, 0.000116809411481298, 0.00011675466266791944, 0.00011669998139493251, 0.00011664540148165264, 0.00011659091154482762, 0.00011653647650232086, 0.0001164821077507808, 0.00011642785355962653, 0.00011637370769780904, 0.00011631966898824323, 0.00011626567134626487, 0.00011621181432576462, 0.00011615803290216925, 0.00011610429935682204, 0.00011605067874912647, 0.00011599717031370934, 0.00011594375180741358, 0.00011589044010595974, 0.0001158371845393182, 0.00011578405985149838, 0.00011573102633240092, 0.00011567807530035356, 0.00011562521556652578, 0.00011557247304733027, 0.00011551981848086063, 0.0001154672403856254, 0.00011541475640986298, 0.0001153623684683461, 0.00011531007856604892, 0.00011525786182789507, 0.00011520574971902982, 0.0001151537388528776, 0.0001151018141416726, 0.00011504998323646785, 0.0001149982490871207, 0.00011494660781139383, 0.0001148950325113749, 0.00011484355899795734, 0.000114792177382912, 0.00011474090638260608, 0.0001146896991904926, 0.00011463858155061894, 0.00011458757209183006, 0.00011453664424933411, 0.00011448581372623196, 0.00011443508745732301, 0.0001143844184011791, 0.00011433384507831129, 0.00011428338890130824, 0.00011423300388347431, 0.00011418274960067554, 0.0001141325135555508, 0.0001140823919823965, 0.00011403236351149203, 0.00011398244748079127, 0.00011393261048715603, 0.00011388283920844817], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0003682337056585246, 0.0006137228427642077, 0.0012274456855284155, 0.001841168528292623, 0.0029458696452681968, 0.0035595924880324047, 0.0046642936050079785, 0.00638271756474776, 0.008592119799613426, 0.010187799189885847, 0.012888179698048362, 0.01522032650055235, 0.01841168528292623, 0.02148029949674727, 0.024057935436356943, 0.02663557137688113, 0.031054375844783426, 0.03670062599821414, 0.04320608813060022, 0.05192095249785197, 0.06174051798299381, 0.07106910519209525, 0.0821161163627655, 0.09488155146208192, 0.10531483981833804, 0.11783478581438595, 0.12925003068705665, 0.14250644407521673, 0.1589542162612975, 0.17883883636685782, 0.19945992392031595, 0.22143120169127456, 0.24426169140552237, 0.267337670315405, 0.2921320731594209, 0.31803117712772855, 0.3384067755038422, 0.3528906345784452, 0.36430587945385945, 0.375966613448089, 0.3882410703545862, 0.3992880814950774, 0.40984411440525403, 0.41794525589316084, 0.42555541919830814, 0.4307106910409467, 0.43844359884148537, 0.44458082732399856, 0.45059531120137813, 0.45660979502388666, 0.46102859951007935, 0.4669203387786673, 0.47207561059569936, 0.475512458617605, 0.4787038173487658, 0.482386154401693, 0.4844728120853817, 0.485577513238938, 0.4875414262333574]}
[2018-05-09 05:30:31,351 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:92]: done!
[2018-05-09 05:30:31,352 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:152]: >> Executing classifier part ... 
[2018-05-09 05:30:31,352 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:97]: =======================================
[2018-05-09 05:30:31,352 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f9c94a0be10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-05-09 05:30:31,807 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:110]: training ... 
[2018-05-10 13:12:57,874 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:122]: trained!
[2018-05-10 13:12:57,876 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:125]: Training history: 
{'val_loss': [0.00011848799904705891, 0.00011846568621198747, 0.00011844314098480859, 0.00011842033255567897, 0.00011839725615952824, 0.00011837382898788326, 0.00011835001465293398, 0.00011832568323565186, 0.0001183009173305899, 0.00011827555054534145, 0.00011824952154366409, 0.00011822278083514118, 0.00011819524047186906, 0.00011816660358087227, 0.00011813628887704607, 0.00011810414720994435, 0.00011807013771013083, 0.00011803425614733539, 0.00011799628755324327, 0.00011795628883595072, 0.00011791430844836182, 0.00011787020860453612, 0.00011782440341101533, 0.00011777695704383132, 0.00011772799810105595, 0.00011767785738874158, 0.00011762682880637417, 0.00011757494962953226, 0.00011752213313500473, 0.00011746884318180204, 0.00011741490003959889, 0.00011736056198483557, 0.0001173058010741982, 0.00011725076087481811, 0.00011719551316758693, 0.00011714005047064897, 0.0001170845422515124, 0.00011702902163570567, 0.00011697349838868162, 0.00011691797741990672, 0.00011686253198097333, 0.00011680714600113347, 0.00011675180893412592, 0.0001166965532851108, 0.00011664132723194239, 0.00011658616803415518, 0.00011653111146988695, 0.00011647615029259411, 0.00011642123538087225, 0.00011636638326004958, 0.00011631165141045865, 0.0001162570266064889, 0.00011620251268265822, 0.00011614804809950005, 0.00011609371470284704, 0.00011603945995926911, 0.0001159852495613292, 0.00011593115383526225, 0.00011587717134245555, 0.0001158232785516974, 0.00011576949672664638, 0.00011571576541882844, 0.00011566216845818526, 0.00011560866196970299, 0.00011555523456748402, 0.0001155018968459216, 0.00011544867772701409, 0.00011539555370628982, 0.00011534250054125274, 0.00011528954795610162, 0.00011523669276877489, 0.00011518393407011208, 0.00011513125184253926, 0.00011507867022159242, 0.00011502619184383686, 0.00011497379476641767, 0.00011492149952031707, 0.00011486930057570032, 0.00011481719465424176, 0.00011476516232129977, 0.00011471322249810772, 0.00011466138445810223, 0.00011460965833040033, 0.00011455799572092598, 0.00011450642194177577, 0.00011445495280699351, 0.00011440357038472634, 0.00011435228407943693, 0.00011430110266719761, 0.00011424998427314759, 0.0001141989561587304, 0.00011414804270816419, 0.00011409720452806136, 0.00011404649963622874, 0.0001139958130024772, 0.00011394524241770929, 0.00011389476477320554, 0.00011384439939932157, 0.0001137941211711409, 0.00011374390163996337, 0.00011369376142768724], 'val_acc': [0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.001470047776552738, 0.0018375597206909224, 0.002205071664829107, 0.0033076074972436605, 0.003675119441381845, 0.004410143329658214, 0.005512679162072767, 0.00808526277104006, 0.009922822491730982, 0.012127894156560088, 0.016538037486218304, 0.02058066887173833, 0.02388827636898199, 0.028298419698640206, 0.030871003307607496, 0.0356486585814039, 0.040793825799338476, 0.04961411245865491, 0.05622932745314223, 0.06504961411245866, 0.07460492466005145, 0.08379272326350606, 0.0970231532524807, 0.1065784638000735, 0.11723631018008085, 0.12936420433664095, 0.14553472987872107, 0.16060271958838662, 0.17567070929805217, 0.1969864020580669, 0.22418228592429254, 0.2517456817346564, 0.27600147004777653, 0.30687247335538403, 0.3340683572216097, 0.3528114663726571, 0.37045203969129, 0.3862550532892319, 0.39654538772510106, 0.40683572216097025, 0.4152884968761485, 0.4241087835354649, 0.43072399852995225, 0.4358691657478868, 0.4410143329658214, 0.4483645718485851, 0.4553472987872106, 0.4593899301727306, 0.4649026093348034, 0.47004777655273794, 0.4737228959941198, 0.47813303932377804, 0.48180815876515987, 0.48401323042998895, 0.4854832782065417, 0.4865858140389563, 0.48768834987137083, 0.48915839764792357], 'loss': [0.00011862949583028215, 0.00011860728272732239, 0.00011858484497883637, 0.00011856216437572876, 0.00011853918941293617, 0.00011851594769301435, 0.00011849236627955649, 0.000118468342683997, 0.0001184437974057596, 0.00011841876177692003, 0.00011839305722081144, 0.00011836654216750022, 0.00011833922503877113, 0.00011831089764506881, 0.00011828129610320928, 0.0001182499909155669, 0.00011821686658580356, 0.0001181819371478456, 0.00011814513750299384, 0.00011810635835380813, 0.00011806561972413108, 0.00011802278238748221, 0.00011797805080657619, 0.00011793163006839357, 0.00011788370892718961, 0.00011783454120287468, 0.00011778429913746882, 0.00011773317087435767, 0.00011768113789365255, 0.00011762856405217773, 0.00011757546290873874, 0.00011752183791510628, 0.00011746781809784529, 0.00011741350992689109, 0.0001173589460105368, 0.00011730412530030152, 0.00011724915263624174, 0.00011719411855924156, 0.00011713906381180577, 0.00011708401769781569, 0.00011702898480593834, 0.00011697402409402545, 0.0001169190921796151, 0.0001168642037816293, 0.000116809411481298, 0.00011675466266791944, 0.00011669998139493251, 0.00011664540148165264, 0.00011659091154482762, 0.00011653647650232086, 0.0001164821077507808, 0.00011642785355962653, 0.00011637370769780904, 0.00011631966898824323, 0.00011626567134626487, 0.00011621181432576462, 0.00011615803290216925, 0.00011610429935682204, 0.00011605067874912647, 0.00011599717031370934, 0.00011594375180741358, 0.00011589044010595974, 0.0001158371845393182, 0.00011578405985149838, 0.00011573102633240092, 0.00011567807530035356, 0.00011562521556652578, 0.00011557247304733027, 0.00011551981848086063, 0.0001154672403856254, 0.00011541475640986298, 0.0001153623684683461, 0.00011531007856604892, 0.00011525786182789507, 0.00011520574971902982, 0.0001151537388528776, 0.0001151018141416726, 0.00011504998323646785, 0.0001149982490871207, 0.00011494660781139383, 0.0001148950325113749, 0.00011484355899795734, 0.000114792177382912, 0.00011474090638260608, 0.0001146896991904926, 0.00011463858155061894, 0.00011458757209183006, 0.00011453664424933411, 0.00011448581372623196, 0.00011443508745732301, 0.0001143844184011791, 0.00011433384507831129, 0.00011428338890130824, 0.00011423300388347431, 0.00011418274960067554, 0.0001141325135555508, 0.0001140823919823965, 0.00011403236351149203, 0.00011398244748079127, 0.00011393261048715603, 0.00011388283920844817], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0003682337056585246, 0.0006137228427642077, 0.0012274456855284155, 0.001841168528292623, 0.0029458696452681968, 0.0035595924880324047, 0.0046642936050079785, 0.00638271756474776, 0.008592119799613426, 0.010187799189885847, 0.012888179698048362, 0.01522032650055235, 0.01841168528292623, 0.02148029949674727, 0.024057935436356943, 0.02663557137688113, 0.031054375844783426, 0.03670062599821414, 0.04320608813060022, 0.05192095249785197, 0.06174051798299381, 0.07106910519209525, 0.0821161163627655, 0.09488155146208192, 0.10531483981833804, 0.11783478581438595, 0.12925003068705665, 0.14250644407521673, 0.1589542162612975, 0.17883883636685782, 0.19945992392031595, 0.22143120169127456, 0.24426169140552237, 0.267337670315405, 0.2921320731594209, 0.31803117712772855, 0.3384067755038422, 0.3528906345784452, 0.36430587945385945, 0.375966613448089, 0.3882410703545862, 0.3992880814950774, 0.40984411440525403, 0.41794525589316084, 0.42555541919830814, 0.4307106910409467, 0.43844359884148537, 0.44458082732399856, 0.45059531120137813, 0.45660979502388666, 0.46102859951007935, 0.4669203387786673, 0.47207561059569936, 0.475512458617605, 0.4787038173487658, 0.482386154401693, 0.4844728120853817, 0.485577513238938, 0.4875414262333574]}
[2018-05-10 13:12:57,876 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:129]: evaluating model ... 
[2018-05-10 13:13:18,963 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:133]: evaluated! 
[2018-05-10 13:13:18,963 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:135]: generating reports ... 
[2018-05-10 13:13:21,494 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:138]: done!
[2018-05-10 13:13:21,495 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6 finished!
