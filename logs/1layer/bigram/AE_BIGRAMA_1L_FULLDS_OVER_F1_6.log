[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6
[2018-01-18 00:19:28,522 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:146]: >> Printing header log
[2018-01-18 00:19:28,523 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_6
	layers = 9216,14746
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,523 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:148]: >> Loading dataset... 
[2018-01-18 00:22:02,837 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:22:02,837 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:22:02,837 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:57]: =======================================
[2018-01-18 00:22:02,838 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843be0>, 'discard_decoder_function': True}
[2018-01-18 00:22:02,880 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:73]: training and evaluate autoencoder
[2018-01-20 15:59:56,043 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:85]: trained and evaluated!
[2018-01-20 15:59:56,044 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:88]: Training history: 
{'val_loss': [0.00011881631711228021, 0.00011878693500385326, 0.00011875619542795599, 0.00011872395244294395, 0.00011869031339392644, 0.00011865539354907872, 0.00011861904240223603, 0.00011858128412369637, 0.00011854227144171962, 0.00011850202833942367, 0.0001184603467393952, 0.00011841738325789196, 0.00011837322736432443, 0.00011832790441089918, 0.00011828159106353597, 0.00011823408318095139, 0.00011818553901856608, 0.00011813605055132968, 0.00011808557264209981, 0.00011803426534055195, 0.00011798230571905407, 0.00011792938165747513, 0.00011787568825897403, 0.0001178214441953574, 0.00011776668522871901, 0.00011771150414957892, 0.0001176559396694544, 0.00011759999909104306, 0.00011754373109721309, 0.00011748718235196165, 0.00011743043348445081, 0.00011737350365924809, 0.00011731645669941716, 0.00011725931354773648, 0.00011720215376644152, 0.00011714495737004637, 0.00011708770417786302, 0.00011703043849541947, 0.00011697316506639406, 0.00011691589648265905, 0.0001168585987817236, 0.00011680130511585613, 0.00011674402411405897, 0.00011668678513954068, 0.00011662964972641983, 0.00011657252150101454, 0.00011651546544423111, 0.00011645846827163093, 0.00011640156431204304, 0.00011634472505526531, 0.0001162879786478357, 0.00011623131347924043, 0.00011617475587502258, 0.00011611825568161327, 0.00011606183139775366, 0.00011600550593428714, 0.00011594927320251268, 0.00011589312425522183, 0.00011583708169842183, 0.00011578113784970686, 0.00011572529066881392, 0.00011566951112143656, 0.0001156138323839093, 0.00011555824853866715, 0.00011550277324183493, 0.00011544735278876995, 0.00011539205651900066, 0.00011533685456393221, 0.00011528174315857076, 0.00011522672837022528, 0.00011517184915374714, 0.0001151170546683491, 0.0001150623846764309, 0.0001150077815211759, 0.00011495327527707703, 0.00011489886512588991, 0.00011484455403308197, 0.00011479033255942857, 0.0001147362184736685, 0.00011468219106566149, 0.00011462831473338152, 0.00011457450866048644, 0.00011452079386462673, 0.00011446721235436319, 0.00011441368722274368, 0.00011436026819549687, 0.00011430695376716002, 0.00011425374776422903, 0.00011420062861553517, 0.00011414761656059451, 0.00011409467217125747, 0.00011404184395925613, 0.00011398910481823905, 0.00011393643742602559, 0.0001138838748519902, 0.00011383140854467663, 0.00011377903245549388, 0.00011372673356205548, 0.00011367454497651985, 0.00011362247082219708, 0.00011357048224393882], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.0011025358324145535, 0.0014700477765527381, 0.0025725836089672913, 0.0033076074972436605, 0.0036751194413818448, 0.0051451672179345827, 0.006615214994487321, 0.010657846380007351, 0.016905549430356485, 0.022418228592429253, 0.030871003307607496, 0.038221242190371187, 0.046306504961411248, 0.060639470782800443, 0.071664829106945979, 0.087835354649026087, 0.1018008085262771, 0.12238147739801543, 0.13928702682837193, 0.15545755237045203, 0.16648291069459759, 0.18118338846012497, 0.1988239617787578, 0.22050716648291069, 0.23778022785740535, 0.25284821756707093, 0.26828371922087468, 0.27820654171260567, 0.28629180448364572, 0.30062477030503493, 0.31128261668504226, 0.32267548695332599, 0.33112826166850423, 0.336640940830577, 0.3439911797133407, 0.35023888276368981, 0.35501653803748623, 0.36089672914369719, 0.36530687247335536, 0.37008452774715178, 0.37596471885336274, 0.37963983829474457, 0.38221242190371185, 0.38809261300992282, 0.39360529217199558, 0.3980154355016538, 0.40132304299889748, 0.40463065049614111, 0.40720323410510839, 0.41161337743476661, 0.41639103270856304, 0.42374127159132674, 0.42778390297684676, 0.42998897464167585, 0.43366409408305767, 0.43770672546857775, 0.44174935685409777, 0.4454244762954796, 0.44799705990444688, 0.44983461962513782, 0.45350973906651965, 0.45534729878721059], 'loss': [0.00011894635547869605, 0.00011891733849175452, 0.00011888728734804918, 0.00011885581693534991, 0.00011882306809036814, 0.00011878894310432534, 0.00011875345987909584, 0.00011871675839849559, 0.00011867888733651083, 0.00011863973338575302, 0.00011859920439332092, 0.00011855722777111056, 0.00011851390745984258, 0.00011846941255341495, 0.00011842382160930694, 0.00011837711792773565, 0.00011832920885477954, 0.00011828018637633309, 0.00011823027370184305, 0.00011817940304264034, 0.00011812777280632822, 0.00011807526476998228, 0.00011802187855582785, 0.00011796782567747998, 0.00011791327467958978, 0.0001178582429942693, 0.00011780279517186399, 0.0001177469185019984, 0.00011769077737737487, 0.00011763441150005498, 0.00011757787003254208, 0.00011752119831583187, 0.00011746442023457031, 0.00011740759773040368, 0.00011735066045508337, 0.00011729371938951338, 0.00011723677668513374, 0.00011717979976490924, 0.00011712280944395514, 0.00011706583613447037, 0.00011700887366167025, 0.00011695194922354334, 0.00011689508901871698, 0.00011683825525543685, 0.00011678145034503049, 0.00011672472454492257, 0.00011666800763636173, 0.00011661134756904285, 0.00011655474825288893, 0.00011649824094049115, 0.00011644179161069706, 0.00011638544023260042, 0.00011632917396722167, 0.00011627301903104977, 0.00011621692767801306, 0.0001161609017844816, 0.00011610496574505245, 0.00011604911631693661, 0.00011599334742001628, 0.00011593768495820098, 0.00011588211581833424, 0.00011582664140255837, 0.00011577123584804578, 0.00011571594295075638, 0.00011566073860366623, 0.00011560564212686754, 0.00011555060215819038, 0.00011549568413302672, 0.00011544085879393563, 0.0001153861273840904, 0.00011533149258363698, 0.00011527700461427663, 0.00011522259551676122, 0.00011516831362123955, 0.00011511410029315643, 0.00011505997974759897, 0.00011500595676435421, 0.00011495203404500212, 0.00011489821207448744, 0.00011484448169780325, 0.00011479084497082956, 0.00011473735305211305, 0.00011468393849414289, 0.00011463060850589536, 0.00011457741356717314, 0.00011452426864474282, 0.00011447123025208446, 0.00011441829167588352, 0.00011436546029569541, 0.0001143127205932877, 0.00011426008398406366, 0.00011420751791599439, 0.00011415506709955815, 0.00011410269889163147, 0.00011405040304228609, 0.00011399821695389157, 0.000113946115639736, 0.00011389411775813609, 0.00011384219183858808, 0.0001137903769758562, 0.00011373867767733686], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.0003682337056585246, 0.00049097827421136617, 0.0011047011169755738, 0.0020866576653983063, 0.0044188044679022952, 0.0069964404075119674, 0.010187799190800366, 0.015220326500552351, 0.020130109243580531, 0.026021848533202406, 0.033877500921498785, 0.043819810973364431, 0.054375843868908799, 0.066282067020363461, 0.080397692402111212, 0.094022339513305658, 0.11145206823134782, 0.12716337302165834, 0.14459310174061504, 0.16140910764790115, 0.17969804836136, 0.19369092919833239, 0.21161163618875689, 0.23075978890129054, 0.24389345769986384, 0.25395851232485495, 0.26647845829895439, 0.27740272495137031, 0.28930894804978291, 0.30109242670401715, 0.30968454646247728, 0.31901313365786094, 0.32821897629566599, 0.33570639501397004, 0.34245734623316332, 0.34957653122751847, 0.35694120534068896, 0.36185098810109301, 0.36761998280478619, 0.37105683077913687, 0.37645759177351346, 0.38161286365273278, 0.3872591138281119, 0.392782619372751, 0.39744691296312668, 0.40100650548773981, 0.40554805452053688, 0.41008960355699203, 0.41450840799197164, 0.41929544614724212, 0.42334601692777624, 0.42788756594594102, 0.43120166931515808, 0.43451577261852986, 0.43746164234793378, 0.44065300113030764, 0.44384435989439114, 0.44629925125081565, 0.44863139806795194, 0.45071805569676954, 0.45292745794901107]}
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:92]: done!
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:152]: >> Executing classifier part ... 
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:97]: =======================================
[2018-01-20 15:59:56,045 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f834f843470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-20 15:59:56,187 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:110]: training ... 
[2018-01-24 10:20:45,708 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:122]: trained!
[2018-01-24 10:20:45,710 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:125]: Training history: 
{'val_loss': [0.00011881631711228021, 0.00011878693500385326, 0.00011875619542795599, 0.00011872395244294395, 0.00011869031339392644, 0.00011865539354907872, 0.00011861904240223603, 0.00011858128412369637, 0.00011854227144171962, 0.00011850202833942367, 0.0001184603467393952, 0.00011841738325789196, 0.00011837322736432443, 0.00011832790441089918, 0.00011828159106353597, 0.00011823408318095139, 0.00011818553901856608, 0.00011813605055132968, 0.00011808557264209981, 0.00011803426534055195, 0.00011798230571905407, 0.00011792938165747513, 0.00011787568825897403, 0.0001178214441953574, 0.00011776668522871901, 0.00011771150414957892, 0.0001176559396694544, 0.00011759999909104306, 0.00011754373109721309, 0.00011748718235196165, 0.00011743043348445081, 0.00011737350365924809, 0.00011731645669941716, 0.00011725931354773648, 0.00011720215376644152, 0.00011714495737004637, 0.00011708770417786302, 0.00011703043849541947, 0.00011697316506639406, 0.00011691589648265905, 0.0001168585987817236, 0.00011680130511585613, 0.00011674402411405897, 0.00011668678513954068, 0.00011662964972641983, 0.00011657252150101454, 0.00011651546544423111, 0.00011645846827163093, 0.00011640156431204304, 0.00011634472505526531, 0.0001162879786478357, 0.00011623131347924043, 0.00011617475587502258, 0.00011611825568161327, 0.00011606183139775366, 0.00011600550593428714, 0.00011594927320251268, 0.00011589312425522183, 0.00011583708169842183, 0.00011578113784970686, 0.00011572529066881392, 0.00011566951112143656, 0.0001156138323839093, 0.00011555824853866715, 0.00011550277324183493, 0.00011544735278876995, 0.00011539205651900066, 0.00011533685456393221, 0.00011528174315857076, 0.00011522672837022528, 0.00011517184915374714, 0.0001151170546683491, 0.0001150623846764309, 0.0001150077815211759, 0.00011495327527707703, 0.00011489886512588991, 0.00011484455403308197, 0.00011479033255942857, 0.0001147362184736685, 0.00011468219106566149, 0.00011462831473338152, 0.00011457450866048644, 0.00011452079386462673, 0.00011446721235436319, 0.00011441368722274368, 0.00011436026819549687, 0.00011430695376716002, 0.00011425374776422903, 0.00011420062861553517, 0.00011414761656059451, 0.00011409467217125747, 0.00011404184395925613, 0.00011398910481823905, 0.00011393643742602559, 0.0001138838748519902, 0.00011383140854467663, 0.00011377903245549388, 0.00011372673356205548, 0.00011367454497651985, 0.00011362247082219708, 0.00011357048224393882], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.0011025358324145535, 0.0014700477765527381, 0.0025725836089672913, 0.0033076074972436605, 0.0036751194413818448, 0.0051451672179345827, 0.006615214994487321, 0.010657846380007351, 0.016905549430356485, 0.022418228592429253, 0.030871003307607496, 0.038221242190371187, 0.046306504961411248, 0.060639470782800443, 0.071664829106945979, 0.087835354649026087, 0.1018008085262771, 0.12238147739801543, 0.13928702682837193, 0.15545755237045203, 0.16648291069459759, 0.18118338846012497, 0.1988239617787578, 0.22050716648291069, 0.23778022785740535, 0.25284821756707093, 0.26828371922087468, 0.27820654171260567, 0.28629180448364572, 0.30062477030503493, 0.31128261668504226, 0.32267548695332599, 0.33112826166850423, 0.336640940830577, 0.3439911797133407, 0.35023888276368981, 0.35501653803748623, 0.36089672914369719, 0.36530687247335536, 0.37008452774715178, 0.37596471885336274, 0.37963983829474457, 0.38221242190371185, 0.38809261300992282, 0.39360529217199558, 0.3980154355016538, 0.40132304299889748, 0.40463065049614111, 0.40720323410510839, 0.41161337743476661, 0.41639103270856304, 0.42374127159132674, 0.42778390297684676, 0.42998897464167585, 0.43366409408305767, 0.43770672546857775, 0.44174935685409777, 0.4454244762954796, 0.44799705990444688, 0.44983461962513782, 0.45350973906651965, 0.45534729878721059], 'loss': [0.00011894635547869605, 0.00011891733849175452, 0.00011888728734804918, 0.00011885581693534991, 0.00011882306809036814, 0.00011878894310432534, 0.00011875345987909584, 0.00011871675839849559, 0.00011867888733651083, 0.00011863973338575302, 0.00011859920439332092, 0.00011855722777111056, 0.00011851390745984258, 0.00011846941255341495, 0.00011842382160930694, 0.00011837711792773565, 0.00011832920885477954, 0.00011828018637633309, 0.00011823027370184305, 0.00011817940304264034, 0.00011812777280632822, 0.00011807526476998228, 0.00011802187855582785, 0.00011796782567747998, 0.00011791327467958978, 0.0001178582429942693, 0.00011780279517186399, 0.0001177469185019984, 0.00011769077737737487, 0.00011763441150005498, 0.00011757787003254208, 0.00011752119831583187, 0.00011746442023457031, 0.00011740759773040368, 0.00011735066045508337, 0.00011729371938951338, 0.00011723677668513374, 0.00011717979976490924, 0.00011712280944395514, 0.00011706583613447037, 0.00011700887366167025, 0.00011695194922354334, 0.00011689508901871698, 0.00011683825525543685, 0.00011678145034503049, 0.00011672472454492257, 0.00011666800763636173, 0.00011661134756904285, 0.00011655474825288893, 0.00011649824094049115, 0.00011644179161069706, 0.00011638544023260042, 0.00011632917396722167, 0.00011627301903104977, 0.00011621692767801306, 0.0001161609017844816, 0.00011610496574505245, 0.00011604911631693661, 0.00011599334742001628, 0.00011593768495820098, 0.00011588211581833424, 0.00011582664140255837, 0.00011577123584804578, 0.00011571594295075638, 0.00011566073860366623, 0.00011560564212686754, 0.00011555060215819038, 0.00011549568413302672, 0.00011544085879393563, 0.0001153861273840904, 0.00011533149258363698, 0.00011527700461427663, 0.00011522259551676122, 0.00011516831362123955, 0.00011511410029315643, 0.00011505997974759897, 0.00011500595676435421, 0.00011495203404500212, 0.00011489821207448744, 0.00011484448169780325, 0.00011479084497082956, 0.00011473735305211305, 0.00011468393849414289, 0.00011463060850589536, 0.00011457741356717314, 0.00011452426864474282, 0.00011447123025208446, 0.00011441829167588352, 0.00011436546029569541, 0.0001143127205932877, 0.00011426008398406366, 0.00011420751791599439, 0.00011415506709955815, 0.00011410269889163147, 0.00011405040304228609, 0.00011399821695389157, 0.000113946115639736, 0.00011389411775813609, 0.00011384219183858808, 0.0001137903769758562, 0.00011373867767733686], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.0003682337056585246, 0.00049097827421136617, 0.0011047011169755738, 0.0020866576653983063, 0.0044188044679022952, 0.0069964404075119674, 0.010187799190800366, 0.015220326500552351, 0.020130109243580531, 0.026021848533202406, 0.033877500921498785, 0.043819810973364431, 0.054375843868908799, 0.066282067020363461, 0.080397692402111212, 0.094022339513305658, 0.11145206823134782, 0.12716337302165834, 0.14459310174061504, 0.16140910764790115, 0.17969804836136, 0.19369092919833239, 0.21161163618875689, 0.23075978890129054, 0.24389345769986384, 0.25395851232485495, 0.26647845829895439, 0.27740272495137031, 0.28930894804978291, 0.30109242670401715, 0.30968454646247728, 0.31901313365786094, 0.32821897629566599, 0.33570639501397004, 0.34245734623316332, 0.34957653122751847, 0.35694120534068896, 0.36185098810109301, 0.36761998280478619, 0.37105683077913687, 0.37645759177351346, 0.38161286365273278, 0.3872591138281119, 0.392782619372751, 0.39744691296312668, 0.40100650548773981, 0.40554805452053688, 0.41008960355699203, 0.41450840799197164, 0.41929544614724212, 0.42334601692777624, 0.42788756594594102, 0.43120166931515808, 0.43451577261852986, 0.43746164234793378, 0.44065300113030764, 0.44384435989439114, 0.44629925125081565, 0.44863139806795194, 0.45071805569676954, 0.45292745794901107]}
[2018-01-24 10:20:45,710 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:129]: evaluating model ... 
[2018-01-24 10:21:01,188 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:133]: evaluated! 
[2018-01-24 10:21:01,189 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:135]: generating reports ... 
[2018-01-24 10:21:02,585 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:138]: done!
[2018-01-24 10:21:02,586 AE_BIGRAMA_1L_FULLDS_OVER_F1_6.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_6 finished!
