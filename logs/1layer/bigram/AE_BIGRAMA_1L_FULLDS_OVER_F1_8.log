[2018-01-18 00:19:28,515 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_8
[2018-01-18 00:19:28,515 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:146]: >> Printing header log
[2018-01-18 00:19:28,516 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_OVER_F1_8
	layers = 9216,16589
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2ad7bbec18>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2ad7bbe4a8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,516 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:148]: >> Loading dataset... 
[2018-01-18 00:21:56,077 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:21:56,077 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:21:56,077 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:57]: =======================================
[2018-01-18 00:21:56,077 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2ad7bbec18>, 'discard_decoder_function': True}
[2018-01-18 00:21:56,134 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:73]: training and evaluate autoencoder
[2018-01-20 18:24:31,641 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:85]: trained and evaluated!
[2018-01-20 18:24:31,643 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:88]: Training history: 
{'val_loss': [0.00011867505891158908, 0.00011863277385631084, 0.00011858861317895493, 0.00011854291962498959, 0.00011849591554029928, 0.00011844798155292904, 0.00011839908697069165, 0.0001183494785905397, 0.00011829900809631552, 0.00011824790049186085, 0.00011819616025345396, 0.00011814380969028788, 0.00011809073334700728, 0.00011803681688331539, 0.00011798218021480174, 0.00011792695853362549, 0.00011787090622206865, 0.00011781436501215296, 0.00011775715761759036, 0.00011769968218648261, 0.00011764194642262754, 0.00011758408985274047, 0.00011752619827215401, 0.00011746835234479223, 0.00011741049801304427, 0.00011735274031168232, 0.00011729506789224472, 0.00011723744544989194, 0.00011717996745174291, 0.00011712257640676908, 0.00011706527307973483, 0.00011700810070121962, 0.00011695102254381522, 0.00011689399575932431, 0.00011683709689103497, 0.00011678028670867367, 0.00011672359890733116, 0.00011666702124008136, 0.00011661053240850369, 0.0001165541162429121, 0.0001164978193885858, 0.00011644159801864298, 0.00011638548404996351, 0.0001163294994708603, 0.00011627360071650375, 0.00011621777347831271, 0.00011616205395156917, 0.00011610644210151111, 0.00011605092540311633, 0.00011599548855842321, 0.00011594017456269911, 0.0001158849483276986, 0.00011582984004289669, 0.00011577483984657646, 0.00011571990545742893, 0.00011566508054991778, 0.00011561034745424223, 0.00011555571149968693, 0.0001155011761250176, 0.00011544673410240863, 0.0001153923803271915, 0.00011533813112414432, 0.00011528397750327461, 0.00011522995474000791, 0.00011517595843063635, 0.00011512207781193224, 0.00011506832342480886, 0.00011501462819996485, 0.00011496105484807938, 0.00011490757921757245, 0.00011485421972429121, 0.00011480093407890465, 0.00011474777653422573, 0.00011469468955644185, 0.00011464169683987881, 0.00011458881437773853, 0.00011453601356622879, 0.00011448331734293303, 0.00011443072378257024, 0.0001143782277162959, 0.00011432581842671265, 0.00011427350793078248, 0.00011422130025822539, 0.00011416918143738443, 0.00011411717291642425, 0.00011406525625543171, 0.0001140134705081962, 0.00011396175758203887, 0.00011391014002413889, 0.0001138586218775863, 0.00011380721044775272, 0.00011375589479529873, 0.00011370463605361499, 0.00011365347830361342, 0.00011360239594173129, 0.00011355141158467186, 0.00011350052608544152, 0.0001134497442652647, 0.00011339908314415981, 0.00011334846941972848, 0.0001132979759692029], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.0014700477765527381, 0.0033076074972436605, 0.0040426313855200296, 0.005512679162072767, 0.006615214994487321, 0.0084527747151782427, 0.010657846380007351, 0.014700477765527379, 0.019110621095185593, 0.023888276368981991, 0.028665931642778392, 0.035281146637265712, 0.041528849687614847, 0.047776552737963981, 0.054759279676589487, 0.062477030503491363, 0.071664829106945979, 0.091877986034546125, 0.10363836824696802, 0.11539875045938992, 0.12789415656008821, 0.13965453877251011, 0.15361999264976112, 0.17089305402425578, 0.18890113928702681, 0.20654171260565968, 0.22822491730981256, 0.24770305034913634, 0.27085630282984197, 0.29547960308710031, 0.3201029033443587, 0.33737596471885334, 0.35611907386990077, 0.37155457552370452, 0.38441749356854099, 0.39360529217199558, 0.40536567438441751, 0.41234840132304301, 0.42043366409408306, 0.42998897464167585, 0.43733921352443955, 0.44762954796030868, 0.45203969128996691, 0.45865490628445427, 0.46343256155825063, 0.4693127526644616, 0.4755604557148107, 0.47886806321205438, 0.48254318265343621, 0.48548327820654169, 0.48768834987137083, 0.48989342153619991, 0.49136346931275265, 0.49136346931275265, 0.4924660051451672, 0.4928335170893054, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359], 'loss': [0.00011881354707874075, 0.0001187729355162017, 0.00011873029787141128, 0.00011868601338457042, 0.0001186403697431315, 0.00011859369659521858, 0.00011854599756764695, 0.00011849741845374572, 0.00011844804345439374, 0.00011839785649050169, 0.0001183469161984109, 0.00011829537771668443, 0.0001182431179756295, 0.00011819009342309819, 0.00011813621506681453, 0.00011808158594548402, 0.00011802619619588391, 0.00011797020546843897, 0.00011791375394076447, 0.00011785680437571142, 0.00011779963658194265, 0.00011774231179467478, 0.00011768483890456183, 0.00011762730109704578, 0.00011756982281984846, 0.00011751235926514545, 0.00011745499032557705, 0.00011739770057847085, 0.00011734046813790352, 0.00011728337853991489, 0.000117226373841197, 0.00011716946134182073, 0.00011711267275342264, 0.00011705597724137494, 0.00011699933525008186, 0.00011694281644101017, 0.00011688638303669492, 0.00011683007282353192, 0.0001167738723088039, 0.00011671775311475789, 0.00011666171503241221, 0.00011660578816049318, 0.00011654992963184854, 0.00011649418450883169, 0.00011643856756841513, 0.00011638304048210088, 0.00011632757944829985, 0.00011627223168527089, 0.00011621698251874624, 0.00011616183724025026, 0.00011610676712640637, 0.00011605182311606256, 0.00011599696682892198, 0.0001159422261908369, 0.00011588759687213478, 0.0001158330318251358, 0.00011577857679629598, 0.00011572421292367533, 0.0001156699477154334, 0.00011561577168344281, 0.00011556170355657398, 0.00011550771334059138, 0.00011545382574713703, 0.00011540003707705583, 0.00011534638476486841, 0.00011529275741438653, 0.00011523924006330905, 0.0001151858555656626, 0.00011513252061275959, 0.000115079312816303, 0.00011502620290545564, 0.00011497320322889381, 0.00011492027880004093, 0.00011486748534914211, 0.00011481475835532369, 0.00011476212894882434, 0.0001147096050807734, 0.00011465716525641845, 0.000114604832804907, 0.00011455259785051312, 0.00011450047128707884, 0.00011444841809766268, 0.00011439647840675508, 0.00011434462815823795, 0.00011429287466825769, 0.00011424122930309789, 0.00011418966981245687, 0.0001141382522007566, 0.00011408690030934221, 0.00011403563486580667, 0.00011398447948240525, 0.00011393343073237355, 0.00011388247154083328, 0.00011383156945131557, 0.00011378076412480015, 0.00011373004134427839, 0.00011367941117481012, 0.0001136288814505306, 0.00011357845317169424, 0.00011352814543065674, 0.00011347788498736261], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00049097827421136617, 0.00061372284276420773, 0.0012274456855284155, 0.0015956793911869401, 0.001841168528292623, 0.0027003805081625139, 0.003682337056585246, 0.0052780164486867041, 0.0060144838600037533, 0.0073646741140850104, 0.0094513317794833168, 0.012274456856198672, 0.016079538480422241, 0.020007364674113171, 0.025039891985694191, 0.030931631275316066, 0.035473180313600243, 0.041487664171774956, 0.048115870874542922, 0.056953479809432994, 0.069350681232355466, 0.082607094637891385, 0.094758806924622699, 0.10801522032832959, 0.121639867437695, 0.13489628082494057, 0.15158954215178508, 0.17012397198497378, 0.19319995090948872, 0.21283908187794337, 0.23382840307853084, 0.25776359394633491, 0.27826193691294981, 0.29925125811719538, 0.31950411195036266, 0.3360746286867059, 0.34908555293501675, 0.36614704796386172, 0.38149011908783803, 0.39315085311864834, 0.40309316309826704, 0.41266723946733708, 0.42285503865722296, 0.43230637046505632, 0.43979378916872808, 0.44605376211005193, 0.45354118082835598, 0.45931017554668147, 0.46520191475674028, 0.47195286609299186, 0.47489873573826002, 0.4784583282080021, 0.4818951761091913, 0.48459555658808923, 0.4868049589244664, 0.48913710565380891, 0.49073278508157658, 0.49159199706144652, 0.49196023080368578, 0.49208297533565787, 0.49220571992250106, 0.4924512090413164, 0.49269669821500278, 0.49281944272868455, 0.49281944278355566, 0.49281944274697492, 0.49294218735210849, 0.49294218733016004, 0.49294218729723738, 0.49294218730089545, 0.49318767648921419, 0.49318767638678812, 0.49318767647458189, 0.49318767645263345, 0.49318767648921419, 0.49318767647092382, 0.49318767642336886, 0.49318767643800115]}
[2018-01-20 18:24:31,643 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:92]: done!
[2018-01-20 18:24:31,680 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:152]: >> Executing classifier part ... 
[2018-01-20 18:24:31,681 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:97]: =======================================
[2018-01-20 18:24:31,681 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2ad7bbe4a8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-20 18:24:31,778 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:110]: training ... 
[2018-01-24 10:09:09,163 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:122]: trained!
[2018-01-24 10:09:09,165 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:125]: Training history: 
{'val_loss': [0.00011867505891158908, 0.00011863277385631084, 0.00011858861317895493, 0.00011854291962498959, 0.00011849591554029928, 0.00011844798155292904, 0.00011839908697069165, 0.0001183494785905397, 0.00011829900809631552, 0.00011824790049186085, 0.00011819616025345396, 0.00011814380969028788, 0.00011809073334700728, 0.00011803681688331539, 0.00011798218021480174, 0.00011792695853362549, 0.00011787090622206865, 0.00011781436501215296, 0.00011775715761759036, 0.00011769968218648261, 0.00011764194642262754, 0.00011758408985274047, 0.00011752619827215401, 0.00011746835234479223, 0.00011741049801304427, 0.00011735274031168232, 0.00011729506789224472, 0.00011723744544989194, 0.00011717996745174291, 0.00011712257640676908, 0.00011706527307973483, 0.00011700810070121962, 0.00011695102254381522, 0.00011689399575932431, 0.00011683709689103497, 0.00011678028670867367, 0.00011672359890733116, 0.00011666702124008136, 0.00011661053240850369, 0.0001165541162429121, 0.0001164978193885858, 0.00011644159801864298, 0.00011638548404996351, 0.0001163294994708603, 0.00011627360071650375, 0.00011621777347831271, 0.00011616205395156917, 0.00011610644210151111, 0.00011605092540311633, 0.00011599548855842321, 0.00011594017456269911, 0.0001158849483276986, 0.00011582984004289669, 0.00011577483984657646, 0.00011571990545742893, 0.00011566508054991778, 0.00011561034745424223, 0.00011555571149968693, 0.0001155011761250176, 0.00011544673410240863, 0.0001153923803271915, 0.00011533813112414432, 0.00011528397750327461, 0.00011522995474000791, 0.00011517595843063635, 0.00011512207781193224, 0.00011506832342480886, 0.00011501462819996485, 0.00011496105484807938, 0.00011490757921757245, 0.00011485421972429121, 0.00011480093407890465, 0.00011474777653422573, 0.00011469468955644185, 0.00011464169683987881, 0.00011458881437773853, 0.00011453601356622879, 0.00011448331734293303, 0.00011443072378257024, 0.0001143782277162959, 0.00011432581842671265, 0.00011427350793078248, 0.00011422130025822539, 0.00011416918143738443, 0.00011411717291642425, 0.00011406525625543171, 0.0001140134705081962, 0.00011396175758203887, 0.00011391014002413889, 0.0001138586218775863, 0.00011380721044775272, 0.00011375589479529873, 0.00011370463605361499, 0.00011365347830361342, 0.00011360239594173129, 0.00011355141158467186, 0.00011350052608544152, 0.0001134497442652647, 0.00011339908314415981, 0.00011334846941972848, 0.0001132979759692029], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00036751194413818452, 0.00036751194413818452, 0.0014700477765527381, 0.0033076074972436605, 0.0040426313855200296, 0.005512679162072767, 0.006615214994487321, 0.0084527747151782427, 0.010657846380007351, 0.014700477765527379, 0.019110621095185593, 0.023888276368981991, 0.028665931642778392, 0.035281146637265712, 0.041528849687614847, 0.047776552737963981, 0.054759279676589487, 0.062477030503491363, 0.071664829106945979, 0.091877986034546125, 0.10363836824696802, 0.11539875045938992, 0.12789415656008821, 0.13965453877251011, 0.15361999264976112, 0.17089305402425578, 0.18890113928702681, 0.20654171260565968, 0.22822491730981256, 0.24770305034913634, 0.27085630282984197, 0.29547960308710031, 0.3201029033443587, 0.33737596471885334, 0.35611907386990077, 0.37155457552370452, 0.38441749356854099, 0.39360529217199558, 0.40536567438441751, 0.41234840132304301, 0.42043366409408306, 0.42998897464167585, 0.43733921352443955, 0.44762954796030868, 0.45203969128996691, 0.45865490628445427, 0.46343256155825063, 0.4693127526644616, 0.4755604557148107, 0.47886806321205438, 0.48254318265343621, 0.48548327820654169, 0.48768834987137083, 0.48989342153619991, 0.49136346931275265, 0.49136346931275265, 0.4924660051451672, 0.4928335170893054, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359, 0.49320102903344359], 'loss': [0.00011881354707874075, 0.0001187729355162017, 0.00011873029787141128, 0.00011868601338457042, 0.0001186403697431315, 0.00011859369659521858, 0.00011854599756764695, 0.00011849741845374572, 0.00011844804345439374, 0.00011839785649050169, 0.0001183469161984109, 0.00011829537771668443, 0.0001182431179756295, 0.00011819009342309819, 0.00011813621506681453, 0.00011808158594548402, 0.00011802619619588391, 0.00011797020546843897, 0.00011791375394076447, 0.00011785680437571142, 0.00011779963658194265, 0.00011774231179467478, 0.00011768483890456183, 0.00011762730109704578, 0.00011756982281984846, 0.00011751235926514545, 0.00011745499032557705, 0.00011739770057847085, 0.00011734046813790352, 0.00011728337853991489, 0.000117226373841197, 0.00011716946134182073, 0.00011711267275342264, 0.00011705597724137494, 0.00011699933525008186, 0.00011694281644101017, 0.00011688638303669492, 0.00011683007282353192, 0.0001167738723088039, 0.00011671775311475789, 0.00011666171503241221, 0.00011660578816049318, 0.00011654992963184854, 0.00011649418450883169, 0.00011643856756841513, 0.00011638304048210088, 0.00011632757944829985, 0.00011627223168527089, 0.00011621698251874624, 0.00011616183724025026, 0.00011610676712640637, 0.00011605182311606256, 0.00011599696682892198, 0.0001159422261908369, 0.00011588759687213478, 0.0001158330318251358, 0.00011577857679629598, 0.00011572421292367533, 0.0001156699477154334, 0.00011561577168344281, 0.00011556170355657398, 0.00011550771334059138, 0.00011545382574713703, 0.00011540003707705583, 0.00011534638476486841, 0.00011529275741438653, 0.00011523924006330905, 0.0001151858555656626, 0.00011513252061275959, 0.000115079312816303, 0.00011502620290545564, 0.00011497320322889381, 0.00011492027880004093, 0.00011486748534914211, 0.00011481475835532369, 0.00011476212894882434, 0.0001147096050807734, 0.00011465716525641845, 0.000114604832804907, 0.00011455259785051312, 0.00011450047128707884, 0.00011444841809766268, 0.00011439647840675508, 0.00011434462815823795, 0.00011429287466825769, 0.00011424122930309789, 0.00011418966981245687, 0.0001141382522007566, 0.00011408690030934221, 0.00011403563486580667, 0.00011398447948240525, 0.00011393343073237355, 0.00011388247154083328, 0.00011383156945131557, 0.00011378076412480015, 0.00011373004134427839, 0.00011367941117481012, 0.0001136288814505306, 0.00011357845317169424, 0.00011352814543065674, 0.00011347788498736261], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00049097827421136617, 0.00061372284276420773, 0.0012274456855284155, 0.0015956793911869401, 0.001841168528292623, 0.0027003805081625139, 0.003682337056585246, 0.0052780164486867041, 0.0060144838600037533, 0.0073646741140850104, 0.0094513317794833168, 0.012274456856198672, 0.016079538480422241, 0.020007364674113171, 0.025039891985694191, 0.030931631275316066, 0.035473180313600243, 0.041487664171774956, 0.048115870874542922, 0.056953479809432994, 0.069350681232355466, 0.082607094637891385, 0.094758806924622699, 0.10801522032832959, 0.121639867437695, 0.13489628082494057, 0.15158954215178508, 0.17012397198497378, 0.19319995090948872, 0.21283908187794337, 0.23382840307853084, 0.25776359394633491, 0.27826193691294981, 0.29925125811719538, 0.31950411195036266, 0.3360746286867059, 0.34908555293501675, 0.36614704796386172, 0.38149011908783803, 0.39315085311864834, 0.40309316309826704, 0.41266723946733708, 0.42285503865722296, 0.43230637046505632, 0.43979378916872808, 0.44605376211005193, 0.45354118082835598, 0.45931017554668147, 0.46520191475674028, 0.47195286609299186, 0.47489873573826002, 0.4784583282080021, 0.4818951761091913, 0.48459555658808923, 0.4868049589244664, 0.48913710565380891, 0.49073278508157658, 0.49159199706144652, 0.49196023080368578, 0.49208297533565787, 0.49220571992250106, 0.4924512090413164, 0.49269669821500278, 0.49281944272868455, 0.49281944278355566, 0.49281944274697492, 0.49294218735210849, 0.49294218733016004, 0.49294218729723738, 0.49294218730089545, 0.49318767648921419, 0.49318767638678812, 0.49318767647458189, 0.49318767645263345, 0.49318767648921419, 0.49318767647092382, 0.49318767642336886, 0.49318767643800115]}
[2018-01-24 10:09:09,165 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:129]: evaluating model ... 
[2018-01-24 10:09:31,344 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:133]: evaluated! 
[2018-01-24 10:09:31,346 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:135]: generating reports ... 
[2018-01-24 10:09:32,898 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:138]: done!
[2018-01-24 10:09:32,899 AE_BIGRAMA_1L_FULLDS_OVER_F1_8.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_OVER_F1_8 finished!
