[2017-12-14 09:31:57,965 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_7
[2017-12-14 09:31:57,965 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:146]: >> Printing header log
[2017-12-14 09:31:57,965 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_OVER_F1_7
	layers = 9216,15667
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f59f30eeeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f59f30d1400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 09:31:57,965 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:148]: >> Loading dataset... 
[2017-12-14 09:32:19,797 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 09:32:19,798 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:150]: >> Executing autoencoder part ... 
[2017-12-14 09:32:19,798 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:57]: =======================================
[2017-12-14 09:32:19,798 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f59f30eeeb8>, 'discard_decoder_function': True}
[2017-12-14 09:32:19,846 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:73]: training and evaluate autoencoder
[2017-12-14 10:18:55,075 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_7
[2017-12-14 10:18:55,075 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:146]: >> Printing header log
[2017-12-14 10:18:55,075 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_OVER_F1_7
	layers = 9216,15667
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa14905ee80>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa1490413c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 10:18:55,075 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:148]: >> Loading dataset... 
[2017-12-14 10:19:18,103 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 10:19:18,103 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:150]: >> Executing autoencoder part ... 
[2017-12-14 10:19:18,103 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:57]: =======================================
[2017-12-14 10:19:18,104 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa14905ee80>, 'discard_decoder_function': True}
[2017-12-14 10:19:18,150 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:73]: training and evaluate autoencoder
[2017-12-15 03:26:39,036 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:85]: trained and evaluated!
[2017-12-15 03:26:39,039 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:88]: Training history: 
{'val_loss': [0.00011902249743060738, 0.00011901771408735708, 0.00011901290046039131, 0.00011900809296525223, 0.00011900327901649964, 0.00011899847422079446, 0.00011899365928880435, 0.0001189888275702683, 0.00011898395457363365, 0.0001189790727457384, 0.00011897420734684818, 0.00011896931627652029, 0.00011896445520387514, 0.00011895957385866013, 0.00011895467592354667, 0.00011894973644217893, 0.00011894477105697191, 0.00011893984171188911, 0.00011893487019485541, 0.00011892989204543773, 0.00011892491471836417, 0.0001189199141690082, 0.00011891490986547262, 0.00011890990009156104, 0.00011890486391325292, 0.00011889978481215798, 0.00011889471799259346, 0.00011888964323562064, 0.0001188845662797712, 0.00011887940503365111, 0.00011887426643774796, 0.00011886910756927496, 0.00011886394698460556, 0.00011885874633747668, 0.00011885354054175862, 0.00011884829060761464, 0.00011884302301094947, 0.00011883775754165275, 0.00011883246754504928, 0.00011882717656520829, 0.000118821862792134, 0.00011881654387047052, 0.00011881122346501225, 0.00011880589006294174, 0.00011880054890223337, 0.00011879515296625688, 0.00011878974435545495, 0.00011878434693568365, 0.00011877889506243105, 0.00011877340959820951, 0.00011876792175634089, 0.00011876242704968671, 0.00011875684510304933, 0.0001187512711832055, 0.00011874567550699701, 0.00011874003781973104, 0.00011873437528337148, 0.00011872871340846263, 0.00011872307572119666, 0.00011871735335036504, 0.00011871164823088256, 0.00011870588163223978, 0.00011870007359460499, 0.00011869421169343142, 0.00011868837578548233, 0.00011868254667081063, 0.00011867672279411333, 0.00011867084936224524, 0.00011866496021645396, 0.00011865910500129548, 0.00011865320598737495, 0.00011864724499373685, 0.00011864123194214158, 0.00011863522014193951, 0.0001186290841856548, 0.00011862296001034324, 0.00011861681057476606, 0.00011861061371138654, 0.0001186044399809042, 0.00011859822920918309, 0.00011859194160191942, 0.00011858569479007411, 0.00011857936663767071, 0.00011857302100151658, 0.00011856665975870153, 0.00011856023827024234, 0.0001185537705159888, 0.0001185472279641759, 0.00011854063825271634, 0.00011853407249649808, 0.00011852738190486945, 0.00011852072279471835, 0.00011851401822323996, 0.0001185072655088774, 0.00011850047714768563, 0.0001184937238612576, 0.00011848689200521358, 0.00011848003637269872, 0.0001184731621123022, 0.00011846624387437317, 0.00011845928314270644, 0.00011845222855654959, 0.00011844517870780987, 0.00011843811620212176, 0.00011843102868644667, 0.00011842387005588365, 0.0001184166014993664, 0.00011840936580085921, 0.00011840205775394793, 0.00011839478142091579, 0.00011838739603790466, 0.0001183800304626602, 0.00011837257750441619, 0.00011836507034296952, 0.00011835759734455725, 0.00011835008077978452, 0.00011834259592889092, 0.00011833506652839935, 0.00011832747173367448, 0.00011831984971220895, 0.00011831225706272957, 0.00011830456932524393, 0.0001182968718626454, 0.00011828916794643336, 0.0001182814914178554, 0.00011827381358425309, 0.00011826610215968185, 0.00011825836096982946, 0.00011825061929729682, 0.00011824284655445871, 0.00011823504847984679, 0.0001182272435404493, 0.0001182193973944614, 0.00011821151626309499, 0.00011820365467133957, 0.00011819579651197693, 0.00011818788380974776, 0.00011817993024059203, 0.00011817197232731419, 0.00011816401949111734, 0.00011815600199364606, 0.00011814802913515798, 0.0001181400831637467, 0.00011813203116357716, 0.00011812397172655658, 0.0001181159247140828, 0.00011810782022690698, 0.00011809971665146049, 0.00011809159623583691, 0.00011808342234996955, 0.00011807524578254533, 0.00011806701903425373, 0.00011805876359330371, 0.00011805051705512248, 0.00011804228017054595, 0.00011803406175295765, 0.000118025843585648, 0.0001180175409671743, 0.00011800926884694061, 0.00011800092634477787, 0.00011799262136653413, 0.00011798429897604784, 0.00011797590595335386, 0.00011796748066259232, 0.00011795896570056938, 0.00011795043414864799, 0.00011794185225496581, 0.00011793327617132349, 0.00011792462675603958, 0.00011791597097652738, 0.00011790734880586116, 0.00011789866696161628, 0.00011789001339885775, 0.0001178813234741882, 0.00011787267531029747, 0.00011786400712411553, 0.00011785531130002088, 0.0001178466183541306, 0.00011783786335701457, 0.00011782906397119398, 0.00011782030547017698, 0.00011781154729094682, 0.00011780284706909891, 0.00011779405962514487, 0.00011778526744377371, 0.00011777644803566189, 0.00011776758497180441, 0.00011775873629896871, 0.00011774988524848595, 0.00011774104163485421, 0.00011773218952962575, 0.00011772325043469274, 0.00011771437380215753, 0.00011770556052587239, 0.00011769666165429229, 0.00011768775575703321, 0.00011767889490992938, 0.00011766996244738034, 0.00011766107151320855, 0.00011765211438033638], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011986194228516825, 0.00011985714612559019, 0.00011985236724344893, 0.00011984756022918489, 0.00011984276184178919, 0.0001198379534055139, 0.00011983315188969343, 0.00011982834300311458, 0.00011982350878103512, 0.000119818643156207, 0.00011981376435407453, 0.00011980889370480661, 0.00011980398226751573, 0.00011979909517031757, 0.00011979417700217339, 0.00011978922733647979, 0.00011978421813591477, 0.00011977918613576921, 0.00011977418030063085, 0.00011976911348490961, 0.00011976402794604011, 0.00011975894766861227, 0.00011975384290889057, 0.00011974875414679556, 0.00011974364741995827, 0.00011973852744471609, 0.00011973337801014065, 0.00011972824504719562, 0.0001197230995705515, 0.00011971794449533138, 0.00011971271625763194, 0.00011970750503666723, 0.00011970226539917752, 0.00011969701398269452, 0.00011969172962295067, 0.00011968643884045596, 0.00011968109219661893, 0.0001196757117089139, 0.00011967032574646551, 0.00011966490397303357, 0.00011965948824314947, 0.00011965405277100904, 0.00011964861357793915, 0.00011964316488109401, 0.00011963769765070212, 0.00011963221501518824, 0.00011962669294256208, 0.00011962114361472009, 0.00011961563239677988, 0.00011961006012715624, 0.00011960447759535133, 0.00011959890051458959, 0.00011959330727029987, 0.00011958761149899828, 0.0001195819266771834, 0.00011957621033411892, 0.00011957045097521382, 0.0001195646680109218, 0.00011955888758254987, 0.00011955312983525753, 0.00011954726261679836, 0.00011954141163296773, 0.00011953550988333512, 0.00011952956862548967, 0.0001195235856790141, 0.0001195176335664827, 0.00011951168972531679, 0.0001195057416418173, 0.00011949975016327417, 0.00011949374150209498, 0.00011948776559457517, 0.00011948174501220159, 0.0001194756956341, 0.00011946961693886625, 0.00011946354227266441, 0.00011945735429586533, 0.00011945118710413083, 0.00011944498360370883, 0.00011943868800435755, 0.00011943239143329858, 0.00011942604340913217, 0.00011941962530351084, 0.00011941323502190981, 0.00011940677352124485, 0.00011940030536082716, 0.00011939385201302675, 0.00011938734633521197, 0.00011938076678391224, 0.00011937412286290281, 0.00011936744602233269, 0.00011936077657622112, 0.00011935399979195961, 0.00011934723201376941, 0.0001193404133275761, 0.00011933353131448135, 0.00011932659455395307, 0.00011931969336740649, 0.00011931273710162376, 0.00011930573755929836, 0.00011929872192454552, 0.0001192916822341022, 0.0001192846079176847, 0.00011927742439080242, 0.00011927025989517084, 0.00011926307662899063, 0.00011925588810136875, 0.00011924862693267168, 0.00011924134358059894, 0.00011923406700677988, 0.00011922671847919106, 0.00011921941512415993, 0.00011921202379403217, 0.00011920467595374879, 0.00011919723975916579, 0.00011918974080648583, 0.00011918225661902278, 0.00011917470251600612, 0.00011916717666361317, 0.0001191596143129312, 0.00011915195730369969, 0.00011914429529372858, 0.0001191366627904911, 0.00011912893605530747, 0.00011912118820325662, 0.00011911345352851013, 0.00011910573255247208, 0.00011909802420863408, 0.00011909026727941136, 0.00011908246806905384, 0.00011907466205674244, 0.00011906682829151131, 0.00011905897284060844, 0.0001190511162046962, 0.00011904322036867355, 0.00011903529481261556, 0.00011902736567782924, 0.00011901944287099302, 0.00011901144495826208, 0.00011900338248621994, 0.00011899532726643522, 0.00011898727669188729, 0.0001189791501108375, 0.00011897106818094128, 0.00011896298762565594, 0.00011895479032324615, 0.00011894658700098869, 0.00011893836907941564, 0.00011893009541500116, 0.00011892180914208688, 0.00011891350348241906, 0.00011890515528091439, 0.00011889681608548103, 0.00011888844238257442, 0.00011888001092231047, 0.0001188715846760878, 0.00011886316414161037, 0.00011885474875007365, 0.00011884632783639321, 0.00011883782816698914, 0.00011882934477961401, 0.00011882077258763568, 0.00011881222077781874, 0.00011880362879618371, 0.00011879496265666147, 0.00011878629611423603, 0.00011877757698109416, 0.00011876883846119877, 0.00011876005009980872, 0.0001187512847513009, 0.00011874245088555052, 0.00011873361957942042, 0.00011872483479675871, 0.00011871601811364439, 0.00011870722740593576, 0.00011869838970075498, 0.00011868958849386321, 0.00011868076458219166, 0.00011867192739841501, 0.00011866306886076927, 0.00011865414875003598, 0.00011864517891630895, 0.00011863626470692238, 0.00011862733999835266, 0.00011861846652958869, 0.00011860949117371794, 0.00011860049560158711, 0.0001185914636496682, 0.00011858237958103662, 0.00011857331923629288, 0.00011856425853604633, 0.00011855519641378852, 0.00011854611440707325, 0.00011853694821729139, 0.00011852783954786501, 0.00011851880579473184, 0.00011850967520263186, 0.00011850053612586468, 0.0001184914366758113, 0.00011848228814266925, 0.00011847317011166873], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-15 03:26:39,039 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:92]: done!
[2017-12-15 03:26:39,039 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:152]: >> Executing classifier part ... 
[2017-12-15 03:26:39,040 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:97]: =======================================
[2017-12-15 03:26:39,040 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa1490413c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-15 03:26:39,187 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:110]: training ... 
[2017-12-15 09:08:21,649 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:122]: trained!
[2017-12-15 09:08:21,654 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:125]: Training history: 
{'val_loss': [0.00011902249743060738, 0.00011901771408735708, 0.00011901290046039131, 0.00011900809296525223, 0.00011900327901649964, 0.00011899847422079446, 0.00011899365928880435, 0.0001189888275702683, 0.00011898395457363365, 0.0001189790727457384, 0.00011897420734684818, 0.00011896931627652029, 0.00011896445520387514, 0.00011895957385866013, 0.00011895467592354667, 0.00011894973644217893, 0.00011894477105697191, 0.00011893984171188911, 0.00011893487019485541, 0.00011892989204543773, 0.00011892491471836417, 0.0001189199141690082, 0.00011891490986547262, 0.00011890990009156104, 0.00011890486391325292, 0.00011889978481215798, 0.00011889471799259346, 0.00011888964323562064, 0.0001188845662797712, 0.00011887940503365111, 0.00011887426643774796, 0.00011886910756927496, 0.00011886394698460556, 0.00011885874633747668, 0.00011885354054175862, 0.00011884829060761464, 0.00011884302301094947, 0.00011883775754165275, 0.00011883246754504928, 0.00011882717656520829, 0.000118821862792134, 0.00011881654387047052, 0.00011881122346501225, 0.00011880589006294174, 0.00011880054890223337, 0.00011879515296625688, 0.00011878974435545495, 0.00011878434693568365, 0.00011877889506243105, 0.00011877340959820951, 0.00011876792175634089, 0.00011876242704968671, 0.00011875684510304933, 0.0001187512711832055, 0.00011874567550699701, 0.00011874003781973104, 0.00011873437528337148, 0.00011872871340846263, 0.00011872307572119666, 0.00011871735335036504, 0.00011871164823088256, 0.00011870588163223978, 0.00011870007359460499, 0.00011869421169343142, 0.00011868837578548233, 0.00011868254667081063, 0.00011867672279411333, 0.00011867084936224524, 0.00011866496021645396, 0.00011865910500129548, 0.00011865320598737495, 0.00011864724499373685, 0.00011864123194214158, 0.00011863522014193951, 0.0001186290841856548, 0.00011862296001034324, 0.00011861681057476606, 0.00011861061371138654, 0.0001186044399809042, 0.00011859822920918309, 0.00011859194160191942, 0.00011858569479007411, 0.00011857936663767071, 0.00011857302100151658, 0.00011856665975870153, 0.00011856023827024234, 0.0001185537705159888, 0.0001185472279641759, 0.00011854063825271634, 0.00011853407249649808, 0.00011852738190486945, 0.00011852072279471835, 0.00011851401822323996, 0.0001185072655088774, 0.00011850047714768563, 0.0001184937238612576, 0.00011848689200521358, 0.00011848003637269872, 0.0001184731621123022, 0.00011846624387437317, 0.00011845928314270644, 0.00011845222855654959, 0.00011844517870780987, 0.00011843811620212176, 0.00011843102868644667, 0.00011842387005588365, 0.0001184166014993664, 0.00011840936580085921, 0.00011840205775394793, 0.00011839478142091579, 0.00011838739603790466, 0.0001183800304626602, 0.00011837257750441619, 0.00011836507034296952, 0.00011835759734455725, 0.00011835008077978452, 0.00011834259592889092, 0.00011833506652839935, 0.00011832747173367448, 0.00011831984971220895, 0.00011831225706272957, 0.00011830456932524393, 0.0001182968718626454, 0.00011828916794643336, 0.0001182814914178554, 0.00011827381358425309, 0.00011826610215968185, 0.00011825836096982946, 0.00011825061929729682, 0.00011824284655445871, 0.00011823504847984679, 0.0001182272435404493, 0.0001182193973944614, 0.00011821151626309499, 0.00011820365467133957, 0.00011819579651197693, 0.00011818788380974776, 0.00011817993024059203, 0.00011817197232731419, 0.00011816401949111734, 0.00011815600199364606, 0.00011814802913515798, 0.0001181400831637467, 0.00011813203116357716, 0.00011812397172655658, 0.0001181159247140828, 0.00011810782022690698, 0.00011809971665146049, 0.00011809159623583691, 0.00011808342234996955, 0.00011807524578254533, 0.00011806701903425373, 0.00011805876359330371, 0.00011805051705512248, 0.00011804228017054595, 0.00011803406175295765, 0.000118025843585648, 0.0001180175409671743, 0.00011800926884694061, 0.00011800092634477787, 0.00011799262136653413, 0.00011798429897604784, 0.00011797590595335386, 0.00011796748066259232, 0.00011795896570056938, 0.00011795043414864799, 0.00011794185225496581, 0.00011793327617132349, 0.00011792462675603958, 0.00011791597097652738, 0.00011790734880586116, 0.00011789866696161628, 0.00011789001339885775, 0.0001178813234741882, 0.00011787267531029747, 0.00011786400712411553, 0.00011785531130002088, 0.0001178466183541306, 0.00011783786335701457, 0.00011782906397119398, 0.00011782030547017698, 0.00011781154729094682, 0.00011780284706909891, 0.00011779405962514487, 0.00011778526744377371, 0.00011777644803566189, 0.00011776758497180441, 0.00011775873629896871, 0.00011774988524848595, 0.00011774104163485421, 0.00011773218952962575, 0.00011772325043469274, 0.00011771437380215753, 0.00011770556052587239, 0.00011769666165429229, 0.00011768775575703321, 0.00011767889490992938, 0.00011766996244738034, 0.00011766107151320855, 0.00011765211438033638], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011986194228516825, 0.00011985714612559019, 0.00011985236724344893, 0.00011984756022918489, 0.00011984276184178919, 0.0001198379534055139, 0.00011983315188969343, 0.00011982834300311458, 0.00011982350878103512, 0.000119818643156207, 0.00011981376435407453, 0.00011980889370480661, 0.00011980398226751573, 0.00011979909517031757, 0.00011979417700217339, 0.00011978922733647979, 0.00011978421813591477, 0.00011977918613576921, 0.00011977418030063085, 0.00011976911348490961, 0.00011976402794604011, 0.00011975894766861227, 0.00011975384290889057, 0.00011974875414679556, 0.00011974364741995827, 0.00011973852744471609, 0.00011973337801014065, 0.00011972824504719562, 0.0001197230995705515, 0.00011971794449533138, 0.00011971271625763194, 0.00011970750503666723, 0.00011970226539917752, 0.00011969701398269452, 0.00011969172962295067, 0.00011968643884045596, 0.00011968109219661893, 0.0001196757117089139, 0.00011967032574646551, 0.00011966490397303357, 0.00011965948824314947, 0.00011965405277100904, 0.00011964861357793915, 0.00011964316488109401, 0.00011963769765070212, 0.00011963221501518824, 0.00011962669294256208, 0.00011962114361472009, 0.00011961563239677988, 0.00011961006012715624, 0.00011960447759535133, 0.00011959890051458959, 0.00011959330727029987, 0.00011958761149899828, 0.0001195819266771834, 0.00011957621033411892, 0.00011957045097521382, 0.0001195646680109218, 0.00011955888758254987, 0.00011955312983525753, 0.00011954726261679836, 0.00011954141163296773, 0.00011953550988333512, 0.00011952956862548967, 0.0001195235856790141, 0.0001195176335664827, 0.00011951168972531679, 0.0001195057416418173, 0.00011949975016327417, 0.00011949374150209498, 0.00011948776559457517, 0.00011948174501220159, 0.0001194756956341, 0.00011946961693886625, 0.00011946354227266441, 0.00011945735429586533, 0.00011945118710413083, 0.00011944498360370883, 0.00011943868800435755, 0.00011943239143329858, 0.00011942604340913217, 0.00011941962530351084, 0.00011941323502190981, 0.00011940677352124485, 0.00011940030536082716, 0.00011939385201302675, 0.00011938734633521197, 0.00011938076678391224, 0.00011937412286290281, 0.00011936744602233269, 0.00011936077657622112, 0.00011935399979195961, 0.00011934723201376941, 0.0001193404133275761, 0.00011933353131448135, 0.00011932659455395307, 0.00011931969336740649, 0.00011931273710162376, 0.00011930573755929836, 0.00011929872192454552, 0.0001192916822341022, 0.0001192846079176847, 0.00011927742439080242, 0.00011927025989517084, 0.00011926307662899063, 0.00011925588810136875, 0.00011924862693267168, 0.00011924134358059894, 0.00011923406700677988, 0.00011922671847919106, 0.00011921941512415993, 0.00011921202379403217, 0.00011920467595374879, 0.00011919723975916579, 0.00011918974080648583, 0.00011918225661902278, 0.00011917470251600612, 0.00011916717666361317, 0.0001191596143129312, 0.00011915195730369969, 0.00011914429529372858, 0.0001191366627904911, 0.00011912893605530747, 0.00011912118820325662, 0.00011911345352851013, 0.00011910573255247208, 0.00011909802420863408, 0.00011909026727941136, 0.00011908246806905384, 0.00011907466205674244, 0.00011906682829151131, 0.00011905897284060844, 0.0001190511162046962, 0.00011904322036867355, 0.00011903529481261556, 0.00011902736567782924, 0.00011901944287099302, 0.00011901144495826208, 0.00011900338248621994, 0.00011899532726643522, 0.00011898727669188729, 0.0001189791501108375, 0.00011897106818094128, 0.00011896298762565594, 0.00011895479032324615, 0.00011894658700098869, 0.00011893836907941564, 0.00011893009541500116, 0.00011892180914208688, 0.00011891350348241906, 0.00011890515528091439, 0.00011889681608548103, 0.00011888844238257442, 0.00011888001092231047, 0.0001188715846760878, 0.00011886316414161037, 0.00011885474875007365, 0.00011884632783639321, 0.00011883782816698914, 0.00011882934477961401, 0.00011882077258763568, 0.00011881222077781874, 0.00011880362879618371, 0.00011879496265666147, 0.00011878629611423603, 0.00011877757698109416, 0.00011876883846119877, 0.00011876005009980872, 0.0001187512847513009, 0.00011874245088555052, 0.00011873361957942042, 0.00011872483479675871, 0.00011871601811364439, 0.00011870722740593576, 0.00011869838970075498, 0.00011868958849386321, 0.00011868076458219166, 0.00011867192739841501, 0.00011866306886076927, 0.00011865414875003598, 0.00011864517891630895, 0.00011863626470692238, 0.00011862733999835266, 0.00011861846652958869, 0.00011860949117371794, 0.00011860049560158711, 0.0001185914636496682, 0.00011858237958103662, 0.00011857331923629288, 0.00011856425853604633, 0.00011855519641378852, 0.00011854611440707325, 0.00011853694821729139, 0.00011852783954786501, 0.00011851880579473184, 0.00011850967520263186, 0.00011850053612586468, 0.0001184914366758113, 0.00011848228814266925, 0.00011847317011166873], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-15 09:08:21,655 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:129]: evaluating model ... 
[2017-12-15 09:08:24,839 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:133]: evaluated! 
[2017-12-15 09:08:24,839 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:135]: generating reports ... 
[2017-12-15 09:08:26,049 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:138]: done!
[2017-12-15 09:08:26,050 AE_BIGRAMA_1L_MINIDS_OVER_F1_7.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_7 finished!
