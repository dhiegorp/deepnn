[2018-01-18 00:19:28,515 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_5
[2018-01-18 00:19:28,515 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:146]: >> Printing header log
[2018-01-18 00:19:28,516 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_UNDER_F0_5
	layers = 9216,4608
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f37bb09fbe0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f37bb09f470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,516 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:148]: >> Loading dataset... 
[2018-01-18 00:22:01,355 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:22:01,356 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:22:01,356 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:57]: =======================================
[2018-01-18 00:22:01,356 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f37bb09fbe0>, 'discard_decoder_function': True}
[2018-01-18 00:22:01,400 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:73]: training and evaluate autoencoder
[2018-01-19 03:15:02,453 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:85]: trained and evaluated!
[2018-01-19 03:15:02,455 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:88]: Training history: 
{'val_loss': [0.00011753226332965871, 0.00011751163840177169, 0.0001174910412861725, 0.00011747046190187611, 0.00011744989461476173, 0.00011742935595550557, 0.00011740882080721316, 0.00011738830156388063, 0.00011736781188698081, 0.00011734733665771016, 0.00011732687708204329, 0.00011730644087447402, 0.00011728602230996551, 0.000117265619845619, 0.0001172452268659552, 0.00011722485078597979, 0.00011720449170997884, 0.00011718415695401997, 0.00011716384264347525, 0.00011714353473716371, 0.00011712325639193685, 0.00011710298615963004, 0.0001170827412634858, 0.0001170625228292587, 0.00011704231902984087, 0.00011702213294300784, 0.00011700196520249794, 0.00011698181581633315, 0.00011696168948540779, 0.00011694157987233876, 0.00011692148293403601, 0.00011690141530278783, 0.00011688136424767387, 0.00011686132849586952, 0.00011684131413072779, 0.00011682131506354766, 0.0001168013348400549, 0.0001167813763080609, 0.00011676143533088563, 0.00011674151712015766, 0.00011672161162698002, 0.00011670171661053958, 0.00011668184795707823, 0.00011666199124838081, 0.00011664215555733385, 0.0001166223320142749, 0.00011660253111733321, 0.00011658273804451941, 0.00011656296861522534, 0.00011654320659291496, 0.00011652347676290657, 0.00011650376276833404, 0.0001164840696684079, 0.00011646439665023173, 0.00011644474291427914, 0.0001164251017595028, 0.00011640546899574263, 0.00011638585485640169, 0.00011636625710066692, 0.00011634666004284647, 0.00011632708057193278, 0.00011630751498175996, 0.00011628795837890562, 0.00011626840788347032, 0.00011624885607510035, 0.00011622933014571524, 0.0001162098124121442, 0.0001161903138618587, 0.0001161708328476739, 0.00011615136673035051, 0.00011613190345549052, 0.00011611244455262272, 0.00011609298108256064, 0.00011607352200588273, 0.0001160540811712419, 0.00011603463005239194, 0.00011601519751250323, 0.00011599575737577674, 0.00011597630091427214, 0.00011595684985157622, 0.00011593740718524448, 0.00011591794165085337, 0.00011589846037729044, 0.00011587897116729157, 0.00011585945936198148, 0.00011583994422219174, 0.00011582042524253608, 0.00011580088313811694, 0.000115781317272522, 0.0001157617011651161, 0.00011574203662887214, 0.00011572233721295485, 0.0001157026020135518, 0.00011568279090994704, 0.00011566291701811709, 0.00011564300031017787, 0.00011562297001066222, 0.00011560279504500072, 0.00011558248284959106, 0.00011556198096587515, 0.00011554127270006275], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011768728000307728, 0.00011766656168653182, 0.0001176458647664995, 0.00011762519473366245, 0.00011760453795955461, 0.00011758388899011026, 0.00011756326343733569, 0.00011754265160054947, 0.00011752205329845548, 0.00011750148252121894, 0.0001174809335861446, 0.00011746039385341065, 0.00011743987469287305, 0.000117419369833294, 0.00011739887743313372, 0.00011737839402633211, 0.00011735792896080233, 0.00011733747370044484, 0.00011731704761982997, 0.00011729663485063625, 0.00011727623221616293, 0.00011725586194081226, 0.00011723550004527138, 0.00011721516153960774, 0.00011719484944691163, 0.00011717455484259185, 0.00011715428027819018, 0.00011713402137402135, 0.00011711378009754998, 0.00011709357095425094, 0.00011707337779448124, 0.00011705319806312674, 0.00011703304627548621, 0.00011701290969617787, 0.00011699278952818622, 0.00011697269083351294, 0.0001169526056172676, 0.00011693254034538036, 0.00011691248916100452, 0.00011689246409130605, 0.00011687245730840127, 0.00011685245831944298, 0.00011683247886670328, 0.00011681252938676505, 0.00011679259448732073, 0.00011677267876239586, 0.00011675278330155327, 0.0001167329121915466, 0.00011671305168512957, 0.00011669322009767456, 0.00011667339409199627, 0.00011665359899417869, 0.00011663381542607914, 0.00011661405262218906, 0.00011659430697980646, 0.00011657457801220043, 0.00011655486208719718, 0.00011653515807147279, 0.00011651546944537669, 0.00011649580005899518, 0.0001164761349540597, 0.00011645649317648558, 0.00011643686255621334, 0.0001164172463128118, 0.00011639764193224873, 0.00011637804373897355, 0.0001163584705440204, 0.00011633890335684518, 0.00011631935470652723, 0.00011629981971057483, 0.00011628029560846444, 0.00011626077119913307, 0.00011624125244302517, 0.00011622172964928325, 0.00011620221648834836, 0.0001161827169246216, 0.00011616321024658547, 0.00011614371694873801, 0.00011612422699817042, 0.00011610471538048517, 0.00011608520295187938, 0.0001160656929140602, 0.00011604615711254579, 0.00011602660873640471, 0.00011600704519479952, 0.00011598745970028969, 0.00011596786508649629, 0.00011594826054875039, 0.0001159286200982995, 0.0001159089468198567, 0.00011588920908126997, 0.00011586944050269695, 0.00011584963378763908, 0.00011582977531477495, 0.00011580983791558773, 0.00011578982125785008, 0.00011576975840622124, 0.00011574955638348316, 0.00011572920763860827, 0.0001157086952815867, 0.00011568802313839151], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154]}
[2018-01-19 03:15:02,455 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:92]: done!
[2018-01-19 03:15:02,455 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:152]: >> Executing classifier part ... 
[2018-01-19 03:15:02,455 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:97]: =======================================
[2018-01-19 03:15:02,455 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f37bb09f470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-19 03:15:02,715 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:110]: training ... 
[2018-01-21 12:42:14,010 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:122]: trained!
[2018-01-21 12:42:14,012 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:125]: Training history: 
{'val_loss': [0.00011753226332965871, 0.00011751163840177169, 0.0001174910412861725, 0.00011747046190187611, 0.00011744989461476173, 0.00011742935595550557, 0.00011740882080721316, 0.00011738830156388063, 0.00011736781188698081, 0.00011734733665771016, 0.00011732687708204329, 0.00011730644087447402, 0.00011728602230996551, 0.000117265619845619, 0.0001172452268659552, 0.00011722485078597979, 0.00011720449170997884, 0.00011718415695401997, 0.00011716384264347525, 0.00011714353473716371, 0.00011712325639193685, 0.00011710298615963004, 0.0001170827412634858, 0.0001170625228292587, 0.00011704231902984087, 0.00011702213294300784, 0.00011700196520249794, 0.00011698181581633315, 0.00011696168948540779, 0.00011694157987233876, 0.00011692148293403601, 0.00011690141530278783, 0.00011688136424767387, 0.00011686132849586952, 0.00011684131413072779, 0.00011682131506354766, 0.0001168013348400549, 0.0001167813763080609, 0.00011676143533088563, 0.00011674151712015766, 0.00011672161162698002, 0.00011670171661053958, 0.00011668184795707823, 0.00011666199124838081, 0.00011664215555733385, 0.0001166223320142749, 0.00011660253111733321, 0.00011658273804451941, 0.00011656296861522534, 0.00011654320659291496, 0.00011652347676290657, 0.00011650376276833404, 0.0001164840696684079, 0.00011646439665023173, 0.00011644474291427914, 0.0001164251017595028, 0.00011640546899574263, 0.00011638585485640169, 0.00011636625710066692, 0.00011634666004284647, 0.00011632708057193278, 0.00011630751498175996, 0.00011628795837890562, 0.00011626840788347032, 0.00011624885607510035, 0.00011622933014571524, 0.0001162098124121442, 0.0001161903138618587, 0.0001161708328476739, 0.00011615136673035051, 0.00011613190345549052, 0.00011611244455262272, 0.00011609298108256064, 0.00011607352200588273, 0.0001160540811712419, 0.00011603463005239194, 0.00011601519751250323, 0.00011599575737577674, 0.00011597630091427214, 0.00011595684985157622, 0.00011593740718524448, 0.00011591794165085337, 0.00011589846037729044, 0.00011587897116729157, 0.00011585945936198148, 0.00011583994422219174, 0.00011582042524253608, 0.00011580088313811694, 0.000115781317272522, 0.0001157617011651161, 0.00011574203662887214, 0.00011572233721295485, 0.0001157026020135518, 0.00011568279090994704, 0.00011566291701811709, 0.00011564300031017787, 0.00011562297001066222, 0.00011560279504500072, 0.00011558248284959106, 0.00011556198096587515, 0.00011554127270006275], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011768728000307728, 0.00011766656168653182, 0.0001176458647664995, 0.00011762519473366245, 0.00011760453795955461, 0.00011758388899011026, 0.00011756326343733569, 0.00011754265160054947, 0.00011752205329845548, 0.00011750148252121894, 0.0001174809335861446, 0.00011746039385341065, 0.00011743987469287305, 0.000117419369833294, 0.00011739887743313372, 0.00011737839402633211, 0.00011735792896080233, 0.00011733747370044484, 0.00011731704761982997, 0.00011729663485063625, 0.00011727623221616293, 0.00011725586194081226, 0.00011723550004527138, 0.00011721516153960774, 0.00011719484944691163, 0.00011717455484259185, 0.00011715428027819018, 0.00011713402137402135, 0.00011711378009754998, 0.00011709357095425094, 0.00011707337779448124, 0.00011705319806312674, 0.00011703304627548621, 0.00011701290969617787, 0.00011699278952818622, 0.00011697269083351294, 0.0001169526056172676, 0.00011693254034538036, 0.00011691248916100452, 0.00011689246409130605, 0.00011687245730840127, 0.00011685245831944298, 0.00011683247886670328, 0.00011681252938676505, 0.00011679259448732073, 0.00011677267876239586, 0.00011675278330155327, 0.0001167329121915466, 0.00011671305168512957, 0.00011669322009767456, 0.00011667339409199627, 0.00011665359899417869, 0.00011663381542607914, 0.00011661405262218906, 0.00011659430697980646, 0.00011657457801220043, 0.00011655486208719718, 0.00011653515807147279, 0.00011651546944537669, 0.00011649580005899518, 0.0001164761349540597, 0.00011645649317648558, 0.00011643686255621334, 0.0001164172463128118, 0.00011639764193224873, 0.00011637804373897355, 0.0001163584705440204, 0.00011633890335684518, 0.00011631935470652723, 0.00011629981971057483, 0.00011628029560846444, 0.00011626077119913307, 0.00011624125244302517, 0.00011622172964928325, 0.00011620221648834836, 0.0001161827169246216, 0.00011616321024658547, 0.00011614371694873801, 0.00011612422699817042, 0.00011610471538048517, 0.00011608520295187938, 0.0001160656929140602, 0.00011604615711254579, 0.00011602660873640471, 0.00011600704519479952, 0.00011598745970028969, 0.00011596786508649629, 0.00011594826054875039, 0.0001159286200982995, 0.0001159089468198567, 0.00011588920908126997, 0.00011586944050269695, 0.00011584963378763908, 0.00011582977531477495, 0.00011580983791558773, 0.00011578982125785008, 0.00011576975840622124, 0.00011574955638348316, 0.00011572920763860827, 0.0001157086952815867, 0.00011568802313839151], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154]}
[2018-01-21 12:42:14,012 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:129]: evaluating model ... 
[2018-01-21 12:43:02,485 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:133]: evaluated! 
[2018-01-21 12:43:02,486 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:135]: generating reports ... 
[2018-01-21 12:43:07,438 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:138]: done!
[2018-01-21 12:43:07,440 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_5 finished!
[2018-05-03 21:43:55,188 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_5
[2018-05-03 21:43:55,188 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:146]: >> Printing header log
[2018-05-03 21:43:55,188 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_UNDER_F0_5
	layers = 9216,4608
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f852576a630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f852576ae10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-05-03 21:43:55,189 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:148]: >> Loading dataset... 
[2018-05-03 21:46:40,990 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-03 21:46:40,991 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:150]: >> Executing autoencoder part ... 
[2018-05-03 21:46:40,991 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:57]: =======================================
[2018-05-03 21:46:40,991 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f852576a630>, 'discard_decoder_function': True}
[2018-05-03 21:46:41,477 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:73]: training and evaluate autoencoder
[2018-05-04 19:54:27,544 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:85]: trained and evaluated!
[2018-05-04 19:54:27,545 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:88]: Training history: 
{'val_loss': [0.00011808136471862761, 0.00011805779531150399, 0.00011803417561176339, 0.00011801048191171003, 0.00011798671566600063, 0.00011796285512430839, 0.0001179389085118614, 0.00011791485878457519, 0.00011789069671714517, 0.00011786642994117115, 0.0001178420389043554, 0.00011781753854366935, 0.00011779292018465268, 0.00011776811017461282, 0.00011774309359262234, 0.00011771786523507467, 0.00011769246227593626, 0.00011766678632265425, 0.00011764087045797308, 0.00011761464598145061, 0.00011758804202135563, 0.000117561013969998, 0.00011753353567564471, 0.00011750545430307587, 0.00011747678313673005, 0.00011744765074259114, 0.00011741792189641193, 0.00011738743539869639, 0.00011735593455066498, 0.0001173233315381141, 0.00011728966557794723, 0.00011725514702315284, 0.00011721978639325217, 0.00011718347465316705, 0.00011714626312767898, 0.00011710813164946995, 0.00011706897064331353, 0.000117028672004684, 0.00011698730557849607, 0.00011694505748059019, 0.00011690194454647872, 0.00011685808889245432, 0.00011681368853366335, 0.00011676857825960774, 0.00011672294472092821, 0.00011667672228158816, 0.0001166299576938268, 0.00011658270786574042, 0.00011653502840586061, 0.00011648687808108692, 0.00011643839546886417, 0.00011638969545498544, 0.00011634082742290724, 0.00011629180643260506, 0.00011624258082772125, 0.00011619326155791891, 0.00011614383819459286, 0.00011609434945193434, 0.00011604484689538496, 0.00011599530956077429, 0.0001159457208158141, 0.00011589614835017399, 0.00011584657545669366, 0.00011579700195354104, 0.0001157474270117757, 0.00011569788930280486, 0.00011564836624201328, 0.00011559891291917636, 0.00011554947269894593, 0.00011550007620398524, 0.00011545073456883579, 0.00011540142023523989, 0.00011535217704077534, 0.0001153030049373101, 0.00011525387427016945, 0.00011520477966461071, 0.00011515576612407623, 0.00011510679513759889, 0.00011505789089954272, 0.00011500906848592717, 0.00011496031108263193, 0.00011491163089914704, 0.00011486302302600607, 0.00011481447414668241, 0.00011476599802693489, 0.00011471757676165061, 0.0001146692381764874, 0.0001146209885660444, 0.00011457280091221216, 0.00011452467087776055, 0.00011447662327742188, 0.00011442865917544869, 0.00011438077302596222, 0.00011433293560747596, 0.00011428519730352293, 0.00011423755294793258, 0.00011418996829744387, 0.00011414247561655686, 0.00011409504605814518, 0.00011404769514211259, 0.00011400042824854972], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.000735023888276369, 0.0011025358324145535, 0.0033076074972436605, 0.004410143329658214, 0.005512679162072767, 0.00735023888276369, 0.008820286659316428, 0.01139287026828372, 0.01396545387725101, 0.01727306137449467, 0.02058066887173833, 0.02388827636898199, 0.029033443586916573, 0.03270856302829842, 0.03895626607864756, 0.047409040793825796, 0.05880191106210952, 0.06651966188901139, 0.07460492466005145, 0.08599779492833518, 0.09481808158765159, 0.10915104740904079, 0.1278941565600882, 0.1444321940463065, 0.15803013597941934, 0.17162807791253215], 'loss': [0.00011818148037274687, 0.00011815769076080283, 0.00011813385101557285, 0.00011810992861360675, 0.00011808592479361242, 0.00011806184569107887, 0.00011803764505495751, 0.00011801335647414801, 0.00011798897628164634, 0.00011796445752533276, 0.00011793984517557298, 0.00011791512726325153, 0.00011789030883697383, 0.00011786531536439143, 0.00011784010442400114, 0.0001178146526428943, 0.0001177890068803099, 0.00011776315445266504, 0.0001177370204793084, 0.00011771059493715513, 0.00011768383605129504, 0.00011765668244719035, 0.00011762908768445862, 0.00011760102089810718, 0.00011757232417476015, 0.00011754311190422419, 0.00011751336611228514, 0.00011748297474723094, 0.00011745173727323852, 0.00011741946391882963, 0.00011738613122178717, 0.0001173518120845808, 0.00011731661688171026, 0.00011728047063339192, 0.00011724344020484567, 0.00011720552531385687, 0.00011716673458047499, 0.00011712692800480858, 0.00011708598576799162, 0.00011704401624312201, 0.0001170011456105051, 0.00011695758050751573, 0.0001169133645211321, 0.00011686840751950267, 0.00011682276674218504, 0.00011677661694701764, 0.00011672999325364663, 0.00011668286955453931, 0.00011663534689325092, 0.00011658748051865415, 0.0001165392537756203, 0.0001164907798813364, 0.00011644211283614331, 0.00011639326801627307, 0.00011634421027171465, 0.00011629495629599939, 0.00011624562707257518, 0.00011619624913854826, 0.0001161468232307132, 0.00011609735815577401, 0.00011604787935145021, 0.0001159983833088137, 0.0001159489235003925, 0.00011589945940695295, 0.00011585000442654535, 0.000115800574711492, 0.00011575116807820181, 0.00011570178290215449, 0.0001156524487301503, 0.00011560313002904505, 0.00011555386296785894, 0.00011550465965234936, 0.0001154554819710378, 0.00011540638260607277, 0.00011535735066718457, 0.0001153083541730252, 0.00011525940009947596, 0.00011521052538450259, 0.00011516170436711454, 0.00011511294622018041, 0.00011506428603030225, 0.00011501568106429042, 0.00011496715422707742, 0.00011491870451572961, 0.0001148703182267618, 0.0001148220104363297, 0.00011477376447054985, 0.000114725599252985, 0.0001146775163777906, 0.00011462949915947308, 0.00011458153856537805, 0.00011453366512916389, 0.00011448588266340738, 0.00011443817272145279, 0.00011439051257073285, 0.0001143429489668888, 0.00011429548367018977, 0.00011424807523259439, 0.00011420076378127236, 0.00011415351172719949, 0.00011410634184045257], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0004909782742113662, 0.0011047011169755738, 0.001841168528292623, 0.0028231250767153555, 0.004173315330796613, 0.006259972996194918, 0.008346630662507742, 0.010801522033564574, 0.013624647109365411, 0.0176752178725237, 0.02172578863476747, 0.026021848535031443, 0.032404566097950165, 0.03915551737018549, 0.04713391432520567, 0.05449858842282935, 0.06333619737326623, 0.07119184976247712, 0.07966122497616186, 0.09119921442012897, 0.10236897017489888, 0.1151344053245138, 0.13072296553072468, 0.14827543880085836, 0.16361850986630547, 0.17748864611277657]}
[2018-05-04 19:54:27,546 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:92]: done!
[2018-05-04 19:54:27,546 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:152]: >> Executing classifier part ... 
[2018-05-04 19:54:27,546 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:97]: =======================================
[2018-05-04 19:54:27,546 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f852576ae10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-05-04 19:54:27,796 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:110]: training ... 
[2018-05-05 18:58:52,794 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:122]: trained!
[2018-05-05 18:58:52,798 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:125]: Training history: 
{'val_loss': [0.00011808136471862761, 0.00011805779531150399, 0.00011803417561176339, 0.00011801048191171003, 0.00011798671566600063, 0.00011796285512430839, 0.0001179389085118614, 0.00011791485878457519, 0.00011789069671714517, 0.00011786642994117115, 0.0001178420389043554, 0.00011781753854366935, 0.00011779292018465268, 0.00011776811017461282, 0.00011774309359262234, 0.00011771786523507467, 0.00011769246227593626, 0.00011766678632265425, 0.00011764087045797308, 0.00011761464598145061, 0.00011758804202135563, 0.000117561013969998, 0.00011753353567564471, 0.00011750545430307587, 0.00011747678313673005, 0.00011744765074259114, 0.00011741792189641193, 0.00011738743539869639, 0.00011735593455066498, 0.0001173233315381141, 0.00011728966557794723, 0.00011725514702315284, 0.00011721978639325217, 0.00011718347465316705, 0.00011714626312767898, 0.00011710813164946995, 0.00011706897064331353, 0.000117028672004684, 0.00011698730557849607, 0.00011694505748059019, 0.00011690194454647872, 0.00011685808889245432, 0.00011681368853366335, 0.00011676857825960774, 0.00011672294472092821, 0.00011667672228158816, 0.0001166299576938268, 0.00011658270786574042, 0.00011653502840586061, 0.00011648687808108692, 0.00011643839546886417, 0.00011638969545498544, 0.00011634082742290724, 0.00011629180643260506, 0.00011624258082772125, 0.00011619326155791891, 0.00011614383819459286, 0.00011609434945193434, 0.00011604484689538496, 0.00011599530956077429, 0.0001159457208158141, 0.00011589614835017399, 0.00011584657545669366, 0.00011579700195354104, 0.0001157474270117757, 0.00011569788930280486, 0.00011564836624201328, 0.00011559891291917636, 0.00011554947269894593, 0.00011550007620398524, 0.00011545073456883579, 0.00011540142023523989, 0.00011535217704077534, 0.0001153030049373101, 0.00011525387427016945, 0.00011520477966461071, 0.00011515576612407623, 0.00011510679513759889, 0.00011505789089954272, 0.00011500906848592717, 0.00011496031108263193, 0.00011491163089914704, 0.00011486302302600607, 0.00011481447414668241, 0.00011476599802693489, 0.00011471757676165061, 0.0001146692381764874, 0.0001146209885660444, 0.00011457280091221216, 0.00011452467087776055, 0.00011447662327742188, 0.00011442865917544869, 0.00011438077302596222, 0.00011433293560747596, 0.00011428519730352293, 0.00011423755294793258, 0.00011418996829744387, 0.00011414247561655686, 0.00011409504605814518, 0.00011404769514211259, 0.00011400042824854972], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.000735023888276369, 0.0011025358324145535, 0.0033076074972436605, 0.004410143329658214, 0.005512679162072767, 0.00735023888276369, 0.008820286659316428, 0.01139287026828372, 0.01396545387725101, 0.01727306137449467, 0.02058066887173833, 0.02388827636898199, 0.029033443586916573, 0.03270856302829842, 0.03895626607864756, 0.047409040793825796, 0.05880191106210952, 0.06651966188901139, 0.07460492466005145, 0.08599779492833518, 0.09481808158765159, 0.10915104740904079, 0.1278941565600882, 0.1444321940463065, 0.15803013597941934, 0.17162807791253215], 'loss': [0.00011818148037274687, 0.00011815769076080283, 0.00011813385101557285, 0.00011810992861360675, 0.00011808592479361242, 0.00011806184569107887, 0.00011803764505495751, 0.00011801335647414801, 0.00011798897628164634, 0.00011796445752533276, 0.00011793984517557298, 0.00011791512726325153, 0.00011789030883697383, 0.00011786531536439143, 0.00011784010442400114, 0.0001178146526428943, 0.0001177890068803099, 0.00011776315445266504, 0.0001177370204793084, 0.00011771059493715513, 0.00011768383605129504, 0.00011765668244719035, 0.00011762908768445862, 0.00011760102089810718, 0.00011757232417476015, 0.00011754311190422419, 0.00011751336611228514, 0.00011748297474723094, 0.00011745173727323852, 0.00011741946391882963, 0.00011738613122178717, 0.0001173518120845808, 0.00011731661688171026, 0.00011728047063339192, 0.00011724344020484567, 0.00011720552531385687, 0.00011716673458047499, 0.00011712692800480858, 0.00011708598576799162, 0.00011704401624312201, 0.0001170011456105051, 0.00011695758050751573, 0.0001169133645211321, 0.00011686840751950267, 0.00011682276674218504, 0.00011677661694701764, 0.00011672999325364663, 0.00011668286955453931, 0.00011663534689325092, 0.00011658748051865415, 0.0001165392537756203, 0.0001164907798813364, 0.00011644211283614331, 0.00011639326801627307, 0.00011634421027171465, 0.00011629495629599939, 0.00011624562707257518, 0.00011619624913854826, 0.0001161468232307132, 0.00011609735815577401, 0.00011604787935145021, 0.0001159983833088137, 0.0001159489235003925, 0.00011589945940695295, 0.00011585000442654535, 0.000115800574711492, 0.00011575116807820181, 0.00011570178290215449, 0.0001156524487301503, 0.00011560313002904505, 0.00011555386296785894, 0.00011550465965234936, 0.0001154554819710378, 0.00011540638260607277, 0.00011535735066718457, 0.0001153083541730252, 0.00011525940009947596, 0.00011521052538450259, 0.00011516170436711454, 0.00011511294622018041, 0.00011506428603030225, 0.00011501568106429042, 0.00011496715422707742, 0.00011491870451572961, 0.0001148703182267618, 0.0001148220104363297, 0.00011477376447054985, 0.000114725599252985, 0.0001146775163777906, 0.00011462949915947308, 0.00011458153856537805, 0.00011453366512916389, 0.00011448588266340738, 0.00011443817272145279, 0.00011439051257073285, 0.0001143429489668888, 0.00011429548367018977, 0.00011424807523259439, 0.00011420076378127236, 0.00011415351172719949, 0.00011410634184045257], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0004909782742113662, 0.0011047011169755738, 0.001841168528292623, 0.0028231250767153555, 0.004173315330796613, 0.006259972996194918, 0.008346630662507742, 0.010801522033564574, 0.013624647109365411, 0.0176752178725237, 0.02172578863476747, 0.026021848535031443, 0.032404566097950165, 0.03915551737018549, 0.04713391432520567, 0.05449858842282935, 0.06333619737326623, 0.07119184976247712, 0.07966122497616186, 0.09119921442012897, 0.10236897017489888, 0.1151344053245138, 0.13072296553072468, 0.14827543880085836, 0.16361850986630547, 0.17748864611277657]}
[2018-05-05 18:58:52,798 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:129]: evaluating model ... 
[2018-05-05 18:59:29,749 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:133]: evaluated! 
[2018-05-05 18:59:29,749 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:135]: generating reports ... 
[2018-05-05 18:59:35,667 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:138]: done!
[2018-05-05 18:59:35,667 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_5 finished!
[2018-05-06 02:23:43,678 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_5
[2018-05-06 02:23:43,679 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:146]: >> Printing header log
[2018-05-06 02:23:43,679 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_UNDER_F0_5
	layers = 9216,4608
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa4457d8630>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa4457d8e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-05-06 02:23:43,679 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:148]: >> Loading dataset... 
[2018-05-06 02:29:10,627 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-06 02:29:10,628 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:150]: >> Executing autoencoder part ... 
[2018-05-06 02:29:10,628 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:57]: =======================================
[2018-05-06 02:29:10,628 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa4457d8630>, 'discard_decoder_function': True}
[2018-05-06 02:29:11,403 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:73]: training and evaluate autoencoder
[2018-05-07 12:22:11,711 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:85]: trained and evaluated!
[2018-05-07 12:22:11,902 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:88]: Training history: 
{'val_loss': [0.00011738942021896631, 0.0001173686183417154, 0.00011734783556218197, 0.00011732708660876536, 0.00011730636381510374, 0.00011728566885779593, 0.00011726500410333315, 0.00011724437109996211, 0.00011722375539203168, 0.00011720318777066713, 0.00011718264395058841, 0.00011716212180061645, 0.00011714163397679955, 0.00011712118129470809, 0.00011710074943773899, 0.00011708034606155803, 0.00011705997942348131, 0.00011703963826863726, 0.0001170193202519267, 0.00011699904233988806, 0.0001169787921732872, 0.00011695857336202592, 0.00011693838455840755, 0.00011691822820646929, 0.00011689810153327179, 0.00011687799780567966, 0.00011685792602170742, 0.0001168378857241008, 0.00011681787641549559, 0.00011679789798090971, 0.00011677795013957303, 0.00011675803787582401, 0.00011673815699682859, 0.00011671829882277846, 0.00011669848284714328, 0.00011667868458409289, 0.00011665892351907498, 0.00011663918396104975, 0.00011661947186501819, 0.00011659979594555057, 0.0001165801466992462, 0.00011656052086917148, 0.00011654093012199417, 0.00011652138133257171, 0.00011650184571260578, 0.0001164823470045542, 0.0001164628677766023, 0.00011644341083912545, 0.0001164239945277508, 0.00011640460144007768, 0.00011638524573494313, 0.00011636591392201045, 0.0001163466164111668, 0.00011632734628477075, 0.00011630810165765138, 0.00011628888958649818, 0.00011626970178992903, 0.00011625054654665206, 0.00011623142157574411, 0.00011621232415239787, 0.00011619325364287498, 0.00011617420012395653, 0.00011615518250350592, 0.00011613619114174834, 0.00011611723121287639, 0.0001160983115063324, 0.00011607940204656151, 0.0001160605208991167, 0.00011604167798454287, 0.00011602286020558151, 0.00011600406567973572, 0.00011598530045292248, 0.00011596656352773929, 0.00011594784724852036, 0.00011592916401728385, 0.00011591051029365199, 0.00011589187480403519, 0.00011587327613006867, 0.00011585469609389142, 0.00011583614267472339, 0.00011581761325739129, 0.00011579911537723083, 0.0001157806334207483, 0.00011576218047718018, 0.00011574375229219035, 0.00011572535284736681, 0.00011570697042790972, 0.0001156886195536463, 0.00011567029789819539, 0.00011565200192117924, 0.00011563372964116285, 0.00011561548325350133, 0.00011559726372083515, 0.00011557905898609232, 0.00011556089174084811, 0.00011554273460065492, 0.00011552460639315611, 0.00011550649931561578, 0.00011548841953160702, 0.00011547036723633191, 0.0001154523336670881], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535], 'loss': [0.00011750795225771803, 0.0001174870262419205, 0.00011746612973987912, 0.00011744525893991017, 0.00011742441683563218, 0.000117403599218832, 0.0001173828099431683, 0.00011736205440287013, 0.00011734133281942239, 0.00011732062587005361, 0.000117299965537898, 0.00011727933079885855, 0.00011725872037850398, 0.00011723814039803397, 0.00011721760137976745, 0.00011719708113859787, 0.00011717658924124403, 0.0001171561316034962, 0.00011713570019027509, 0.00011711528867050629, 0.0001170949194641775, 0.00011707457943133975, 0.00011705427075558409, 0.00011703399274209094, 0.00011701374968659569, 0.00011699353210275714, 0.00011697334099797436, 0.0001169531783575737, 0.0001169330522157413, 0.0001169129520403343, 0.00011689288671932742, 0.00011687284572861553, 0.0001168528429360113, 0.00011683287195506907, 0.00011681291900728457, 0.000116793007651328, 0.0001167731120145478, 0.0001167532550563546, 0.00011673342333672311, 0.00011671361592059409, 0.00011669384535401546, 0.00011667410096016468, 0.00011665438037147534, 0.00011663469581159195, 0.00011661505153070259, 0.00011659542091043035, 0.00011657582679408488, 0.0001165562577073194, 0.00011653670489880107, 0.00011651719530484479, 0.0001164977056034477, 0.00011647825732597871, 0.00011645882904288053, 0.0001164394389302044, 0.0001164200764057947, 0.00011640073520198597, 0.00011638142752009563, 0.00011636214741486163, 0.00011634289807012942, 0.00011632367734874833, 0.00011630448509710786, 0.00011628531818137527, 0.00011626617235136249, 0.00011624705842678555, 0.00011622797463844448, 0.00011620892278501104, 0.00011618990677640819, 0.00011617090277443037, 0.00011615192501394789, 0.00011613298950349645, 0.00011611407363643371, 0.00011609518241403163, 0.0001160763222093396, 0.00011605748712710832, 0.00011603866766581416, 0.00011601988714745993, 0.0001160011325106881, 0.00011598239852916944, 0.00011596370096673457, 0.00011594502007907625, 0.0001159263667502126, 0.00011590773505363631, 0.00011588913246178358, 0.00011587054794059813, 0.00011585199298050229, 0.00011583346061543868, 0.00011581495222343636, 0.00011579645983996972, 0.00011577799890914519, 0.00011575956945775528, 0.00011574116379545131, 0.00011572278483904651, 0.00011570442733452606, 0.00011568610182653604, 0.0001156677875392569, 0.0001156495102926482, 0.00011563124738629375, 0.00011561301163863219, 0.00011559479596661213, 0.00011557661272426837, 0.00011555845472316557], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0003682337056585246, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0007364674113170492, 0.0007364674113170492]}
[2018-05-07 12:22:11,902 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:92]: done!
[2018-05-07 12:22:11,903 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:152]: >> Executing classifier part ... 
[2018-05-07 12:22:11,903 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:97]: =======================================
[2018-05-07 12:22:11,903 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa4457d8e10>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-05-07 12:22:13,295 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:110]: training ... 
[2018-05-08 21:05:04,446 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:122]: trained!
[2018-05-08 21:05:04,449 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:125]: Training history: 
{'val_loss': [0.00011738942021896631, 0.0001173686183417154, 0.00011734783556218197, 0.00011732708660876536, 0.00011730636381510374, 0.00011728566885779593, 0.00011726500410333315, 0.00011724437109996211, 0.00011722375539203168, 0.00011720318777066713, 0.00011718264395058841, 0.00011716212180061645, 0.00011714163397679955, 0.00011712118129470809, 0.00011710074943773899, 0.00011708034606155803, 0.00011705997942348131, 0.00011703963826863726, 0.0001170193202519267, 0.00011699904233988806, 0.0001169787921732872, 0.00011695857336202592, 0.00011693838455840755, 0.00011691822820646929, 0.00011689810153327179, 0.00011687799780567966, 0.00011685792602170742, 0.0001168378857241008, 0.00011681787641549559, 0.00011679789798090971, 0.00011677795013957303, 0.00011675803787582401, 0.00011673815699682859, 0.00011671829882277846, 0.00011669848284714328, 0.00011667868458409289, 0.00011665892351907498, 0.00011663918396104975, 0.00011661947186501819, 0.00011659979594555057, 0.0001165801466992462, 0.00011656052086917148, 0.00011654093012199417, 0.00011652138133257171, 0.00011650184571260578, 0.0001164823470045542, 0.0001164628677766023, 0.00011644341083912545, 0.0001164239945277508, 0.00011640460144007768, 0.00011638524573494313, 0.00011636591392201045, 0.0001163466164111668, 0.00011632734628477075, 0.00011630810165765138, 0.00011628888958649818, 0.00011626970178992903, 0.00011625054654665206, 0.00011623142157574411, 0.00011621232415239787, 0.00011619325364287498, 0.00011617420012395653, 0.00011615518250350592, 0.00011613619114174834, 0.00011611723121287639, 0.0001160983115063324, 0.00011607940204656151, 0.0001160605208991167, 0.00011604167798454287, 0.00011602286020558151, 0.00011600406567973572, 0.00011598530045292248, 0.00011596656352773929, 0.00011594784724852036, 0.00011592916401728385, 0.00011591051029365199, 0.00011589187480403519, 0.00011587327613006867, 0.00011585469609389142, 0.00011583614267472339, 0.00011581761325739129, 0.00011579911537723083, 0.0001157806334207483, 0.00011576218047718018, 0.00011574375229219035, 0.00011572535284736681, 0.00011570697042790972, 0.0001156886195536463, 0.00011567029789819539, 0.00011565200192117924, 0.00011563372964116285, 0.00011561548325350133, 0.00011559726372083515, 0.00011557905898609232, 0.00011556089174084811, 0.00011554273460065492, 0.00011552460639315611, 0.00011550649931561578, 0.00011548841953160702, 0.00011547036723633191, 0.0001154523336670881], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.000735023888276369, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535, 0.0011025358324145535], 'loss': [0.00011750795225771803, 0.0001174870262419205, 0.00011746612973987912, 0.00011744525893991017, 0.00011742441683563218, 0.000117403599218832, 0.0001173828099431683, 0.00011736205440287013, 0.00011734133281942239, 0.00011732062587005361, 0.000117299965537898, 0.00011727933079885855, 0.00011725872037850398, 0.00011723814039803397, 0.00011721760137976745, 0.00011719708113859787, 0.00011717658924124403, 0.0001171561316034962, 0.00011713570019027509, 0.00011711528867050629, 0.0001170949194641775, 0.00011707457943133975, 0.00011705427075558409, 0.00011703399274209094, 0.00011701374968659569, 0.00011699353210275714, 0.00011697334099797436, 0.0001169531783575737, 0.0001169330522157413, 0.0001169129520403343, 0.00011689288671932742, 0.00011687284572861553, 0.0001168528429360113, 0.00011683287195506907, 0.00011681291900728457, 0.000116793007651328, 0.0001167731120145478, 0.0001167532550563546, 0.00011673342333672311, 0.00011671361592059409, 0.00011669384535401546, 0.00011667410096016468, 0.00011665438037147534, 0.00011663469581159195, 0.00011661505153070259, 0.00011659542091043035, 0.00011657582679408488, 0.0001165562577073194, 0.00011653670489880107, 0.00011651719530484479, 0.0001164977056034477, 0.00011647825732597871, 0.00011645882904288053, 0.0001164394389302044, 0.0001164200764057947, 0.00011640073520198597, 0.00011638142752009563, 0.00011636214741486163, 0.00011634289807012942, 0.00011632367734874833, 0.00011630448509710786, 0.00011628531818137527, 0.00011626617235136249, 0.00011624705842678555, 0.00011622797463844448, 0.00011620892278501104, 0.00011618990677640819, 0.00011617090277443037, 0.00011615192501394789, 0.00011613298950349645, 0.00011611407363643371, 0.00011609518241403163, 0.0001160763222093396, 0.00011605748712710832, 0.00011603866766581416, 0.00011601988714745993, 0.0001160011325106881, 0.00011598239852916944, 0.00011596370096673457, 0.00011594502007907625, 0.0001159263667502126, 0.00011590773505363631, 0.00011588913246178358, 0.00011587054794059813, 0.00011585199298050229, 0.00011583346061543868, 0.00011581495222343636, 0.00011579645983996972, 0.00011577799890914519, 0.00011575956945775528, 0.00011574116379545131, 0.00011572278483904651, 0.00011570442733452606, 0.00011568610182653604, 0.0001156677875392569, 0.0001156495102926482, 0.00011563124738629375, 0.00011561301163863219, 0.00011559479596661213, 0.00011557661272426837, 0.00011555845472316557], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0003682337056585246, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0006137228427642077, 0.0007364674113170492, 0.0007364674113170492]}
[2018-05-08 21:05:04,449 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:129]: evaluating model ... 
[2018-05-08 21:05:41,868 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:133]: evaluated! 
[2018-05-08 21:05:41,869 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:135]: generating reports ... 
[2018-05-08 21:05:47,445 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:138]: done!
[2018-05-08 21:05:47,445 AE_BIGRAMA_1L_FULLDS_UNDER_F0_5.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_5 finished!
