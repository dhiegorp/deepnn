[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_7
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:146]: >> Printing header log
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_FULLDS_UNDER_F0_7
	layers = 9216,6451
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8053b32be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8053b32470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-01-18 00:19:28,511 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:148]: >> Loading dataset... 
[2018-01-18 00:22:04,139 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-01-18 00:22:04,139 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:150]: >> Executing autoencoder part ... 
[2018-01-18 00:22:04,139 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:57]: =======================================
[2018-01-18 00:22:04,139 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8053b32be0>, 'discard_decoder_function': True}
[2018-01-18 00:22:04,181 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:73]: training and evaluate autoencoder
[2018-01-19 09:14:19,302 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:85]: trained and evaluated!
[2018-01-19 09:14:19,304 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:88]: Training history: 
{'val_loss': [0.00011898136054943817, 0.0001189306446808301, 0.00011887997641479368, 0.0001188293724798812, 0.00011877878020361452, 0.00011872827824976471, 0.00011867782232617375, 0.00011862742546592414, 0.00011857708285581348, 0.00011852682833800257, 0.00011847663492647002, 0.00011842650826335863, 0.00011837649046953731, 0.00011832656592883832, 0.00011827672256012364, 0.00011822696844422529, 0.00011817725019203277, 0.00011812760759803382, 0.00011807805249201034, 0.00011802856318246353, 0.00011797917623368757, 0.00011792985362673157, 0.00011788060491847628, 0.00011783143621634074, 0.00011778232988261216, 0.000117733339108525, 0.00011768440910379201, 0.0001176355637953771, 0.00011758680522086928, 0.00011753814119370042, 0.00011748953784496969, 0.0001174410215403302, 0.00011739255711666449, 0.00011734420196873707, 0.00011729592692854142, 0.00011724773942445326, 0.00011719959312672558, 0.00011715153058941549, 0.00011710356321981267, 0.00011705566305855925, 0.00011700784385002203, 0.00011696010388284017, 0.0001169124413814768, 0.00011686487711757423, 0.00011681738189103795, 0.0001167699489526886, 0.00011672260542224767, 0.00011667532830865173, 0.00011662812332891561, 0.00011658101443674324, 0.00011653395307761847, 0.00011648696628569474, 0.00011644005690610947, 0.00011639322047862842, 0.00011634644254225244, 0.00011629975194410783, 0.00011625314451275254, 0.00011620661046668971, 0.0001161601318366304, 0.00011611373832003336, 0.00011606740690444318, 0.00011602114668681236, 0.00011597497208000807, 0.00011592887629741493, 0.000115882873532632, 0.00011583690643902678, 0.00011579100563391449, 0.0001157451956325393, 0.0001156994691188336, 0.000115653791159644, 0.00011560820492404797, 0.00011556268436192455, 0.00011551720590997406, 0.00011547181122913719, 0.00011542646241544509, 0.00011538119910027147, 0.00011533601659609197, 0.00011529090585676013, 0.00011524587878158186, 0.00011520088899802609, 0.0001151559921600825, 0.00011511115154836484, 0.00011506638900411597, 0.0001150216993531433, 0.00011497706355923137, 0.00011493250980635421, 0.00011488800987844979, 0.00011484357100066968, 0.00011479922264318253, 0.00011475493876121542, 0.00011471070293105217, 0.00011466655169292095, 0.00011462244238580454, 0.00011457839540698511, 0.00011453445502990263, 0.00011449055095238817, 0.0001144467225303933, 0.00011440295522269878, 0.00011435926161315487, 0.00011431562240616799, 0.00011427205277936967], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00073502388827636903, 0.00073502388827636903, 0.00073502388827636903, 0.002205071664829107, 0.0025725836089672913, 0.0033076074972436605, 0.0040426313855200296, 0.0058801911062109522, 0.0091877986034546114, 0.012127894156560088, 0.020580668871738331, 0.027930907754502021, 0.040793825799338476, 0.050716648291069456, 0.063579566335905918, 0.074972436604189632, 0.096288129364204333, 0.11980889378904815, 0.13708195516354282, 0.15545755237045203, 0.17677324513046674, 0.19404630650496141, 0.21536199926497612, 0.23557515619257627, 0.25946343256155824, 0.28261668504226389, 0.30429988974641675, 0.32414553472987873, 0.3428886438809261, 0.35575156192576257, 0.37081955163542812, 0.38699007717750827, 0.40058801911062109, 0.41014332965821387, 0.42006615214994486, 0.42851892686512311, 0.43403160602719587, 0.44101433296582138, 0.44652701212789414, 0.45130466740169056, 0.45608232267548693, 0.46380007350238883, 0.46784270488790886, 0.4696802646085998, 0.47298787210584342, 0.47335538404998162, 0.4755604557148107, 0.47703050349136344, 0.47886806321205438, 0.48107313487688352, 0.48327820654171261, 0.48401323042998895, 0.48585079015067989, 0.48695332598309443, 0.48732083792723263, 0.48732083792723263, 0.48842337375964717, 0.48952590959206171, 0.49062844542447631, 0.49209849320102905, 0.49209849320102905, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054], 'loss': [0.00011913586948433757, 0.00011908540255192058, 0.00011903495186292042, 0.00011898455691220316, 0.0001189342534856558, 0.00011888398084550968, 0.00011883380520324702, 0.00011878366970155031, 0.00011873360662898857, 0.00011868360125949513, 0.00011863368753920339, 0.00011858383479692, 0.00011853405185274527, 0.00011848437143553878, 0.00011843478270861587, 0.00011838527326435666, 0.00011833585257659919, 0.00011828646152227115, 0.00011823714093675807, 0.00011818791281404649, 0.00011813876268170567, 0.00011808971012507383, 0.00011804071912784819, 0.0001179918010321991, 0.00011794296620862119, 0.00011789418850939294, 0.00011784552636901872, 0.00011779692355176768, 0.00011774840752801911, 0.00011769997267044901, 0.00011765163408647099, 0.00011760335969024623, 0.00011755517789167868, 0.00011750704102686041, 0.00011745901538854432, 0.00011741106775578142, 0.00011736321561426878, 0.00011731540588622162, 0.00011726768200590067, 0.00011722006066237187, 0.0001171725008898594, 0.0001171250253485906, 0.00011707762677957649, 0.00011703030702882226, 0.00011698308422772493, 0.00011693592779707882, 0.00011688883256146054, 0.00011684182803730547, 0.00011679488725257533, 0.00011674801641420587, 0.0001167012420075044, 0.00011665451568267432, 0.0001166078611332415, 0.00011656128727040088, 0.00011651478686106288, 0.00011646834322777171, 0.00011642199354962583, 0.00011637572199134796, 0.00011632952663459302, 0.00011628338021528418, 0.00011623732806905867, 0.00011619133251490462, 0.00011614540814939145, 0.00011609957316018052, 0.00011605381286228701, 0.00011600814701609368, 0.00011596251281634174, 0.00011591694711079544, 0.00011587147213814637, 0.00011582607583550521, 0.00011578073583021769, 0.00011573548253091039, 0.00011569029342828717, 0.00011564513989542459, 0.00011560007632115517, 0.00011555505474506701, 0.00011551012092522621, 0.0001154652638891993, 0.00011542048509985834, 0.00011537578598792433, 0.00011533112536881582, 0.00011528656070178904, 0.00011524204482752874, 0.00011519761329525456, 0.00011515324439766008, 0.00011510893728631521, 0.0001150647146125165, 0.00011502054395105306, 0.00011497643439888136, 0.00011493241693798809, 0.00011488846159646487, 0.00011484455704821688, 0.00011480073478964737, 0.00011475695176605637, 0.00011471323319814388, 0.00011466961964265317, 0.00011462604271344179, 0.00011458254709508851, 0.00011453910690958329, 0.00011449575168139929, 0.00011445244106456114], 'acc': [0.00012274456855284154, 0.00012274456855284154, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.0003682337056585246, 0.0003682337056585246, 0.00049097827421136617, 0.00049097827421136617, 0.00049097827421136617, 0.00049097827421136617, 0.00085921197986989076, 0.00085921197986989076, 0.00085921197986989076, 0.0012274456855284155, 0.0014729348226340984, 0.0017184239597397815, 0.001841168528292623, 0.0022094022339511476, 0.0025776359396096722, 0.0031913587823738801, 0.0039278261936909293, 0.0051552718792193444, 0.0077329078188290165, 0.010801522033564574, 0.014729348227255502, 0.019761875537922007, 0.026881060513986813, 0.035718669448876889, 0.047256658893758512, 0.061004050571676759, 0.076347121639867441, 0.094267828652240371, 0.11047011171950583, 0.13121394378390211, 0.14938013993063717, 0.17000122743105323, 0.18841291273226984, 0.20633361974098469, 0.22548177243522799, 0.24426169142381274, 0.26340984411805601, 0.28452190992743515, 0.30465201917010115, 0.32048606849878541, 0.33717932981831378, 0.35289063456015485, 0.36897017305886742, 0.38308579849731533, 0.39499202161036023, 0.40579354365764259, 0.41512213088960698, 0.42224131581080065, 0.42825579970647065, 0.43402479439553154, 0.43967104456359452, 0.44568552844097414, 0.45022707747742929, 0.45599607219941279, 0.46016938747533831, 0.46446544739297818, 0.46777955069634991, 0.47060267585720095, 0.472812078036281, 0.47502148032510327, 0.47870381739997886, 0.48103596418419248, 0.48349085551866861, 0.4858230023614114, 0.48741868173064989, 0.48815514907612162, 0.48913710566112506, 0.48999631769220803, 0.49073278508157658, 0.49110101880552548, 0.49159199699560119, 0.4918374861802618, 0.49232846450934425, 0.49245120902302603, 0.49269669814184136, 0.49281944278355566, 0.49281944274697492, 0.49281944278355566, 0.49294218730089545, 0.49294218731552775, 0.49306493192066131, 0.49318767643800115, 0.49318767643434308, 0.49318767647458189, 0.49318767638678812, 0.49318767647092382, 0.49331042104313472, 0.49318767646726575, 0.49318767645263345, 0.49318767648921419, 0.49318767648921419, 0.49318767643800115]}
[2018-01-19 09:14:19,304 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:92]: done!
[2018-01-19 09:14:19,304 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:152]: >> Executing classifier part ... 
[2018-01-19 09:14:19,305 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:97]: =======================================
[2018-01-19 09:14:19,305 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8053b32470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-01-19 09:14:19,734 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:110]: training ... 
[2018-01-22 00:02:45,254 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:122]: trained!
[2018-01-22 00:02:45,257 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:125]: Training history: 
{'val_loss': [0.00011898136054943817, 0.0001189306446808301, 0.00011887997641479368, 0.0001188293724798812, 0.00011877878020361452, 0.00011872827824976471, 0.00011867782232617375, 0.00011862742546592414, 0.00011857708285581348, 0.00011852682833800257, 0.00011847663492647002, 0.00011842650826335863, 0.00011837649046953731, 0.00011832656592883832, 0.00011827672256012364, 0.00011822696844422529, 0.00011817725019203277, 0.00011812760759803382, 0.00011807805249201034, 0.00011802856318246353, 0.00011797917623368757, 0.00011792985362673157, 0.00011788060491847628, 0.00011783143621634074, 0.00011778232988261216, 0.000117733339108525, 0.00011768440910379201, 0.0001176355637953771, 0.00011758680522086928, 0.00011753814119370042, 0.00011748953784496969, 0.0001174410215403302, 0.00011739255711666449, 0.00011734420196873707, 0.00011729592692854142, 0.00011724773942445326, 0.00011719959312672558, 0.00011715153058941549, 0.00011710356321981267, 0.00011705566305855925, 0.00011700784385002203, 0.00011696010388284017, 0.0001169124413814768, 0.00011686487711757423, 0.00011681738189103795, 0.0001167699489526886, 0.00011672260542224767, 0.00011667532830865173, 0.00011662812332891561, 0.00011658101443674324, 0.00011653395307761847, 0.00011648696628569474, 0.00011644005690610947, 0.00011639322047862842, 0.00011634644254225244, 0.00011629975194410783, 0.00011625314451275254, 0.00011620661046668971, 0.0001161601318366304, 0.00011611373832003336, 0.00011606740690444318, 0.00011602114668681236, 0.00011597497208000807, 0.00011592887629741493, 0.000115882873532632, 0.00011583690643902678, 0.00011579100563391449, 0.0001157451956325393, 0.0001156994691188336, 0.000115653791159644, 0.00011560820492404797, 0.00011556268436192455, 0.00011551720590997406, 0.00011547181122913719, 0.00011542646241544509, 0.00011538119910027147, 0.00011533601659609197, 0.00011529090585676013, 0.00011524587878158186, 0.00011520088899802609, 0.0001151559921600825, 0.00011511115154836484, 0.00011506638900411597, 0.0001150216993531433, 0.00011497706355923137, 0.00011493250980635421, 0.00011488800987844979, 0.00011484357100066968, 0.00011479922264318253, 0.00011475493876121542, 0.00011471070293105217, 0.00011466655169292095, 0.00011462244238580454, 0.00011457839540698511, 0.00011453445502990263, 0.00011449055095238817, 0.0001144467225303933, 0.00011440295522269878, 0.00011435926161315487, 0.00011431562240616799, 0.00011427205277936967], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036751194413818452, 0.00073502388827636903, 0.00073502388827636903, 0.00073502388827636903, 0.002205071664829107, 0.0025725836089672913, 0.0033076074972436605, 0.0040426313855200296, 0.0058801911062109522, 0.0091877986034546114, 0.012127894156560088, 0.020580668871738331, 0.027930907754502021, 0.040793825799338476, 0.050716648291069456, 0.063579566335905918, 0.074972436604189632, 0.096288129364204333, 0.11980889378904815, 0.13708195516354282, 0.15545755237045203, 0.17677324513046674, 0.19404630650496141, 0.21536199926497612, 0.23557515619257627, 0.25946343256155824, 0.28261668504226389, 0.30429988974641675, 0.32414553472987873, 0.3428886438809261, 0.35575156192576257, 0.37081955163542812, 0.38699007717750827, 0.40058801911062109, 0.41014332965821387, 0.42006615214994486, 0.42851892686512311, 0.43403160602719587, 0.44101433296582138, 0.44652701212789414, 0.45130466740169056, 0.45608232267548693, 0.46380007350238883, 0.46784270488790886, 0.4696802646085998, 0.47298787210584342, 0.47335538404998162, 0.4755604557148107, 0.47703050349136344, 0.47886806321205438, 0.48107313487688352, 0.48327820654171261, 0.48401323042998895, 0.48585079015067989, 0.48695332598309443, 0.48732083792723263, 0.48732083792723263, 0.48842337375964717, 0.48952590959206171, 0.49062844542447631, 0.49209849320102905, 0.49209849320102905, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054, 0.4928335170893054], 'loss': [0.00011913586948433757, 0.00011908540255192058, 0.00011903495186292042, 0.00011898455691220316, 0.0001189342534856558, 0.00011888398084550968, 0.00011883380520324702, 0.00011878366970155031, 0.00011873360662898857, 0.00011868360125949513, 0.00011863368753920339, 0.00011858383479692, 0.00011853405185274527, 0.00011848437143553878, 0.00011843478270861587, 0.00011838527326435666, 0.00011833585257659919, 0.00011828646152227115, 0.00011823714093675807, 0.00011818791281404649, 0.00011813876268170567, 0.00011808971012507383, 0.00011804071912784819, 0.0001179918010321991, 0.00011794296620862119, 0.00011789418850939294, 0.00011784552636901872, 0.00011779692355176768, 0.00011774840752801911, 0.00011769997267044901, 0.00011765163408647099, 0.00011760335969024623, 0.00011755517789167868, 0.00011750704102686041, 0.00011745901538854432, 0.00011741106775578142, 0.00011736321561426878, 0.00011731540588622162, 0.00011726768200590067, 0.00011722006066237187, 0.0001171725008898594, 0.0001171250253485906, 0.00011707762677957649, 0.00011703030702882226, 0.00011698308422772493, 0.00011693592779707882, 0.00011688883256146054, 0.00011684182803730547, 0.00011679488725257533, 0.00011674801641420587, 0.0001167012420075044, 0.00011665451568267432, 0.0001166078611332415, 0.00011656128727040088, 0.00011651478686106288, 0.00011646834322777171, 0.00011642199354962583, 0.00011637572199134796, 0.00011632952663459302, 0.00011628338021528418, 0.00011623732806905867, 0.00011619133251490462, 0.00011614540814939145, 0.00011609957316018052, 0.00011605381286228701, 0.00011600814701609368, 0.00011596251281634174, 0.00011591694711079544, 0.00011587147213814637, 0.00011582607583550521, 0.00011578073583021769, 0.00011573548253091039, 0.00011569029342828717, 0.00011564513989542459, 0.00011560007632115517, 0.00011555505474506701, 0.00011551012092522621, 0.0001154652638891993, 0.00011542048509985834, 0.00011537578598792433, 0.00011533112536881582, 0.00011528656070178904, 0.00011524204482752874, 0.00011519761329525456, 0.00011515324439766008, 0.00011510893728631521, 0.0001150647146125165, 0.00011502054395105306, 0.00011497643439888136, 0.00011493241693798809, 0.00011488846159646487, 0.00011484455704821688, 0.00011480073478964737, 0.00011475695176605637, 0.00011471323319814388, 0.00011466961964265317, 0.00011462604271344179, 0.00011458254709508851, 0.00011453910690958329, 0.00011449575168139929, 0.00011445244106456114], 'acc': [0.00012274456855284154, 0.00012274456855284154, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.00024548913710568308, 0.0003682337056585246, 0.0003682337056585246, 0.00049097827421136617, 0.00049097827421136617, 0.00049097827421136617, 0.00049097827421136617, 0.00085921197986989076, 0.00085921197986989076, 0.00085921197986989076, 0.0012274456855284155, 0.0014729348226340984, 0.0017184239597397815, 0.001841168528292623, 0.0022094022339511476, 0.0025776359396096722, 0.0031913587823738801, 0.0039278261936909293, 0.0051552718792193444, 0.0077329078188290165, 0.010801522033564574, 0.014729348227255502, 0.019761875537922007, 0.026881060513986813, 0.035718669448876889, 0.047256658893758512, 0.061004050571676759, 0.076347121639867441, 0.094267828652240371, 0.11047011171950583, 0.13121394378390211, 0.14938013993063717, 0.17000122743105323, 0.18841291273226984, 0.20633361974098469, 0.22548177243522799, 0.24426169142381274, 0.26340984411805601, 0.28452190992743515, 0.30465201917010115, 0.32048606849878541, 0.33717932981831378, 0.35289063456015485, 0.36897017305886742, 0.38308579849731533, 0.39499202161036023, 0.40579354365764259, 0.41512213088960698, 0.42224131581080065, 0.42825579970647065, 0.43402479439553154, 0.43967104456359452, 0.44568552844097414, 0.45022707747742929, 0.45599607219941279, 0.46016938747533831, 0.46446544739297818, 0.46777955069634991, 0.47060267585720095, 0.472812078036281, 0.47502148032510327, 0.47870381739997886, 0.48103596418419248, 0.48349085551866861, 0.4858230023614114, 0.48741868173064989, 0.48815514907612162, 0.48913710566112506, 0.48999631769220803, 0.49073278508157658, 0.49110101880552548, 0.49159199699560119, 0.4918374861802618, 0.49232846450934425, 0.49245120902302603, 0.49269669814184136, 0.49281944278355566, 0.49281944274697492, 0.49281944278355566, 0.49294218730089545, 0.49294218731552775, 0.49306493192066131, 0.49318767643800115, 0.49318767643434308, 0.49318767647458189, 0.49318767638678812, 0.49318767647092382, 0.49331042104313472, 0.49318767646726575, 0.49318767645263345, 0.49318767648921419, 0.49318767648921419, 0.49318767643800115]}
[2018-01-22 00:02:45,258 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:129]: evaluating model ... 
[2018-01-22 00:03:38,059 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:133]: evaluated! 
[2018-01-22 00:03:38,060 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:135]: generating reports ... 
[2018-01-22 00:03:43,941 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:138]: done!
[2018-01-22 00:03:44,023 AE_BIGRAMA_1L_FULLDS_UNDER_F0_7.py:154]: >> experiment AE_BIGRAMA_1L_FULLDS_UNDER_F0_7 finished!
