[2017-12-14 09:31:57,985 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_8
[2017-12-14 09:31:57,986 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:146]: >> Printing header log
[2017-12-14 09:31:57,986 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_OVER_F1_8
	layers = 9216,16589
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbafe4a6eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbafe489400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 09:31:57,986 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:148]: >> Loading dataset... 
[2017-12-14 09:32:20,970 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 09:32:20,970 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:150]: >> Executing autoencoder part ... 
[2017-12-14 09:32:20,970 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:57]: =======================================
[2017-12-14 09:32:20,971 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbafe4a6eb8>, 'discard_decoder_function': True}
[2017-12-14 09:32:21,016 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:73]: training and evaluate autoencoder
[2017-12-14 10:18:55,000 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:145]: >> Initializing execution of experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_8
[2017-12-14 10:18:55,000 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:146]: >> Printing header log
[2017-12-14 10:18:55,001 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_1L_MINIDS_OVER_F1_8
	layers = 9216,16589
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/bigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/bigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/bigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/bigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/bigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f641cfbdeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f641cfa0400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-12-14 10:18:55,001 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:148]: >> Loading dataset... 
[2017-12-14 10:19:18,137 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2017-12-14 10:19:18,138 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:150]: >> Executing autoencoder part ... 
[2017-12-14 10:19:18,138 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:57]: =======================================
[2017-12-14 10:19:18,138 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f641cfbdeb8>, 'discard_decoder_function': True}
[2017-12-14 10:19:18,186 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:73]: training and evaluate autoencoder
[2017-12-15 04:24:10,989 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:85]: trained and evaluated!
[2017-12-15 04:24:10,991 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:88]: Training history: 
{'val_loss': [0.00011823860147117845, 0.0001182355363444249, 0.00011823248192602174, 0.00011822943698245281, 0.00011822637929255028, 0.00011822331972555796, 0.00011822025468818962, 0.00011821719928654894, 0.00011821414404580168, 0.00011821108562294028, 0.00011820801232637682, 0.00011820496607778356, 0.00011820191019346265, 0.00011819883714717783, 0.00011819577643605457, 0.00011819270755512141, 0.00011818964471662971, 0.00011818658482785056, 0.00011818352869325101, 0.00011818046013410466, 0.00011817740424978376, 0.00011817436413301718, 0.00011817128985321621, 0.0001181682511308592, 0.0001181651935303419, 0.00011816213787842258, 0.00011815909229128001, 0.00011815603755109003, 0.00011815298999747243, 0.0001181499482538947, 0.00011814689939525276, 0.00011814383435788443, 0.00011814078492717702, 0.0001181377280596186, 0.00011813467732388687, 0.00011813162617698307, 0.0001181285697205967, 0.00011812551056477642, 0.00011812244912069428, 0.00011811939094811152, 0.00011811635050955812, 0.00011811328776045164, 0.00011811024919898806, 0.00011810719503086353, 0.00011810413129851955, 0.00011810107509241181, 0.00011809802092428729, 0.00011809494845006794, 0.00011809190727855566, 0.00011808884436855577, 0.0001180857751658358, 0.00011808270841227108, 0.00011807962735706977, 0.00011807656673533173, 0.00011807351240631381, 0.00011807044565274909, 0.00011806738070476599, 0.00011806431557801244, 0.00011806125765570831, 0.00011805821101382004, 0.00011805514295523098, 0.000118052082744665, 0.0001180490088045279, 0.0001180459331481944, 0.00011804285666951681, 0.00011803979261538599, 0.00011803673428190982, 0.00011803368061434258, 0.00011803060969542621, 0.00011802757049038897, 0.00011802449924968576, 0.00011802142808049075, 0.00011801835912804941, 0.00011801529205269786, 0.00011801223323654146, 0.00011800917057682021, 0.00011800610611151734, 0.00011800303642611713, 0.00011799995463795695, 0.0001179968829860817, 0.00011799380659678933, 0.00011799073739406934, 0.00011798765757238419, 0.00011798458159426388, 0.00011798151239154389, 0.00011797843755755449, 0.00011797537130454707, 0.00011797229123258327, 0.00011796920953380832, 0.00011796615014558644, 0.00011796306263677163, 0.00011795997251790814, 0.00011795688942472362, 0.00011795381859519247, 0.00011795074687180903, 0.00011794766222332154, 0.00011794457855807155, 0.0001179414842738564, 0.00011793838712931394, 0.00011793529627749157, 0.00011793218540337798, 0.00011792908425437725, 0.00011792598752100684, 0.00011792286895976359, 0.00011791973463096598, 0.00011791660364517595, 0.00011791348279567083, 0.00011791036407353417, 0.00011790723644862871, 0.0001179041244303842, 0.00011790102451489964, 0.0001178979008050672, 0.00011789478258348782, 0.00011789164040666715, 0.00011788852037950614, 0.00011788539904732078, 0.00011788225973082743, 0.00011787914109807599, 0.00011787599368328091, 0.00011787286573658865, 0.00011786972495417753, 0.00011786656284445087, 0.00011786342320617069, 0.00011786027327071216, 0.00011785711434309964, 0.00011785397479420468, 0.00011785079992026736, 0.00011784763192899264, 0.00011784443467299406, 0.00011784126700350616, 0.00011783808796421719, 0.00011783490908582162, 0.00011783173185211426, 0.00011782854709217064, 0.00011782535171326186, 0.00011782215649524649, 0.00011781896013310018, 0.00011781577775080366, 0.00011781256871383193, 0.00011780936189361388, 0.00011780616985771266, 0.00011780296148219161, 0.00011779974640277844, 0.00011779650942398423, 0.00011779327489434529, 0.00011779005924286664, 0.00011778683493889786, 0.00011778358725175325, 0.00011778034226404256, 0.00011777706196916654, 0.00011777379654799256, 0.00011777051993578797, 0.00011776724879395935, 0.00011776395476951221, 0.00011776065632943475, 0.0001177573650759297, 0.00011775405869844394, 0.00011775075559245757, 0.00011774742248878844, 0.00011774410189905133, 0.00011774076250266211, 0.00011773740733871854, 0.00011773405732336415, 0.00011773066840755824, 0.00011772729509841325, 0.00011772389906754315, 0.00011772049298977333, 0.00011771706933886756, 0.00011771361340201718, 0.0001177101832974979, 0.00011770673889134203, 0.00011770327510646858, 0.00011769980552943231, 0.00011769630350555804, 0.00011769280294760151, 0.00011768928980420478, 0.0001176857823814627, 0.00011768224832192246, 0.00011767870543112163, 0.00011767513885323521, 0.0001176715430821331, 0.00011766794495126095, 0.00011766432139922977, 0.00011766068697795478, 0.00011765699061271631, 0.0001176532938363058, 0.00011764961373917896, 0.00011764589824550156, 0.00011764215411279689, 0.00011763838799132597, 0.00011763459367775392, 0.00011763078195193934, 0.00011762696295016713, 0.00011762314124896102, 0.00011761930206400418, 0.00011761542118977668, 0.00011761153010775607, 0.00011760762332968931, 0.00011760370707678831, 0.00011759978297586422], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011907671136456976, 0.00011907356371894533, 0.00011907040737535204, 0.00011906726183904432, 0.0001190641309020522, 0.00011906097723658011, 0.00011905782847704688, 0.00011905466744081642, 0.00011905152451152934, 0.00011904837871451956, 0.00011904522476464522, 0.00011904206029188756, 0.00011903891857131005, 0.00011903577478881622, 0.00011903261273347769, 0.00011902946281263526, 0.00011902630246371024, 0.00011902315180816199, 0.00011902000274052631, 0.00011901685677761522, 0.00011901369986521741, 0.00011901055572722077, 0.00011900742367631984, 0.00011900426057817305, 0.0001190011347130211, 0.00011899799026692201, 0.00011899484520461805, 0.00011899170853218052, 0.00011898856439418387, 0.0001189854277928469, 0.00011898229638185103, 0.00011897915295486001, 0.00011897599786737667, 0.00011897285500919016, 0.00011896970091711469, 0.00011896655950463963, 0.00011896341906387226, 0.00011896027222405421, 0.00011895712751725306, 0.00011895397539229318, 0.00011895082348063498, 0.00011894769270954417, 0.00011894453740875913, 0.00011894140538155838, 0.00011893826148056362, 0.00011893510162934254, 0.00011893195026278865, 0.00011892880024714547, 0.00011892563726749962, 0.00011892250102166548, 0.00011891934112304403, 0.00011891617800119706, 0.00011891301298333507, 0.00011890984090281717, 0.00011890668515172857, 0.00011890353060934953, 0.00011890036917021588, 0.00011889720756518093, 0.0001188940439930304, 0.00011889089935732981, 0.00011888775337071853, 0.00011888459162348245, 0.00011888143639379797, 0.00011887827222914275, 0.00011887510171283723, 0.00011887193693197712, 0.00011886877776806149, 0.00011886562903222844, 0.00011886247354184189, 0.00011885930982749024, 0.00011885617014512886, 0.00011885300389485713, 0.00011884983335485142, 0.0001188466695693992, 0.0001188434978443841, 0.00011884034311240357, 0.00011883718063046167, 0.00011883401189167022, 0.00011883083718043148, 0.0001188276533209203, 0.00011882447223433108, 0.0001188212866684064, 0.00011881811299997591, 0.00011881492722074953, 0.00011881174400114342, 0.00011880857604445816, 0.00011880539360695825, 0.00011880221761590937, 0.00011879902475032688, 0.00011879583046273313, 0.00011879265961462499, 0.00011878946205640533, 0.00011878625776733238, 0.00011878305530317388, 0.00011877986705912798, 0.00011877667142062354, 0.00011877346957266991, 0.00011877026559169941, 0.00011876704933403169, 0.00011876383255495984, 0.00011876061525448386, 0.00011875738233558421, 0.00011875416129047858, 0.00011875094505651105, 0.00011874770474315284, 0.00011874445705903628, 0.00011874120051104952, 0.00011873796332611609, 0.00011873473453104908, 0.00011873149478649538, 0.00011872827641951096, 0.00011872506250816181, 0.00011872182236070493, 0.0001187185859341775, 0.00011871532443285152, 0.00011871208862252898, 0.00011870885191159929, 0.00011870558642864178, 0.00011870234272615674, 0.00011869907816750656, 0.00011869582166692017, 0.00011869256042629627, 0.00011868926932343588, 0.00011868600504918795, 0.00011868273579790059, 0.00011867946521940273, 0.00011867620395507864, 0.00011867290467565351, 0.0001186696121033815, 0.00011866629282099799, 0.00011866301181441755, 0.00011865971582931851, 0.00011865640889473278, 0.00011865311300443449, 0.00011864979696897669, 0.00011864646787471548, 0.0001186431404631676, 0.00011863981639334617, 0.00011863650360481407, 0.00011863314872474868, 0.00011862980230565028, 0.00011862646361281307, 0.00011862310648122985, 0.00011861974259509313, 0.00011861635844529598, 0.00011861298925031722, 0.00011860963349334489, 0.00011860627008121193, 0.0001186028816416808, 0.00011859949087953129, 0.00011859607295696669, 0.00011859267404195262, 0.00011858926645266984, 0.00011858585857898482, 0.00011858242117486596, 0.00011857897791680076, 0.000118575537621259, 0.00011857207777306243, 0.00011856861799596642, 0.00011856513425798067, 0.00011856166319959533, 0.00011855817050293864, 0.00011855465284998435, 0.0001185511318316034, 0.0001185475686268884, 0.00011854401352763758, 0.00011854043311658634, 0.00011853684983781239, 0.00011853324989780651, 0.00011852961611393262, 0.00011852600690715337, 0.00011852238414386676, 0.00011851874571475611, 0.00011851509593325555, 0.00011851141548371215, 0.00011850772401358149, 0.00011850401386770295, 0.00011850030301081878, 0.00011849656783754207, 0.000118492828706334, 0.00011848907537871354, 0.00011848531065130279, 0.00011848154838871156, 0.00011847777358872106, 0.00011847397947307761, 0.00011847014400060668, 0.00011846630402510009, 0.00011846248085302655, 0.00011845861300609927, 0.00011845473321427739, 0.00011845086477484542, 0.00011844697073921076, 0.00011844303688726081, 0.00011843908369595774, 0.00011843511912856457, 0.00011843112915457024, 0.00011842708381693749, 0.00011842304191583197, 0.00011841897373121833, 0.00011841489234560014], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-15 04:24:10,992 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:92]: done!
[2017-12-15 04:24:10,992 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:152]: >> Executing classifier part ... 
[2017-12-15 04:24:10,992 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:97]: =======================================
[2017-12-15 04:24:10,992 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f641cfa0400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-12-15 04:24:11,425 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:110]: training ... 
[2017-12-15 09:44:03,345 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:122]: trained!
[2017-12-15 09:44:03,348 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:125]: Training history: 
{'val_loss': [0.00011823860147117845, 0.0001182355363444249, 0.00011823248192602174, 0.00011822943698245281, 0.00011822637929255028, 0.00011822331972555796, 0.00011822025468818962, 0.00011821719928654894, 0.00011821414404580168, 0.00011821108562294028, 0.00011820801232637682, 0.00011820496607778356, 0.00011820191019346265, 0.00011819883714717783, 0.00011819577643605457, 0.00011819270755512141, 0.00011818964471662971, 0.00011818658482785056, 0.00011818352869325101, 0.00011818046013410466, 0.00011817740424978376, 0.00011817436413301718, 0.00011817128985321621, 0.0001181682511308592, 0.0001181651935303419, 0.00011816213787842258, 0.00011815909229128001, 0.00011815603755109003, 0.00011815298999747243, 0.0001181499482538947, 0.00011814689939525276, 0.00011814383435788443, 0.00011814078492717702, 0.0001181377280596186, 0.00011813467732388687, 0.00011813162617698307, 0.0001181285697205967, 0.00011812551056477642, 0.00011812244912069428, 0.00011811939094811152, 0.00011811635050955812, 0.00011811328776045164, 0.00011811024919898806, 0.00011810719503086353, 0.00011810413129851955, 0.00011810107509241181, 0.00011809802092428729, 0.00011809494845006794, 0.00011809190727855566, 0.00011808884436855577, 0.0001180857751658358, 0.00011808270841227108, 0.00011807962735706977, 0.00011807656673533173, 0.00011807351240631381, 0.00011807044565274909, 0.00011806738070476599, 0.00011806431557801244, 0.00011806125765570831, 0.00011805821101382004, 0.00011805514295523098, 0.000118052082744665, 0.0001180490088045279, 0.0001180459331481944, 0.00011804285666951681, 0.00011803979261538599, 0.00011803673428190982, 0.00011803368061434258, 0.00011803060969542621, 0.00011802757049038897, 0.00011802449924968576, 0.00011802142808049075, 0.00011801835912804941, 0.00011801529205269786, 0.00011801223323654146, 0.00011800917057682021, 0.00011800610611151734, 0.00011800303642611713, 0.00011799995463795695, 0.0001179968829860817, 0.00011799380659678933, 0.00011799073739406934, 0.00011798765757238419, 0.00011798458159426388, 0.00011798151239154389, 0.00011797843755755449, 0.00011797537130454707, 0.00011797229123258327, 0.00011796920953380832, 0.00011796615014558644, 0.00011796306263677163, 0.00011795997251790814, 0.00011795688942472362, 0.00011795381859519247, 0.00011795074687180903, 0.00011794766222332154, 0.00011794457855807155, 0.0001179414842738564, 0.00011793838712931394, 0.00011793529627749157, 0.00011793218540337798, 0.00011792908425437725, 0.00011792598752100684, 0.00011792286895976359, 0.00011791973463096598, 0.00011791660364517595, 0.00011791348279567083, 0.00011791036407353417, 0.00011790723644862871, 0.0001179041244303842, 0.00011790102451489964, 0.0001178979008050672, 0.00011789478258348782, 0.00011789164040666715, 0.00011788852037950614, 0.00011788539904732078, 0.00011788225973082743, 0.00011787914109807599, 0.00011787599368328091, 0.00011787286573658865, 0.00011786972495417753, 0.00011786656284445087, 0.00011786342320617069, 0.00011786027327071216, 0.00011785711434309964, 0.00011785397479420468, 0.00011785079992026736, 0.00011784763192899264, 0.00011784443467299406, 0.00011784126700350616, 0.00011783808796421719, 0.00011783490908582162, 0.00011783173185211426, 0.00011782854709217064, 0.00011782535171326186, 0.00011782215649524649, 0.00011781896013310018, 0.00011781577775080366, 0.00011781256871383193, 0.00011780936189361388, 0.00011780616985771266, 0.00011780296148219161, 0.00011779974640277844, 0.00011779650942398423, 0.00011779327489434529, 0.00011779005924286664, 0.00011778683493889786, 0.00011778358725175325, 0.00011778034226404256, 0.00011777706196916654, 0.00011777379654799256, 0.00011777051993578797, 0.00011776724879395935, 0.00011776395476951221, 0.00011776065632943475, 0.0001177573650759297, 0.00011775405869844394, 0.00011775075559245757, 0.00011774742248878844, 0.00011774410189905133, 0.00011774076250266211, 0.00011773740733871854, 0.00011773405732336415, 0.00011773066840755824, 0.00011772729509841325, 0.00011772389906754315, 0.00011772049298977333, 0.00011771706933886756, 0.00011771361340201718, 0.0001177101832974979, 0.00011770673889134203, 0.00011770327510646858, 0.00011769980552943231, 0.00011769630350555804, 0.00011769280294760151, 0.00011768928980420478, 0.0001176857823814627, 0.00011768224832192246, 0.00011767870543112163, 0.00011767513885323521, 0.0001176715430821331, 0.00011766794495126095, 0.00011766432139922977, 0.00011766068697795478, 0.00011765699061271631, 0.0001176532938363058, 0.00011764961373917896, 0.00011764589824550156, 0.00011764215411279689, 0.00011763838799132597, 0.00011763459367775392, 0.00011763078195193934, 0.00011762696295016713, 0.00011762314124896102, 0.00011761930206400418, 0.00011761542118977668, 0.00011761153010775607, 0.00011760762332968931, 0.00011760370707678831, 0.00011759978297586422], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00011907671136456976, 0.00011907356371894533, 0.00011907040737535204, 0.00011906726183904432, 0.0001190641309020522, 0.00011906097723658011, 0.00011905782847704688, 0.00011905466744081642, 0.00011905152451152934, 0.00011904837871451956, 0.00011904522476464522, 0.00011904206029188756, 0.00011903891857131005, 0.00011903577478881622, 0.00011903261273347769, 0.00011902946281263526, 0.00011902630246371024, 0.00011902315180816199, 0.00011902000274052631, 0.00011901685677761522, 0.00011901369986521741, 0.00011901055572722077, 0.00011900742367631984, 0.00011900426057817305, 0.0001190011347130211, 0.00011899799026692201, 0.00011899484520461805, 0.00011899170853218052, 0.00011898856439418387, 0.0001189854277928469, 0.00011898229638185103, 0.00011897915295486001, 0.00011897599786737667, 0.00011897285500919016, 0.00011896970091711469, 0.00011896655950463963, 0.00011896341906387226, 0.00011896027222405421, 0.00011895712751725306, 0.00011895397539229318, 0.00011895082348063498, 0.00011894769270954417, 0.00011894453740875913, 0.00011894140538155838, 0.00011893826148056362, 0.00011893510162934254, 0.00011893195026278865, 0.00011892880024714547, 0.00011892563726749962, 0.00011892250102166548, 0.00011891934112304403, 0.00011891617800119706, 0.00011891301298333507, 0.00011890984090281717, 0.00011890668515172857, 0.00011890353060934953, 0.00011890036917021588, 0.00011889720756518093, 0.0001188940439930304, 0.00011889089935732981, 0.00011888775337071853, 0.00011888459162348245, 0.00011888143639379797, 0.00011887827222914275, 0.00011887510171283723, 0.00011887193693197712, 0.00011886877776806149, 0.00011886562903222844, 0.00011886247354184189, 0.00011885930982749024, 0.00011885617014512886, 0.00011885300389485713, 0.00011884983335485142, 0.0001188466695693992, 0.0001188434978443841, 0.00011884034311240357, 0.00011883718063046167, 0.00011883401189167022, 0.00011883083718043148, 0.0001188276533209203, 0.00011882447223433108, 0.0001188212866684064, 0.00011881811299997591, 0.00011881492722074953, 0.00011881174400114342, 0.00011880857604445816, 0.00011880539360695825, 0.00011880221761590937, 0.00011879902475032688, 0.00011879583046273313, 0.00011879265961462499, 0.00011878946205640533, 0.00011878625776733238, 0.00011878305530317388, 0.00011877986705912798, 0.00011877667142062354, 0.00011877346957266991, 0.00011877026559169941, 0.00011876704933403169, 0.00011876383255495984, 0.00011876061525448386, 0.00011875738233558421, 0.00011875416129047858, 0.00011875094505651105, 0.00011874770474315284, 0.00011874445705903628, 0.00011874120051104952, 0.00011873796332611609, 0.00011873473453104908, 0.00011873149478649538, 0.00011872827641951096, 0.00011872506250816181, 0.00011872182236070493, 0.0001187185859341775, 0.00011871532443285152, 0.00011871208862252898, 0.00011870885191159929, 0.00011870558642864178, 0.00011870234272615674, 0.00011869907816750656, 0.00011869582166692017, 0.00011869256042629627, 0.00011868926932343588, 0.00011868600504918795, 0.00011868273579790059, 0.00011867946521940273, 0.00011867620395507864, 0.00011867290467565351, 0.0001186696121033815, 0.00011866629282099799, 0.00011866301181441755, 0.00011865971582931851, 0.00011865640889473278, 0.00011865311300443449, 0.00011864979696897669, 0.00011864646787471548, 0.0001186431404631676, 0.00011863981639334617, 0.00011863650360481407, 0.00011863314872474868, 0.00011862980230565028, 0.00011862646361281307, 0.00011862310648122985, 0.00011861974259509313, 0.00011861635844529598, 0.00011861298925031722, 0.00011860963349334489, 0.00011860627008121193, 0.0001186028816416808, 0.00011859949087953129, 0.00011859607295696669, 0.00011859267404195262, 0.00011858926645266984, 0.00011858585857898482, 0.00011858242117486596, 0.00011857897791680076, 0.000118575537621259, 0.00011857207777306243, 0.00011856861799596642, 0.00011856513425798067, 0.00011856166319959533, 0.00011855817050293864, 0.00011855465284998435, 0.0001185511318316034, 0.0001185475686268884, 0.00011854401352763758, 0.00011854043311658634, 0.00011853684983781239, 0.00011853324989780651, 0.00011852961611393262, 0.00011852600690715337, 0.00011852238414386676, 0.00011851874571475611, 0.00011851509593325555, 0.00011851141548371215, 0.00011850772401358149, 0.00011850401386770295, 0.00011850030301081878, 0.00011849656783754207, 0.000118492828706334, 0.00011848907537871354, 0.00011848531065130279, 0.00011848154838871156, 0.00011847777358872106, 0.00011847397947307761, 0.00011847014400060668, 0.00011846630402510009, 0.00011846248085302655, 0.00011845861300609927, 0.00011845473321427739, 0.00011845086477484542, 0.00011844697073921076, 0.00011844303688726081, 0.00011843908369595774, 0.00011843511912856457, 0.00011843112915457024, 0.00011842708381693749, 0.00011842304191583197, 0.00011841897373121833, 0.00011841489234560014], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2017-12-15 09:44:03,349 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:129]: evaluating model ... 
[2017-12-15 09:44:06,240 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:133]: evaluated! 
[2017-12-15 09:44:06,241 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:135]: generating reports ... 
[2017-12-15 09:44:07,092 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:138]: done!
[2017-12-15 09:44:07,093 AE_BIGRAMA_1L_MINIDS_OVER_F1_8.py:154]: >> experiment AE_BIGRAMA_1L_MINIDS_OVER_F1_8 finished!
