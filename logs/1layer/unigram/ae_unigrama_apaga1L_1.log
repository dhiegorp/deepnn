[2017-11-12 16:12:49,683 trial.py:142]: The experiment ae_unigrama_apaga1L_1 was already executed!
[2017-11-12 16:12:49,684 trial.py:144]: >> Initializing execution of experiment ae_unigrama_apaga2L_2
[2017-11-12 16:12:49,684 trial.py:145]: >> Printing header log
[2017-11-12 16:12:49,684 trial.py:49]: 
		=======================================
		network_name = ae_unigrama_apaga2L_2
		layers = 96,2
		using GLOBAL obj = 
			{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f96d67040f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'softmax', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f96d67040b8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
		=======================================
		
[2017-11-12 16:12:49,684 trial.py:150]: >> Executing autoencoder part ... 
[2017-11-12 16:12:49,685 trial.py:54]: =======================================
[2017-11-12 16:12:49,685 trial.py:58]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f96d67040f0>, 'discard_decoder_function': True}
[2017-11-12 16:12:49,732 trial.py:69]: training and evaluating autoencoder
[2017-11-12 16:14:32,427 trial.py:144]: >> Initializing execution of experiment ae_unigrama_apaga1L_1
[2017-11-12 16:14:32,428 trial.py:145]: >> Printing header log
[2017-11-12 16:14:32,428 trial.py:49]: 
		=======================================
		network_name = ae_unigrama_apaga1L_1
		layers = 96,1
		using GLOBAL obj = 
			{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cc940>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'softmax', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cceb8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
		=======================================
		
[2017-11-12 16:14:32,428 trial.py:150]: >> Executing autoencoder part ... 
[2017-11-12 16:14:32,428 trial.py:54]: =======================================
[2017-11-12 16:14:32,428 trial.py:58]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cc940>, 'discard_decoder_function': True}
[2017-11-12 16:14:32,467 trial.py:69]: training and evaluating autoencoder
[2017-11-12 16:16:17,774 trial.py:80]: trained and evaluated!
[2017-11-12 16:16:17,774 trial.py:81]: MODEL FOR AE <bound method Trial.__network_name of <trial.Trial object at 0x7f93822ccac8>>, TOPOLOGY:
		None
[2017-11-12 16:16:17,775 trial.py:84]: Training history: 
{'val_loss': [0.010165809689980248, 0.010040726005080889, 0.0099274204326509474, 0.0098255530628829219, 0.0097341343913828343, 0.0096523444089889315, 0.0095794576297910158, 0.0095146921658748121, 0.0094573955687884889, 0.0094069330674109754, 0.009362640314198447, 0.0093237306896661494, 0.0092896591144306217, 0.0092598989058952693, 0.0092339157244927823, 0.0092112857181659655, 0.009191557946068997, 0.009174426946034658, 0.0091595158993359963, 0.0091465200981736532, 0.0091351753744909059, 0.0091252643330921503, 0.0091166069247827983, 0.0091090229480571498, 0.009102336390478586, 0.0090964481515898206, 0.0090912359406249525, 0.0090866033966731426, 0.0090824573974028228, 0.0090787408706410021, 0.0090753895489691337, 0.0090723543296794343, 0.0090695943430788989, 0.0090670650783831776, 0.0090647405194846289, 0.009062593206913867, 0.0090605997415762612, 0.0090587406776207451, 0.0090569980529461094, 0.0090553632292873238, 0.009053818346540286, 0.0090523538395669342, 0.0090509630836894169, 0.0090496364966560616, 0.0090483640190877918, 0.0090471452573716131, 0.0090459710855046553, 0.0090448394495116265, 0.0090437441039522403, 0.0090426821052858337, 0.0090416513820812359, 0.00904064892747743, 0.0090396700520034186, 0.0090387137343190434, 0.0090377779276367282, 0.0090368601494564237, 0.009035960067089583, 0.0090350751035690353, 0.0090342062549067965, 0.0090333502500077375, 0.0090325082604694965, 0.0090316768187327177, 0.0090308553032311441, 0.0090300441548113262, 0.0090292438132930052, 0.0090284530961258318, 0.0090276692059193635, 0.0090268925212266156, 0.009026124381358594, 0.0090253633124913329, 0.0090246102983150486, 0.0090238630620352658, 0.0090231209475162364, 0.0090223841433499236, 0.0090216524934602204, 0.0090209263918023912, 0.0090202059615944203, 0.0090194895014013496, 0.0090187782772879355, 0.0090180716324338838, 0.0090173700525234043, 0.0090166739999661977, 0.0090159813023608024, 0.0090152936525853718, 0.009014609656565354, 0.0090139293509238737, 0.009013252603543874, 0.0090125805685671093, 0.0090119117040574574, 0.0090112464717400729, 0.0090105849592366314, 0.0090099269146348172, 0.0090092728735905753, 0.0090086229148265071, 0.0090079744435772879, 0.0090073296613375174, 0.0090066887101501458, 0.0090060508623445393, 0.0090054169715474922, 0.0090047855909745379, 0.0090041564183993526], 'val_acc': [0.045571481073134877, 0.046674016905549433, 0.047041528849687618, 0.047409040793825796, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.0040426313855200296, 0.0036751194413818448, 0.0040426313855200296, 0.004410143329658214, 0.0047776552737963983, 0.0047776552737963983, 0.0047776552737963983, 0.0047776552737963983, 0.0047776552737963983, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.005512679162072767, 0.005512679162072767, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296], 'loss': [0.010234399140018311, 0.010102581637574841, 0.0099826335850510921, 0.0098743210228305657, 0.0097768597984536736, 0.0096894564186852158, 0.0096115017529497908, 0.0095420953489239197, 0.0094805522671519687, 0.0094261361911117374, 0.0093782507966848564, 0.0093361068703531423, 0.0092991324734000812, 0.0092667289147053133, 0.0092384212818287098, 0.0092137194069074283, 0.0091921916047237578, 0.0091734037186885966, 0.0091570363002433149, 0.0091427400584967213, 0.0091302524514773418, 0.0091193233564865507, 0.0091097495751026741, 0.0091013538337831514, 0.0090939746690634881, 0.0090874421879067521, 0.0090816699268372499, 0.0090765335899003225, 0.009071944203953429, 0.0090678195182494221, 0.0090641079144032216, 0.0090607437000503506, 0.0090576876595029228, 0.0090548942017373429, 0.0090523262871620228, 0.0090499606417434649, 0.0090477648893618375, 0.0090457241561771821, 0.0090438176310680997, 0.0090420291777021152, 0.0090403473259620722, 0.0090387569809232127, 0.0090372470354178249, 0.0090358125366434248, 0.0090344449786652938, 0.0090331352907193508, 0.0090318777615244917, 0.0090306670991062554, 0.009029500060125489, 0.009028372232602961, 0.0090272798056266011, 0.0090262198737717653, 0.0090251894237006521, 0.0090241840915605605, 0.0090232023702253288, 0.0090222435451132229, 0.0090213046971961402, 0.0090203857927512177, 0.009019483430684894, 0.0090185978438563907, 0.0090177274768987112, 0.0090168707601555043, 0.0090160265680833719, 0.0090151936928322667, 0.0090143714435979294, 0.0090135616287259843, 0.0090127601901557868, 0.0090119688716451055, 0.0090111857852852237, 0.0090104130073756297, 0.0090096471835775099, 0.0090088884040852319, 0.0090081370944927498, 0.0090073921249127029, 0.0090066532715167378, 0.0090059193145660688, 0.0090051918209734915, 0.0090044708531548806, 0.0090037540873192309, 0.0090030434712762113, 0.0090023380662727845, 0.0090016378451020299, 0.0090009431851170649, 0.0090002522038962786, 0.0089995673369162206, 0.0089988855093377368, 0.0089982077512513782, 0.0089975347831832472, 0.0089968661669647676, 0.0089962004126169955, 0.0089955397512216408, 0.0089948817015762378, 0.0089942283970233534, 0.0089935780811162755, 0.00899293107988078, 0.0089922887830417384, 0.008991648295691471, 0.0089910113348380845, 0.0089903789773268811, 0.0089897497288349577, 0.0089891223508759017], 'acc': [0.048606849148754287, 0.053148398184294905, 0.053271142752847743, 0.053025653616656579, 0.053025653600195254, 0.052780164481379933, 0.052780164481379933, 0.052780164478636378, 0.052780164478636378, 0.051675463361660803, 0.040873941328096235, 0.0083466306615932254, 0.0050325273106665031, 0.0057689947219835523, 0.0061372284276420769, 0.0061372284276420769, 0.0061372284276420769, 0.0062599729961949182, 0.0062599729961949182, 0.0062599729961949182, 0.0062599729961949182, 0.0063827175647477603, 0.0063827175647477603, 0.0063827175656622779, 0.0063827175647477603, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.00650546213421512, 0.0063827175647477603, 0.0062599729961949182, 0.0062599729961949182, 0.0063827175647477603, 0.0062599729961949182, 0.0061372284276420769, 0.0058917392905363936, 0.0058917392905363936, 0.0057689947219835523, 0.0056462501534307111, 0.0052780164477721865, 0.0052780164477721865, 0.0052780164477721865, 0.0052780164477721865, 0.0052780164486867041, 0.0051552718792193444, 0.0050325273106665031, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827430281795, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0047870381735608198, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0046642936050079785, 0.0049097827421136619, 0.0046642936050079785, 0.0049097827421136619, 0.0049097827421136619, 0.0047870381735608198, 0.0046642936050079785, 0.0049097827421136619, 0.0047870381735608198, 0.0045415490364551373, 0.0046642936050079785, 0.0046642936050079785, 0.0046642936050079785, 0.0045415490364551373, 0.0046642936050079785, 0.0047870381735608198, 0.0047870381735608198, 0.0045415490364551373, 0.0047870381735608198, 0.0049097827421136619, 0.0049097827421136619, 0.0047870381735608198, 0.0049097827421136619, 0.0047870381735608198, 0.0047870381735608198, 0.0049097827421136619]}
[2017-11-12 16:16:17,775 trial.py:88]: done!
[2017-11-12 16:16:17,775 trial.py:152]: >> Executing classifier part ... 
[2017-11-12 16:16:17,775 trial.py:93]: =======================================
[2017-11-12 16:16:17,775 trial.py:97]: setting configurations for classifier: 
	 {'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cc940>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'softmax', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cceb8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
[2017-11-12 16:16:17,807 trial.py:106]: training ... 
[2017-11-12 16:19:13,588 trial.py:118]: trained!
[2017-11-12 16:19:13,589 trial.py:120]: MODEL FOR MLP <bound method Trial.__network_name of <trial.Trial object at 0x7f93822ccac8>>, TOPOLOGY:
		None
[2017-11-12 16:19:13,589 trial.py:124]: Training history: 
{'val_loss': [0.010165809689980248, 0.010040726005080889, 0.0099274204326509474, 0.0098255530628829219, 0.0097341343913828343, 0.0096523444089889315, 0.0095794576297910158, 0.0095146921658748121, 0.0094573955687884889, 0.0094069330674109754, 0.009362640314198447, 0.0093237306896661494, 0.0092896591144306217, 0.0092598989058952693, 0.0092339157244927823, 0.0092112857181659655, 0.009191557946068997, 0.009174426946034658, 0.0091595158993359963, 0.0091465200981736532, 0.0091351753744909059, 0.0091252643330921503, 0.0091166069247827983, 0.0091090229480571498, 0.009102336390478586, 0.0090964481515898206, 0.0090912359406249525, 0.0090866033966731426, 0.0090824573974028228, 0.0090787408706410021, 0.0090753895489691337, 0.0090723543296794343, 0.0090695943430788989, 0.0090670650783831776, 0.0090647405194846289, 0.009062593206913867, 0.0090605997415762612, 0.0090587406776207451, 0.0090569980529461094, 0.0090553632292873238, 0.009053818346540286, 0.0090523538395669342, 0.0090509630836894169, 0.0090496364966560616, 0.0090483640190877918, 0.0090471452573716131, 0.0090459710855046553, 0.0090448394495116265, 0.0090437441039522403, 0.0090426821052858337, 0.0090416513820812359, 0.00904064892747743, 0.0090396700520034186, 0.0090387137343190434, 0.0090377779276367282, 0.0090368601494564237, 0.009035960067089583, 0.0090350751035690353, 0.0090342062549067965, 0.0090333502500077375, 0.0090325082604694965, 0.0090316768187327177, 0.0090308553032311441, 0.0090300441548113262, 0.0090292438132930052, 0.0090284530961258318, 0.0090276692059193635, 0.0090268925212266156, 0.009026124381358594, 0.0090253633124913329, 0.0090246102983150486, 0.0090238630620352658, 0.0090231209475162364, 0.0090223841433499236, 0.0090216524934602204, 0.0090209263918023912, 0.0090202059615944203, 0.0090194895014013496, 0.0090187782772879355, 0.0090180716324338838, 0.0090173700525234043, 0.0090166739999661977, 0.0090159813023608024, 0.0090152936525853718, 0.009014609656565354, 0.0090139293509238737, 0.009013252603543874, 0.0090125805685671093, 0.0090119117040574574, 0.0090112464717400729, 0.0090105849592366314, 0.0090099269146348172, 0.0090092728735905753, 0.0090086229148265071, 0.0090079744435772879, 0.0090073296613375174, 0.0090066887101501458, 0.0090060508623445393, 0.0090054169715474922, 0.0090047855909745379, 0.0090041564183993526], 'val_acc': [0.045571481073134877, 0.046674016905549433, 0.047041528849687618, 0.047409040793825796, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.0040426313855200296, 0.0036751194413818448, 0.0040426313855200296, 0.004410143329658214, 0.0047776552737963983, 0.0047776552737963983, 0.0047776552737963983, 0.0047776552737963983, 0.0047776552737963983, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.005512679162072767, 0.005512679162072767, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.0051451672179345827, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.004410143329658214, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0036751194413818448, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296, 0.0040426313855200296], 'loss': [0.010234399140018311, 0.010102581637574841, 0.0099826335850510921, 0.0098743210228305657, 0.0097768597984536736, 0.0096894564186852158, 0.0096115017529497908, 0.0095420953489239197, 0.0094805522671519687, 0.0094261361911117374, 0.0093782507966848564, 0.0093361068703531423, 0.0092991324734000812, 0.0092667289147053133, 0.0092384212818287098, 0.0092137194069074283, 0.0091921916047237578, 0.0091734037186885966, 0.0091570363002433149, 0.0091427400584967213, 0.0091302524514773418, 0.0091193233564865507, 0.0091097495751026741, 0.0091013538337831514, 0.0090939746690634881, 0.0090874421879067521, 0.0090816699268372499, 0.0090765335899003225, 0.009071944203953429, 0.0090678195182494221, 0.0090641079144032216, 0.0090607437000503506, 0.0090576876595029228, 0.0090548942017373429, 0.0090523262871620228, 0.0090499606417434649, 0.0090477648893618375, 0.0090457241561771821, 0.0090438176310680997, 0.0090420291777021152, 0.0090403473259620722, 0.0090387569809232127, 0.0090372470354178249, 0.0090358125366434248, 0.0090344449786652938, 0.0090331352907193508, 0.0090318777615244917, 0.0090306670991062554, 0.009029500060125489, 0.009028372232602961, 0.0090272798056266011, 0.0090262198737717653, 0.0090251894237006521, 0.0090241840915605605, 0.0090232023702253288, 0.0090222435451132229, 0.0090213046971961402, 0.0090203857927512177, 0.009019483430684894, 0.0090185978438563907, 0.0090177274768987112, 0.0090168707601555043, 0.0090160265680833719, 0.0090151936928322667, 0.0090143714435979294, 0.0090135616287259843, 0.0090127601901557868, 0.0090119688716451055, 0.0090111857852852237, 0.0090104130073756297, 0.0090096471835775099, 0.0090088884040852319, 0.0090081370944927498, 0.0090073921249127029, 0.0090066532715167378, 0.0090059193145660688, 0.0090051918209734915, 0.0090044708531548806, 0.0090037540873192309, 0.0090030434712762113, 0.0090023380662727845, 0.0090016378451020299, 0.0090009431851170649, 0.0090002522038962786, 0.0089995673369162206, 0.0089988855093377368, 0.0089982077512513782, 0.0089975347831832472, 0.0089968661669647676, 0.0089962004126169955, 0.0089955397512216408, 0.0089948817015762378, 0.0089942283970233534, 0.0089935780811162755, 0.00899293107988078, 0.0089922887830417384, 0.008991648295691471, 0.0089910113348380845, 0.0089903789773268811, 0.0089897497288349577, 0.0089891223508759017], 'acc': [0.048606849148754287, 0.053148398184294905, 0.053271142752847743, 0.053025653616656579, 0.053025653600195254, 0.052780164481379933, 0.052780164481379933, 0.052780164478636378, 0.052780164478636378, 0.051675463361660803, 0.040873941328096235, 0.0083466306615932254, 0.0050325273106665031, 0.0057689947219835523, 0.0061372284276420769, 0.0061372284276420769, 0.0061372284276420769, 0.0062599729961949182, 0.0062599729961949182, 0.0062599729961949182, 0.0062599729961949182, 0.0063827175647477603, 0.0063827175647477603, 0.0063827175656622779, 0.0063827175647477603, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.0065054621333006015, 0.00650546213421512, 0.0063827175647477603, 0.0062599729961949182, 0.0062599729961949182, 0.0063827175647477603, 0.0062599729961949182, 0.0061372284276420769, 0.0058917392905363936, 0.0058917392905363936, 0.0057689947219835523, 0.0056462501534307111, 0.0052780164477721865, 0.0052780164477721865, 0.0052780164477721865, 0.0052780164477721865, 0.0052780164486867041, 0.0051552718792193444, 0.0050325273106665031, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827430281795, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0047870381735608198, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0049097827421136619, 0.0046642936050079785, 0.0049097827421136619, 0.0046642936050079785, 0.0049097827421136619, 0.0049097827421136619, 0.0047870381735608198, 0.0046642936050079785, 0.0049097827421136619, 0.0047870381735608198, 0.0045415490364551373, 0.0046642936050079785, 0.0046642936050079785, 0.0046642936050079785, 0.0045415490364551373, 0.0046642936050079785, 0.0047870381735608198, 0.0047870381735608198, 0.0045415490364551373, 0.0047870381735608198, 0.0049097827421136619, 0.0049097827421136619, 0.0047870381735608198, 0.0049097827421136619, 0.0047870381735608198, 0.0047870381735608198, 0.0049097827421136619]}
[2017-11-12 16:19:13,589 trial.py:128]: evaluating model ... 
[2017-11-12 16:19:13,657 trial.py:132]: evaluated! 
[2017-11-12 16:19:13,658 trial.py:134]: generating reports ... 
[2017-11-12 16:19:14,502 trial.py:137]: done!
[2017-11-12 16:19:14,503 trial.py:154]: >> experiment ae_unigrama_apaga1L_1 finished!
[2017-11-12 16:19:14,503 trial.py:144]: >> Initializing execution of experiment ae_unigrama_apaga2L_2
[2017-11-12 16:19:14,503 trial.py:145]: >> Printing header log
[2017-11-12 16:19:14,503 trial.py:49]: 
		=======================================
		network_name = ae_unigrama_apaga2L_2
		layers = 96,2
		using GLOBAL obj = 
			{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/1layer/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/1layer/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/1layer/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/1layer/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/1layer/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cc940>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'softmax', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cceb8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
		=======================================
		
[2017-11-12 16:19:14,503 trial.py:150]: >> Executing autoencoder part ... 
[2017-11-12 16:19:14,503 trial.py:54]: =======================================
[2017-11-12 16:19:14,504 trial.py:58]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f93822cc940>, 'discard_decoder_function': True}
[2017-11-12 16:19:14,542 trial.py:69]: training and evaluating autoencoder
