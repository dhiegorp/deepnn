[2017-11-18 20:00:23,228 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_9FULLDS_UNDER_02
[2017-11-18 20:00:23,228 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 20:00:23,228 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_9FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,29,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f19b8cf8eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f19b8cfd400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:00:23,228 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 20:00:25,445 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:00:25,446 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:00:25,446 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 20:00:25,446 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f19b8cf8eb8>, 'discard_decoder_function': True}
[2017-11-18 20:00:25,637 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 20:02:08,432 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 20:02:08,434 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0095299526861499489, 0.0088439935517799582, 0.0083005020009180568, 0.0078633984977647103, 0.007508712549458057, 0.0072085407784346252, 0.0069589338201012235, 0.0067514352172199678, 0.0065781846555214799, 0.0064328286441871999, 0.0063103440564053212, 0.0062068401244070237, 0.0061190245693254477, 0.0060442110824096467, 0.0059803097622824347, 0.0059255621411749672, 0.005878600685435215, 0.0058381740251629288, 0.0058032651779264793, 0.0057731384752186142, 0.0057470841872006469, 0.005724456383737515, 0.0057047971572045161, 0.0056876969644036558, 0.0056728148249000892, 0.0056598638007242762, 0.0056485508492258229, 0.0056386577873841579, 0.005629998631860947, 0.0056224116227750077, 0.005615740843087802, 0.0056099209425172049, 0.0056047954783801949, 0.005600265223065371, 0.0055962885726203553, 0.0055927795679566886, 0.0055896888668616387, 0.0055869603475664619, 0.0055845514100211994, 0.0055824189508646635, 0.0055805293433108076, 0.0055788692054590319, 0.0055773735435892449, 0.0055760503348677758, 0.0055748708446902726, 0.0055738201588891971, 0.0055728807199290466, 0.0055720498093131086, 0.0055712962132741352, 0.005570623183312173, 0.0055700185470309044, 0.0055694782274553758, 0.0055689922250185715, 0.0055685461333992888, 0.0055681475930536104, 0.0055677810813396494, 0.0055674490327537827, 0.0055671423651039798, 0.0055668608972426941, 0.0055666047312526012, 0.0055663657160931069, 0.0055661494913827577, 0.0055659449027282365, 0.0055657532287728025, 0.0055655785677122833, 0.0055654134610938219, 0.0055652536340235828, 0.0055651051943484409, 0.0055649670416633686, 0.0055648270505489024, 0.0055646968130788977, 0.0055645771078369722, 0.0055643556221466658, 0.0055642378225906159, 0.0055641302475599634, 0.0055640201046323568, 0.0055639211829267071, 0.0055638166692639126, 0.0055637176759378111, 0.0055636198009860263, 0.0055635241905924856, 0.0055634278925741553, 0.0055633355107484262, 0.0055632485742162186, 0.0055631574706059084, 0.0055630636627031832, 0.0055629765760846295, 0.0055628856586703796, 0.0055627950315029302, 0.0055627014075714971, 0.00556261016482755, 0.0055625151690692582, 0.0055624156421408442, 0.0055623200224203875, 0.0055622306173357212, 0.0055621333046515431, 0.0055620366421989201, 0.0055619167736931695, 0.0055617908989098125, 0.0055616924580965616, 0.0055615892027974], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099535587686019698, 0.0091777411997693223, 0.0085683668453424237, 0.0080820453385005691, 0.0076892277234654255, 0.0073646760277717126, 0.0070915243599705127, 0.0068648603649466323, 0.0066761338791925546, 0.0065182977309376205, 0.0063856625496221788, 0.0062738225431350336, 0.0061791745658423894, 0.0060988030131991777, 0.0060303018865525007, 0.0059717407360228491, 0.0059215846067728643, 0.0058785333053284448, 0.0058414788191494026, 0.0058095096193809103, 0.005781898894146628, 0.0057580317523775364, 0.0057373323190417283, 0.0057193528583251111, 0.0057037213135465413, 0.0056901655536100619, 0.0056783538002498392, 0.0056680526743398693, 0.0056590621596392249, 0.0056511993808949614, 0.0056443169121555611, 0.0056382832502619544, 0.0056330232224385442, 0.0056284038755574943, 0.0056243296127345237, 0.0056207605379372857, 0.0056176258666490913, 0.0056148615469226691, 0.005612440430310583, 0.0056103036021721156, 0.0056084098912363069, 0.0056067454580977106, 0.0056052800848996861, 0.0056039759665416676, 0.0056028183515576752, 0.0056017971266327645, 0.0056008876776211837, 0.0056000806023602809, 0.0055993671820612064, 0.0055987214123960748, 0.0055981450560417543, 0.0055976356774073803, 0.0055971792669871024, 0.0055967690949550583, 0.0055963980879122945, 0.0055960598652646252, 0.0055957553311848625, 0.0055954785158118543, 0.0055952281866035597, 0.005594995576816076, 0.0055947823434994055, 0.0055945872975511285, 0.0055944067961019072, 0.0055942368300749843, 0.0055940807676984183, 0.0055939356279854939, 0.005593797693990891, 0.0055936649579468372, 0.0055935473526080711, 0.0055934242303804982, 0.0055933109894088515, 0.0055932067443822571, 0.0055930483663310391, 0.0055929011728957975, 0.0055927986132692743, 0.005592707546851497, 0.0055926097356897783, 0.0055925210020938716, 0.00559243285133191, 0.0055923444110677475, 0.0055922595982975838, 0.0055921724549346874, 0.0055920909592367153, 0.0055920071867311188, 0.0055919217277966178, 0.0055918458841646892, 0.005591760334807191, 0.0055916776805288466, 0.005591592176954421, 0.0055915106834284302, 0.0055914269324140132, 0.0055913372617797923, 0.0055912496146316272, 0.0055911575495027075, 0.0055910724153365185, 0.0055909841144220832, 0.0055908885370284716, 0.0055907922449388086, 0.0055906581566651332, 0.0055905536695769762, 0.0055904546681125314], 'acc': [0.57554928188574483, 0.5938382226842539, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.59383822268059583, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427]}
[2017-11-18 20:02:08,434 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:95]: done!
[2017-11-18 20:02:08,434 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 20:02:08,435 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 20:02:08,435 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f19b8cfd400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:02:08,487 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 20:06:19,765 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 20:06:19,768 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0095299526861499489, 0.0088439935517799582, 0.0083005020009180568, 0.0078633984977647103, 0.007508712549458057, 0.0072085407784346252, 0.0069589338201012235, 0.0067514352172199678, 0.0065781846555214799, 0.0064328286441871999, 0.0063103440564053212, 0.0062068401244070237, 0.0061190245693254477, 0.0060442110824096467, 0.0059803097622824347, 0.0059255621411749672, 0.005878600685435215, 0.0058381740251629288, 0.0058032651779264793, 0.0057731384752186142, 0.0057470841872006469, 0.005724456383737515, 0.0057047971572045161, 0.0056876969644036558, 0.0056728148249000892, 0.0056598638007242762, 0.0056485508492258229, 0.0056386577873841579, 0.005629998631860947, 0.0056224116227750077, 0.005615740843087802, 0.0056099209425172049, 0.0056047954783801949, 0.005600265223065371, 0.0055962885726203553, 0.0055927795679566886, 0.0055896888668616387, 0.0055869603475664619, 0.0055845514100211994, 0.0055824189508646635, 0.0055805293433108076, 0.0055788692054590319, 0.0055773735435892449, 0.0055760503348677758, 0.0055748708446902726, 0.0055738201588891971, 0.0055728807199290466, 0.0055720498093131086, 0.0055712962132741352, 0.005570623183312173, 0.0055700185470309044, 0.0055694782274553758, 0.0055689922250185715, 0.0055685461333992888, 0.0055681475930536104, 0.0055677810813396494, 0.0055674490327537827, 0.0055671423651039798, 0.0055668608972426941, 0.0055666047312526012, 0.0055663657160931069, 0.0055661494913827577, 0.0055659449027282365, 0.0055657532287728025, 0.0055655785677122833, 0.0055654134610938219, 0.0055652536340235828, 0.0055651051943484409, 0.0055649670416633686, 0.0055648270505489024, 0.0055646968130788977, 0.0055645771078369722, 0.0055643556221466658, 0.0055642378225906159, 0.0055641302475599634, 0.0055640201046323568, 0.0055639211829267071, 0.0055638166692639126, 0.0055637176759378111, 0.0055636198009860263, 0.0055635241905924856, 0.0055634278925741553, 0.0055633355107484262, 0.0055632485742162186, 0.0055631574706059084, 0.0055630636627031832, 0.0055629765760846295, 0.0055628856586703796, 0.0055627950315029302, 0.0055627014075714971, 0.00556261016482755, 0.0055625151690692582, 0.0055624156421408442, 0.0055623200224203875, 0.0055622306173357212, 0.0055621333046515431, 0.0055620366421989201, 0.0055619167736931695, 0.0055617908989098125, 0.0055616924580965616, 0.0055615892027974], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099535587686019698, 0.0091777411997693223, 0.0085683668453424237, 0.0080820453385005691, 0.0076892277234654255, 0.0073646760277717126, 0.0070915243599705127, 0.0068648603649466323, 0.0066761338791925546, 0.0065182977309376205, 0.0063856625496221788, 0.0062738225431350336, 0.0061791745658423894, 0.0060988030131991777, 0.0060303018865525007, 0.0059717407360228491, 0.0059215846067728643, 0.0058785333053284448, 0.0058414788191494026, 0.0058095096193809103, 0.005781898894146628, 0.0057580317523775364, 0.0057373323190417283, 0.0057193528583251111, 0.0057037213135465413, 0.0056901655536100619, 0.0056783538002498392, 0.0056680526743398693, 0.0056590621596392249, 0.0056511993808949614, 0.0056443169121555611, 0.0056382832502619544, 0.0056330232224385442, 0.0056284038755574943, 0.0056243296127345237, 0.0056207605379372857, 0.0056176258666490913, 0.0056148615469226691, 0.005612440430310583, 0.0056103036021721156, 0.0056084098912363069, 0.0056067454580977106, 0.0056052800848996861, 0.0056039759665416676, 0.0056028183515576752, 0.0056017971266327645, 0.0056008876776211837, 0.0056000806023602809, 0.0055993671820612064, 0.0055987214123960748, 0.0055981450560417543, 0.0055976356774073803, 0.0055971792669871024, 0.0055967690949550583, 0.0055963980879122945, 0.0055960598652646252, 0.0055957553311848625, 0.0055954785158118543, 0.0055952281866035597, 0.005594995576816076, 0.0055947823434994055, 0.0055945872975511285, 0.0055944067961019072, 0.0055942368300749843, 0.0055940807676984183, 0.0055939356279854939, 0.005593797693990891, 0.0055936649579468372, 0.0055935473526080711, 0.0055934242303804982, 0.0055933109894088515, 0.0055932067443822571, 0.0055930483663310391, 0.0055929011728957975, 0.0055927986132692743, 0.005592707546851497, 0.0055926097356897783, 0.0055925210020938716, 0.00559243285133191, 0.0055923444110677475, 0.0055922595982975838, 0.0055921724549346874, 0.0055920909592367153, 0.0055920071867311188, 0.0055919217277966178, 0.0055918458841646892, 0.005591760334807191, 0.0055916776805288466, 0.005591592176954421, 0.0055915106834284302, 0.0055914269324140132, 0.0055913372617797923, 0.0055912496146316272, 0.0055911575495027075, 0.0055910724153365185, 0.0055909841144220832, 0.0055908885370284716, 0.0055907922449388086, 0.0055906581566651332, 0.0055905536695769762, 0.0055904546681125314], 'acc': [0.57554928188574483, 0.5938382226842539, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.59383822268059583, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427]}
[2017-11-18 20:06:19,768 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 20:06:19,928 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 20:06:19,928 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 20:06:20,782 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:141]: done!
[2017-11-18 20:06:20,783 AE_UNIGRAMA_8L_9FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_8L_9FULLDS_UNDER_02 finished!
