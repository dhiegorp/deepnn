[2017-11-13 15:24:29,695 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_FULLDS_OVER_05
[2017-11-13 15:24:29,696 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-13 15:24:29,696 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd1d7e4aef0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd1d7e2f438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 15:24:29,696 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-13 15:24:31,993 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 15:24:31,993 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-13 15:24:31,993 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-13 15:24:31,993 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd1d7e4aef0>, 'discard_decoder_function': True}
[2017-11-13 15:24:32,187 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-13 15:30:54,266 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-13 15:30:54,266 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0091167431545828206, 0.0082085169487260082, 0.0075755753391482227, 0.0071250761775946804, 0.0067975046046390361, 0.0065548217062006992, 0.0063708238873544506, 0.0062286863158272495, 0.0061171867710821271, 0.0060277126797258261, 0.0059552300378792498, 0.005895972980760676, 0.0058471633245273796, 0.0058064850154875315, 0.0057728121260633555, 0.0057443866874332629, 0.0057203258219688793, 0.0056998063874345731, 0.0056822725092682087, 0.0056672331348071149, 0.0056543213262940451, 0.0056430603982829371, 0.0056332538551447289, 0.0056249094299201264, 0.0056177361385546997, 0.0056114383477400007, 0.0056059675476692128, 0.0056011798725357689, 0.0055969926020871877, 0.00559333443991807, 0.0055901323274347506, 0.0055873266862618409, 0.0055848293978301962, 0.0055826303200164412, 0.0055806812068200347, 0.005578926482995324, 0.0055773406255632931, 0.0055759009857754777, 0.0055745818098758525, 0.0055733755780592734, 0.0055722682799278691, 0.0055712575407117571, 0.0055702908548332401, 0.0055694765101047625, 0.0055687244391450109, 0.0055680335844185466, 0.005567392899861196, 0.0055667600158577357, 0.0055661769676234787, 0.0055656350864311741, 0.0055651223118075039, 0.0055646325113475649, 0.0055641560222801593, 0.0055637045116367443, 0.0055632694244099994, 0.0055628460718134681, 0.0055624252201141146, 0.005562013426134332, 0.0055615925441438912, 0.0055611710013114589, 0.0055607494633564047, 0.0055603284905782705, 0.0055599012735578031, 0.0055594734924728001, 0.0055590545626316807, 0.0055586126235439327, 0.0055580509111876654, 0.0055573997917786671, 0.0055567788381851013, 0.0055562124031574324, 0.0055547807750198682, 0.0055542376811572652, 0.0055537274233464296, 0.0055532028665167144, 0.0055526976944424841, 0.0055521712055719378, 0.0055516593440448495, 0.0055511341258597333, 0.0055506363484901693, 0.0055501391304788985, 0.0055496669522439052, 0.0055491747426157298, 0.0055486808282154444, 0.0055481855891362925, 0.00554767589419204, 0.0055471585647814672, 0.0055466135897910178, 0.0055460509740929255, 0.0055454568953678769, 0.0055447676931314506, 0.0055439893716076188, 0.0055433047447799927, 0.0055426194410235817, 0.0055418643673100822, 0.0055410743863703472, 0.0055399498307905637, 0.0055386214867885917, 0.005537603228879721, 0.0055367755397294468, 0.0055360373458525564, 0.0055352907826509961], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097368251572555013, 0.0086415987731588238, 0.0078830851418105301, 0.0073498807676827867, 0.0069668396819386105, 0.0066863646090846423, 0.006476473184975763, 0.006316018825868101, 0.0061913100014665571, 0.0060926157122310302, 0.0060130698727316927, 0.0059483540654790591, 0.0058953641318594133, 0.0058514944403335713, 0.0058150671690435397, 0.0057847152499072105, 0.0057590413245674149, 0.0057372338524561755, 0.0057186771624203629, 0.0057027849866706261, 0.0056891509938088421, 0.0056773875146689072, 0.0056670892726352418, 0.0056582626132645484, 0.0056507105096475956, 0.0056441801599472329, 0.0056384752458915966, 0.0056335237745995369, 0.0056291655920252953, 0.0056253773394281167, 0.0056220623665701082, 0.0056191540733130669, 0.0056166055412672448, 0.0056143582328020926, 0.0056123553994849619, 0.0056105809926628204, 0.0056089829256600566, 0.005607528640139069, 0.0056062063852255805, 0.0056049894618435854, 0.0056038822141836406, 0.0056028545998623065, 0.0056019220601209903, 0.0056010526176269977, 0.0056003043062256069, 0.005599617358259157, 0.0055989771058257776, 0.005598363907987393, 0.0055977792480926877, 0.0055972442568300498, 0.0055967392053533306, 0.0055962505426161366, 0.0055957930401466923, 0.0055953446349052034, 0.0055949181419223037, 0.0055945061805208899, 0.0055940975767162599, 0.0055936868556302919, 0.0055932855694010037, 0.0055928785128470243, 0.0055924619375293102, 0.005592051917364462, 0.005591638352240893, 0.0055912201368489211, 0.005590804450042894, 0.0055903822738721616, 0.0055899185005507286, 0.0055892865363967098, 0.0055886449177301456, 0.0055880447026793465, 0.0055869940285504273, 0.0055860638216309816, 0.0055855552293680314, 0.0055850404065490552, 0.0055845296547654523, 0.0055840178691760681, 0.0055834983808276655, 0.0055829819716623815, 0.0055824785623747441, 0.0055819946677644981, 0.0055815077519858888, 0.005581033958859007, 0.0055805558853292189, 0.0055800772333094474, 0.0055795829814365011, 0.0055790720549227452, 0.0055785544419084329, 0.0055780184809706085, 0.0055774559153236357, 0.0055768468236152644, 0.0055761043012290332, 0.0055753807959079233, 0.0055747353587273524, 0.0055740351648206751, 0.0055732660963116239, 0.00557237195696513, 0.0055710710786311367, 0.0055698856525740418, 0.0055689887807040227, 0.0055682166428429238, 0.0055674892254411528], 'acc': [0.5793543635767282, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822267327968, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822272449271, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198]}
[2017-11-13 15:30:54,266 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:95]: done!
[2017-11-13 15:30:54,267 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-13 15:30:54,267 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-13 15:30:54,267 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd1d7e2f438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 15:30:54,307 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-13 15:40:33,753 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:125]: trained!
[2017-11-13 15:40:33,754 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0091167431545828206, 0.0082085169487260082, 0.0075755753391482227, 0.0071250761775946804, 0.0067975046046390361, 0.0065548217062006992, 0.0063708238873544506, 0.0062286863158272495, 0.0061171867710821271, 0.0060277126797258261, 0.0059552300378792498, 0.005895972980760676, 0.0058471633245273796, 0.0058064850154875315, 0.0057728121260633555, 0.0057443866874332629, 0.0057203258219688793, 0.0056998063874345731, 0.0056822725092682087, 0.0056672331348071149, 0.0056543213262940451, 0.0056430603982829371, 0.0056332538551447289, 0.0056249094299201264, 0.0056177361385546997, 0.0056114383477400007, 0.0056059675476692128, 0.0056011798725357689, 0.0055969926020871877, 0.00559333443991807, 0.0055901323274347506, 0.0055873266862618409, 0.0055848293978301962, 0.0055826303200164412, 0.0055806812068200347, 0.005578926482995324, 0.0055773406255632931, 0.0055759009857754777, 0.0055745818098758525, 0.0055733755780592734, 0.0055722682799278691, 0.0055712575407117571, 0.0055702908548332401, 0.0055694765101047625, 0.0055687244391450109, 0.0055680335844185466, 0.005567392899861196, 0.0055667600158577357, 0.0055661769676234787, 0.0055656350864311741, 0.0055651223118075039, 0.0055646325113475649, 0.0055641560222801593, 0.0055637045116367443, 0.0055632694244099994, 0.0055628460718134681, 0.0055624252201141146, 0.005562013426134332, 0.0055615925441438912, 0.0055611710013114589, 0.0055607494633564047, 0.0055603284905782705, 0.0055599012735578031, 0.0055594734924728001, 0.0055590545626316807, 0.0055586126235439327, 0.0055580509111876654, 0.0055573997917786671, 0.0055567788381851013, 0.0055562124031574324, 0.0055547807750198682, 0.0055542376811572652, 0.0055537274233464296, 0.0055532028665167144, 0.0055526976944424841, 0.0055521712055719378, 0.0055516593440448495, 0.0055511341258597333, 0.0055506363484901693, 0.0055501391304788985, 0.0055496669522439052, 0.0055491747426157298, 0.0055486808282154444, 0.0055481855891362925, 0.00554767589419204, 0.0055471585647814672, 0.0055466135897910178, 0.0055460509740929255, 0.0055454568953678769, 0.0055447676931314506, 0.0055439893716076188, 0.0055433047447799927, 0.0055426194410235817, 0.0055418643673100822, 0.0055410743863703472, 0.0055399498307905637, 0.0055386214867885917, 0.005537603228879721, 0.0055367755397294468, 0.0055360373458525564, 0.0055352907826509961], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097368251572555013, 0.0086415987731588238, 0.0078830851418105301, 0.0073498807676827867, 0.0069668396819386105, 0.0066863646090846423, 0.006476473184975763, 0.006316018825868101, 0.0061913100014665571, 0.0060926157122310302, 0.0060130698727316927, 0.0059483540654790591, 0.0058953641318594133, 0.0058514944403335713, 0.0058150671690435397, 0.0057847152499072105, 0.0057590413245674149, 0.0057372338524561755, 0.0057186771624203629, 0.0057027849866706261, 0.0056891509938088421, 0.0056773875146689072, 0.0056670892726352418, 0.0056582626132645484, 0.0056507105096475956, 0.0056441801599472329, 0.0056384752458915966, 0.0056335237745995369, 0.0056291655920252953, 0.0056253773394281167, 0.0056220623665701082, 0.0056191540733130669, 0.0056166055412672448, 0.0056143582328020926, 0.0056123553994849619, 0.0056105809926628204, 0.0056089829256600566, 0.005607528640139069, 0.0056062063852255805, 0.0056049894618435854, 0.0056038822141836406, 0.0056028545998623065, 0.0056019220601209903, 0.0056010526176269977, 0.0056003043062256069, 0.005599617358259157, 0.0055989771058257776, 0.005598363907987393, 0.0055977792480926877, 0.0055972442568300498, 0.0055967392053533306, 0.0055962505426161366, 0.0055957930401466923, 0.0055953446349052034, 0.0055949181419223037, 0.0055945061805208899, 0.0055940975767162599, 0.0055936868556302919, 0.0055932855694010037, 0.0055928785128470243, 0.0055924619375293102, 0.005592051917364462, 0.005591638352240893, 0.0055912201368489211, 0.005590804450042894, 0.0055903822738721616, 0.0055899185005507286, 0.0055892865363967098, 0.0055886449177301456, 0.0055880447026793465, 0.0055869940285504273, 0.0055860638216309816, 0.0055855552293680314, 0.0055850404065490552, 0.0055845296547654523, 0.0055840178691760681, 0.0055834983808276655, 0.0055829819716623815, 0.0055824785623747441, 0.0055819946677644981, 0.0055815077519858888, 0.005581033958859007, 0.0055805558853292189, 0.0055800772333094474, 0.0055795829814365011, 0.0055790720549227452, 0.0055785544419084329, 0.0055780184809706085, 0.0055774559153236357, 0.0055768468236152644, 0.0055761043012290332, 0.0055753807959079233, 0.0055747353587273524, 0.0055740351648206751, 0.0055732660963116239, 0.00557237195696513, 0.0055710710786311367, 0.0055698856525740418, 0.0055689887807040227, 0.0055682166428429238, 0.0055674892254411528], 'acc': [0.5793543635767282, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822267327968, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822262938279, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822272449271, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198]}
[2017-11-13 15:40:33,754 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-13 15:40:33,968 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-13 15:40:33,968 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-13 15:40:34,856 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:141]: done!
[2017-11-13 15:40:34,857 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_8L_FULLDS_OVER_05 finished!
[2017-11-14 07:04:00,198 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_8L_FULLDS_OVER_05 was already executed!
[2017-11-18 14:55:50,245 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_8L_FULLDS_OVER_05 was already executed!
[2017-11-18 16:22:20,591 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_8L_FULLDS_OVER_05 was already executed!
[2017-11-18 16:59:38,210 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_FULLDS_OVER_05
[2017-11-18 16:59:38,210 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 16:59:38,210 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc9e5531be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc9e5531470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:59:38,210 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 16:59:40,766 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:59:40,766 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:59:40,766 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 16:59:40,767 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc9e5531be0>, 'discard_decoder_function': True}
[2017-11-18 16:59:40,949 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 17:03:26,639 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 17:03:26,641 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0093105013435381342, 0.0084798930244344376, 0.0078638072984032296, 0.0074063945617780054, 0.0070625492734427246, 0.006798643820933814, 0.0065957247137541459, 0.0064389763495110277, 0.0063164448870420562, 0.0062198633482444922, 0.0061431010390636306, 0.0060814824128144918, 0.0060316996687584416, 0.0059911902326144463, 0.0059580043632878029, 0.0059308485721485419, 0.0059084192091905102, 0.0058897883334881303, 0.0058742213105383778, 0.0058610960473236308, 0.0058500486734442657, 0.0058405405752092483, 0.0058323747607804382, 0.0058254879130579694, 0.0058037970101790081, 0.0057838748196172105, 0.0057649067172644407, 0.0057450074391718169, 0.0057257560757938628, 0.0057068921134282467, 0.0056910928241560802, 0.0056788085737203694, 0.0056690892518848146, 0.0056612743700531721, 0.0056549092513077485, 0.0056497071371151928, 0.0056454190671702698, 0.0056418382124759688, 0.0056388257756775865, 0.0056362923843774485, 0.0056341473042769152, 0.0056323023975540319, 0.0056306841639984636, 0.005629272178176192, 0.0056279906194427083, 0.0056268203042985623, 0.005625790435747572, 0.005624827683859808, 0.0056239901055252948, 0.0056232378090081822, 0.0056225648551162105, 0.0056219476082446772, 0.0056213818754739337, 0.0056208587779216154, 0.0056203565804492468, 0.0056198880457015042, 0.0056194285589185756, 0.0056189941236347461, 0.0056185700935960222, 0.0056181569939334789, 0.0056177508565147145, 0.0056173472412140027, 0.0056169488129624605, 0.0056165515608436615, 0.0056161248861534476, 0.0056156919470268414, 0.0056152624983918254, 0.0056148383492423863, 0.0056144011595232694, 0.0056139621687679936, 0.0056135028631326108, 0.005613037939185125, 0.0056125345031153417, 0.0056120146594589764, 0.0056115084562898343, 0.0056110066773307618, 0.0056104703056935774, 0.0056099059165122369, 0.0056093162571198797, 0.005608710433239749, 0.0056081023562674914, 0.0056074893030857217, 0.0056068858472155996, 0.0056062745749614982, 0.0056056700969811081, 0.005605038010300668, 0.0056043838525416164, 0.0056036915577905655, 0.0056029500625274587, 0.0056021641613864222, 0.005601397383847205, 0.005600658088281767, 0.0055999306740957353, 0.0055992087474738368, 0.0055984773515500826, 0.0055975669782570413, 0.0055965239904137744, 0.005595690540395039, 0.0055948645873347795, 0.0055940265133045952, 0.0055931825882172331], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098494900500476611, 0.008881108168884334, 0.008166739031580111, 0.0076366404169303688, 0.007241284624540021, 0.0069414876210290083, 0.0067110909370249831, 0.0065338004069985592, 0.0063961960134790675, 0.0062881879520727017, 0.0062027760024355224, 0.0061346095951455345, 0.0060797535324048756, 0.0060352876398776867, 0.005998985656165935, 0.0059692282750365795, 0.0059448254706912593, 0.0059245880826373975, 0.0059076999709658518, 0.0058935447308511857, 0.0058815959482979036, 0.0058714338122510725, 0.0058626616073010288, 0.0058552321975169821, 0.0058412174074653949, 0.005820778814525444, 0.005800784164663563, 0.0057824581520952217, 0.005761861131205648, 0.0057433762120516684, 0.0057257276781271889, 0.0057118551503710074, 0.0057010193030384545, 0.0056923769495131138, 0.0056853850974117309, 0.0056796804415932007, 0.0056750133603434482, 0.0056711429250735808, 0.0056678976297650152, 0.0056651562322111741, 0.0056628444776413624, 0.005660869568168872, 0.0056591567799322761, 0.0056576624615441422, 0.0056563268057367323, 0.0056551111864006761, 0.0056540032766294818, 0.0056530225730959628, 0.0056521348079420263, 0.0056513489372740202, 0.0056506435236398271, 0.0056500050628621136, 0.0056494139926513785, 0.0056488758146354054, 0.0056483647954695152, 0.0056478866776999035, 0.0056474222472399143, 0.005646978358518526, 0.0056465520275768375, 0.0056461371412029537, 0.0056457291612141197, 0.005645324995338174, 0.0056449306028049954, 0.0056445292046043722, 0.0056441164630045334, 0.0056436933214454197, 0.0056432684081785698, 0.0056428346568353892, 0.0056424063048082559, 0.0056419683255326553, 0.0056415180104911668, 0.0056410527369596189, 0.0056405667625061282, 0.0056400491289723114, 0.0056395348218844996, 0.0056390405909311587, 0.0056385275569671364, 0.0056379866923250248, 0.0056374181660192391, 0.0056368337629898622, 0.005636235011625604, 0.005635632691582306, 0.0056350340336132291, 0.005634442716939813, 0.0056338427026257814, 0.0056332400626725506, 0.0056326063755660523, 0.0056319434766302018, 0.005631227588446335, 0.0056304751348486151, 0.0056297184944146426, 0.0056289724079791213, 0.005628251385518041, 0.0056275351223816711, 0.0056268261995692844, 0.005626031050084284, 0.0056250647927391043, 0.0056241246364892765, 0.0056233098248036507, 0.005622493347665884, 0.0056216582332167201], 'acc': [0.5659752056264169, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822264767316, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822262938279, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427]}
[2017-11-18 17:03:26,641 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:95]: done!
[2017-11-18 17:03:26,641 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 17:03:26,641 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 17:03:26,641 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc9e5531470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:03:26,706 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 17:10:35,217 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:125]: trained!
[2017-11-18 17:10:35,219 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0093105013435381342, 0.0084798930244344376, 0.0078638072984032296, 0.0074063945617780054, 0.0070625492734427246, 0.006798643820933814, 0.0065957247137541459, 0.0064389763495110277, 0.0063164448870420562, 0.0062198633482444922, 0.0061431010390636306, 0.0060814824128144918, 0.0060316996687584416, 0.0059911902326144463, 0.0059580043632878029, 0.0059308485721485419, 0.0059084192091905102, 0.0058897883334881303, 0.0058742213105383778, 0.0058610960473236308, 0.0058500486734442657, 0.0058405405752092483, 0.0058323747607804382, 0.0058254879130579694, 0.0058037970101790081, 0.0057838748196172105, 0.0057649067172644407, 0.0057450074391718169, 0.0057257560757938628, 0.0057068921134282467, 0.0056910928241560802, 0.0056788085737203694, 0.0056690892518848146, 0.0056612743700531721, 0.0056549092513077485, 0.0056497071371151928, 0.0056454190671702698, 0.0056418382124759688, 0.0056388257756775865, 0.0056362923843774485, 0.0056341473042769152, 0.0056323023975540319, 0.0056306841639984636, 0.005629272178176192, 0.0056279906194427083, 0.0056268203042985623, 0.005625790435747572, 0.005624827683859808, 0.0056239901055252948, 0.0056232378090081822, 0.0056225648551162105, 0.0056219476082446772, 0.0056213818754739337, 0.0056208587779216154, 0.0056203565804492468, 0.0056198880457015042, 0.0056194285589185756, 0.0056189941236347461, 0.0056185700935960222, 0.0056181569939334789, 0.0056177508565147145, 0.0056173472412140027, 0.0056169488129624605, 0.0056165515608436615, 0.0056161248861534476, 0.0056156919470268414, 0.0056152624983918254, 0.0056148383492423863, 0.0056144011595232694, 0.0056139621687679936, 0.0056135028631326108, 0.005613037939185125, 0.0056125345031153417, 0.0056120146594589764, 0.0056115084562898343, 0.0056110066773307618, 0.0056104703056935774, 0.0056099059165122369, 0.0056093162571198797, 0.005608710433239749, 0.0056081023562674914, 0.0056074893030857217, 0.0056068858472155996, 0.0056062745749614982, 0.0056056700969811081, 0.005605038010300668, 0.0056043838525416164, 0.0056036915577905655, 0.0056029500625274587, 0.0056021641613864222, 0.005601397383847205, 0.005600658088281767, 0.0055999306740957353, 0.0055992087474738368, 0.0055984773515500826, 0.0055975669782570413, 0.0055965239904137744, 0.005595690540395039, 0.0055948645873347795, 0.0055940265133045952, 0.0055931825882172331], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098494900500476611, 0.008881108168884334, 0.008166739031580111, 0.0076366404169303688, 0.007241284624540021, 0.0069414876210290083, 0.0067110909370249831, 0.0065338004069985592, 0.0063961960134790675, 0.0062881879520727017, 0.0062027760024355224, 0.0061346095951455345, 0.0060797535324048756, 0.0060352876398776867, 0.005998985656165935, 0.0059692282750365795, 0.0059448254706912593, 0.0059245880826373975, 0.0059076999709658518, 0.0058935447308511857, 0.0058815959482979036, 0.0058714338122510725, 0.0058626616073010288, 0.0058552321975169821, 0.0058412174074653949, 0.005820778814525444, 0.005800784164663563, 0.0057824581520952217, 0.005761861131205648, 0.0057433762120516684, 0.0057257276781271889, 0.0057118551503710074, 0.0057010193030384545, 0.0056923769495131138, 0.0056853850974117309, 0.0056796804415932007, 0.0056750133603434482, 0.0056711429250735808, 0.0056678976297650152, 0.0056651562322111741, 0.0056628444776413624, 0.005660869568168872, 0.0056591567799322761, 0.0056576624615441422, 0.0056563268057367323, 0.0056551111864006761, 0.0056540032766294818, 0.0056530225730959628, 0.0056521348079420263, 0.0056513489372740202, 0.0056506435236398271, 0.0056500050628621136, 0.0056494139926513785, 0.0056488758146354054, 0.0056483647954695152, 0.0056478866776999035, 0.0056474222472399143, 0.005646978358518526, 0.0056465520275768375, 0.0056461371412029537, 0.0056457291612141197, 0.005645324995338174, 0.0056449306028049954, 0.0056445292046043722, 0.0056441164630045334, 0.0056436933214454197, 0.0056432684081785698, 0.0056428346568353892, 0.0056424063048082559, 0.0056419683255326553, 0.0056415180104911668, 0.0056410527369596189, 0.0056405667625061282, 0.0056400491289723114, 0.0056395348218844996, 0.0056390405909311587, 0.0056385275569671364, 0.0056379866923250248, 0.0056374181660192391, 0.0056368337629898622, 0.005636235011625604, 0.005635632691582306, 0.0056350340336132291, 0.005634442716939813, 0.0056338427026257814, 0.0056332400626725506, 0.0056326063755660523, 0.0056319434766302018, 0.005631227588446335, 0.0056304751348486151, 0.0056297184944146426, 0.0056289724079791213, 0.005628251385518041, 0.0056275351223816711, 0.0056268261995692844, 0.005626031050084284, 0.0056250647927391043, 0.0056241246364892765, 0.0056233098248036507, 0.005622493347665884, 0.0056216582332167201], 'acc': [0.5659752056264169, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822264767316, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822262938279, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427]}
[2017-11-18 17:10:35,219 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 17:10:35,418 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 17:10:35,418 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 17:10:36,239 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:141]: done!
[2017-11-18 17:10:36,240 AE_UNIGRAMA_8L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_8L_FULLDS_OVER_05 finished!
