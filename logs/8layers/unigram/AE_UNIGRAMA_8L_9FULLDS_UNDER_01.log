[2017-11-18 19:14:39,728 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_9FULLDS_UNDER_01
[2017-11-18 19:14:39,728 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 19:14:39,728 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_9FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17,15,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f1acad46eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f1acad4b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:14:39,728 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 19:14:42,235 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:14:42,236 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:14:42,236 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 19:14:42,236 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f1acad46eb8>, 'discard_decoder_function': True}
[2017-11-18 19:14:42,444 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 19:16:13,699 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 19:16:13,700 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0094931480173228288, 0.0087958629267377176, 0.0082521982806249058, 0.0078266198210861816, 0.0074892001141318608, 0.0072184728284991756, 0.0069985255626061416, 0.0068180773669743594, 0.0066688745689894267, 0.0065420473422971512, 0.0064335444366072679, 0.0063414405687386632, 0.0062626111314305812, 0.006194906042103588, 0.0061364674029234512, 0.006085743852273227, 0.0060416690353886013, 0.0060031987763996056, 0.0059696284709932976, 0.005940248569793991, 0.0059144279369533342, 0.0058918253148815911, 0.0058719333871693861, 0.0058544305002933604, 0.0058390533246780382, 0.0058254819259476037, 0.005813516268865347, 0.0058029601353849396, 0.0057936628635436053, 0.0057854680156212701, 0.0057782055721103112, 0.0057717739110343634, 0.0057661021469713339, 0.0057610854895313798, 0.0057566475713757672, 0.0057527150258658748, 0.0057492358841923384, 0.0057461759230742855, 0.0057434449033097711, 0.0057410377938401681, 0.0057389051555897198, 0.0057370083322539752, 0.0057353303117081336, 0.0057338442960093447, 0.0057325204492925516, 0.005731340104119167, 0.0057302753909777484, 0.0057292925345361267, 0.0057283982264719289, 0.005727587518556395, 0.0057268871164900198, 0.0057262687897497912, 0.0057257266207065916, 0.0057252532874741613, 0.0057248327632437061, 0.0057244535442475932, 0.005724115421528661, 0.005723794417980153, 0.0057235216058397756, 0.0057232764634094621, 0.0057230528672689556, 0.0057228619643671522, 0.005722683235230756, 0.0057225225470893051, 0.0057223734779756428, 0.0057222421541337698, 0.0057221186682390231, 0.0057219987501893757, 0.0057218994415450383, 0.0057218024703629177, 0.0057217126732910491, 0.0057216311236949575, 0.0057215605318568204, 0.0057214819701256357, 0.0057214171485684452, 0.0057213563037860297, 0.0057212895323042866, 0.0057212375729929731, 0.0057211816221036122, 0.0057211256404953248, 0.005721078141075954, 0.0057210271698188275, 0.0057209708711809422, 0.005720929996781695, 0.0057208860770158144, 0.005720844045052088, 0.0057208057076597327, 0.0057207618174148272, 0.0057207233639922058, 0.0057206825581329604, 0.0057206473665641199, 0.0057206020698373, 0.0057205661494854412, 0.005720528107473968, 0.0057204928795387099, 0.0057204533748271185, 0.0057204178644317512, 0.0057203836751213927, 0.0057203469880798725, 0.0057203096698029039, 0.0057202719627903178], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099347799350405254, 0.0091374774481879431, 0.0085230154752716693, 0.0080439490299867144, 0.0076667094639532984, 0.0073662136259099063, 0.0071236539484730221, 0.0069257017548309307, 0.0067628231183644617, 0.006626832526420887, 0.0065100204569475189, 0.0064108451216547818, 0.0063263521620271447, 0.0062538740659875414, 0.0061914844220549662, 0.0061374853301792882, 0.006090597629492705, 0.0060497654375702608, 0.0060141029166624936, 0.0059829576438693195, 0.005955652257033644, 0.0059316558145513388, 0.0059106337329288402, 0.0058921222072938319, 0.0058758378973567038, 0.0058615128362805797, 0.0058488776061166731, 0.0058377352322547676, 0.0058279045368450451, 0.0058192431643112304, 0.0058116078873124829, 0.0058048400126888703, 0.0057988539599321169, 0.0057935663547521868, 0.0057888982246642583, 0.0057847596774920516, 0.0057810953717321667, 0.0057778578149631473, 0.0057750046470402445, 0.0057724628838016255, 0.0057702250650070947, 0.0057682408852912179, 0.0057664769455311312, 0.005764918044946582, 0.0057635348942027924, 0.0057623004000092104, 0.0057611940449762856, 0.0057601843521271484, 0.0057592549627870629, 0.0057584075287475537, 0.0057576619082591067, 0.0057570100483593512, 0.0057564462332517488, 0.0057559459244669381, 0.0057555095893237701, 0.0057551189951851964, 0.0057547681501844668, 0.0057544437681997067, 0.0057541613854679126, 0.0057539056446547299, 0.005753676178523905, 0.0057534694646938864, 0.0057532915099495043, 0.0057531256503955391, 0.0057529699130730713, 0.005752833177611859, 0.0057527046305760401, 0.0057525934152052715, 0.0057524853678973696, 0.0057523882489688479, 0.0057522979117079435, 0.0057522154598810878, 0.0057521384035978925, 0.00575206540628986, 0.0057519982202312138, 0.0057519342205257992, 0.0057518725172901524, 0.00575181850486763, 0.0057517588436370344, 0.0057517076118074051, 0.0057516566539903211, 0.0057516112456989172, 0.0057515588936415266, 0.0057515169910988704, 0.0057514731875584549, 0.0057514290222688931, 0.0057513872710218588, 0.0057513469553970844, 0.0057513062319543059, 0.0057512662408120566, 0.0057512267844343828, 0.0057511869397293761, 0.0057511536935025403, 0.0057511127084503696, 0.0057510788174881308, 0.0057510419549701465, 0.0057510050082593203, 0.0057509701776295276, 0.0057509312528727739, 0.0057508960357446843, 0.0057508566368101926], 'acc': [0.58291395608305097, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822267327968, 0.59383822272449271, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822268791198, 0.59383822263669894, 0.59383822264767316, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427]}
[2017-11-18 19:16:13,700 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:95]: done!
[2017-11-18 19:16:13,700 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 19:16:13,700 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 19:16:13,700 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f1acad4b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:16:13,735 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 19:19:42,844 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 19:19:42,845 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0094931480173228288, 0.0087958629267377176, 0.0082521982806249058, 0.0078266198210861816, 0.0074892001141318608, 0.0072184728284991756, 0.0069985255626061416, 0.0068180773669743594, 0.0066688745689894267, 0.0065420473422971512, 0.0064335444366072679, 0.0063414405687386632, 0.0062626111314305812, 0.006194906042103588, 0.0061364674029234512, 0.006085743852273227, 0.0060416690353886013, 0.0060031987763996056, 0.0059696284709932976, 0.005940248569793991, 0.0059144279369533342, 0.0058918253148815911, 0.0058719333871693861, 0.0058544305002933604, 0.0058390533246780382, 0.0058254819259476037, 0.005813516268865347, 0.0058029601353849396, 0.0057936628635436053, 0.0057854680156212701, 0.0057782055721103112, 0.0057717739110343634, 0.0057661021469713339, 0.0057610854895313798, 0.0057566475713757672, 0.0057527150258658748, 0.0057492358841923384, 0.0057461759230742855, 0.0057434449033097711, 0.0057410377938401681, 0.0057389051555897198, 0.0057370083322539752, 0.0057353303117081336, 0.0057338442960093447, 0.0057325204492925516, 0.005731340104119167, 0.0057302753909777484, 0.0057292925345361267, 0.0057283982264719289, 0.005727587518556395, 0.0057268871164900198, 0.0057262687897497912, 0.0057257266207065916, 0.0057252532874741613, 0.0057248327632437061, 0.0057244535442475932, 0.005724115421528661, 0.005723794417980153, 0.0057235216058397756, 0.0057232764634094621, 0.0057230528672689556, 0.0057228619643671522, 0.005722683235230756, 0.0057225225470893051, 0.0057223734779756428, 0.0057222421541337698, 0.0057221186682390231, 0.0057219987501893757, 0.0057218994415450383, 0.0057218024703629177, 0.0057217126732910491, 0.0057216311236949575, 0.0057215605318568204, 0.0057214819701256357, 0.0057214171485684452, 0.0057213563037860297, 0.0057212895323042866, 0.0057212375729929731, 0.0057211816221036122, 0.0057211256404953248, 0.005721078141075954, 0.0057210271698188275, 0.0057209708711809422, 0.005720929996781695, 0.0057208860770158144, 0.005720844045052088, 0.0057208057076597327, 0.0057207618174148272, 0.0057207233639922058, 0.0057206825581329604, 0.0057206473665641199, 0.0057206020698373, 0.0057205661494854412, 0.005720528107473968, 0.0057204928795387099, 0.0057204533748271185, 0.0057204178644317512, 0.0057203836751213927, 0.0057203469880798725, 0.0057203096698029039, 0.0057202719627903178], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099347799350405254, 0.0091374774481879431, 0.0085230154752716693, 0.0080439490299867144, 0.0076667094639532984, 0.0073662136259099063, 0.0071236539484730221, 0.0069257017548309307, 0.0067628231183644617, 0.006626832526420887, 0.0065100204569475189, 0.0064108451216547818, 0.0063263521620271447, 0.0062538740659875414, 0.0061914844220549662, 0.0061374853301792882, 0.006090597629492705, 0.0060497654375702608, 0.0060141029166624936, 0.0059829576438693195, 0.005955652257033644, 0.0059316558145513388, 0.0059106337329288402, 0.0058921222072938319, 0.0058758378973567038, 0.0058615128362805797, 0.0058488776061166731, 0.0058377352322547676, 0.0058279045368450451, 0.0058192431643112304, 0.0058116078873124829, 0.0058048400126888703, 0.0057988539599321169, 0.0057935663547521868, 0.0057888982246642583, 0.0057847596774920516, 0.0057810953717321667, 0.0057778578149631473, 0.0057750046470402445, 0.0057724628838016255, 0.0057702250650070947, 0.0057682408852912179, 0.0057664769455311312, 0.005764918044946582, 0.0057635348942027924, 0.0057623004000092104, 0.0057611940449762856, 0.0057601843521271484, 0.0057592549627870629, 0.0057584075287475537, 0.0057576619082591067, 0.0057570100483593512, 0.0057564462332517488, 0.0057559459244669381, 0.0057555095893237701, 0.0057551189951851964, 0.0057547681501844668, 0.0057544437681997067, 0.0057541613854679126, 0.0057539056446547299, 0.005753676178523905, 0.0057534694646938864, 0.0057532915099495043, 0.0057531256503955391, 0.0057529699130730713, 0.005752833177611859, 0.0057527046305760401, 0.0057525934152052715, 0.0057524853678973696, 0.0057523882489688479, 0.0057522979117079435, 0.0057522154598810878, 0.0057521384035978925, 0.00575206540628986, 0.0057519982202312138, 0.0057519342205257992, 0.0057518725172901524, 0.00575181850486763, 0.0057517588436370344, 0.0057517076118074051, 0.0057516566539903211, 0.0057516112456989172, 0.0057515588936415266, 0.0057515169910988704, 0.0057514731875584549, 0.0057514290222688931, 0.0057513872710218588, 0.0057513469553970844, 0.0057513062319543059, 0.0057512662408120566, 0.0057512267844343828, 0.0057511869397293761, 0.0057511536935025403, 0.0057511127084503696, 0.0057510788174881308, 0.0057510419549701465, 0.0057510050082593203, 0.0057509701776295276, 0.0057509312528727739, 0.0057508960357446843, 0.0057508566368101926], 'acc': [0.58291395608305097, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822267327968, 0.59383822272449271, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822267327968, 0.59383822268791198, 0.59383822263669894, 0.59383822264767316, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427]}
[2017-11-18 19:19:42,845 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 19:19:42,953 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 19:19:42,953 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 19:19:43,815 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:141]: done!
[2017-11-18 19:19:43,815 AE_UNIGRAMA_8L_9FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_8L_9FULLDS_UNDER_01 finished!
