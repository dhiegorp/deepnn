[2017-11-13 16:30:09,773 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_FULLDS_OVER_04
[2017-11-13 16:30:09,774 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-13 16:30:09,774 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,59,47
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0c4bc01eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0c4bb87400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 16:30:09,774 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-13 16:30:12,141 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 16:30:12,142 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-13 16:30:12,142 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-13 16:30:12,142 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0c4bc01eb8>, 'discard_decoder_function': True}
[2017-11-13 16:30:12,344 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-13 16:35:23,612 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-13 16:35:23,613 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0097300917453015164, 0.0090443121059874711, 0.0085027216328188195, 0.0080714325611546331, 0.007721509373733464, 0.007435661490571243, 0.0072016443371655022, 0.0070083448322793111, 0.0068477145089839405, 0.0067133802062503576, 0.0066003533140460121, 0.0064984930481368766, 0.0064096232066365652, 0.0063342916709396586, 0.0062701653041224827, 0.0062154569587465243, 0.0061672898060760265, 0.0061249806215724432, 0.0060887825833609585, 0.0060576538277912484, 0.0060308161736710719, 0.0060076227236897824, 0.0059876176585963231, 0.0059702438786653246, 0.0059550488243603076, 0.0059419017348771187, 0.0059304529355543858, 0.0059204454100268075, 0.0059113251083851882, 0.0059006963067580916, 0.0058916829288031842, 0.0058839514027378744, 0.0058773068690796421, 0.0058715687018197245, 0.0058665797235023191, 0.00586224527080098, 0.0058584561112320728, 0.0058551475427769612, 0.0058522425488066049, 0.0058496671433408923, 0.0058473886658281134, 0.0058453454719380625, 0.0058434823078186539, 0.0058418066832635696, 0.0058402416890316619, 0.0058388240951654539, 0.0058375277078324753, 0.0058363415704727264, 0.0058352623646719488, 0.0058342894447336946, 0.0058333836536093291, 0.005832545124271591, 0.0058317474772909281, 0.0058309485589402897, 0.0058287088007100392, 0.0058205266992600192, 0.0058138691451405993, 0.0058083579481402409, 0.0058037875703981267, 0.0057999476043761426, 0.0057966495296434906, 0.0057938129068494321, 0.005791375178823885, 0.0057892817527278899, 0.0057874922549919538, 0.0057859279933936266, 0.0057845278111694105, 0.0057832876968039052, 0.0057821265018440015, 0.0057809129090365657, 0.0057797956525819432, 0.0057788764433616968, 0.0057780288658880082, 0.005777244218917771, 0.0057765290757024424, 0.0057758652022911403, 0.0057752272010620342, 0.0057746069780484155, 0.0057735963342406705, 0.0057723369046864988, 0.0057715376834249895, 0.0057709080774476697, 0.005770186540331501, 0.0057693881268323132, 0.0057686708710275834, 0.005768014148452026, 0.0057673635510936553, 0.0057666565505332511, 0.0057658544019034402, 0.0057649767406740713, 0.0057640760669464882, 0.0057631428330385077, 0.0057620030897301555, 0.0057610693442964158, 0.0057600625501949033, 0.0057591087601905041, 0.0057581625936141472, 0.0057572399553401654, 0.0057562687854395165, 0.0057553248202721887, 0.005754456447967243], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010115284695503456, 0.0093767433979986218, 0.0087682122663687717, 0.0082861819491201905, 0.0078994758183423969, 0.0075841212349212084, 0.0073267094060121083, 0.0071153614557552475, 0.0069402788460050735, 0.0067945460345821508, 0.0066724340304502782, 0.0065673521611388222, 0.0064720854311093199, 0.0063910747332286038, 0.0063223940203368948, 0.0062639056973006592, 0.006213631924587926, 0.0061688472472137658, 0.0061303482684043308, 0.0060973685275709771, 0.0060690080533696931, 0.0060445819679605158, 0.0060234769267248746, 0.0060052732592150229, 0.0059894237193944622, 0.00597565894710053, 0.0059637207483818587, 0.0059533377915458024, 0.0059442569180930722, 0.0059344603805134592, 0.0059249297098652289, 0.0059168355569048639, 0.0059099022053388803, 0.0059039480748150934, 0.0058988012057709979, 0.0058943474770682394, 0.0058904752239074621, 0.0058871085013738359, 0.0058841606477698224, 0.0058815719356765644, 0.0058792720202892031, 0.0058772405139654706, 0.0058754138561402111, 0.0058737567533230549, 0.0058722512782117525, 0.0058708485759240512, 0.0058695807094715797, 0.0058684211896031244, 0.0058673734282149934, 0.0058664149073516941, 0.0058655462457991728, 0.0058647441230549706, 0.0058639850087918374, 0.0058632375452632264, 0.0058623483091637604, 0.0058564506151647239, 0.005849088141832986, 0.0058430504180491888, 0.0058380458850906944, 0.0058338718821011222, 0.0058303325837911297, 0.0058272934834949185, 0.0058246823147760519, 0.0058224433259125123, 0.0058205286268388562, 0.0058188766199463024, 0.0058174230288876496, 0.0058161220263506395, 0.0058149627826095535, 0.0058137872856491232, 0.005812584688653569, 0.0058116177224995487, 0.0058107369292901929, 0.0058099354971787804, 0.0058091954884032567, 0.0058085142961863626, 0.0058078686874764524, 0.0058072496594695853, 0.0058064896924181356, 0.0058052873960704734, 0.005804235368340154, 0.0058035733830080864, 0.0058029222611817562, 0.0058021617726834035, 0.0058014073006866377, 0.005800727435150011, 0.0058000816760589973, 0.0057994108893456445, 0.0057986608794551404, 0.0057977992108239635, 0.0057969017966445916, 0.0057960176614995779, 0.0057949995341624663, 0.0057939669676102187, 0.0057929883555800539, 0.0057920189443470419, 0.0057910757506961499, 0.0057901354582402531, 0.0057891982621718499, 0.0057882261943203311, 0.0057873144899923054], 'acc': [0.25297655578009026, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822262938279, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427]}
[2017-11-13 16:35:23,613 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:95]: done!
[2017-11-13 16:35:23,613 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-13 16:35:23,613 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-13 16:35:23,613 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0c4bb87400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 16:35:23,665 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-13 16:43:39,293 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:125]: trained!
[2017-11-13 16:43:39,294 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0097300917453015164, 0.0090443121059874711, 0.0085027216328188195, 0.0080714325611546331, 0.007721509373733464, 0.007435661490571243, 0.0072016443371655022, 0.0070083448322793111, 0.0068477145089839405, 0.0067133802062503576, 0.0066003533140460121, 0.0064984930481368766, 0.0064096232066365652, 0.0063342916709396586, 0.0062701653041224827, 0.0062154569587465243, 0.0061672898060760265, 0.0061249806215724432, 0.0060887825833609585, 0.0060576538277912484, 0.0060308161736710719, 0.0060076227236897824, 0.0059876176585963231, 0.0059702438786653246, 0.0059550488243603076, 0.0059419017348771187, 0.0059304529355543858, 0.0059204454100268075, 0.0059113251083851882, 0.0059006963067580916, 0.0058916829288031842, 0.0058839514027378744, 0.0058773068690796421, 0.0058715687018197245, 0.0058665797235023191, 0.00586224527080098, 0.0058584561112320728, 0.0058551475427769612, 0.0058522425488066049, 0.0058496671433408923, 0.0058473886658281134, 0.0058453454719380625, 0.0058434823078186539, 0.0058418066832635696, 0.0058402416890316619, 0.0058388240951654539, 0.0058375277078324753, 0.0058363415704727264, 0.0058352623646719488, 0.0058342894447336946, 0.0058333836536093291, 0.005832545124271591, 0.0058317474772909281, 0.0058309485589402897, 0.0058287088007100392, 0.0058205266992600192, 0.0058138691451405993, 0.0058083579481402409, 0.0058037875703981267, 0.0057999476043761426, 0.0057966495296434906, 0.0057938129068494321, 0.005791375178823885, 0.0057892817527278899, 0.0057874922549919538, 0.0057859279933936266, 0.0057845278111694105, 0.0057832876968039052, 0.0057821265018440015, 0.0057809129090365657, 0.0057797956525819432, 0.0057788764433616968, 0.0057780288658880082, 0.005777244218917771, 0.0057765290757024424, 0.0057758652022911403, 0.0057752272010620342, 0.0057746069780484155, 0.0057735963342406705, 0.0057723369046864988, 0.0057715376834249895, 0.0057709080774476697, 0.005770186540331501, 0.0057693881268323132, 0.0057686708710275834, 0.005768014148452026, 0.0057673635510936553, 0.0057666565505332511, 0.0057658544019034402, 0.0057649767406740713, 0.0057640760669464882, 0.0057631428330385077, 0.0057620030897301555, 0.0057610693442964158, 0.0057600625501949033, 0.0057591087601905041, 0.0057581625936141472, 0.0057572399553401654, 0.0057562687854395165, 0.0057553248202721887, 0.005754456447967243], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010115284695503456, 0.0093767433979986218, 0.0087682122663687717, 0.0082861819491201905, 0.0078994758183423969, 0.0075841212349212084, 0.0073267094060121083, 0.0071153614557552475, 0.0069402788460050735, 0.0067945460345821508, 0.0066724340304502782, 0.0065673521611388222, 0.0064720854311093199, 0.0063910747332286038, 0.0063223940203368948, 0.0062639056973006592, 0.006213631924587926, 0.0061688472472137658, 0.0061303482684043308, 0.0060973685275709771, 0.0060690080533696931, 0.0060445819679605158, 0.0060234769267248746, 0.0060052732592150229, 0.0059894237193944622, 0.00597565894710053, 0.0059637207483818587, 0.0059533377915458024, 0.0059442569180930722, 0.0059344603805134592, 0.0059249297098652289, 0.0059168355569048639, 0.0059099022053388803, 0.0059039480748150934, 0.0058988012057709979, 0.0058943474770682394, 0.0058904752239074621, 0.0058871085013738359, 0.0058841606477698224, 0.0058815719356765644, 0.0058792720202892031, 0.0058772405139654706, 0.0058754138561402111, 0.0058737567533230549, 0.0058722512782117525, 0.0058708485759240512, 0.0058695807094715797, 0.0058684211896031244, 0.0058673734282149934, 0.0058664149073516941, 0.0058655462457991728, 0.0058647441230549706, 0.0058639850087918374, 0.0058632375452632264, 0.0058623483091637604, 0.0058564506151647239, 0.005849088141832986, 0.0058430504180491888, 0.0058380458850906944, 0.0058338718821011222, 0.0058303325837911297, 0.0058272934834949185, 0.0058246823147760519, 0.0058224433259125123, 0.0058205286268388562, 0.0058188766199463024, 0.0058174230288876496, 0.0058161220263506395, 0.0058149627826095535, 0.0058137872856491232, 0.005812584688653569, 0.0058116177224995487, 0.0058107369292901929, 0.0058099354971787804, 0.0058091954884032567, 0.0058085142961863626, 0.0058078686874764524, 0.0058072496594695853, 0.0058064896924181356, 0.0058052873960704734, 0.005804235368340154, 0.0058035733830080864, 0.0058029222611817562, 0.0058021617726834035, 0.0058014073006866377, 0.005800727435150011, 0.0058000816760589973, 0.0057994108893456445, 0.0057986608794551404, 0.0057977992108239635, 0.0057969017966445916, 0.0057960176614995779, 0.0057949995341624663, 0.0057939669676102187, 0.0057929883555800539, 0.0057920189443470419, 0.0057910757506961499, 0.0057901354582402531, 0.0057891982621718499, 0.0057882261943203311, 0.0057873144899923054], 'acc': [0.25297655578009026, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.59383822262938279, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822262938279, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427]}
[2017-11-13 16:43:39,294 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-13 16:43:39,467 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-13 16:43:39,467 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-13 16:43:40,303 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:141]: done!
[2017-11-13 16:43:40,303 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_8L_FULLDS_OVER_04 finished!
[2017-11-14 07:04:28,004 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_8L_FULLDS_OVER_04 was already executed!
[2017-11-18 14:56:15,981 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_8L_FULLDS_OVER_04 was already executed!
[2017-11-18 16:22:45,811 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:146]: The experiment AE_UNIGRAMA_8L_FULLDS_OVER_04 was already executed!
[2017-11-18 17:47:43,909 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_FULLDS_OVER_04
[2017-11-18 17:47:43,909 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 17:47:43,910 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,59,47
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8b6c38eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff8b6c3d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:47:43,910 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 17:47:46,072 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:47:46,072 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:47:46,072 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 17:47:46,072 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8b6c38eb8>, 'discard_decoder_function': True}
[2017-11-18 17:47:46,236 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 17:50:24,445 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 17:50:24,446 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0099086111691430931, 0.009528723826720209, 0.0092564058150905806, 0.0090591888344247352, 0.008915822501528772, 0.0088101652550460745, 0.0087313524264950437, 0.008671873360694287, 0.0086263008980448086, 0.0085910389888504551, 0.0085633452071266457, 0.0085413562844465305, 0.0085237069214252337, 0.0085093160784532589, 0.0084976265083715041, 0.0084879307065382249, 0.00847985556445679, 0.0084731179720440447, 0.0084672678995826849, 0.0084624148591071393, 0.0084577424490043275, 0.0084518569790974166, 0.0084469501139272322, 0.0084427595456862924, 0.0084391321274303027, 0.0084360433908063706, 0.0084334143366594817, 0.0084311573891785816, 0.0084292044697445098, 0.0084275050042214219, 0.0084260175855490095, 0.0084247131945236076, 0.0084235716754216695, 0.008422571189225115, 0.0084216871679798511, 0.0084209084803103657, 0.0084202034626182105, 0.0084195281941962571, 0.0084189218710265974, 0.0084184068979032117, 0.0084179410168771715, 0.0084175188275781767, 0.0084171333647675706, 0.0084167772695936949, 0.0084164465785448225, 0.0084161342545051379, 0.0084158438345152461, 0.0084129291268607038, 0.0084083527049343409, 0.0084046902198677154, 0.0084017544607633571, 0.0083993338253821395, 0.0083972809795880305, 0.0083931686270411112, 0.0083894886823288224, 0.0083864526535654405, 0.0083839357250432723, 0.0083818030620636599, 0.0083799657751749603, 0.0083783861028577464, 0.0083770058780103553, 0.0083757970360262089, 0.0083747131274913827, 0.0083737390578609103, 0.0083728740529151399, 0.0083720844926279021, 0.0083713578306705318, 0.0083706851316857588, 0.0083700644744998907, 0.008369487378977648, 0.0083689507335227269, 0.0083684505619593327, 0.0083679872527663776, 0.0083675421579292222, 0.0083671222310492729, 0.0083667208816758949, 0.0083663332409874697, 0.0083659638964578929, 0.008365611512198886, 0.0083652744692630822, 0.0083649376987759271, 0.0083645949655652974, 0.0083642454563925168, 0.0083638946702022706, 0.0083635583439843914, 0.008363223923880227, 0.0083628541138605003, 0.0083612346951875433, 0.0083586630770489598, 0.0083566151579204662, 0.0083549174297709149, 0.0083534645093950623, 0.0083521476528172281, 0.0083509750920253752, 0.0083498979252254815, 0.0083488265838979232, 0.0083478513389048173, 0.0083470729828970646, 0.0083463818398918661, 0.0083457696039704703, 0.0083451987744248418], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010147525802139448, 0.0097098267195137918, 0.0093869350553820938, 0.0091545488501322686, 0.0089859495461179148, 0.0088626917574394191, 0.0087713318164398067, 0.0087027949764245469, 0.0086506693195851133, 0.008610487693004612, 0.008579196063503285, 0.008554471439367696, 0.0085346945746086981, 0.0085186847753441451, 0.0085056227489773654, 0.0084949100751425689, 0.0084859785289249055, 0.0084785090006519355, 0.008472179187038997, 0.0084667577077541471, 0.0084621549212562756, 0.0084565346876514375, 0.0084511192647640336, 0.0084465335654690388, 0.0084425864608143764, 0.0084391961066705972, 0.0084363135230379176, 0.0084338472540852367, 0.008431721180339042, 0.0084298702564565581, 0.0084282567080307385, 0.0084268447418441219, 0.0084256113084346124, 0.0084245251611696371, 0.0084235728933823775, 0.0084227362875824944, 0.008421989831110005, 0.0084212980143624355, 0.0084206454765188322, 0.0084200924042005538, 0.0084196002437166451, 0.0084191554956338406, 0.0084187450074642532, 0.0084183684628988623, 0.0084180179356932415, 0.0084176911700736875, 0.0084173874191073774, 0.0084164003799625433, 0.008411782875778713, 0.0084075414553573639, 0.0084041770574149431, 0.0084014348657162723, 0.0083991438915171808, 0.0083961401701044842, 0.0083919934816617352, 0.0083886070697777211, 0.0083858169381152026, 0.0083834838312577872, 0.0083815003557210031, 0.0083798026232563515, 0.0083783344185381949, 0.0083770561476681736, 0.0083759279896044366, 0.0083749193314184428, 0.0083740257619311659, 0.0083732236715380482, 0.0083724924181321075, 0.00837181995990793, 0.0083711935170438373, 0.0083706172183613276, 0.008370087887281082, 0.0083695938015075216, 0.008369129968570926, 0.0083686996017456623, 0.0083682873334662011, 0.0083678920395609223, 0.0083675159594565132, 0.0083671622169188622, 0.0083668196770017664, 0.0083664934845565572, 0.0083661702025658417, 0.0083658470775293276, 0.0083655216312167376, 0.0083651870180013292, 0.0083648624026429301, 0.0083645382009325912, 0.0083642095281422774, 0.0083634843121575281, 0.0083610190729524539, 0.0083586863437910986, 0.0083568024087701375, 0.0083552160889835778, 0.0083538262332202365, 0.00835257842569786, 0.0083514651776547145, 0.0083504003296924374, 0.0083493722035266425, 0.0083484993438207034, 0.0083477814420390099, 0.0083471442432965521, 0.0083465582051084532], 'acc': [0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408]}
[2017-11-18 17:50:24,446 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:95]: done!
[2017-11-18 17:50:24,446 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 17:50:24,446 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 17:50:24,446 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff8b6c3d400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:50:24,506 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 17:56:47,585 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:125]: trained!
[2017-11-18 17:56:47,587 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0099086111691430931, 0.009528723826720209, 0.0092564058150905806, 0.0090591888344247352, 0.008915822501528772, 0.0088101652550460745, 0.0087313524264950437, 0.008671873360694287, 0.0086263008980448086, 0.0085910389888504551, 0.0085633452071266457, 0.0085413562844465305, 0.0085237069214252337, 0.0085093160784532589, 0.0084976265083715041, 0.0084879307065382249, 0.00847985556445679, 0.0084731179720440447, 0.0084672678995826849, 0.0084624148591071393, 0.0084577424490043275, 0.0084518569790974166, 0.0084469501139272322, 0.0084427595456862924, 0.0084391321274303027, 0.0084360433908063706, 0.0084334143366594817, 0.0084311573891785816, 0.0084292044697445098, 0.0084275050042214219, 0.0084260175855490095, 0.0084247131945236076, 0.0084235716754216695, 0.008422571189225115, 0.0084216871679798511, 0.0084209084803103657, 0.0084202034626182105, 0.0084195281941962571, 0.0084189218710265974, 0.0084184068979032117, 0.0084179410168771715, 0.0084175188275781767, 0.0084171333647675706, 0.0084167772695936949, 0.0084164465785448225, 0.0084161342545051379, 0.0084158438345152461, 0.0084129291268607038, 0.0084083527049343409, 0.0084046902198677154, 0.0084017544607633571, 0.0083993338253821395, 0.0083972809795880305, 0.0083931686270411112, 0.0083894886823288224, 0.0083864526535654405, 0.0083839357250432723, 0.0083818030620636599, 0.0083799657751749603, 0.0083783861028577464, 0.0083770058780103553, 0.0083757970360262089, 0.0083747131274913827, 0.0083737390578609103, 0.0083728740529151399, 0.0083720844926279021, 0.0083713578306705318, 0.0083706851316857588, 0.0083700644744998907, 0.008369487378977648, 0.0083689507335227269, 0.0083684505619593327, 0.0083679872527663776, 0.0083675421579292222, 0.0083671222310492729, 0.0083667208816758949, 0.0083663332409874697, 0.0083659638964578929, 0.008365611512198886, 0.0083652744692630822, 0.0083649376987759271, 0.0083645949655652974, 0.0083642454563925168, 0.0083638946702022706, 0.0083635583439843914, 0.008363223923880227, 0.0083628541138605003, 0.0083612346951875433, 0.0083586630770489598, 0.0083566151579204662, 0.0083549174297709149, 0.0083534645093950623, 0.0083521476528172281, 0.0083509750920253752, 0.0083498979252254815, 0.0083488265838979232, 0.0083478513389048173, 0.0083470729828970646, 0.0083463818398918661, 0.0083457696039704703, 0.0083451987744248418], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010147525802139448, 0.0097098267195137918, 0.0093869350553820938, 0.0091545488501322686, 0.0089859495461179148, 0.0088626917574394191, 0.0087713318164398067, 0.0087027949764245469, 0.0086506693195851133, 0.008610487693004612, 0.008579196063503285, 0.008554471439367696, 0.0085346945746086981, 0.0085186847753441451, 0.0085056227489773654, 0.0084949100751425689, 0.0084859785289249055, 0.0084785090006519355, 0.008472179187038997, 0.0084667577077541471, 0.0084621549212562756, 0.0084565346876514375, 0.0084511192647640336, 0.0084465335654690388, 0.0084425864608143764, 0.0084391961066705972, 0.0084363135230379176, 0.0084338472540852367, 0.008431721180339042, 0.0084298702564565581, 0.0084282567080307385, 0.0084268447418441219, 0.0084256113084346124, 0.0084245251611696371, 0.0084235728933823775, 0.0084227362875824944, 0.008421989831110005, 0.0084212980143624355, 0.0084206454765188322, 0.0084200924042005538, 0.0084196002437166451, 0.0084191554956338406, 0.0084187450074642532, 0.0084183684628988623, 0.0084180179356932415, 0.0084176911700736875, 0.0084173874191073774, 0.0084164003799625433, 0.008411782875778713, 0.0084075414553573639, 0.0084041770574149431, 0.0084014348657162723, 0.0083991438915171808, 0.0083961401701044842, 0.0083919934816617352, 0.0083886070697777211, 0.0083858169381152026, 0.0083834838312577872, 0.0083815003557210031, 0.0083798026232563515, 0.0083783344185381949, 0.0083770561476681736, 0.0083759279896044366, 0.0083749193314184428, 0.0083740257619311659, 0.0083732236715380482, 0.0083724924181321075, 0.00837181995990793, 0.0083711935170438373, 0.0083706172183613276, 0.008370087887281082, 0.0083695938015075216, 0.008369129968570926, 0.0083686996017456623, 0.0083682873334662011, 0.0083678920395609223, 0.0083675159594565132, 0.0083671622169188622, 0.0083668196770017664, 0.0083664934845565572, 0.0083661702025658417, 0.0083658470775293276, 0.0083655216312167376, 0.0083651870180013292, 0.0083648624026429301, 0.0083645382009325912, 0.0083642095281422774, 0.0083634843121575281, 0.0083610190729524539, 0.0083586863437910986, 0.0083568024087701375, 0.0083552160889835778, 0.0083538262332202365, 0.00835257842569786, 0.0083514651776547145, 0.0083504003296924374, 0.0083493722035266425, 0.0083484993438207034, 0.0083477814420390099, 0.0083471442432965521, 0.0083465582051084532], 'acc': [0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408]}
[2017-11-18 17:56:47,587 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 17:56:47,766 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 17:56:47,766 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 17:56:48,586 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:141]: done!
[2017-11-18 17:56:48,587 AE_UNIGRAMA_8L_FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_8L_FULLDS_OVER_04 finished!
