[2017-11-18 20:11:21,703 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_9FULLDS_OVER_05
[2017-11-18 20:11:21,704 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 20:11:21,704 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_9FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,58,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc13e04ceb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc13e051400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:11:21,704 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 20:11:24,094 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:11:24,095 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:11:24,095 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 20:11:24,095 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc13e04ceb8>, 'discard_decoder_function': True}
[2017-11-18 20:11:24,280 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 20:14:55,637 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 20:14:55,638 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0092973300460856088, 0.0084898626296282999, 0.0078987265722767937, 0.0074586191081819466, 0.0071268212358244461, 0.0068728133753005061, 0.0066757484988467916, 0.0065203269131383071, 0.006394040448921748, 0.006292665876805487, 0.0062104461900136876, 0.0061431946244894448, 0.0060878402911344297, 0.0060420241498671413, 0.0060040631116043061, 0.0059723397709178722, 0.0059457762616603347, 0.0059234395095936814, 0.0059045989761003746, 0.0058886525785062397, 0.0058752234989400028, 0.0058638082179030384, 0.0058541890478993122, 0.0058440208676873882, 0.0058346870555537273, 0.0058268749136963739, 0.0058202943193888133, 0.0058147737066521939, 0.0058089730858450943, 0.0058005571659539377, 0.005793766375290191, 0.0057883428638846844, 0.0057839483490062463, 0.0057803482067617573, 0.0057773805689408922, 0.0057749155182692602, 0.0057728909242190408, 0.0057711962953439881, 0.0057697660639335823, 0.0057685668772762145, 0.005767559400170587, 0.0057667019024514581, 0.005765978305798075, 0.0057653629777043268, 0.0057648295123001389, 0.0057643765503371551, 0.0057639929572738452, 0.0057636519416705331, 0.0057633583129646148, 0.0057631137460649549, 0.0057628966070600715, 0.0057627029422785605, 0.0057625376326927028, 0.0057623895138977192, 0.0057622555985421117, 0.0057621404610934315, 0.0057620366742455898, 0.0057619419593216139, 0.0057618589275158895, 0.0057617794295847522, 0.0057617089960474944, 0.0057616393234668373, 0.005761580712181468, 0.005761524737932032, 0.0057614745878714086, 0.0057614289931966645, 0.0057613865487094046, 0.0057613412899747956, 0.005761304307295689, 0.0057612612905293611, 0.0057612282497988372, 0.005761183396057773, 0.0057611504260920198, 0.0057611103522673783, 0.0057610670647637637, 0.005761030717427373, 0.0057609995986406511, 0.0057609659236797957, 0.0057609305141691509, 0.0057608907496729828, 0.0057608568197193609, 0.0057608196738619978, 0.0057607860605957007, 0.0057607537135652967, 0.0057607183633533055, 0.005760693296623094, 0.0057606586479834829, 0.0057606283771760624, 0.0057605982658674735, 0.0057605774556339683, 0.0057605461513357305, 0.0057605240586939728, 0.0057604976956079175, 0.0057604699302327813, 0.0057604438103311031, 0.0057604158032262473, 0.0057603916493359133, 0.0057603702392704298, 0.0057603458061715731, 0.005760325558804652, 0.0057603031981637845], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098308560847586782, 0.008883437912829327, 0.0081953280826574885, 0.0076881261917163338, 0.007308702713969834, 0.0070208284433584053, 0.0067992091451077553, 0.0066263974365658581, 0.0064877339597501985, 0.0063758366685797352, 0.0062857305416586986, 0.0062122717741508746, 0.0061520597265537855, 0.0061024332850461828, 0.0060612700150359791, 0.0060271116696518521, 0.0059985008260606256, 0.0059745244619419302, 0.0059543330184872994, 0.0059372956095883177, 0.0059228861888286901, 0.0059107207981575786, 0.0059004118400842508, 0.0058910091725049227, 0.0058810663869305196, 0.0058726020565669614, 0.0058655273871171896, 0.0058595782371743833, 0.0058544512449569264, 0.0058468031900798497, 0.0058392065461636746, 0.0058330956467979337, 0.0058281899246268179, 0.0058242036238892528, 0.0058209237908253796, 0.0058182218866300456, 0.0058159848310581942, 0.005814131038103171, 0.0058125853907178377, 0.0058112908747448202, 0.0058102000784117473, 0.0058092771462567548, 0.0058085022013960467, 0.00580784570546008, 0.0058072856932625174, 0.005806803060801842, 0.0058063913559228113, 0.0058060337778954065, 0.005805727309609438, 0.0058054648597185288, 0.0058052353057367889, 0.0058050352991554609, 0.0058048628459245466, 0.0058047078744539989, 0.0058045711461374612, 0.0058044497611517152, 0.0058043415930702398, 0.0058042468465165052, 0.0058041585654356855, 0.0058040789570176993, 0.0058040067037846196, 0.0058039399744707065, 0.0058038780727845893, 0.0058038283550543215, 0.0058037721796817023, 0.0058037232595257076, 0.0058036773548794957, 0.0058036352331953915, 0.0058035915402545324, 0.0058035558107104078, 0.005803518113180057, 0.0058034808911420644, 0.0058034473138024456, 0.0058034066304841576, 0.0058033667056444846, 0.0058033315372144944, 0.0058032920750639245, 0.0058032559871429405, 0.0058032227846986683, 0.0058031915126310557, 0.0058031580473199293, 0.0058031260751885581, 0.0058030924050824894, 0.0058030549204634296, 0.0058030229838268001, 0.0058029904532676917, 0.0058029579784941989, 0.0058029286158836424, 0.0058028989862337413, 0.0058028745125237053, 0.0058028455799082213, 0.00580281862282374, 0.0058027954320685662, 0.0058027664941946019, 0.0058027416359867781, 0.0058027224583665372, 0.005802695582388398, 0.0058026726910236515, 0.0058026433204682168, 0.0058026209265442698, 0.0058025951875981651], 'acc': [0.57493555910882588, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822266230546, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822262206665, 0.59383822268791198, 0.59383822267327968, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822264767316]}
[2017-11-18 20:14:55,638 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:95]: done!
[2017-11-18 20:14:55,638 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 20:14:55,639 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 20:14:55,639 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc13e051400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:14:55,684 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 20:21:41,193 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:125]: trained!
[2017-11-18 20:21:41,194 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0092973300460856088, 0.0084898626296282999, 0.0078987265722767937, 0.0074586191081819466, 0.0071268212358244461, 0.0068728133753005061, 0.0066757484988467916, 0.0065203269131383071, 0.006394040448921748, 0.006292665876805487, 0.0062104461900136876, 0.0061431946244894448, 0.0060878402911344297, 0.0060420241498671413, 0.0060040631116043061, 0.0059723397709178722, 0.0059457762616603347, 0.0059234395095936814, 0.0059045989761003746, 0.0058886525785062397, 0.0058752234989400028, 0.0058638082179030384, 0.0058541890478993122, 0.0058440208676873882, 0.0058346870555537273, 0.0058268749136963739, 0.0058202943193888133, 0.0058147737066521939, 0.0058089730858450943, 0.0058005571659539377, 0.005793766375290191, 0.0057883428638846844, 0.0057839483490062463, 0.0057803482067617573, 0.0057773805689408922, 0.0057749155182692602, 0.0057728909242190408, 0.0057711962953439881, 0.0057697660639335823, 0.0057685668772762145, 0.005767559400170587, 0.0057667019024514581, 0.005765978305798075, 0.0057653629777043268, 0.0057648295123001389, 0.0057643765503371551, 0.0057639929572738452, 0.0057636519416705331, 0.0057633583129646148, 0.0057631137460649549, 0.0057628966070600715, 0.0057627029422785605, 0.0057625376326927028, 0.0057623895138977192, 0.0057622555985421117, 0.0057621404610934315, 0.0057620366742455898, 0.0057619419593216139, 0.0057618589275158895, 0.0057617794295847522, 0.0057617089960474944, 0.0057616393234668373, 0.005761580712181468, 0.005761524737932032, 0.0057614745878714086, 0.0057614289931966645, 0.0057613865487094046, 0.0057613412899747956, 0.005761304307295689, 0.0057612612905293611, 0.0057612282497988372, 0.005761183396057773, 0.0057611504260920198, 0.0057611103522673783, 0.0057610670647637637, 0.005761030717427373, 0.0057609995986406511, 0.0057609659236797957, 0.0057609305141691509, 0.0057608907496729828, 0.0057608568197193609, 0.0057608196738619978, 0.0057607860605957007, 0.0057607537135652967, 0.0057607183633533055, 0.005760693296623094, 0.0057606586479834829, 0.0057606283771760624, 0.0057605982658674735, 0.0057605774556339683, 0.0057605461513357305, 0.0057605240586939728, 0.0057604976956079175, 0.0057604699302327813, 0.0057604438103311031, 0.0057604158032262473, 0.0057603916493359133, 0.0057603702392704298, 0.0057603458061715731, 0.005760325558804652, 0.0057603031981637845], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098308560847586782, 0.008883437912829327, 0.0081953280826574885, 0.0076881261917163338, 0.007308702713969834, 0.0070208284433584053, 0.0067992091451077553, 0.0066263974365658581, 0.0064877339597501985, 0.0063758366685797352, 0.0062857305416586986, 0.0062122717741508746, 0.0061520597265537855, 0.0061024332850461828, 0.0060612700150359791, 0.0060271116696518521, 0.0059985008260606256, 0.0059745244619419302, 0.0059543330184872994, 0.0059372956095883177, 0.0059228861888286901, 0.0059107207981575786, 0.0059004118400842508, 0.0058910091725049227, 0.0058810663869305196, 0.0058726020565669614, 0.0058655273871171896, 0.0058595782371743833, 0.0058544512449569264, 0.0058468031900798497, 0.0058392065461636746, 0.0058330956467979337, 0.0058281899246268179, 0.0058242036238892528, 0.0058209237908253796, 0.0058182218866300456, 0.0058159848310581942, 0.005814131038103171, 0.0058125853907178377, 0.0058112908747448202, 0.0058102000784117473, 0.0058092771462567548, 0.0058085022013960467, 0.00580784570546008, 0.0058072856932625174, 0.005806803060801842, 0.0058063913559228113, 0.0058060337778954065, 0.005805727309609438, 0.0058054648597185288, 0.0058052353057367889, 0.0058050352991554609, 0.0058048628459245466, 0.0058047078744539989, 0.0058045711461374612, 0.0058044497611517152, 0.0058043415930702398, 0.0058042468465165052, 0.0058041585654356855, 0.0058040789570176993, 0.0058040067037846196, 0.0058039399744707065, 0.0058038780727845893, 0.0058038283550543215, 0.0058037721796817023, 0.0058037232595257076, 0.0058036773548794957, 0.0058036352331953915, 0.0058035915402545324, 0.0058035558107104078, 0.005803518113180057, 0.0058034808911420644, 0.0058034473138024456, 0.0058034066304841576, 0.0058033667056444846, 0.0058033315372144944, 0.0058032920750639245, 0.0058032559871429405, 0.0058032227846986683, 0.0058031915126310557, 0.0058031580473199293, 0.0058031260751885581, 0.0058030924050824894, 0.0058030549204634296, 0.0058030229838268001, 0.0058029904532676917, 0.0058029579784941989, 0.0058029286158836424, 0.0058028989862337413, 0.0058028745125237053, 0.0058028455799082213, 0.00580281862282374, 0.0058027954320685662, 0.0058027664941946019, 0.0058027416359867781, 0.0058027224583665372, 0.005802695582388398, 0.0058026726910236515, 0.0058026433204682168, 0.0058026209265442698, 0.0058025951875981651], 'acc': [0.57493555910882588, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822266230546, 0.5938382226001182, 0.59383822263669894, 0.59383822264767316, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822262206665, 0.59383822268791198, 0.59383822267327968, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822264767316]}
[2017-11-18 20:21:41,194 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 20:21:41,432 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 20:21:41,433 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 20:21:42,303 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:141]: done!
[2017-11-18 20:21:42,304 AE_UNIGRAMA_8L_9FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_8L_9FULLDS_OVER_05 finished!
