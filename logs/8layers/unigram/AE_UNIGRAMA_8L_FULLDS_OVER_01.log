[2018-07-21 00:52:16,550 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_8L_FULLDS_OVER_01
[2018-07-21 00:52:16,550 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-07-21 00:52:16,550 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_FULLDS_OVER_01
	layers = 96,144,130,117,103,90,76,63,49
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0f5857f668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0f5857fe48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,550 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,556 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,556 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,556 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:57]: =======================================
[2018-07-21 00:52:18,557 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0f5857f668>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,962 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-07-21 00:56:38,527 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:85]: trained and evaluated!
[2018-07-21 00:56:38,529 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:88]: Training history: 
{'val_loss': [0.00947203159774491, 0.008757432765617983, 0.008212322283820966, 0.007792603660741796, 0.007466265595443095, 0.007210532126818859, 0.007008591954497424, 0.006847990572538798, 0.006719391183254748, 0.006615702216867706, 0.006531443307912117, 0.006462623269216064, 0.006406014492014441, 0.006359189516874643, 0.0063202282869404556, 0.006287679486750231, 0.006260530581613623, 0.006237881437994099, 0.006218766622643717, 0.006202528650233387, 0.006185385243859702, 0.006170584647876896, 0.006158192850305715, 0.006147723074061868, 0.006138854675496032, 0.006131300499210273, 0.006124896144693617, 0.006119375131669694, 0.006114644226055074, 0.006110580131659358, 0.006107078854902314, 0.006104057657134332, 0.006101427406917344, 0.006099147748308874, 0.006097173757230926, 0.0060954272066945, 0.006093745413196959, 0.006092377420557948, 0.0060911924007168335, 0.006090081369765144, 0.006089104673794742, 0.006088284058468974, 0.006087560784749383, 0.006086912725852561, 0.006086330707515263, 0.006085801618830881, 0.006085319661794423, 0.006084890164300054, 0.006084491133820628, 0.0060841257447593845, 0.006083786790147944, 0.0060834699372484735, 0.006083176979310441, 0.006082901513191657, 0.006082655217132994, 0.006082398491356767, 0.006082152848610109, 0.00608193541217071, 0.006081728350514192, 0.0060815303419565715, 0.006081344987201076, 0.006081175933585518, 0.006080999181242041, 0.006080827723592328, 0.0060806709148492205, 0.006080506624122044, 0.006080356374768371, 0.0060802003630060115, 0.006080063023388479, 0.006079918598822595, 0.006079777945154776, 0.006079632609973784, 0.006079485468536983, 0.006079355234660835, 0.00607921183391658, 0.006079067059634106, 0.006078922657401481, 0.006078775607522485, 0.006078628639959946, 0.006078484244401629, 0.006078334795879265, 0.0060781871369269425, 0.006078040569566138, 0.00607788890235, 0.006077724526996031, 0.006077545484766167, 0.006077386641471713, 0.006077215590526906, 0.006077056150737628, 0.006076885429315354, 0.006076721667313112, 0.0060765572345429855, 0.006076393817123251, 0.006076233209843601, 0.006076070990633166, 0.006075912881854789, 0.0060757457059443555, 0.006075574696328914, 0.006075398687143885, 0.0060752371834534215, 0.0060750681503741934], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009923375392616403, 0.009104886077041713, 0.00848216402839503, 0.008005103718238373, 0.00763632043412158, 0.007348706746640579, 0.007122527788803247, 0.006943410678857091, 0.0068005374315552244, 0.0066858543597145305, 0.006593038602576083, 0.006517428898255862, 0.006455457110252408, 0.0064043454198632905, 0.006361940580945929, 0.006326603526184369, 0.006297049289062844, 0.006272366120156147, 0.006251679328435442, 0.006234130778739635, 0.006217746657303477, 0.006201790707219931, 0.006188383823146579, 0.006177087526880932, 0.0061675214759202525, 0.0061593900023253914, 0.006152457526353523, 0.006146528979879304, 0.006141426588318455, 0.006137039009296479, 0.006133248465773799, 0.006129976325523557, 0.006127142278292131, 0.006124668168145223, 0.006122523174387162, 0.0061206503323588774, 0.006118924130425104, 0.00611735886547907, 0.006116070326969139, 0.0061148984671051485, 0.006113810946405157, 0.006112893027696647, 0.006112101156131024, 0.006111392742762489, 0.006110757549615821, 0.006110181492880559, 0.006109666289564813, 0.006109191720183366, 0.006108757580055592, 0.006108356801726905, 0.006107988284060114, 0.006107650970157848, 0.006107336125684448, 0.006107040151495981, 0.006106753047620616, 0.006106490668319088, 0.006106235952795236, 0.006105992850339185, 0.006105773422990062, 0.00610556327039976, 0.006105359956520155, 0.0061051690851192915, 0.00610498598592368, 0.0061048101528045975, 0.006104642940849538, 0.006104477033912093, 0.006104314354824149, 0.006104160692200762, 0.006104000245337675, 0.0061038511746821485, 0.006103702754191976, 0.006103553764014061, 0.006103406577380549, 0.006103258375060149, 0.006103115773421296, 0.006102974594544289, 0.006102829602640385, 0.006102686317970676, 0.006102544775572645, 0.006102399571443337, 0.006102253889078115, 0.006102103395260641, 0.00610195818221478, 0.006101802739652992, 0.006101641298136938, 0.006101463451477188, 0.006101286755452931, 0.006101123825444028, 0.006100962188049586, 0.00610079976165448, 0.006100637653626056, 0.0061004740352706595, 0.0061003142466892766, 0.00610015490999425, 0.0060999888450737685, 0.006099829466996789, 0.006099660195375042, 0.006099498874861191, 0.006099324609397949, 0.006099157487865887, 0.006098998956347065], 'acc': [0.5850006137118685, 0.5938382226513312, 0.5938382226366989, 0.5938382227025443, 0.5938382227025443, 0.5938382226732797, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.593838222687912, 0.5938382227025443, 0.593838222687912, 0.5938382226842539, 0.5938382226513312, 0.5938382226842539, 0.5938382227244927, 0.5938382226001182, 0.5938382226366989, 0.5938382227025443, 0.5938382226366989, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.593838222687912, 0.593838222687912, 0.5938382226366989, 0.5938382226476732, 0.5938382226842539, 0.5938382226366989, 0.5938382227025443, 0.5938382226842539, 0.593838222687912, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.5938382226366989, 0.593838222687912, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382227025443, 0.593838222687912, 0.5938382226513312, 0.5938382226366989, 0.5938382227244927, 0.5938382226366989, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382226659635, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.5938382227244927, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382227025443, 0.5938382226842539, 0.5938382226293828, 0.5938382226001182, 0.5938382226001182, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382226366989, 0.5938382226001182, 0.593838222687912, 0.5938382226366989, 0.5938382226293828, 0.5938382226842539, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226001182, 0.5938382226513312, 0.5938382226366989, 0.5938382226513312, 0.5938382227025443, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226001182]}
[2018-07-21 00:56:38,529 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:92]: done!
[2018-07-21 00:56:38,529 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:152]: >> Executing classifier part ... 
[2018-07-21 00:56:38,529 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:97]: =======================================
[2018-07-21 00:56:38,530 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0f5857fe48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 00:56:38,585 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:110]: training ... 
[2018-07-21 01:05:34,231 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:122]: trained!
[2018-07-21 01:05:34,232 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:125]: Training history: 
{'val_loss': [0.00947203159774491, 0.008757432765617983, 0.008212322283820966, 0.007792603660741796, 0.007466265595443095, 0.007210532126818859, 0.007008591954497424, 0.006847990572538798, 0.006719391183254748, 0.006615702216867706, 0.006531443307912117, 0.006462623269216064, 0.006406014492014441, 0.006359189516874643, 0.0063202282869404556, 0.006287679486750231, 0.006260530581613623, 0.006237881437994099, 0.006218766622643717, 0.006202528650233387, 0.006185385243859702, 0.006170584647876896, 0.006158192850305715, 0.006147723074061868, 0.006138854675496032, 0.006131300499210273, 0.006124896144693617, 0.006119375131669694, 0.006114644226055074, 0.006110580131659358, 0.006107078854902314, 0.006104057657134332, 0.006101427406917344, 0.006099147748308874, 0.006097173757230926, 0.0060954272066945, 0.006093745413196959, 0.006092377420557948, 0.0060911924007168335, 0.006090081369765144, 0.006089104673794742, 0.006088284058468974, 0.006087560784749383, 0.006086912725852561, 0.006086330707515263, 0.006085801618830881, 0.006085319661794423, 0.006084890164300054, 0.006084491133820628, 0.0060841257447593845, 0.006083786790147944, 0.0060834699372484735, 0.006083176979310441, 0.006082901513191657, 0.006082655217132994, 0.006082398491356767, 0.006082152848610109, 0.00608193541217071, 0.006081728350514192, 0.0060815303419565715, 0.006081344987201076, 0.006081175933585518, 0.006080999181242041, 0.006080827723592328, 0.0060806709148492205, 0.006080506624122044, 0.006080356374768371, 0.0060802003630060115, 0.006080063023388479, 0.006079918598822595, 0.006079777945154776, 0.006079632609973784, 0.006079485468536983, 0.006079355234660835, 0.00607921183391658, 0.006079067059634106, 0.006078922657401481, 0.006078775607522485, 0.006078628639959946, 0.006078484244401629, 0.006078334795879265, 0.0060781871369269425, 0.006078040569566138, 0.00607788890235, 0.006077724526996031, 0.006077545484766167, 0.006077386641471713, 0.006077215590526906, 0.006077056150737628, 0.006076885429315354, 0.006076721667313112, 0.0060765572345429855, 0.006076393817123251, 0.006076233209843601, 0.006076070990633166, 0.006075912881854789, 0.0060757457059443555, 0.006075574696328914, 0.006075398687143885, 0.0060752371834534215, 0.0060750681503741934], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009923375392616403, 0.009104886077041713, 0.00848216402839503, 0.008005103718238373, 0.00763632043412158, 0.007348706746640579, 0.007122527788803247, 0.006943410678857091, 0.0068005374315552244, 0.0066858543597145305, 0.006593038602576083, 0.006517428898255862, 0.006455457110252408, 0.0064043454198632905, 0.006361940580945929, 0.006326603526184369, 0.006297049289062844, 0.006272366120156147, 0.006251679328435442, 0.006234130778739635, 0.006217746657303477, 0.006201790707219931, 0.006188383823146579, 0.006177087526880932, 0.0061675214759202525, 0.0061593900023253914, 0.006152457526353523, 0.006146528979879304, 0.006141426588318455, 0.006137039009296479, 0.006133248465773799, 0.006129976325523557, 0.006127142278292131, 0.006124668168145223, 0.006122523174387162, 0.0061206503323588774, 0.006118924130425104, 0.00611735886547907, 0.006116070326969139, 0.0061148984671051485, 0.006113810946405157, 0.006112893027696647, 0.006112101156131024, 0.006111392742762489, 0.006110757549615821, 0.006110181492880559, 0.006109666289564813, 0.006109191720183366, 0.006108757580055592, 0.006108356801726905, 0.006107988284060114, 0.006107650970157848, 0.006107336125684448, 0.006107040151495981, 0.006106753047620616, 0.006106490668319088, 0.006106235952795236, 0.006105992850339185, 0.006105773422990062, 0.00610556327039976, 0.006105359956520155, 0.0061051690851192915, 0.00610498598592368, 0.0061048101528045975, 0.006104642940849538, 0.006104477033912093, 0.006104314354824149, 0.006104160692200762, 0.006104000245337675, 0.0061038511746821485, 0.006103702754191976, 0.006103553764014061, 0.006103406577380549, 0.006103258375060149, 0.006103115773421296, 0.006102974594544289, 0.006102829602640385, 0.006102686317970676, 0.006102544775572645, 0.006102399571443337, 0.006102253889078115, 0.006102103395260641, 0.00610195818221478, 0.006101802739652992, 0.006101641298136938, 0.006101463451477188, 0.006101286755452931, 0.006101123825444028, 0.006100962188049586, 0.00610079976165448, 0.006100637653626056, 0.0061004740352706595, 0.0061003142466892766, 0.00610015490999425, 0.0060999888450737685, 0.006099829466996789, 0.006099660195375042, 0.006099498874861191, 0.006099324609397949, 0.006099157487865887, 0.006098998956347065], 'acc': [0.5850006137118685, 0.5938382226513312, 0.5938382226366989, 0.5938382227025443, 0.5938382227025443, 0.5938382226732797, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.593838222687912, 0.5938382227025443, 0.593838222687912, 0.5938382226842539, 0.5938382226513312, 0.5938382226842539, 0.5938382227244927, 0.5938382226001182, 0.5938382226366989, 0.5938382227025443, 0.5938382226366989, 0.5938382226842539, 0.5938382226001182, 0.5938382226513312, 0.5938382227025443, 0.5938382226513312, 0.5938382226001182, 0.5938382226842539, 0.593838222687912, 0.593838222687912, 0.5938382226366989, 0.5938382226476732, 0.5938382226842539, 0.5938382226366989, 0.5938382227025443, 0.5938382226842539, 0.593838222687912, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.5938382226366989, 0.593838222687912, 0.5938382226513312, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382227025443, 0.593838222687912, 0.5938382226513312, 0.5938382226366989, 0.5938382227244927, 0.5938382226366989, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382226001182, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382226659635, 0.5938382226001182, 0.593838222687912, 0.5938382226513312, 0.5938382227244927, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382227025443, 0.5938382226842539, 0.5938382226293828, 0.5938382226001182, 0.5938382226001182, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226842539, 0.5938382226366989, 0.5938382226001182, 0.593838222687912, 0.5938382226366989, 0.5938382226293828, 0.5938382226842539, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382227025443, 0.593838222687912, 0.5938382226001182, 0.5938382226513312, 0.5938382226366989, 0.5938382226513312, 0.5938382227025443, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226001182]}
[2018-07-21 01:05:34,232 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:129]: evaluating model ... 
[2018-07-21 01:05:34,390 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:133]: evaluated! 
[2018-07-21 01:05:34,390 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:135]: generating reports ... 
[2018-07-21 01:05:35,464 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:138]: done!
[2018-07-21 01:05:35,464 AE_UNIGRAMA_8L_FULLDS_OVER_01.py:154]: >> experiment AE_UNIGRAMA_8L_FULLDS_OVER_01 finished!
