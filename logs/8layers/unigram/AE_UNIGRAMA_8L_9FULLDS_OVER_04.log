[2017-11-18 18:31:55,255 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_8L_9FULLDS_OVER_04
[2017-11-18 18:31:55,256 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 18:31:55,256 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_8L_9FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,59,47,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/8layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/8layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/8layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/8layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/8layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbbccdb3ef0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbbcce18438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:31:55,256 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 18:31:57,376 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:31:57,376 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:31:57,376 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 18:31:57,376 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fbbccdb3ef0>, 'discard_decoder_function': True}
[2017-11-18 18:31:57,559 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 18:34:25,304 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 18:34:25,305 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0090659782225426967, 0.0081979610650187162, 0.0076230872285205599, 0.0072282178295609905, 0.006945103916378253, 0.0067322784675389958, 0.0065703747712913593, 0.0064438505174208112, 0.0063431845508647271, 0.0062569746730841615, 0.0061868255419224687, 0.0061303477187376392, 0.0060839959617412535, 0.0060419077122976228, 0.0060080148623479299, 0.0059804208508224795, 0.0059579225854817413, 0.0059392882243362866, 0.0059238115284668581, 0.0059110839248459291, 0.0059004427635140693, 0.0058915050421697347, 0.0058748576388266849, 0.0058595419026061055, 0.0058473534740881364, 0.005837539706953508, 0.005829543500877876, 0.0058229780533973598, 0.005817524251589351, 0.005812958859725938, 0.0058091331244395335, 0.0058059087157480826, 0.0058031679756250761, 0.0058008429109338271, 0.0057988517454085004, 0.0057971520153090265, 0.0057956677751471201, 0.0057944169087292344, 0.0057932856226239312, 0.0057923190237681122, 0.0057914918244093144, 0.0057907632800405767, 0.0057901386026969369, 0.0057895694104102341, 0.005789095163567814, 0.0057886563360763634, 0.0057882663610061714, 0.0057879288580565715, 0.0057876370785616199, 0.005787363514705989, 0.0057871329220089184, 0.0057868985263257672, 0.005786715943632577, 0.0057865386418566979, 0.0057863678638739478, 0.0057862384645429189, 0.0057860860391083565, 0.0057859657107599462, 0.0057858361796541318, 0.0057857319268882984, 0.0057856227966584742, 0.0057855048744834192, 0.0057854023212700455, 0.0057852980939179207, 0.0057852096922041216, 0.0057851225119741282, 0.005785050286556492, 0.00578497201147825, 0.0057848977500546102, 0.0057848387394231864, 0.0057847616070205842, 0.005784686866330338, 0.0057846128900194155, 0.0057845263311845476, 0.0057844543415924363, 0.0057843778632719516, 0.0057842961766814234, 0.0057842323960594693, 0.0057841472062277128, 0.0057840701000089322, 0.0057839791649676661, 0.0057839136550155729, 0.0057838386289559059, 0.0057837556950400219, 0.0057836792020018336, 0.0057836001673360789, 0.0057835348587255897, 0.0057834589237621744, 0.0057834056824704484, 0.0057833327482927155, 0.0057832842394271479, 0.0057832173121259989, 0.0057831528840106674, 0.0057830880939425166, 0.0057830249662047268, 0.005782964097206556, 0.0057829171460216334, 0.0057828461769139977, 0.0057827794612226174, 0.0057827276600410467, 0.0057826604517344461], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096974027703986138, 0.0086068433961049469, 0.0078987548020543145, 0.0074223173980336949, 0.0070890876763135954, 0.00684387259650804, 0.0066587533688050836, 0.00651624648747992, 0.0064038107127300566, 0.0063117372632946677, 0.0062338575140410872, 0.0061712558851093223, 0.0061206393982637577, 0.0060765246634454, 0.0060389973625597435, 0.0060085783844828107, 0.0059838181348295539, 0.0059635238890581059, 0.0059465713117340712, 0.0059326222115320317, 0.0059210766604456217, 0.0059114191189021462, 0.0058997759799679552, 0.0058830747143878148, 0.0058697139954840766, 0.0058591063105793541, 0.0058505262100866295, 0.0058435394221303385, 0.0058377906557218716, 0.0058330179065122067, 0.0058290227032819272, 0.0058256899558462236, 0.0058228826886828292, 0.0058205067008624918, 0.005818483209034205, 0.0058167641712653277, 0.0058152862304138696, 0.0058140226807735645, 0.0058129342805927544, 0.0058119819202105171, 0.0058111682541876928, 0.005810465408920989, 0.005809852346545628, 0.0058093250425523546, 0.0058088506884828098, 0.005808444049692222, 0.0058080878937979323, 0.0058077730798465795, 0.0058074885185607208, 0.0058072397780421867, 0.0058070196582312395, 0.0058068192598359769, 0.0058066407825015428, 0.0058064793880831808, 0.0058063314565173557, 0.0058061946036548568, 0.0058060705741679718, 0.005805954217089529, 0.0058058448953432172, 0.0058057456425005555, 0.0058056476073390113, 0.0058055556936200282, 0.0058054541710001002, 0.0058053616559853348, 0.005805281697192524, 0.0058052046446817173, 0.0058051302036350744, 0.0058050555298435249, 0.0058049855111787568, 0.0058049164909964998, 0.0058048509923384331, 0.0058047879689384621, 0.0058047230154476175, 0.0058046481256011188, 0.0058045859959713151, 0.0058045131681349555, 0.0058044412028608267, 0.0058043624843263043, 0.0058042913051949687, 0.0058042157140272485, 0.0058041282768181912, 0.0058040472194031143, 0.0058039620306516142, 0.0058038845594057392, 0.0058038134960752847, 0.0058037401363893754, 0.0058036706839829071, 0.0058035954089527319, 0.0058035335283576931, 0.0058034702892457183, 0.0058034037677560891, 0.0058033491929048104, 0.0058032929297384345, 0.0058032288811062909, 0.0058031723042601376, 0.0058031207085093815, 0.0058030600076429502, 0.0058029990747746575, 0.0058029358795024036, 0.0058028698991218217, 0.0058028125848309737], 'acc': [0.59162882036616704, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822272449271, 0.59383822267327968, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822262938279, 0.59383822268791198, 0.59383822263669894, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822264767316, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427]}
[2017-11-18 18:34:25,306 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 18:34:25,306 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 18:34:25,306 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 18:34:25,306 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fbbcce18438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:34:25,350 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 18:40:04,136 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:125]: trained!
[2017-11-18 18:40:04,137 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0090659782225426967, 0.0081979610650187162, 0.0076230872285205599, 0.0072282178295609905, 0.006945103916378253, 0.0067322784675389958, 0.0065703747712913593, 0.0064438505174208112, 0.0063431845508647271, 0.0062569746730841615, 0.0061868255419224687, 0.0061303477187376392, 0.0060839959617412535, 0.0060419077122976228, 0.0060080148623479299, 0.0059804208508224795, 0.0059579225854817413, 0.0059392882243362866, 0.0059238115284668581, 0.0059110839248459291, 0.0059004427635140693, 0.0058915050421697347, 0.0058748576388266849, 0.0058595419026061055, 0.0058473534740881364, 0.005837539706953508, 0.005829543500877876, 0.0058229780533973598, 0.005817524251589351, 0.005812958859725938, 0.0058091331244395335, 0.0058059087157480826, 0.0058031679756250761, 0.0058008429109338271, 0.0057988517454085004, 0.0057971520153090265, 0.0057956677751471201, 0.0057944169087292344, 0.0057932856226239312, 0.0057923190237681122, 0.0057914918244093144, 0.0057907632800405767, 0.0057901386026969369, 0.0057895694104102341, 0.005789095163567814, 0.0057886563360763634, 0.0057882663610061714, 0.0057879288580565715, 0.0057876370785616199, 0.005787363514705989, 0.0057871329220089184, 0.0057868985263257672, 0.005786715943632577, 0.0057865386418566979, 0.0057863678638739478, 0.0057862384645429189, 0.0057860860391083565, 0.0057859657107599462, 0.0057858361796541318, 0.0057857319268882984, 0.0057856227966584742, 0.0057855048744834192, 0.0057854023212700455, 0.0057852980939179207, 0.0057852096922041216, 0.0057851225119741282, 0.005785050286556492, 0.00578497201147825, 0.0057848977500546102, 0.0057848387394231864, 0.0057847616070205842, 0.005784686866330338, 0.0057846128900194155, 0.0057845263311845476, 0.0057844543415924363, 0.0057843778632719516, 0.0057842961766814234, 0.0057842323960594693, 0.0057841472062277128, 0.0057840701000089322, 0.0057839791649676661, 0.0057839136550155729, 0.0057838386289559059, 0.0057837556950400219, 0.0057836792020018336, 0.0057836001673360789, 0.0057835348587255897, 0.0057834589237621744, 0.0057834056824704484, 0.0057833327482927155, 0.0057832842394271479, 0.0057832173121259989, 0.0057831528840106674, 0.0057830880939425166, 0.0057830249662047268, 0.005782964097206556, 0.0057829171460216334, 0.0057828461769139977, 0.0057827794612226174, 0.0057827276600410467, 0.0057826604517344461], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096974027703986138, 0.0086068433961049469, 0.0078987548020543145, 0.0074223173980336949, 0.0070890876763135954, 0.00684387259650804, 0.0066587533688050836, 0.00651624648747992, 0.0064038107127300566, 0.0063117372632946677, 0.0062338575140410872, 0.0061712558851093223, 0.0061206393982637577, 0.0060765246634454, 0.0060389973625597435, 0.0060085783844828107, 0.0059838181348295539, 0.0059635238890581059, 0.0059465713117340712, 0.0059326222115320317, 0.0059210766604456217, 0.0059114191189021462, 0.0058997759799679552, 0.0058830747143878148, 0.0058697139954840766, 0.0058591063105793541, 0.0058505262100866295, 0.0058435394221303385, 0.0058377906557218716, 0.0058330179065122067, 0.0058290227032819272, 0.0058256899558462236, 0.0058228826886828292, 0.0058205067008624918, 0.005818483209034205, 0.0058167641712653277, 0.0058152862304138696, 0.0058140226807735645, 0.0058129342805927544, 0.0058119819202105171, 0.0058111682541876928, 0.005810465408920989, 0.005809852346545628, 0.0058093250425523546, 0.0058088506884828098, 0.005808444049692222, 0.0058080878937979323, 0.0058077730798465795, 0.0058074885185607208, 0.0058072397780421867, 0.0058070196582312395, 0.0058068192598359769, 0.0058066407825015428, 0.0058064793880831808, 0.0058063314565173557, 0.0058061946036548568, 0.0058060705741679718, 0.005805954217089529, 0.0058058448953432172, 0.0058057456425005555, 0.0058056476073390113, 0.0058055556936200282, 0.0058054541710001002, 0.0058053616559853348, 0.005805281697192524, 0.0058052046446817173, 0.0058051302036350744, 0.0058050555298435249, 0.0058049855111787568, 0.0058049164909964998, 0.0058048509923384331, 0.0058047879689384621, 0.0058047230154476175, 0.0058046481256011188, 0.0058045859959713151, 0.0058045131681349555, 0.0058044412028608267, 0.0058043624843263043, 0.0058042913051949687, 0.0058042157140272485, 0.0058041282768181912, 0.0058040472194031143, 0.0058039620306516142, 0.0058038845594057392, 0.0058038134960752847, 0.0058037401363893754, 0.0058036706839829071, 0.0058035954089527319, 0.0058035335283576931, 0.0058034702892457183, 0.0058034037677560891, 0.0058033491929048104, 0.0058032929297384345, 0.0058032288811062909, 0.0058031723042601376, 0.0058031207085093815, 0.0058030600076429502, 0.0058029990747746575, 0.0058029358795024036, 0.0058028698991218217, 0.0058028125848309737], 'acc': [0.59162882036616704, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822272449271, 0.59383822267327968, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822262938279, 0.59383822268791198, 0.59383822263669894, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822264767316, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427]}
[2017-11-18 18:40:04,138 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 18:40:04,307 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 18:40:04,307 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 18:40:05,137 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:141]: done!
[2017-11-18 18:40:05,137 AE_UNIGRAMA_8L_9FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_8L_9FULLDS_OVER_04 finished!
