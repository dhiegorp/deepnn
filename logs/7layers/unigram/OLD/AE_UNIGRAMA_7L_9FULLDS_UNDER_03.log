[2017-11-18 19:53:55,954 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_9FULLDS_UNDER_03
[2017-11-18 19:53:55,954 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 19:53:55,955 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_9FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48,40,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f81e5eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f81ea400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:53:55,955 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 19:53:58,124 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:53:58,124 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:53:58,124 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 19:53:58,124 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f81e5eb8>, 'discard_decoder_function': True}
[2017-11-18 19:53:58,289 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 19:55:52,648 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 19:55:52,649 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0092284865735542988, 0.0083714068789570387, 0.0077492291279252137, 0.0072947411941010499, 0.0069562511348146066, 0.0066996566083272644, 0.0065023797288337138, 0.006347808546226818, 0.0062245500425629121, 0.0061246412929430883, 0.0060426646993125529, 0.0059746080201402586, 0.0059175292863922991, 0.0058694322857401997, 0.0058287164936193332, 0.0057940154892756291, 0.0057643416882908463, 0.0057387392333366778, 0.0057127329832177718, 0.0056870996144123423, 0.005664575269729178, 0.0056456530993603763, 0.0056296214170395258, 0.00561601996997858, 0.005604414314080204, 0.0055944680708444423, 0.005585800988554478, 0.0055784050669406091, 0.0055720268467866303, 0.0055665072605242489, 0.0055617147014236428, 0.0055575316766901944, 0.005553893464196779, 0.0055507003740078607, 0.0055479022101127774, 0.0055454550636127916, 0.005543256767976513, 0.0055413290444803953, 0.0055396525217175693, 0.0055381259530986691, 0.0055368090486027323, 0.0055356473066919005, 0.0055345943482891851, 0.0055336531699874333, 0.005532815084918972, 0.0055320796788489064, 0.0055313988541516807, 0.005530788787380162, 0.0055302467015946677, 0.0055297379417379843, 0.005529282696477354, 0.0055288572944406367, 0.0055284570719128104, 0.0055280951823278007, 0.0055277701971271388, 0.0055274447423290596, 0.0055271307598095754, 0.0055268383702144807, 0.0055265526011044029, 0.0055262914350313139, 0.0055260419691900847, 0.0055257917192033145, 0.0055255422259803122, 0.0055252966602448916, 0.005525057419100198, 0.0055248058798597309, 0.00552457374283063, 0.0055243486860436369, 0.0055241300804025053, 0.0055239093450583634, 0.0055236810535426607, 0.0055234663201121558, 0.005523251479379326, 0.0055230443289031803, 0.0055228440115486369, 0.0055226331335574237, 0.0055224354005289, 0.0055222159732634234, 0.0055219935489772588, 0.0055217619232172119, 0.0055215062114222883, 0.0055212373816186083, 0.0055209710535677869, 0.0055206950360485374, 0.0055204021417731277, 0.0055201242640046336, 0.0055198288352038055, 0.0055195458094907382, 0.0055192642692388893, 0.0055189777349793747, 0.0055186716254899135, 0.0055183578248880873, 0.0055180259312659456, 0.0055177021724264691, 0.0055173968918346356, 0.0055171052581476279, 0.0055168237635891135, 0.0055165429857485229, 0.0055162712210465531, 0.0055160085684854299, 0.0055157486626584715], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097918906470305048, 0.0087844266862452686, 0.0080524740905956044, 0.007521189205616903, 0.0071300184713706067, 0.0068362568348725727, 0.006612235229936563, 0.0064385842662352654, 0.0063014435501271004, 0.0061912345124962576, 0.0061013951209560446, 0.0060272579294210664, 0.0059653811778736486, 0.005913352459402531, 0.0058694296273902082, 0.005832114634785961, 0.0058002759196889376, 0.0057729580261867679, 0.0057475783475103683, 0.0057220524642787986, 0.0056976876550252206, 0.0056771331942169611, 0.0056597752257339304, 0.0056450926272693085, 0.0056326096132466238, 0.0056219289541254566, 0.0056126732312895495, 0.0056047544873404041, 0.0055979349780990086, 0.0055920485382193403, 0.0055869522522112971, 0.005582526770578241, 0.0055786618619710956, 0.0055752941849661506, 0.0055723381823181879, 0.0055697478208911735, 0.0055674623639809916, 0.0055654260052803127, 0.0055636429229374675, 0.0055620691834932841, 0.005560676230999503, 0.0055594544591844207, 0.0055583621958496783, 0.0055573935330927382, 0.005556529030940921, 0.0055557494068901696, 0.005555056045635505, 0.005554429011192386, 0.0055538659021500698, 0.0055533452046941587, 0.0055528797989575591, 0.0055524431903734191, 0.0055520434903189664, 0.0055516731878553953, 0.005551323754413663, 0.0055510027496878302, 0.0055506939362911512, 0.0055504075317936571, 0.0055501239775639193, 0.0055498594369698595, 0.005549603760230116, 0.0055493573252693761, 0.0055491141383918544, 0.0055488697362909827, 0.0055486373462165202, 0.0055484034685637264, 0.0055481653426304811, 0.0055479367691838328, 0.0055477163691301824, 0.005547497726094819, 0.0055472816015856973, 0.0055470715413045869, 0.005546860776730069, 0.0055466472291048905, 0.0055464465426363629, 0.0055462406007169476, 0.0055460474589100871, 0.005545836209240769, 0.0055456277244460613, 0.0055453881998713895, 0.0055451459189957159, 0.0055448907471272318, 0.0055446238126100481, 0.0055443487021277814, 0.0055440658784838516, 0.0055437852531132871, 0.0055435004442215986, 0.0055432127811182921, 0.0055429253196662715, 0.0055426445520309542, 0.0055423506184186034, 0.0055420423888847027, 0.0055417150320290669, 0.0055413874113920594, 0.0055410756473592403, 0.0055407696880027061, 0.0055404900039001028, 0.0055402126530194719, 0.0055399350704227659, 0.0055396692040629572, 0.0055394122239631628], 'acc': [0.589296673563663, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822264767316, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.59383822264767316, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182]}
[2017-11-18 19:55:52,650 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:95]: done!
[2017-11-18 19:55:52,650 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 19:55:52,650 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 19:55:52,650 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa3f81ea400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:55:52,698 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 20:00:17,952 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 20:00:17,954 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0092284865735542988, 0.0083714068789570387, 0.0077492291279252137, 0.0072947411941010499, 0.0069562511348146066, 0.0066996566083272644, 0.0065023797288337138, 0.006347808546226818, 0.0062245500425629121, 0.0061246412929430883, 0.0060426646993125529, 0.0059746080201402586, 0.0059175292863922991, 0.0058694322857401997, 0.0058287164936193332, 0.0057940154892756291, 0.0057643416882908463, 0.0057387392333366778, 0.0057127329832177718, 0.0056870996144123423, 0.005664575269729178, 0.0056456530993603763, 0.0056296214170395258, 0.00561601996997858, 0.005604414314080204, 0.0055944680708444423, 0.005585800988554478, 0.0055784050669406091, 0.0055720268467866303, 0.0055665072605242489, 0.0055617147014236428, 0.0055575316766901944, 0.005553893464196779, 0.0055507003740078607, 0.0055479022101127774, 0.0055454550636127916, 0.005543256767976513, 0.0055413290444803953, 0.0055396525217175693, 0.0055381259530986691, 0.0055368090486027323, 0.0055356473066919005, 0.0055345943482891851, 0.0055336531699874333, 0.005532815084918972, 0.0055320796788489064, 0.0055313988541516807, 0.005530788787380162, 0.0055302467015946677, 0.0055297379417379843, 0.005529282696477354, 0.0055288572944406367, 0.0055284570719128104, 0.0055280951823278007, 0.0055277701971271388, 0.0055274447423290596, 0.0055271307598095754, 0.0055268383702144807, 0.0055265526011044029, 0.0055262914350313139, 0.0055260419691900847, 0.0055257917192033145, 0.0055255422259803122, 0.0055252966602448916, 0.005525057419100198, 0.0055248058798597309, 0.00552457374283063, 0.0055243486860436369, 0.0055241300804025053, 0.0055239093450583634, 0.0055236810535426607, 0.0055234663201121558, 0.005523251479379326, 0.0055230443289031803, 0.0055228440115486369, 0.0055226331335574237, 0.0055224354005289, 0.0055222159732634234, 0.0055219935489772588, 0.0055217619232172119, 0.0055215062114222883, 0.0055212373816186083, 0.0055209710535677869, 0.0055206950360485374, 0.0055204021417731277, 0.0055201242640046336, 0.0055198288352038055, 0.0055195458094907382, 0.0055192642692388893, 0.0055189777349793747, 0.0055186716254899135, 0.0055183578248880873, 0.0055180259312659456, 0.0055177021724264691, 0.0055173968918346356, 0.0055171052581476279, 0.0055168237635891135, 0.0055165429857485229, 0.0055162712210465531, 0.0055160085684854299, 0.0055157486626584715], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097918906470305048, 0.0087844266862452686, 0.0080524740905956044, 0.007521189205616903, 0.0071300184713706067, 0.0068362568348725727, 0.006612235229936563, 0.0064385842662352654, 0.0063014435501271004, 0.0061912345124962576, 0.0061013951209560446, 0.0060272579294210664, 0.0059653811778736486, 0.005913352459402531, 0.0058694296273902082, 0.005832114634785961, 0.0058002759196889376, 0.0057729580261867679, 0.0057475783475103683, 0.0057220524642787986, 0.0056976876550252206, 0.0056771331942169611, 0.0056597752257339304, 0.0056450926272693085, 0.0056326096132466238, 0.0056219289541254566, 0.0056126732312895495, 0.0056047544873404041, 0.0055979349780990086, 0.0055920485382193403, 0.0055869522522112971, 0.005582526770578241, 0.0055786618619710956, 0.0055752941849661506, 0.0055723381823181879, 0.0055697478208911735, 0.0055674623639809916, 0.0055654260052803127, 0.0055636429229374675, 0.0055620691834932841, 0.005560676230999503, 0.0055594544591844207, 0.0055583621958496783, 0.0055573935330927382, 0.005556529030940921, 0.0055557494068901696, 0.005555056045635505, 0.005554429011192386, 0.0055538659021500698, 0.0055533452046941587, 0.0055528797989575591, 0.0055524431903734191, 0.0055520434903189664, 0.0055516731878553953, 0.005551323754413663, 0.0055510027496878302, 0.0055506939362911512, 0.0055504075317936571, 0.0055501239775639193, 0.0055498594369698595, 0.005549603760230116, 0.0055493573252693761, 0.0055491141383918544, 0.0055488697362909827, 0.0055486373462165202, 0.0055484034685637264, 0.0055481653426304811, 0.0055479367691838328, 0.0055477163691301824, 0.005547497726094819, 0.0055472816015856973, 0.0055470715413045869, 0.005546860776730069, 0.0055466472291048905, 0.0055464465426363629, 0.0055462406007169476, 0.0055460474589100871, 0.005545836209240769, 0.0055456277244460613, 0.0055453881998713895, 0.0055451459189957159, 0.0055448907471272318, 0.0055446238126100481, 0.0055443487021277814, 0.0055440658784838516, 0.0055437852531132871, 0.0055435004442215986, 0.0055432127811182921, 0.0055429253196662715, 0.0055426445520309542, 0.0055423506184186034, 0.0055420423888847027, 0.0055417150320290669, 0.0055413874113920594, 0.0055410756473592403, 0.0055407696880027061, 0.0055404900039001028, 0.0055402126530194719, 0.0055399350704227659, 0.0055396692040629572, 0.0055394122239631628], 'acc': [0.589296673563663, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.5938382226842539, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822264767316, 0.59383822268791198, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.59383822264767316, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.5938382226001182]}
[2017-11-18 20:00:17,954 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 20:00:18,132 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 20:00:18,133 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 20:00:18,981 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:141]: done!
[2017-11-18 20:00:18,982 AE_UNIGRAMA_7L_9FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_7L_9FULLDS_UNDER_03 finished!
