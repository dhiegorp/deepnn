[2017-10-20 01:36:36,947 AE_UNIGRAMA_7L_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_OVER_05
[2017-10-20 01:36:36,947 AE_UNIGRAMA_7L_OVER_05.py:149]: >> Printing header log
[2017-10-20 01:36:36,948 AE_UNIGRAMA_7L_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_OVER_05
	layers = 96,172,156,139,123,107,91,74,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc1fc132b70>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc1fc132cf8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:36:36,948 AE_UNIGRAMA_7L_OVER_05.py:151]: >> Loading dataset... 
[2017-10-20 01:36:37,532 AE_UNIGRAMA_7L_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:36:37,532 AE_UNIGRAMA_7L_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:36:37,532 AE_UNIGRAMA_7L_OVER_05.py:60]: =======================================
[2017-10-20 01:36:37,532 AE_UNIGRAMA_7L_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc1fc132b70>, 'discard_decoder_function': True}
[2017-10-20 01:36:37,705 AE_UNIGRAMA_7L_OVER_05.py:76]: training and evaluate autoencoder
[2017-10-20 01:37:42,371 AE_UNIGRAMA_7L_OVER_05.py:88]: trained and evaluated!
[2017-10-20 01:37:42,372 AE_UNIGRAMA_7L_OVER_05.py:91]: Training history: 
{'val_loss': [0.010304651995186025, 0.010201376097685342, 0.010104115488056136, 0.010012822121824918, 0.0099275378323399003, 0.0098477977996200439, 0.0097732870842998348, 0.0097036122216334134, 0.009638436110932588, 0.009577365474408444, 0.0095202581001424882, 0.0094668989599471197, 0.0094169695207288271, 0.0093702379247125201, 0.0093264526524840675, 0.0092854793997114472, 0.0092470074993416286, 0.0092109395502668334, 0.0091770915141446887, 0.0091452938971909453, 0.0091154286811010541, 0.0090873209641879373, 0.0090608860791892808, 0.0090359963275852256, 0.0090125699884164735, 0.0089904905494205562, 0.0089696726335911948, 0.0089500316913797059, 0.0089314661913146316, 0.0089139593141949747, 0.0088973963411601055, 0.0088817534421234776, 0.0088669667955224834, 0.0088529937613243057, 0.0088397433226547282, 0.0088271936540211451, 0.0088152972822074117, 0.0088040410129000268, 0.0087933322954853663, 0.0087831698870459458, 0.0087735293723892101, 0.0087643384061005924, 0.0087556095662280967, 0.0087473414505946142, 0.0087394548379244857, 0.0087319563305677094, 0.008724801822264287, 0.0087179876171523309, 0.0087115095069694257, 0.0087053352018271243, 0.0086994323997193999, 0.008693807450258155, 0.0086884508705715267, 0.0086833246322314088, 0.0086784410328503876, 0.0086737641299551964, 0.0086692855018277587, 0.0086650058720607083, 0.0086609246572791204, 0.0086570093962173474, 0.0086532787257133804, 0.0086497031861992348, 0.0086462700974930182, 0.008642988274268612, 0.0086398354288342947, 0.0086368223354497363, 0.008633928977603917, 0.0086311585249095376, 0.0086284942326021689, 0.0086259416228361072, 0.0086234837015709918, 0.0086211301369045531, 0.0086183581245045243, 0.0086142458177438236, 0.0086103183871695989, 0.0086065668675037559, 0.0086029748221146136, 0.0085995386884336576, 0.008596260557608976, 0.0085931268960348292, 0.0085901447769157497, 0.0085872985495316721, 0.0085845698072786226, 0.0085819484094732529, 0.0085794417478393444, 0.0085770395137785092, 0.0085747203457283479, 0.0085725002111970931, 0.0085703619239941853, 0.0085683112970958413, 0.0085663208668726089, 0.0085644332733573088, 0.0085626225001057509, 0.0085608670072540027, 0.0085591975873038455, 0.0085575997285877239, 0.0085560605449248872, 0.0085545816064074801, 0.0085531547959880085, 0.0085517837749067068, 0.0085504706983617253, 0.0085491999346749038], 'loss': [0.010354101771206011, 0.010250475911335412, 0.010152305186724435, 0.010059913468089805, 0.0099735498112370497, 0.0098928315765336016, 0.009817478727244788, 0.0097470875015481153, 0.0096812855495802819, 0.009619743677145803, 0.0095621900319292925, 0.0095084135030804422, 0.0094581801626320693, 0.0094112110969318003, 0.0093672709578457025, 0.0093261344706354592, 0.0092876454782068324, 0.0092515304705245993, 0.0092176937079715381, 0.0091859493112694136, 0.0091561595883538696, 0.0091281830606216221, 0.0091018794784488381, 0.009077145783866045, 0.009053882091811594, 0.0090319983147144241, 0.0090113777287199083, 0.0089919553879595788, 0.0089736302402133802, 0.0089563393058654864, 0.0089400296975854499, 0.0089246139649276583, 0.0089100622586315223, 0.0088963196444031504, 0.0088833291192333547, 0.0088710300750302323, 0.0088593838238412055, 0.0088483539192989406, 0.0088379152174111741, 0.0088279951935074201, 0.0088185867490435787, 0.0088096680526049791, 0.0088011739448115873, 0.0087931059494376473, 0.0087854699572272373, 0.0087781854525675572, 0.0087712716286030001, 0.0087646760696747875, 0.0087583968438753046, 0.0087524319082480234, 0.0087467462274336931, 0.0087413163689670937, 0.0087361520679453512, 0.0087312229170012339, 0.0087265245898065207, 0.008722039199472573, 0.0087177433593275365, 0.008713639452916094, 0.0087097178287140128, 0.008705980545705495, 0.0087023991851002142, 0.0086989802879080431, 0.008695711302739861, 0.0086925758899503783, 0.0086895775807805057, 0.0086867002004410634, 0.0086839519545307692, 0.0086813125989474837, 0.0086787757684133795, 0.0086763580693201038, 0.0086740247147374158, 0.0086717898067322774, 0.0086695799866225286, 0.0086660602936531484, 0.0086621334163796051, 0.0086583839254322122, 0.008654800306069169, 0.0086513653451367328, 0.0086480915196097997, 0.0086449624440497093, 0.0086419758923264763, 0.0086391329319979344, 0.0086364181908036419, 0.0086338115328282901, 0.0086313193576947334, 0.0086289309863900945, 0.0086266374926425669, 0.0086244302678718191, 0.0086223116166289776, 0.0086202825291955779, 0.0086183244787206952, 0.0086164400851572662, 0.0086146563602944575, 0.0086129358434418844, 0.0086112844636955736, 0.0086097037568505213, 0.0086081874600915584, 0.0086067337937740067, 0.0086053345036437041, 0.0086039756444759655, 0.0086026879493433343, 0.0086014543859758621]}
[2017-10-20 01:37:42,372 AE_UNIGRAMA_7L_OVER_05.py:95]: done!
[2017-10-20 01:37:42,372 AE_UNIGRAMA_7L_OVER_05.py:155]: >> Executing classifier part ... 
[2017-10-20 01:37:42,372 AE_UNIGRAMA_7L_OVER_05.py:100]: =======================================
[2017-10-20 01:37:42,372 AE_UNIGRAMA_7L_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc1fc132cf8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:37:42,405 AE_UNIGRAMA_7L_OVER_05.py:113]: training ... 
[2017-10-20 01:39:24,927 AE_UNIGRAMA_7L_OVER_05.py:125]: trained!
[2017-10-20 01:39:24,928 AE_UNIGRAMA_7L_OVER_05.py:128]: Training history: 
{'val_loss': [0.010304651995186025, 0.010201376097685342, 0.010104115488056136, 0.010012822121824918, 0.0099275378323399003, 0.0098477977996200439, 0.0097732870842998348, 0.0097036122216334134, 0.009638436110932588, 0.009577365474408444, 0.0095202581001424882, 0.0094668989599471197, 0.0094169695207288271, 0.0093702379247125201, 0.0093264526524840675, 0.0092854793997114472, 0.0092470074993416286, 0.0092109395502668334, 0.0091770915141446887, 0.0091452938971909453, 0.0091154286811010541, 0.0090873209641879373, 0.0090608860791892808, 0.0090359963275852256, 0.0090125699884164735, 0.0089904905494205562, 0.0089696726335911948, 0.0089500316913797059, 0.0089314661913146316, 0.0089139593141949747, 0.0088973963411601055, 0.0088817534421234776, 0.0088669667955224834, 0.0088529937613243057, 0.0088397433226547282, 0.0088271936540211451, 0.0088152972822074117, 0.0088040410129000268, 0.0087933322954853663, 0.0087831698870459458, 0.0087735293723892101, 0.0087643384061005924, 0.0087556095662280967, 0.0087473414505946142, 0.0087394548379244857, 0.0087319563305677094, 0.008724801822264287, 0.0087179876171523309, 0.0087115095069694257, 0.0087053352018271243, 0.0086994323997193999, 0.008693807450258155, 0.0086884508705715267, 0.0086833246322314088, 0.0086784410328503876, 0.0086737641299551964, 0.0086692855018277587, 0.0086650058720607083, 0.0086609246572791204, 0.0086570093962173474, 0.0086532787257133804, 0.0086497031861992348, 0.0086462700974930182, 0.008642988274268612, 0.0086398354288342947, 0.0086368223354497363, 0.008633928977603917, 0.0086311585249095376, 0.0086284942326021689, 0.0086259416228361072, 0.0086234837015709918, 0.0086211301369045531, 0.0086183581245045243, 0.0086142458177438236, 0.0086103183871695989, 0.0086065668675037559, 0.0086029748221146136, 0.0085995386884336576, 0.008596260557608976, 0.0085931268960348292, 0.0085901447769157497, 0.0085872985495316721, 0.0085845698072786226, 0.0085819484094732529, 0.0085794417478393444, 0.0085770395137785092, 0.0085747203457283479, 0.0085725002111970931, 0.0085703619239941853, 0.0085683112970958413, 0.0085663208668726089, 0.0085644332733573088, 0.0085626225001057509, 0.0085608670072540027, 0.0085591975873038455, 0.0085575997285877239, 0.0085560605449248872, 0.0085545816064074801, 0.0085531547959880085, 0.0085517837749067068, 0.0085504706983617253, 0.0085491999346749038], 'loss': [0.010354101771206011, 0.010250475911335412, 0.010152305186724435, 0.010059913468089805, 0.0099735498112370497, 0.0098928315765336016, 0.009817478727244788, 0.0097470875015481153, 0.0096812855495802819, 0.009619743677145803, 0.0095621900319292925, 0.0095084135030804422, 0.0094581801626320693, 0.0094112110969318003, 0.0093672709578457025, 0.0093261344706354592, 0.0092876454782068324, 0.0092515304705245993, 0.0092176937079715381, 0.0091859493112694136, 0.0091561595883538696, 0.0091281830606216221, 0.0091018794784488381, 0.009077145783866045, 0.009053882091811594, 0.0090319983147144241, 0.0090113777287199083, 0.0089919553879595788, 0.0089736302402133802, 0.0089563393058654864, 0.0089400296975854499, 0.0089246139649276583, 0.0089100622586315223, 0.0088963196444031504, 0.0088833291192333547, 0.0088710300750302323, 0.0088593838238412055, 0.0088483539192989406, 0.0088379152174111741, 0.0088279951935074201, 0.0088185867490435787, 0.0088096680526049791, 0.0088011739448115873, 0.0087931059494376473, 0.0087854699572272373, 0.0087781854525675572, 0.0087712716286030001, 0.0087646760696747875, 0.0087583968438753046, 0.0087524319082480234, 0.0087467462274336931, 0.0087413163689670937, 0.0087361520679453512, 0.0087312229170012339, 0.0087265245898065207, 0.008722039199472573, 0.0087177433593275365, 0.008713639452916094, 0.0087097178287140128, 0.008705980545705495, 0.0087023991851002142, 0.0086989802879080431, 0.008695711302739861, 0.0086925758899503783, 0.0086895775807805057, 0.0086867002004410634, 0.0086839519545307692, 0.0086813125989474837, 0.0086787757684133795, 0.0086763580693201038, 0.0086740247147374158, 0.0086717898067322774, 0.0086695799866225286, 0.0086660602936531484, 0.0086621334163796051, 0.0086583839254322122, 0.008654800306069169, 0.0086513653451367328, 0.0086480915196097997, 0.0086449624440497093, 0.0086419758923264763, 0.0086391329319979344, 0.0086364181908036419, 0.0086338115328282901, 0.0086313193576947334, 0.0086289309863900945, 0.0086266374926425669, 0.0086244302678718191, 0.0086223116166289776, 0.0086202825291955779, 0.0086183244787206952, 0.0086164400851572662, 0.0086146563602944575, 0.0086129358434418844, 0.0086112844636955736, 0.0086097037568505213, 0.0086081874600915584, 0.0086067337937740067, 0.0086053345036437041, 0.0086039756444759655, 0.0086026879493433343, 0.0086014543859758621]}
[2017-10-20 01:39:24,928 AE_UNIGRAMA_7L_OVER_05.py:132]: evaluating model ... 
[2017-10-20 01:39:25,000 AE_UNIGRAMA_7L_OVER_05.py:136]: evaluated! 
[2017-10-20 01:39:25,000 AE_UNIGRAMA_7L_OVER_05.py:138]: generating reports ... 
[2017-10-20 01:39:25,624 AE_UNIGRAMA_7L_OVER_05.py:141]: done!
[2017-10-20 01:39:25,624 AE_UNIGRAMA_7L_OVER_05.py:157]: >> experiment AE_UNIGRAMA_7L_OVER_05 finished!
