[2017-11-18 20:44:44,490 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_9FULLDS_UNDER_02
[2017-11-18 20:44:44,490 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 20:44:44,490 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_9FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,36,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4e525a8eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4e525ad400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:44:44,490 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 20:44:46,819 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:44:46,819 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:44:46,819 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 20:44:46,820 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f4e525a8eb8>, 'discard_decoder_function': True}
[2017-11-18 20:44:46,983 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 20:46:38,021 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 20:46:38,022 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0094695907049853114, 0.0087410168056894829, 0.0081764930350591656, 0.0077316525062968494, 0.0073765319570466377, 0.0070892123513003127, 0.0068539795373353894, 0.0066594848912777446, 0.0064972574899273619, 0.0063608465635808832, 0.0062453526427140357, 0.0061469112624897215, 0.0060626610304759139, 0.0059903177329349699, 0.0059279330462923777, 0.0058740163737074913, 0.0058272431939306374, 0.0057866739855996392, 0.0057514314668938296, 0.0057207309042481115, 0.0056931616748535632, 0.0056669558694491008, 0.0056442408575185224, 0.0056244359290598999, 0.005607213532943682, 0.0055921899954158947, 0.0055790850145653994, 0.0055672143895222842, 0.0055546283009826579, 0.00554393456330833, 0.0055347053516890277, 0.0055266637005115891, 0.005519681172400921, 0.0055135871478462868, 0.0055082590574722428, 0.0055035929818860489, 0.0054994986129179189, 0.0054959011633285912, 0.0054927377036414309, 0.0054899441583670106, 0.0054874618044680953, 0.0054852692259750088, 0.0054833184433460934, 0.0054815903306691931, 0.0054800549990270606, 0.0054786962768297752, 0.005477478303024131, 0.0054763927234310035, 0.0054754238434167402, 0.0054745521188125932, 0.0054737754318095093, 0.0054730776675491815, 0.0054724305985890433, 0.0054718504476031372, 0.0054713302146977456, 0.005470847400526206, 0.0054704143578622683, 0.0054700149155438539, 0.0054696420408191157, 0.0054693009100412185, 0.0054689827404207098, 0.0054686835670767738, 0.0054684089181327956, 0.0054681431988130285, 0.0054678939849696845, 0.0054676545851818402, 0.0054674297807350046, 0.0054672160811375901, 0.00546700223838484, 0.0054668033529259195, 0.0054666030678305281, 0.005466415236821451, 0.0054662356776750427, 0.0054660497736582821, 0.0054658684939952436, 0.0054656983467345341, 0.0054655259142936822, 0.0054653534811682858, 0.0054651804823525598, 0.0054650096952995964, 0.0054648400089083648, 0.0054646664733243085, 0.0054644930929606808, 0.0054643187015250639, 0.0054641404412159728, 0.0054639593393633256, 0.0054637758294548274, 0.005463586244899855, 0.0054633946677218768, 0.0054631958970097014, 0.0054629897103719866, 0.0054627721991461183, 0.0054625539133583293, 0.0054623263306027223, 0.0054620892067536713, 0.0054618214919871537, 0.0054615236397282255, 0.0054612186233705074, 0.0054607415874377415, 0.0054600546963941426, 0.0054592382321452526], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099263521923250442, 0.0090961855666683803, 0.0084568456190725009, 0.0079575820256820688, 0.007561912633706357, 0.0072440630208750736, 0.0069855288760166155, 0.0067729041165186061, 0.006596344440596571, 0.0064485697737035651, 0.0063238816421647718, 0.0062180081519228637, 0.006127540151882065, 0.0060500240855799635, 0.0059833210936186317, 0.0059257627039465549, 0.0058759072818030302, 0.0058326457521490774, 0.005795120278070884, 0.0057624682985960417, 0.0057338943082061453, 0.0057069902115436189, 0.005682804467088169, 0.0056618135978609629, 0.0056435132506771606, 0.0056275678162394536, 0.0056136823204422934, 0.0056015002088328839, 0.0055892081009056016, 0.0055777586938712048, 0.0055679234658801528, 0.0055594186130392123, 0.0055520198192130542, 0.0055455646095942598, 0.0055399513678819337, 0.0055350380209716419, 0.0055307200679431392, 0.0055269444765088912, 0.0055236148935351378, 0.0055206921184235433, 0.0055181066432678106, 0.0055158157913283851, 0.0055137883440941312, 0.0055119881003581122, 0.0055103937948262774, 0.0055089753644813663, 0.005507718220241555, 0.0055065963394314368, 0.0055055904708120468, 0.0055046932397078072, 0.0055038905555636836, 0.0055031666960953622, 0.0055025116352672388, 0.0055019164013118379, 0.0055013872193552327, 0.0055008972434840734, 0.0055004511157360977, 0.0055000488654330486, 0.005499675007036537, 0.0054993292212653627, 0.0054990110807536909, 0.0054987173254152514, 0.0054984357072207571, 0.0054981650660465842, 0.0054979176261445465, 0.005497676014810585, 0.005497458184038944, 0.0054972386542637723, 0.0054970349427973355, 0.0054968310586584112, 0.0054966407177353196, 0.0054964492347503429, 0.0054962688514454553, 0.0054960870037681379, 0.005495916935372323, 0.0054957399768241566, 0.0054955671783054267, 0.0054953984779718317, 0.0054952295671275558, 0.0054950624199889804, 0.0054948933091509833, 0.0054947261354342204, 0.0054945608031572125, 0.0054943871928320185, 0.005494213990381986, 0.0054940354945285565, 0.0054938596738697857, 0.0054936719093733773, 0.005493481985184844, 0.0054932865075839289, 0.0054930896231109227, 0.0054928825581630333, 0.0054926604061781067, 0.0054924393745924126, 0.0054922102921591718, 0.0054919647063286746, 0.0054916774785932375, 0.0054913747127917668, 0.0054910257262065394, 0.0054904202290695075, 0.0054896716199924105], 'acc': [0.58389591264976404, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822267327968, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822262938279, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.59383822272449271, 0.5938382226842539, 0.59383822267327968, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822272449271, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539]}
[2017-11-18 20:46:38,023 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:95]: done!
[2017-11-18 20:46:38,023 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 20:46:38,023 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 20:46:38,023 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f4e525ad400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:46:38,061 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 20:51:24,509 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 20:51:24,510 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0094695907049853114, 0.0087410168056894829, 0.0081764930350591656, 0.0077316525062968494, 0.0073765319570466377, 0.0070892123513003127, 0.0068539795373353894, 0.0066594848912777446, 0.0064972574899273619, 0.0063608465635808832, 0.0062453526427140357, 0.0061469112624897215, 0.0060626610304759139, 0.0059903177329349699, 0.0059279330462923777, 0.0058740163737074913, 0.0058272431939306374, 0.0057866739855996392, 0.0057514314668938296, 0.0057207309042481115, 0.0056931616748535632, 0.0056669558694491008, 0.0056442408575185224, 0.0056244359290598999, 0.005607213532943682, 0.0055921899954158947, 0.0055790850145653994, 0.0055672143895222842, 0.0055546283009826579, 0.00554393456330833, 0.0055347053516890277, 0.0055266637005115891, 0.005519681172400921, 0.0055135871478462868, 0.0055082590574722428, 0.0055035929818860489, 0.0054994986129179189, 0.0054959011633285912, 0.0054927377036414309, 0.0054899441583670106, 0.0054874618044680953, 0.0054852692259750088, 0.0054833184433460934, 0.0054815903306691931, 0.0054800549990270606, 0.0054786962768297752, 0.005477478303024131, 0.0054763927234310035, 0.0054754238434167402, 0.0054745521188125932, 0.0054737754318095093, 0.0054730776675491815, 0.0054724305985890433, 0.0054718504476031372, 0.0054713302146977456, 0.005470847400526206, 0.0054704143578622683, 0.0054700149155438539, 0.0054696420408191157, 0.0054693009100412185, 0.0054689827404207098, 0.0054686835670767738, 0.0054684089181327956, 0.0054681431988130285, 0.0054678939849696845, 0.0054676545851818402, 0.0054674297807350046, 0.0054672160811375901, 0.00546700223838484, 0.0054668033529259195, 0.0054666030678305281, 0.005466415236821451, 0.0054662356776750427, 0.0054660497736582821, 0.0054658684939952436, 0.0054656983467345341, 0.0054655259142936822, 0.0054653534811682858, 0.0054651804823525598, 0.0054650096952995964, 0.0054648400089083648, 0.0054646664733243085, 0.0054644930929606808, 0.0054643187015250639, 0.0054641404412159728, 0.0054639593393633256, 0.0054637758294548274, 0.005463586244899855, 0.0054633946677218768, 0.0054631958970097014, 0.0054629897103719866, 0.0054627721991461183, 0.0054625539133583293, 0.0054623263306027223, 0.0054620892067536713, 0.0054618214919871537, 0.0054615236397282255, 0.0054612186233705074, 0.0054607415874377415, 0.0054600546963941426, 0.0054592382321452526], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099263521923250442, 0.0090961855666683803, 0.0084568456190725009, 0.0079575820256820688, 0.007561912633706357, 0.0072440630208750736, 0.0069855288760166155, 0.0067729041165186061, 0.006596344440596571, 0.0064485697737035651, 0.0063238816421647718, 0.0062180081519228637, 0.006127540151882065, 0.0060500240855799635, 0.0059833210936186317, 0.0059257627039465549, 0.0058759072818030302, 0.0058326457521490774, 0.005795120278070884, 0.0057624682985960417, 0.0057338943082061453, 0.0057069902115436189, 0.005682804467088169, 0.0056618135978609629, 0.0056435132506771606, 0.0056275678162394536, 0.0056136823204422934, 0.0056015002088328839, 0.0055892081009056016, 0.0055777586938712048, 0.0055679234658801528, 0.0055594186130392123, 0.0055520198192130542, 0.0055455646095942598, 0.0055399513678819337, 0.0055350380209716419, 0.0055307200679431392, 0.0055269444765088912, 0.0055236148935351378, 0.0055206921184235433, 0.0055181066432678106, 0.0055158157913283851, 0.0055137883440941312, 0.0055119881003581122, 0.0055103937948262774, 0.0055089753644813663, 0.005507718220241555, 0.0055065963394314368, 0.0055055904708120468, 0.0055046932397078072, 0.0055038905555636836, 0.0055031666960953622, 0.0055025116352672388, 0.0055019164013118379, 0.0055013872193552327, 0.0055008972434840734, 0.0055004511157360977, 0.0055000488654330486, 0.005499675007036537, 0.0054993292212653627, 0.0054990110807536909, 0.0054987173254152514, 0.0054984357072207571, 0.0054981650660465842, 0.0054979176261445465, 0.005497676014810585, 0.005497458184038944, 0.0054972386542637723, 0.0054970349427973355, 0.0054968310586584112, 0.0054966407177353196, 0.0054964492347503429, 0.0054962688514454553, 0.0054960870037681379, 0.005495916935372323, 0.0054957399768241566, 0.0054955671783054267, 0.0054953984779718317, 0.0054952295671275558, 0.0054950624199889804, 0.0054948933091509833, 0.0054947261354342204, 0.0054945608031572125, 0.0054943871928320185, 0.005494213990381986, 0.0054940354945285565, 0.0054938596738697857, 0.0054936719093733773, 0.005493481985184844, 0.0054932865075839289, 0.0054930896231109227, 0.0054928825581630333, 0.0054926604061781067, 0.0054924393745924126, 0.0054922102921591718, 0.0054919647063286746, 0.0054916774785932375, 0.0054913747127917668, 0.0054910257262065394, 0.0054904202290695075, 0.0054896716199924105], 'acc': [0.58389591264976404, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822267327968, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822262938279, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.59383822272449271, 0.5938382226842539, 0.59383822267327968, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822272449271, 0.59383822264767316, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539]}
[2017-11-18 20:51:24,510 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 20:51:24,633 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 20:51:24,633 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 20:51:25,519 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:141]: done!
[2017-11-18 20:51:25,519 AE_UNIGRAMA_7L_9FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_7L_9FULLDS_UNDER_02 finished!
