[2017-11-18 20:51:29,886 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_9FULLDS_OVER_05
[2017-11-18 20:51:29,886 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 20:51:29,886 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_9FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa5d3483eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa5d3488400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:51:29,886 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 20:51:32,267 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:51:32,267 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:51:32,267 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 20:51:32,267 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa5d3483eb8>, 'discard_decoder_function': True}
[2017-11-18 20:51:32,451 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 20:54:59,672 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 20:54:59,673 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0094398331339993011, 0.0086795559391866749, 0.0080907006372548072, 0.0076299369328671389, 0.0072661390714963449, 0.0069760544652044667, 0.0067431834580781308, 0.0065548844766919112, 0.006401577420896881, 0.0062760193601184931, 0.0061728226461436478, 0.00608739854620057, 0.0060160269086940218, 0.0059567704750242059, 0.0059073180653694268, 0.0058658192757734783, 0.0058312068951070772, 0.0058020292684601502, 0.0057774575517705561, 0.0057567007838310626, 0.0057391712630461269, 0.0057243287842446925, 0.005711666412308582, 0.0057008772460728037, 0.0056917256278967163, 0.0056838991640882483, 0.0056771624563634942, 0.0056713937148718781, 0.0056665122112138106, 0.0056622872756809843, 0.0056584167846289246, 0.00565529432007752, 0.0056526006193600873, 0.005650238076465198, 0.0056482029140771852, 0.0056464189540482547, 0.0056448626999073452, 0.0056435154012148703, 0.0056423247825711674, 0.0056412663022059641, 0.0056403295369904377, 0.0056394748789323672, 0.0056387295335351886, 0.0056380156173655889, 0.0056373667196452466, 0.0056367344324788826, 0.0056360901188097128, 0.0056354714106927181, 0.0056349039132522335, 0.0056343657911496047, 0.0056308622518879492, 0.0056269336170943034, 0.0056238178275347592, 0.0056212282205121682, 0.0056190459394484527, 0.0056169896106071735, 0.0056152585757816209, 0.0056138555441415895, 0.0056126320231308872, 0.0056115806867559851, 0.0056106220518890183, 0.0056097370969252752, 0.0056089011329174517, 0.0056080379245583021, 0.0056071985791581423, 0.0056064974999062798, 0.0056058359056853583, 0.0056051834162464311, 0.0056044942353164467, 0.0056038957946748635, 0.0056033089844416181, 0.0056022918355801456, 0.0055999925014559825, 0.0055966762461669081, 0.005593948642706491, 0.0055916635038927385, 0.0055897248401801155, 0.0055880701194699744, 0.0055866429274364377, 0.0055853549134498278, 0.0055841654401343728, 0.0055830333281263233, 0.00558199268750003, 0.0055810322288358059, 0.0055801269719982982, 0.0055792972978405747, 0.0055783475254269068, 0.0055774807941458794, 0.005576776437466853, 0.0055761129715305698, 0.0055754541573297808, 0.005574782365109554, 0.005574086043440854, 0.005573325387867238, 0.0055725396971380179, 0.0055717515083353658, 0.0055710062320771647, 0.0055703322890186214, 0.0055696640957046944, 0.0055690009008479693, 0.0055683148573558317], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099119706656882137, 0.0090463839573537604, 0.0083771124975994728, 0.0078564241710957442, 0.0074473360995324792, 0.0071230887366101883, 0.0068637771005862856, 0.0066549902063604326, 0.0064857537631616245, 0.0063476783419614356, 0.0062344642476640198, 0.0061412097213919452, 0.0060636615390361557, 0.0059991337317112352, 0.0059454573673995538, 0.0059006302464880049, 0.0058630646675243486, 0.0058316568286392832, 0.005805203919983121, 0.0057829319589398779, 0.0057641142863006124, 0.005748239825799196, 0.0057347507507081773, 0.0057232761396065661, 0.0057134977869947355, 0.0057052082963547556, 0.0056981019827998958, 0.0056919972477447621, 0.0056868005831220278, 0.0056823720878082266, 0.0056784486362548951, 0.0056750499911453591, 0.005672225302408334, 0.0056697817169389575, 0.0056676473172466799, 0.0056658083814988148, 0.005664195915748349, 0.0056627907069946148, 0.0056615594401932742, 0.0056604781519355033, 0.0056595206190377554, 0.0056586661864183197, 0.0056578954716048546, 0.0056571899597171009, 0.0056565359152045969, 0.0056559264281956902, 0.0056553160056917193, 0.0056547019564367968, 0.0056541344000348263, 0.0056536082625096452, 0.0056520374332913242, 0.0056477561124936666, 0.0056442249496241638, 0.0056413789280902078, 0.0056389869229962475, 0.0056369239258064006, 0.0056349820550794074, 0.0056334589875510236, 0.0056321612282388524, 0.0056310521802924755, 0.0056300698593190271, 0.0056291673500724138, 0.0056283319958479834, 0.005627515320488375, 0.0056266537050707315, 0.0056259275993739916, 0.0056252629676545908, 0.0056246336464013036, 0.0056239863979029216, 0.005623368723668927, 0.0056227879718538662, 0.0056220738907581617, 0.0056206390410373621, 0.0056175548546459758, 0.0056145835326733258, 0.0056121257622820568, 0.0056100548529085005, 0.0056082890507890516, 0.0056067801879018603, 0.005605452199244413, 0.0056042459186834582, 0.0056031139565665359, 0.0056020531013340029, 0.0056010760615894262, 0.005600175281582606, 0.0055993232056768313, 0.0055985070821718596, 0.0055975308784113253, 0.0055968220966062295, 0.00559616469541146, 0.0055955157156727777, 0.0055948621718590425, 0.0055941959651676556, 0.0055934890736718881, 0.0055927350143515049, 0.0055919652440068147, 0.0055912204316667588, 0.0055905345617459131, 0.0055898841822798143, 0.0055892122484747257, 0.0055885562506082882], 'acc': [0.57984534182167502, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822264767316, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268059583, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822262938279, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822262206665, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822267327968, 0.59383822268791198, 0.59383822268791198]}
[2017-11-18 20:54:59,673 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:95]: done!
[2017-11-18 20:54:59,673 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 20:54:59,673 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 20:54:59,673 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa5d3488400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:54:59,705 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 21:02:09,668 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:125]: trained!
[2017-11-18 21:02:09,669 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0094398331339993011, 0.0086795559391866749, 0.0080907006372548072, 0.0076299369328671389, 0.0072661390714963449, 0.0069760544652044667, 0.0067431834580781308, 0.0065548844766919112, 0.006401577420896881, 0.0062760193601184931, 0.0061728226461436478, 0.00608739854620057, 0.0060160269086940218, 0.0059567704750242059, 0.0059073180653694268, 0.0058658192757734783, 0.0058312068951070772, 0.0058020292684601502, 0.0057774575517705561, 0.0057567007838310626, 0.0057391712630461269, 0.0057243287842446925, 0.005711666412308582, 0.0057008772460728037, 0.0056917256278967163, 0.0056838991640882483, 0.0056771624563634942, 0.0056713937148718781, 0.0056665122112138106, 0.0056622872756809843, 0.0056584167846289246, 0.00565529432007752, 0.0056526006193600873, 0.005650238076465198, 0.0056482029140771852, 0.0056464189540482547, 0.0056448626999073452, 0.0056435154012148703, 0.0056423247825711674, 0.0056412663022059641, 0.0056403295369904377, 0.0056394748789323672, 0.0056387295335351886, 0.0056380156173655889, 0.0056373667196452466, 0.0056367344324788826, 0.0056360901188097128, 0.0056354714106927181, 0.0056349039132522335, 0.0056343657911496047, 0.0056308622518879492, 0.0056269336170943034, 0.0056238178275347592, 0.0056212282205121682, 0.0056190459394484527, 0.0056169896106071735, 0.0056152585757816209, 0.0056138555441415895, 0.0056126320231308872, 0.0056115806867559851, 0.0056106220518890183, 0.0056097370969252752, 0.0056089011329174517, 0.0056080379245583021, 0.0056071985791581423, 0.0056064974999062798, 0.0056058359056853583, 0.0056051834162464311, 0.0056044942353164467, 0.0056038957946748635, 0.0056033089844416181, 0.0056022918355801456, 0.0055999925014559825, 0.0055966762461669081, 0.005593948642706491, 0.0055916635038927385, 0.0055897248401801155, 0.0055880701194699744, 0.0055866429274364377, 0.0055853549134498278, 0.0055841654401343728, 0.0055830333281263233, 0.00558199268750003, 0.0055810322288358059, 0.0055801269719982982, 0.0055792972978405747, 0.0055783475254269068, 0.0055774807941458794, 0.005576776437466853, 0.0055761129715305698, 0.0055754541573297808, 0.005574782365109554, 0.005574086043440854, 0.005573325387867238, 0.0055725396971380179, 0.0055717515083353658, 0.0055710062320771647, 0.0055703322890186214, 0.0055696640957046944, 0.0055690009008479693, 0.0055683148573558317], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099119706656882137, 0.0090463839573537604, 0.0083771124975994728, 0.0078564241710957442, 0.0074473360995324792, 0.0071230887366101883, 0.0068637771005862856, 0.0066549902063604326, 0.0064857537631616245, 0.0063476783419614356, 0.0062344642476640198, 0.0061412097213919452, 0.0060636615390361557, 0.0059991337317112352, 0.0059454573673995538, 0.0059006302464880049, 0.0058630646675243486, 0.0058316568286392832, 0.005805203919983121, 0.0057829319589398779, 0.0057641142863006124, 0.005748239825799196, 0.0057347507507081773, 0.0057232761396065661, 0.0057134977869947355, 0.0057052082963547556, 0.0056981019827998958, 0.0056919972477447621, 0.0056868005831220278, 0.0056823720878082266, 0.0056784486362548951, 0.0056750499911453591, 0.005672225302408334, 0.0056697817169389575, 0.0056676473172466799, 0.0056658083814988148, 0.005664195915748349, 0.0056627907069946148, 0.0056615594401932742, 0.0056604781519355033, 0.0056595206190377554, 0.0056586661864183197, 0.0056578954716048546, 0.0056571899597171009, 0.0056565359152045969, 0.0056559264281956902, 0.0056553160056917193, 0.0056547019564367968, 0.0056541344000348263, 0.0056536082625096452, 0.0056520374332913242, 0.0056477561124936666, 0.0056442249496241638, 0.0056413789280902078, 0.0056389869229962475, 0.0056369239258064006, 0.0056349820550794074, 0.0056334589875510236, 0.0056321612282388524, 0.0056310521802924755, 0.0056300698593190271, 0.0056291673500724138, 0.0056283319958479834, 0.005627515320488375, 0.0056266537050707315, 0.0056259275993739916, 0.0056252629676545908, 0.0056246336464013036, 0.0056239863979029216, 0.005623368723668927, 0.0056227879718538662, 0.0056220738907581617, 0.0056206390410373621, 0.0056175548546459758, 0.0056145835326733258, 0.0056121257622820568, 0.0056100548529085005, 0.0056082890507890516, 0.0056067801879018603, 0.005605452199244413, 0.0056042459186834582, 0.0056031139565665359, 0.0056020531013340029, 0.0056010760615894262, 0.005600175281582606, 0.0055993232056768313, 0.0055985070821718596, 0.0055975308784113253, 0.0055968220966062295, 0.00559616469541146, 0.0055955157156727777, 0.0055948621718590425, 0.0055941959651676556, 0.0055934890736718881, 0.0055927350143515049, 0.0055919652440068147, 0.0055912204316667588, 0.0055905345617459131, 0.0055898841822798143, 0.0055892122484747257, 0.0055885562506082882], 'acc': [0.57984534182167502, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822264767316, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268059583, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822262938279, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822262206665, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822267327968, 0.59383822268791198, 0.59383822268791198]}
[2017-11-18 21:02:09,670 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 21:02:09,852 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 21:02:09,853 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 21:02:10,718 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:141]: done!
[2017-11-18 21:02:10,718 AE_UNIGRAMA_7L_9FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_7L_9FULLDS_OVER_05 finished!
