[2017-11-18 18:40:08,931 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_9FULLDS_UNDER_01
[2017-11-18 18:40:08,931 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 18:40:08,931 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_9FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7eff6fee4be0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7eff6fee4470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:40:08,931 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 18:40:11,145 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:40:11,146 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:40:11,146 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 18:40:11,146 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7eff6fee4be0>, 'discard_decoder_function': True}
[2017-11-18 18:40:11,312 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 18:41:33,329 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 18:41:33,330 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0096654084475847214, 0.0090648846855494562, 0.0085821876607668265, 0.0081910232314069843, 0.0078716133582552583, 0.0076083006771628424, 0.0073895730264416431, 0.0072074309160856916, 0.0070548236155482018, 0.0069262834071759814, 0.0068174378574373685, 0.0067249125518994554, 0.0066457525238282468, 0.0065778781232403204, 0.0065193894110107979, 0.0064687748543660745, 0.0064248839276543285, 0.0063867815992685742, 0.0063535283514404945, 0.0063245166026367969, 0.0062991608377821256, 0.0062769204143671613, 0.0062574061677366415, 0.006240213336063654, 0.0062250989702835168, 0.0062117793265961518, 0.006200059265540403, 0.0061896948858504129, 0.0061805490491646849, 0.0061724557461219102, 0.006165310709666391, 0.0061590057580044868, 0.0061533740620330407, 0.0061484083549716113, 0.0061439953431916975, 0.0061400925411333801, 0.0061366267605674086, 0.0061335540535760163, 0.0061308088970296317, 0.0061283720509538982, 0.0061262075042948314, 0.0061242862400735388, 0.0061225730022028751, 0.0061210612528565522, 0.0061196775528342519, 0.0061184531966794542, 0.0061173640042324357, 0.0061163909046012925, 0.0061155199228988899, 0.006114736154455745, 0.0061140412533876873, 0.0061134236093093007, 0.0061128586772842986, 0.0061123669088449508, 0.0061119138363280564, 0.0061115076568098144, 0.0061111479154105121, 0.0061108180329796421, 0.0061105210929616148, 0.0061102535192112317, 0.0061100156699163168, 0.0061097986506211243, 0.0061095998799945176, 0.0061094170606201216, 0.0061092606353074126, 0.0061091103856114673, 0.0061089687828229204, 0.0061088409997866475, 0.006108724656684248, 0.0061086170068671277, 0.0061085164345539384, 0.0061084287267969628, 0.0061083368187614855, 0.0061082562989767854, 0.0061081827938890727, 0.0061081098042632485, 0.0061080524990884798, 0.0061079810698814784, 0.0061079192272901197, 0.0061078589771200315, 0.0061078076235448909, 0.0061077556778388956, 0.0061077041283985056, 0.0061076529181498355, 0.0061076032003789639, 0.0061075609710097628, 0.0061075141997744345, 0.0061074720748838136, 0.0061074306851082458, 0.0061073905258011299, 0.0061073515901170217, 0.0061073118748224773, 0.0061072756729517591, 0.0061072365757151867, 0.0061072033184119464, 0.0061071656462255534, 0.0061071283410404952, 0.0061070965117823164, 0.0061070567912681218, 0.0061070230867007243, 0.0061069856306592068], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010030237567335882, 0.0093601846422054023, 0.0088241249989346442, 0.0083918518314648593, 0.0080404919879109756, 0.0077526755464070408, 0.0075143765230259929, 0.0073164753588763568, 0.0071513031060531111, 0.0070126938648595975, 0.0068957104834169976, 0.0067965327594024577, 0.0067120916830272674, 0.0066397743484450473, 0.0065776759808204273, 0.0065241447971463645, 0.0064777700227964313, 0.0064375533676500835, 0.0064026132281204337, 0.0063721325678989336, 0.0063455462683464567, 0.0063223024277281499, 0.0063019141660459318, 0.0062840433118080009, 0.0062683094644397077, 0.0062544811837653182, 0.0062423083650907799, 0.0062315975345819327, 0.0062221542659338059, 0.0062138222641963982, 0.0062064605520296733, 0.0061999666824071736, 0.0061942399490880276, 0.0061891529331518976, 0.0061846560522743829, 0.0061806759388246969, 0.0061771625130947957, 0.0061740506567519119, 0.0061712951783026359, 0.0061688402321725096, 0.0061666710353446719, 0.0061647447580692261, 0.0061630423158924828, 0.0061615269260881789, 0.0061601862157381199, 0.0061589798410960949, 0.0061579115209936166, 0.0061569658912374436, 0.0061561207061699083, 0.0061553680709259921, 0.0061546959467296243, 0.006154100356397873, 0.0061535753825972296, 0.0061530976138878223, 0.0061526798146016772, 0.0061523037605610408, 0.0061519615884517743, 0.0061516650441754625, 0.0061513951937166751, 0.0061511530636793651, 0.0061509344836886059, 0.0061507437201437443, 0.006150569162320433, 0.006150406349484187, 0.0061502649795300126, 0.0061501354181219261, 0.0061500192699537578, 0.0061499113220425637, 0.0061498129365633522, 0.0061497211770550177, 0.0061496352566888764, 0.0061495590997201156, 0.0061494889172422559, 0.0061494241698609731, 0.006149362181752876, 0.0061493010443754289, 0.0061492428945577977, 0.0061491937185653087, 0.0061491440323287651, 0.0061490941576442942, 0.0061490496172307571, 0.0061490052849272909, 0.0061489650130279227, 0.0061489246222983336, 0.0061488868847578062, 0.0061488502705315399, 0.0061488131572640685, 0.0061487757071680754, 0.0061487423136466351, 0.0061487063564446102, 0.0061486739475735937, 0.0061486412362256482, 0.0061486095885768012, 0.0061485740780026525, 0.0061485418027656218, 0.0061485126653551964, 0.0061484807031120543, 0.0061484467817992392, 0.0061484169411242405, 0.0061483837454816975, 0.0061483535906125047], 'acc': [0.59187430959106646, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822268059583, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894]}
[2017-11-18 18:41:33,330 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:95]: done!
[2017-11-18 18:41:33,330 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 18:41:33,330 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 18:41:33,330 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7eff6fee4470>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:41:33,370 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 18:44:40,487 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 18:44:40,488 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0096654084475847214, 0.0090648846855494562, 0.0085821876607668265, 0.0081910232314069843, 0.0078716133582552583, 0.0076083006771628424, 0.0073895730264416431, 0.0072074309160856916, 0.0070548236155482018, 0.0069262834071759814, 0.0068174378574373685, 0.0067249125518994554, 0.0066457525238282468, 0.0065778781232403204, 0.0065193894110107979, 0.0064687748543660745, 0.0064248839276543285, 0.0063867815992685742, 0.0063535283514404945, 0.0063245166026367969, 0.0062991608377821256, 0.0062769204143671613, 0.0062574061677366415, 0.006240213336063654, 0.0062250989702835168, 0.0062117793265961518, 0.006200059265540403, 0.0061896948858504129, 0.0061805490491646849, 0.0061724557461219102, 0.006165310709666391, 0.0061590057580044868, 0.0061533740620330407, 0.0061484083549716113, 0.0061439953431916975, 0.0061400925411333801, 0.0061366267605674086, 0.0061335540535760163, 0.0061308088970296317, 0.0061283720509538982, 0.0061262075042948314, 0.0061242862400735388, 0.0061225730022028751, 0.0061210612528565522, 0.0061196775528342519, 0.0061184531966794542, 0.0061173640042324357, 0.0061163909046012925, 0.0061155199228988899, 0.006114736154455745, 0.0061140412533876873, 0.0061134236093093007, 0.0061128586772842986, 0.0061123669088449508, 0.0061119138363280564, 0.0061115076568098144, 0.0061111479154105121, 0.0061108180329796421, 0.0061105210929616148, 0.0061102535192112317, 0.0061100156699163168, 0.0061097986506211243, 0.0061095998799945176, 0.0061094170606201216, 0.0061092606353074126, 0.0061091103856114673, 0.0061089687828229204, 0.0061088409997866475, 0.006108724656684248, 0.0061086170068671277, 0.0061085164345539384, 0.0061084287267969628, 0.0061083368187614855, 0.0061082562989767854, 0.0061081827938890727, 0.0061081098042632485, 0.0061080524990884798, 0.0061079810698814784, 0.0061079192272901197, 0.0061078589771200315, 0.0061078076235448909, 0.0061077556778388956, 0.0061077041283985056, 0.0061076529181498355, 0.0061076032003789639, 0.0061075609710097628, 0.0061075141997744345, 0.0061074720748838136, 0.0061074306851082458, 0.0061073905258011299, 0.0061073515901170217, 0.0061073118748224773, 0.0061072756729517591, 0.0061072365757151867, 0.0061072033184119464, 0.0061071656462255534, 0.0061071283410404952, 0.0061070965117823164, 0.0061070567912681218, 0.0061070230867007243, 0.0061069856306592068], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010030237567335882, 0.0093601846422054023, 0.0088241249989346442, 0.0083918518314648593, 0.0080404919879109756, 0.0077526755464070408, 0.0075143765230259929, 0.0073164753588763568, 0.0071513031060531111, 0.0070126938648595975, 0.0068957104834169976, 0.0067965327594024577, 0.0067120916830272674, 0.0066397743484450473, 0.0065776759808204273, 0.0065241447971463645, 0.0064777700227964313, 0.0064375533676500835, 0.0064026132281204337, 0.0063721325678989336, 0.0063455462683464567, 0.0063223024277281499, 0.0063019141660459318, 0.0062840433118080009, 0.0062683094644397077, 0.0062544811837653182, 0.0062423083650907799, 0.0062315975345819327, 0.0062221542659338059, 0.0062138222641963982, 0.0062064605520296733, 0.0061999666824071736, 0.0061942399490880276, 0.0061891529331518976, 0.0061846560522743829, 0.0061806759388246969, 0.0061771625130947957, 0.0061740506567519119, 0.0061712951783026359, 0.0061688402321725096, 0.0061666710353446719, 0.0061647447580692261, 0.0061630423158924828, 0.0061615269260881789, 0.0061601862157381199, 0.0061589798410960949, 0.0061579115209936166, 0.0061569658912374436, 0.0061561207061699083, 0.0061553680709259921, 0.0061546959467296243, 0.006154100356397873, 0.0061535753825972296, 0.0061530976138878223, 0.0061526798146016772, 0.0061523037605610408, 0.0061519615884517743, 0.0061516650441754625, 0.0061513951937166751, 0.0061511530636793651, 0.0061509344836886059, 0.0061507437201437443, 0.006150569162320433, 0.006150406349484187, 0.0061502649795300126, 0.0061501354181219261, 0.0061500192699537578, 0.0061499113220425637, 0.0061498129365633522, 0.0061497211770550177, 0.0061496352566888764, 0.0061495590997201156, 0.0061494889172422559, 0.0061494241698609731, 0.006149362181752876, 0.0061493010443754289, 0.0061492428945577977, 0.0061491937185653087, 0.0061491440323287651, 0.0061490941576442942, 0.0061490496172307571, 0.0061490052849272909, 0.0061489650130279227, 0.0061489246222983336, 0.0061488868847578062, 0.0061488502705315399, 0.0061488131572640685, 0.0061487757071680754, 0.0061487423136466351, 0.0061487063564446102, 0.0061486739475735937, 0.0061486412362256482, 0.0061486095885768012, 0.0061485740780026525, 0.0061485418027656218, 0.0061485126653551964, 0.0061484807031120543, 0.0061484467817992392, 0.0061484169411242405, 0.0061483837454816975, 0.0061483535906125047], 'acc': [0.59187430959106646, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822268059583, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894]}
[2017-11-18 18:44:40,488 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 18:44:40,616 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 18:44:40,616 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 18:44:41,439 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:141]: done!
[2017-11-18 18:44:41,439 AE_UNIGRAMA_7L_9FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_7L_9FULLDS_UNDER_01 finished!
