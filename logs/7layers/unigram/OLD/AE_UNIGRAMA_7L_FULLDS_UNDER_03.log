[2017-11-13 17:44:58,669 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_FULLDS_UNDER_03
[2017-11-13 17:44:58,670 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-13 17:44:58,670 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48,40
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0fbec53eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0fbec58400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 17:44:58,670 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-13 17:45:01,016 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 17:45:01,016 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-13 17:45:01,017 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:60]: =======================================
[2017-11-13 17:45:01,017 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0fbec53eb8>, 'discard_decoder_function': True}
[2017-11-13 17:45:01,164 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-13 17:48:13,919 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-13 17:48:13,920 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0098836603901324704, 0.0095252944991671609, 0.0092730020990582224, 0.0090930677306226004, 0.0089620645943507462, 0.0088646138180697599, 0.008790854731207054, 0.0087339018061839239, 0.0086892273236656176, 0.0086512539055895298, 0.0086202409815964616, 0.0085949225981679749, 0.008574056236476571, 0.0085567415150095329, 0.0085422453829571629, 0.008530018135469896, 0.0085197121054837698, 0.0085110051563582582, 0.0085035652248753608, 0.00849714896613263, 0.0084915918146439093, 0.008486746939755525, 0.008482511642702863, 0.0084788032349791872, 0.0084755129483074926, 0.008472577478080846, 0.0084699576081230955, 0.0084676545018173462, 0.0084656153582050187, 0.0084637931295804391, 0.0084621510956161203, 0.0084606652657711213, 0.0084593180907244683, 0.0084580925140271112, 0.0084569737467831297, 0.0084559591387791122, 0.0084550385022839174, 0.0084542021735850969, 0.008453436075028296, 0.0084527392335337383, 0.0084521005139609161, 0.0084515070674125656, 0.0084509571763669387, 0.008450443371076196, 0.0084499614409081023, 0.0084495106492929496, 0.0084490719179799792, 0.0084486567688772489, 0.0084482626298094058, 0.0084478804233762243, 0.0084475139915828144, 0.0084471574497437581, 0.0084468129942195675, 0.0084464717180615656, 0.0084461434253137891, 0.008445818810622752, 0.0084455015619710853, 0.0084451877887510331, 0.0084448757330527289, 0.0084445683507386356, 0.0084442611905591793, 0.0084439586342826833, 0.008443652579642337, 0.0084433495773852032, 0.0084430407784065967, 0.008442731296937284, 0.0084424197436945257, 0.0084421096861811516, 0.0084417990529659873, 0.0084414707263332656, 0.0084410641251357107, 0.0084406351920481518, 0.0084402147120563736, 0.0084397723530006737, 0.0084393374191974284, 0.0084389480096464294, 0.0084386104683623463, 0.0084382890070248111, 0.008437973364314167, 0.0084376614650342446, 0.0084373525024495424, 0.0084370404262149087, 0.0084367299216940791, 0.0084364144330059104, 0.0084361013429611106, 0.0084357869214775668, 0.0084354656049211597, 0.0084351245358378207, 0.0084347025827066248, 0.0084342623423156564, 0.0084338422651782236, 0.0084334502348492185, 0.0084330787292131604, 0.0084327267512312176, 0.0084323797170285011, 0.0084320400173761127, 0.0084316965150799169, 0.0084313519589277099, 0.0084310071645540725, 0.0084306603719955069, 0.0084303119687041093], 'val_acc': [0.0047776552737963983, 0.0051451672179345827, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010125857257304001, 0.0096935171778452702, 0.0093908329095681847, 0.0091767757263377988, 0.0090225440189032023, 0.0089091027620322467, 0.0088239126840229786, 0.0087588080223885232, 0.0087081372623112469, 0.0086670036913400212, 0.008632321699921508, 0.0086041055732888286, 0.0085809701655622031, 0.0085618037209637225, 0.008545833048907412, 0.0085324001567909456, 0.0085210634388164005, 0.0085115074993416303, 0.0085033979518374467, 0.0084964287827049532, 0.0084904151280139999, 0.0084851836472222952, 0.0084806186844011422, 0.0084766208590754226, 0.0084731026677334984, 0.0084699684282122569, 0.0084671724855861392, 0.0084646912344230798, 0.0084625077895144306, 0.0084605711671508089, 0.0084588322327788356, 0.0084572620713875037, 0.0084558363926848547, 0.0084545450644940047, 0.0084533649429859997, 0.0084522917338115278, 0.0084513166217000564, 0.0084504302877101041, 0.0084496245478173915, 0.0084488848806144531, 0.0084482129308624514, 0.0084475904913022207, 0.0084470191458794579, 0.0084464880665831663, 0.0084459873561533484, 0.0084455131444628722, 0.0084450707586951543, 0.0084446409046860273, 0.0084442385431546894, 0.008443847454661816, 0.0084434754976631683, 0.0084431140565961443, 0.0084427636132975784, 0.008442419437192929, 0.0084420858307478544, 0.0084417587637945195, 0.0084414408644298937, 0.0084411296449355636, 0.0084408180700365609, 0.0084405129335750253, 0.0084402057066389688, 0.0084399045441023949, 0.0084396015215499123, 0.0084392984230924097, 0.0084389934905684545, 0.0084386945498540929, 0.0084383897050095795, 0.0084380823519843128, 0.0084377727141493851, 0.0084374617742690276, 0.0084371050017036167, 0.0084366788789291564, 0.0084362762501298452, 0.0084358605862439335, 0.0084354379213774835, 0.0084350376264288752, 0.008434680162601944, 0.0084343596080477447, 0.0084340480514391077, 0.0084337347357545181, 0.008433421868183898, 0.0084331128812573704, 0.008432803216101209, 0.0084324980508323471, 0.0084321887128451078, 0.0084318783507116874, 0.0084315626889447121, 0.0084312444815017318, 0.0084308709783955799, 0.0084304447758293995, 0.0084300295981242779, 0.0084296368497806893, 0.0084292637339730379, 0.0084289113767591402, 0.0084285725879103286, 0.0084282378929598466, 0.0084279025676776264, 0.0084275652847546692, 0.0084272309391501786, 0.0084268930480725507, 0.0084265527070003943], 'acc': [0.0013501902540812569, 0.0024548913710568309, 0.0096968209156744808, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-13 17:48:13,920 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:95]: done!
[2017-11-13 17:48:13,921 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-13 17:48:13,921 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:100]: =======================================
[2017-11-13 17:48:13,921 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0fbec58400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 17:48:13,981 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:113]: training ... 
[2017-11-13 17:53:21,379 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:125]: trained!
[2017-11-13 17:53:21,379 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0098836603901324704, 0.0095252944991671609, 0.0092730020990582224, 0.0090930677306226004, 0.0089620645943507462, 0.0088646138180697599, 0.008790854731207054, 0.0087339018061839239, 0.0086892273236656176, 0.0086512539055895298, 0.0086202409815964616, 0.0085949225981679749, 0.008574056236476571, 0.0085567415150095329, 0.0085422453829571629, 0.008530018135469896, 0.0085197121054837698, 0.0085110051563582582, 0.0085035652248753608, 0.00849714896613263, 0.0084915918146439093, 0.008486746939755525, 0.008482511642702863, 0.0084788032349791872, 0.0084755129483074926, 0.008472577478080846, 0.0084699576081230955, 0.0084676545018173462, 0.0084656153582050187, 0.0084637931295804391, 0.0084621510956161203, 0.0084606652657711213, 0.0084593180907244683, 0.0084580925140271112, 0.0084569737467831297, 0.0084559591387791122, 0.0084550385022839174, 0.0084542021735850969, 0.008453436075028296, 0.0084527392335337383, 0.0084521005139609161, 0.0084515070674125656, 0.0084509571763669387, 0.008450443371076196, 0.0084499614409081023, 0.0084495106492929496, 0.0084490719179799792, 0.0084486567688772489, 0.0084482626298094058, 0.0084478804233762243, 0.0084475139915828144, 0.0084471574497437581, 0.0084468129942195675, 0.0084464717180615656, 0.0084461434253137891, 0.008445818810622752, 0.0084455015619710853, 0.0084451877887510331, 0.0084448757330527289, 0.0084445683507386356, 0.0084442611905591793, 0.0084439586342826833, 0.008443652579642337, 0.0084433495773852032, 0.0084430407784065967, 0.008442731296937284, 0.0084424197436945257, 0.0084421096861811516, 0.0084417990529659873, 0.0084414707263332656, 0.0084410641251357107, 0.0084406351920481518, 0.0084402147120563736, 0.0084397723530006737, 0.0084393374191974284, 0.0084389480096464294, 0.0084386104683623463, 0.0084382890070248111, 0.008437973364314167, 0.0084376614650342446, 0.0084373525024495424, 0.0084370404262149087, 0.0084367299216940791, 0.0084364144330059104, 0.0084361013429611106, 0.0084357869214775668, 0.0084354656049211597, 0.0084351245358378207, 0.0084347025827066248, 0.0084342623423156564, 0.0084338422651782236, 0.0084334502348492185, 0.0084330787292131604, 0.0084327267512312176, 0.0084323797170285011, 0.0084320400173761127, 0.0084316965150799169, 0.0084313519589277099, 0.0084310071645540725, 0.0084306603719955069, 0.0084303119687041093], 'val_acc': [0.0047776552737963983, 0.0051451672179345827, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010125857257304001, 0.0096935171778452702, 0.0093908329095681847, 0.0091767757263377988, 0.0090225440189032023, 0.0089091027620322467, 0.0088239126840229786, 0.0087588080223885232, 0.0087081372623112469, 0.0086670036913400212, 0.008632321699921508, 0.0086041055732888286, 0.0085809701655622031, 0.0085618037209637225, 0.008545833048907412, 0.0085324001567909456, 0.0085210634388164005, 0.0085115074993416303, 0.0085033979518374467, 0.0084964287827049532, 0.0084904151280139999, 0.0084851836472222952, 0.0084806186844011422, 0.0084766208590754226, 0.0084731026677334984, 0.0084699684282122569, 0.0084671724855861392, 0.0084646912344230798, 0.0084625077895144306, 0.0084605711671508089, 0.0084588322327788356, 0.0084572620713875037, 0.0084558363926848547, 0.0084545450644940047, 0.0084533649429859997, 0.0084522917338115278, 0.0084513166217000564, 0.0084504302877101041, 0.0084496245478173915, 0.0084488848806144531, 0.0084482129308624514, 0.0084475904913022207, 0.0084470191458794579, 0.0084464880665831663, 0.0084459873561533484, 0.0084455131444628722, 0.0084450707586951543, 0.0084446409046860273, 0.0084442385431546894, 0.008443847454661816, 0.0084434754976631683, 0.0084431140565961443, 0.0084427636132975784, 0.008442419437192929, 0.0084420858307478544, 0.0084417587637945195, 0.0084414408644298937, 0.0084411296449355636, 0.0084408180700365609, 0.0084405129335750253, 0.0084402057066389688, 0.0084399045441023949, 0.0084396015215499123, 0.0084392984230924097, 0.0084389934905684545, 0.0084386945498540929, 0.0084383897050095795, 0.0084380823519843128, 0.0084377727141493851, 0.0084374617742690276, 0.0084371050017036167, 0.0084366788789291564, 0.0084362762501298452, 0.0084358605862439335, 0.0084354379213774835, 0.0084350376264288752, 0.008434680162601944, 0.0084343596080477447, 0.0084340480514391077, 0.0084337347357545181, 0.008433421868183898, 0.0084331128812573704, 0.008432803216101209, 0.0084324980508323471, 0.0084321887128451078, 0.0084318783507116874, 0.0084315626889447121, 0.0084312444815017318, 0.0084308709783955799, 0.0084304447758293995, 0.0084300295981242779, 0.0084296368497806893, 0.0084292637339730379, 0.0084289113767591402, 0.0084285725879103286, 0.0084282378929598466, 0.0084279025676776264, 0.0084275652847546692, 0.0084272309391501786, 0.0084268930480725507, 0.0084265527070003943], 'acc': [0.0013501902540812569, 0.0024548913710568309, 0.0096968209156744808, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032897373408, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-13 17:53:21,379 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-13 17:53:21,507 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-13 17:53:21,507 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-13 17:53:22,410 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:141]: done!
[2017-11-13 17:53:22,410 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_7L_FULLDS_UNDER_03 finished!
[2017-11-14 07:05:01,488 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:146]: The experiment AE_UNIGRAMA_7L_FULLDS_UNDER_03 was already executed!
[2017-11-18 14:56:48,873 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:146]: The experiment AE_UNIGRAMA_7L_FULLDS_UNDER_03 was already executed!
[2017-11-18 16:23:19,727 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:146]: The experiment AE_UNIGRAMA_7L_FULLDS_UNDER_03 was already executed!
[2017-11-18 18:42:54,867 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_FULLDS_UNDER_03
[2017-11-18 18:42:54,867 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 18:42:54,867 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48,40
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc5008e1e80>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc5008e63c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:42:54,867 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 18:42:57,087 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:42:57,087 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:42:57,087 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 18:42:57,088 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc5008e1e80>, 'discard_decoder_function': True}
[2017-11-18 18:42:57,235 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 18:44:38,334 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 18:44:38,335 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0093806125528258857, 0.0086112217279407793, 0.0080244738034608281, 0.007566311582341073, 0.0072076879421201796, 0.006923422088674744, 0.0066961583526355299, 0.0065128439226184685, 0.0063636756378189357, 0.0062414270590200821, 0.0061405097045078303, 0.0060565123501898103, 0.0059860967897503023, 0.0059268077751926228, 0.0058766887822722042, 0.0058340527152677523, 0.0057978063027892303, 0.0057668092504700938, 0.0057401677017887036, 0.0057172712126184761, 0.0056975300525455783, 0.0056804954616824568, 0.0056656988981792214, 0.0056528814292886934, 0.0056417641884180794, 0.0056320511992166465, 0.005623601851399573, 0.0056162097879631726, 0.0056097386905444987, 0.005604088573484863, 0.0055991097240277845, 0.0055947546031358915, 0.0055909287193889341, 0.0055875469157277155, 0.0055845843044303707, 0.0055819454666046382, 0.0055796074095185201, 0.0055775370578720028, 0.0055756844543892641, 0.0055740348681895136, 0.0055725590447569728, 0.0055712304932524978, 0.0055700383474759398, 0.0055689595772164986, 0.005567989491120676, 0.0055671027542880157, 0.0055663007548033029, 0.0055655750746536519, 0.0055648987813832537, 0.00556426796076757, 0.005563666002937168, 0.0055631208001645895, 0.0055626195406035346, 0.0055621496090430657, 0.0055617098507424493, 0.0055612923736755556, 0.0055608998560365492, 0.0055605239890829323, 0.0055601632775987321, 0.0055597990422514062, 0.0055594430291372836, 0.0055590853467617886, 0.0055587217628439694, 0.0055583642764192916, 0.0055580046112611147, 0.0055576518236343554, 0.0055573069817704537, 0.005556980007027236, 0.0055566577487089529, 0.0055563456512534443, 0.0055560389689715065, 0.0055557372101891662, 0.0055554373317645593, 0.0055551372968360027, 0.0055548330357018273, 0.0055545271426995137, 0.0055542221962508855, 0.0055539159605485612, 0.0055535966637402295, 0.0055532785552153035, 0.0055529601235854492, 0.0055526496952201781, 0.005552336540485937, 0.0055520285498686286, 0.0055517185076719338, 0.0055514023325569277, 0.0055510867653172959, 0.0055507702917409587, 0.0055503990477719749, 0.0055498646813362989, 0.0055492833929799718, 0.005548679002792393, 0.0055480547551714629, 0.0055474047977764817, 0.0055467570055952485, 0.005546121298188658, 0.0055454907546422958, 0.0055448801188432957, 0.0055443012883434209, 0.005543773227502366, 0.0055432640588015747], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098688328120598214, 0.0089849285699991378, 0.0083158176452446404, 0.0077989638525943709, 0.0073955955791007166, 0.0070782257151967495, 0.0068257316277441629, 0.006623212116624924, 0.0064593171510501108, 0.0063256064193933466, 0.0062157175154668124, 0.0061247068133451635, 0.0060487547612710062, 0.0059850030760204773, 0.0059312205823172422, 0.0058857255862328232, 0.0058469773764944161, 0.0058140082421300017, 0.0057857822294401749, 0.0057615253849592225, 0.0057406696680477346, 0.0057226881302885847, 0.005707158770869923, 0.0056936990733075406, 0.0056820261187904468, 0.005671899370600841, 0.0056630674221135541, 0.0056553720780095577, 0.0056486645674238556, 0.0056427952327516434, 0.0056376636687428859, 0.0056331541975204518, 0.0056292111516694785, 0.0056257600435600501, 0.0056227044220334751, 0.0056200289315844372, 0.0056176513480439795, 0.0056155475741406632, 0.0056136829015615165, 0.0056120271713220151, 0.0056105419220403982, 0.0056092197875003804, 0.0056080297410682003, 0.0056069645981737717, 0.0056060016711612995, 0.0056051309273649217, 0.0056043408861505195, 0.0056036224817267053, 0.0056029698628910747, 0.0056023665533961329, 0.0056017965347107948, 0.0056012721667785259, 0.0056007891778271854, 0.0056003412563087199, 0.0055999245022026779, 0.0055995254599726704, 0.005599152200757118, 0.0055987970285415762, 0.0055984534374428508, 0.0055981171470580364, 0.0055977784259407352, 0.0055974415789572197, 0.005597100744445283, 0.0055967591160743044, 0.0055964097551653045, 0.005596071612995245, 0.0055957375350588305, 0.0055954120943476644, 0.0055951026629080863, 0.0055948012342466871, 0.0055945091714529925, 0.0055942125843657922, 0.0055939247667660509, 0.0055936401754725605, 0.0055933524889347228, 0.005593060294850496, 0.0055927685708286748, 0.0055924760113943862, 0.0055921760960893022, 0.0055918774876880274, 0.0055915705219612604, 0.005591266410103166, 0.005590962585689605, 0.0055906626675838091, 0.0055903621629859951, 0.0055900590289765942, 0.0055897543069633208, 0.0055894464350060751, 0.0055891264158451836, 0.0055886767681162675, 0.0055881253589066763, 0.0055875417461354257, 0.0055869402901976076, 0.0055863263406823373, 0.0055856865627124837, 0.0055850691684354034, 0.0055844545984766233, 0.0055838448888396678, 0.0055832625645103884, 0.0055827228894279575, 0.0055822201192742976], 'acc': [0.57174420034840046, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.59383822262938279, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822264767316, 0.59383822266596353, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822262938279, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822267327968]}
[2017-11-18 18:44:38,335 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:95]: done!
[2017-11-18 18:44:38,335 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 18:44:38,335 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 18:44:38,335 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc5008e63c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:44:38,366 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 18:48:20,950 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 18:48:20,950 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0093806125528258857, 0.0086112217279407793, 0.0080244738034608281, 0.007566311582341073, 0.0072076879421201796, 0.006923422088674744, 0.0066961583526355299, 0.0065128439226184685, 0.0063636756378189357, 0.0062414270590200821, 0.0061405097045078303, 0.0060565123501898103, 0.0059860967897503023, 0.0059268077751926228, 0.0058766887822722042, 0.0058340527152677523, 0.0057978063027892303, 0.0057668092504700938, 0.0057401677017887036, 0.0057172712126184761, 0.0056975300525455783, 0.0056804954616824568, 0.0056656988981792214, 0.0056528814292886934, 0.0056417641884180794, 0.0056320511992166465, 0.005623601851399573, 0.0056162097879631726, 0.0056097386905444987, 0.005604088573484863, 0.0055991097240277845, 0.0055947546031358915, 0.0055909287193889341, 0.0055875469157277155, 0.0055845843044303707, 0.0055819454666046382, 0.0055796074095185201, 0.0055775370578720028, 0.0055756844543892641, 0.0055740348681895136, 0.0055725590447569728, 0.0055712304932524978, 0.0055700383474759398, 0.0055689595772164986, 0.005567989491120676, 0.0055671027542880157, 0.0055663007548033029, 0.0055655750746536519, 0.0055648987813832537, 0.00556426796076757, 0.005563666002937168, 0.0055631208001645895, 0.0055626195406035346, 0.0055621496090430657, 0.0055617098507424493, 0.0055612923736755556, 0.0055608998560365492, 0.0055605239890829323, 0.0055601632775987321, 0.0055597990422514062, 0.0055594430291372836, 0.0055590853467617886, 0.0055587217628439694, 0.0055583642764192916, 0.0055580046112611147, 0.0055576518236343554, 0.0055573069817704537, 0.005556980007027236, 0.0055566577487089529, 0.0055563456512534443, 0.0055560389689715065, 0.0055557372101891662, 0.0055554373317645593, 0.0055551372968360027, 0.0055548330357018273, 0.0055545271426995137, 0.0055542221962508855, 0.0055539159605485612, 0.0055535966637402295, 0.0055532785552153035, 0.0055529601235854492, 0.0055526496952201781, 0.005552336540485937, 0.0055520285498686286, 0.0055517185076719338, 0.0055514023325569277, 0.0055510867653172959, 0.0055507702917409587, 0.0055503990477719749, 0.0055498646813362989, 0.0055492833929799718, 0.005548679002792393, 0.0055480547551714629, 0.0055474047977764817, 0.0055467570055952485, 0.005546121298188658, 0.0055454907546422958, 0.0055448801188432957, 0.0055443012883434209, 0.005543773227502366, 0.0055432640588015747], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098688328120598214, 0.0089849285699991378, 0.0083158176452446404, 0.0077989638525943709, 0.0073955955791007166, 0.0070782257151967495, 0.0068257316277441629, 0.006623212116624924, 0.0064593171510501108, 0.0063256064193933466, 0.0062157175154668124, 0.0061247068133451635, 0.0060487547612710062, 0.0059850030760204773, 0.0059312205823172422, 0.0058857255862328232, 0.0058469773764944161, 0.0058140082421300017, 0.0057857822294401749, 0.0057615253849592225, 0.0057406696680477346, 0.0057226881302885847, 0.005707158770869923, 0.0056936990733075406, 0.0056820261187904468, 0.005671899370600841, 0.0056630674221135541, 0.0056553720780095577, 0.0056486645674238556, 0.0056427952327516434, 0.0056376636687428859, 0.0056331541975204518, 0.0056292111516694785, 0.0056257600435600501, 0.0056227044220334751, 0.0056200289315844372, 0.0056176513480439795, 0.0056155475741406632, 0.0056136829015615165, 0.0056120271713220151, 0.0056105419220403982, 0.0056092197875003804, 0.0056080297410682003, 0.0056069645981737717, 0.0056060016711612995, 0.0056051309273649217, 0.0056043408861505195, 0.0056036224817267053, 0.0056029698628910747, 0.0056023665533961329, 0.0056017965347107948, 0.0056012721667785259, 0.0056007891778271854, 0.0056003412563087199, 0.0055999245022026779, 0.0055995254599726704, 0.005599152200757118, 0.0055987970285415762, 0.0055984534374428508, 0.0055981171470580364, 0.0055977784259407352, 0.0055974415789572197, 0.005597100744445283, 0.0055967591160743044, 0.0055964097551653045, 0.005596071612995245, 0.0055957375350588305, 0.0055954120943476644, 0.0055951026629080863, 0.0055948012342466871, 0.0055945091714529925, 0.0055942125843657922, 0.0055939247667660509, 0.0055936401754725605, 0.0055933524889347228, 0.005593060294850496, 0.0055927685708286748, 0.0055924760113943862, 0.0055921760960893022, 0.0055918774876880274, 0.0055915705219612604, 0.005591266410103166, 0.005590962585689605, 0.0055906626675838091, 0.0055903621629859951, 0.0055900590289765942, 0.0055897543069633208, 0.0055894464350060751, 0.0055891264158451836, 0.0055886767681162675, 0.0055881253589066763, 0.0055875417461354257, 0.0055869402901976076, 0.0055863263406823373, 0.0055856865627124837, 0.0055850691684354034, 0.0055844545984766233, 0.0055838448888396678, 0.0055832625645103884, 0.0055827228894279575, 0.0055822201192742976], 'acc': [0.57174420034840046, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.59383822262938279, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822264767316, 0.59383822266596353, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822262938279, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822267327968]}
[2017-11-18 18:48:20,950 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 18:48:21,084 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 18:48:21,084 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 18:48:21,920 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:141]: done!
[2017-11-18 18:48:21,920 AE_UNIGRAMA_7L_FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_7L_FULLDS_UNDER_03 finished!
