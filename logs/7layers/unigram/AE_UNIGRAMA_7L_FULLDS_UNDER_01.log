[2017-11-14 08:32:49,206 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_FULLDS_UNDER_01
[2017-11-14 08:32:49,206 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-14 08:32:49,206 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7faa86b4beb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7faa86b50400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 08:32:49,207 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-14 08:32:51,349 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-14 08:32:51,350 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-14 08:32:51,350 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-14 08:32:51,350 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7faa86b4beb8>, 'discard_decoder_function': True}
[2017-11-14 08:32:51,496 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-14 08:34:50,752 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-14 08:34:50,753 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0092702241133910818, 0.0085393856493472097, 0.0080463007251290186, 0.0076946744702835815, 0.0074279699385582367, 0.0072147803579945529, 0.007039414514752926, 0.0068914563316702622, 0.0067641654240774545, 0.0066534258849310964, 0.0065537037966907769, 0.0064658523504360441, 0.0063884256702657133, 0.0063198616723737066, 0.0062591619941911487, 0.006205335384880311, 0.0061575938734947785, 0.0061152048211494097, 0.0060775376091691032, 0.0060439631288124332, 0.0060140878379342198, 0.0059875008045671418, 0.0059638101467571793, 0.0059427042997954567, 0.0059238901985271836, 0.0059070874947489121, 0.0058920919750219854, 0.0058786832792181295, 0.005866695055789432, 0.0058559757110227045, 0.0058464021132748952, 0.0058378162406191904, 0.0058300645224639144, 0.0058231015068618188, 0.0058168157265487018, 0.0058111639652991282, 0.0058061023324403535, 0.0058015430453433646, 0.0057974184485229717, 0.0057936774162717303, 0.0057902756218621504, 0.0057872043655057825, 0.0057844165455890858, 0.0057818629159922382, 0.0057795004921224963, 0.0057772957941141416, 0.0057752435518314367, 0.0057732666754846639, 0.0057714635511235263, 0.0057698282694190091, 0.0057683387552708038, 0.0057669659270961435, 0.0057657011562991904, 0.0057645317801787426, 0.0057634539029929608, 0.0057624562215457028, 0.0057615198753568804, 0.0057606136616119531, 0.005759688441921265, 0.0057587763407527413, 0.0057578893920536079, 0.0057570024533659349, 0.0057561066112378715, 0.0057552542347660872, 0.0057544265999515207, 0.005753611215057919, 0.0057527684240893913, 0.005751935801428059, 0.005751168888263495, 0.0057504735973474353, 0.0057497854425494167, 0.0057491036800264451, 0.0057484333943171742, 0.0057477742902974256, 0.0057471440532557922, 0.0057465381906133383, 0.0057459640666125055, 0.005745406564118362, 0.0057448624265823449, 0.0057443210042058841, 0.0057438095915687461, 0.0057432778112560196, 0.0057427706118181581, 0.0057422424173198209, 0.005741651580340062, 0.0057409971671604039, 0.005740380278134425, 0.0057397361906215919, 0.0057391022087801462, 0.0057384665481792748, 0.0057378284052494897, 0.005737183071609254, 0.005736535901422121, 0.0057358740244843869, 0.0057351963826616382, 0.005734505551209682, 0.0057338147223247671, 0.0057330989494997816, 0.0057323887421914166, 0.0057316705087718011, 0.0057309275579107231], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097970358737712038, 0.0088900953371910448, 0.0082924899919390883, 0.0078798256221414703, 0.0075773883042705012, 0.0073415174582687108, 0.0071505456801622324, 0.0069913791482978929, 0.0068557648988111638, 0.0067384165977025538, 0.0066347241600465783, 0.0065419814969836293, 0.0064603996831099283, 0.0063884112541200862, 0.0063246595915610422, 0.0062681972176637677, 0.0062181495198765291, 0.0061737727986565689, 0.0061343928131549121, 0.0060993840253090103, 0.0060682181363583077, 0.0060405189517692944, 0.0060158669432446611, 0.0059939376516943256, 0.0059744106246471928, 0.0059570029291172392, 0.0059414827324860637, 0.0059276436416909415, 0.0059152829242001192, 0.00590422795073791, 0.0058943845511257387, 0.0058855743585715702, 0.0058776560247838826, 0.0058705280549784002, 0.0058641323251154755, 0.005858366599536694, 0.0058531931215538022, 0.0058485706077530345, 0.0058444105784316268, 0.0058406364483976235, 0.0058372240064648983, 0.0058341378195075717, 0.005831341399845846, 0.0058288102318161585, 0.0058264825619415142, 0.0058243281040050304, 0.005822312244403537, 0.0058203947036928917, 0.0058185891423758965, 0.0058169609048999722, 0.0058154756857403019, 0.0058141230720200393, 0.0058128840192956718, 0.0058117360058964774, 0.0058106866927422618, 0.005809708898577245, 0.0058087968878855886, 0.0058079341150878783, 0.0058070582423299256, 0.0058061763688458268, 0.0058053117249436733, 0.0058044552728391992, 0.0058035921642418005, 0.0058027460915770976, 0.0058019362178901935, 0.0058011287058896454, 0.005800303062649264, 0.0057994516886362849, 0.0057986715103874433, 0.0057979685919021182, 0.0057973082033761607, 0.0057966526250449943, 0.0057959959626095389, 0.0057953464119828079, 0.0057947221728791905, 0.0057941296958535218, 0.0057935651886270381, 0.0057930082772752467, 0.0057924673740518953, 0.0057919332602695663, 0.0057914088698172838, 0.0057909022215344545, 0.0057903963250428257, 0.0057898903269825086, 0.0057893485959486218, 0.005788711071180389, 0.005788068647794878, 0.0057874312207657885, 0.0057867936092897898, 0.0057861497137012864, 0.0057855160651188713, 0.005784874441936874, 0.0057842282880025842, 0.0057835777062564681, 0.0057829047317867104, 0.0057822357200962224, 0.0057815560053408009, 0.0057808565662546664, 0.0057801445864362304, 0.0057794274918312521, 0.0057787104803902816], 'acc': [0.55664661845298169, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226842539, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822262938279, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353]}
[2017-11-14 08:34:50,753 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:95]: done!
[2017-11-14 08:34:50,753 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-14 08:34:50,753 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-14 08:34:50,754 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7faa86b50400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 08:34:50,787 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-14 08:38:05,405 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-14 08:38:05,406 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0092702241133910818, 0.0085393856493472097, 0.0080463007251290186, 0.0076946744702835815, 0.0074279699385582367, 0.0072147803579945529, 0.007039414514752926, 0.0068914563316702622, 0.0067641654240774545, 0.0066534258849310964, 0.0065537037966907769, 0.0064658523504360441, 0.0063884256702657133, 0.0063198616723737066, 0.0062591619941911487, 0.006205335384880311, 0.0061575938734947785, 0.0061152048211494097, 0.0060775376091691032, 0.0060439631288124332, 0.0060140878379342198, 0.0059875008045671418, 0.0059638101467571793, 0.0059427042997954567, 0.0059238901985271836, 0.0059070874947489121, 0.0058920919750219854, 0.0058786832792181295, 0.005866695055789432, 0.0058559757110227045, 0.0058464021132748952, 0.0058378162406191904, 0.0058300645224639144, 0.0058231015068618188, 0.0058168157265487018, 0.0058111639652991282, 0.0058061023324403535, 0.0058015430453433646, 0.0057974184485229717, 0.0057936774162717303, 0.0057902756218621504, 0.0057872043655057825, 0.0057844165455890858, 0.0057818629159922382, 0.0057795004921224963, 0.0057772957941141416, 0.0057752435518314367, 0.0057732666754846639, 0.0057714635511235263, 0.0057698282694190091, 0.0057683387552708038, 0.0057669659270961435, 0.0057657011562991904, 0.0057645317801787426, 0.0057634539029929608, 0.0057624562215457028, 0.0057615198753568804, 0.0057606136616119531, 0.005759688441921265, 0.0057587763407527413, 0.0057578893920536079, 0.0057570024533659349, 0.0057561066112378715, 0.0057552542347660872, 0.0057544265999515207, 0.005753611215057919, 0.0057527684240893913, 0.005751935801428059, 0.005751168888263495, 0.0057504735973474353, 0.0057497854425494167, 0.0057491036800264451, 0.0057484333943171742, 0.0057477742902974256, 0.0057471440532557922, 0.0057465381906133383, 0.0057459640666125055, 0.005745406564118362, 0.0057448624265823449, 0.0057443210042058841, 0.0057438095915687461, 0.0057432778112560196, 0.0057427706118181581, 0.0057422424173198209, 0.005741651580340062, 0.0057409971671604039, 0.005740380278134425, 0.0057397361906215919, 0.0057391022087801462, 0.0057384665481792748, 0.0057378284052494897, 0.005737183071609254, 0.005736535901422121, 0.0057358740244843869, 0.0057351963826616382, 0.005734505551209682, 0.0057338147223247671, 0.0057330989494997816, 0.0057323887421914166, 0.0057316705087718011, 0.0057309275579107231], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097970358737712038, 0.0088900953371910448, 0.0082924899919390883, 0.0078798256221414703, 0.0075773883042705012, 0.0073415174582687108, 0.0071505456801622324, 0.0069913791482978929, 0.0068557648988111638, 0.0067384165977025538, 0.0066347241600465783, 0.0065419814969836293, 0.0064603996831099283, 0.0063884112541200862, 0.0063246595915610422, 0.0062681972176637677, 0.0062181495198765291, 0.0061737727986565689, 0.0061343928131549121, 0.0060993840253090103, 0.0060682181363583077, 0.0060405189517692944, 0.0060158669432446611, 0.0059939376516943256, 0.0059744106246471928, 0.0059570029291172392, 0.0059414827324860637, 0.0059276436416909415, 0.0059152829242001192, 0.00590422795073791, 0.0058943845511257387, 0.0058855743585715702, 0.0058776560247838826, 0.0058705280549784002, 0.0058641323251154755, 0.005858366599536694, 0.0058531931215538022, 0.0058485706077530345, 0.0058444105784316268, 0.0058406364483976235, 0.0058372240064648983, 0.0058341378195075717, 0.005831341399845846, 0.0058288102318161585, 0.0058264825619415142, 0.0058243281040050304, 0.005822312244403537, 0.0058203947036928917, 0.0058185891423758965, 0.0058169609048999722, 0.0058154756857403019, 0.0058141230720200393, 0.0058128840192956718, 0.0058117360058964774, 0.0058106866927422618, 0.005809708898577245, 0.0058087968878855886, 0.0058079341150878783, 0.0058070582423299256, 0.0058061763688458268, 0.0058053117249436733, 0.0058044552728391992, 0.0058035921642418005, 0.0058027460915770976, 0.0058019362178901935, 0.0058011287058896454, 0.005800303062649264, 0.0057994516886362849, 0.0057986715103874433, 0.0057979685919021182, 0.0057973082033761607, 0.0057966526250449943, 0.0057959959626095389, 0.0057953464119828079, 0.0057947221728791905, 0.0057941296958535218, 0.0057935651886270381, 0.0057930082772752467, 0.0057924673740518953, 0.0057919332602695663, 0.0057914088698172838, 0.0057909022215344545, 0.0057903963250428257, 0.0057898903269825086, 0.0057893485959486218, 0.005788711071180389, 0.005788068647794878, 0.0057874312207657885, 0.0057867936092897898, 0.0057861497137012864, 0.0057855160651188713, 0.005784874441936874, 0.0057842282880025842, 0.0057835777062564681, 0.0057829047317867104, 0.0057822357200962224, 0.0057815560053408009, 0.0057808565662546664, 0.0057801445864362304, 0.0057794274918312521, 0.0057787104803902816], 'acc': [0.55664661845298169, 0.59383822263669894, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822264767316, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.5938382226842539, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822262938279, 0.59383822268791198, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353]}
[2017-11-14 08:38:05,406 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-14 08:38:05,526 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-14 08:38:05,526 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-14 08:38:06,391 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:141]: done!
[2017-11-14 08:38:06,391 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_7L_FULLDS_UNDER_01 finished!
[2017-11-18 16:24:17,808 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_7L_FULLDS_UNDER_01 was already executed!
[2017-11-18 20:21:23,463 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_FULLDS_UNDER_01
[2017-11-18 20:21:23,463 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 20:21:23,463 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,17
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3550cd3eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f3550cd8400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:21:23,463 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 20:21:25,825 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:21:25,826 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:21:25,826 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 20:21:25,826 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f3550cd3eb8>, 'discard_decoder_function': True}
[2017-11-18 20:21:25,975 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 20:22:43,365 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 20:22:43,366 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010073535423280889, 0.009802977026031872, 0.0095793998220751325, 0.009394067929676354, 0.0092401699091484782, 0.0091115415496056847, 0.0090037729506932257, 0.0089131352169598693, 0.0088366139060634535, 0.008771948498228441, 0.0087169789103671326, 0.0086701242831624288, 0.0086300655054897119, 0.0085957448967882745, 0.0085662083059565765, 0.0085407511718935368, 0.0085187368266057203, 0.0084996543049768499, 0.0084830772946973745, 0.0084686184833178794, 0.0084560066091909167, 0.0084450010197269307, 0.0084353599369454725, 0.0084269026716029937, 0.0084194756646595072, 0.0084129300023929147, 0.0084071619520343782, 0.0084020723795839337, 0.0083975673980739834, 0.0083935986677214133, 0.008390070965670347, 0.0083869569974265867, 0.0083841968509849492, 0.0083817538820023657, 0.0083795844548844277, 0.0083776612956732652, 0.0083759476162715025, 0.0083744251903438115, 0.0083730797109134881, 0.0083718819294545145, 0.0083708181013433611, 0.0083698688272779726, 0.0083690255990567473, 0.0083682725242982883, 0.0083676008582909238, 0.0083670038206229667, 0.0083664733757706777, 0.0083659989156926965, 0.0083655778771127374, 0.0083652006473169081, 0.0083648620665522453, 0.0083645611809062114, 0.0083642912209198252, 0.0083640495449364815, 0.0083638314049566381, 0.0083636384894089071, 0.0083634649269564848, 0.0083633101706484456, 0.0083631674541062573, 0.0083630367619276745, 0.0083629225337250139, 0.0083628206009655169, 0.0083627280355107695, 0.00836264532475634, 0.0083625728123434898, 0.0083625039855173642, 0.0083624423395613681, 0.0083623856182173523, 0.0083623362197864145, 0.0083622891768725515, 0.0083622472232035838, 0.0083622063504301281, 0.0083621707212663196, 0.0083621377796235883, 0.0083621086224842413, 0.008362078951594366, 0.0083620523060482024, 0.0083620251149202005, 0.0083620024527375509, 0.0083619776291061487, 0.0083619573296282897, 0.0083619357527906918, 0.008361918436557066, 0.0083619009560327983, 0.008361883424509978, 0.0083618641545868053, 0.008361849403683095, 0.0083618337238527147, 0.0083618192731216966, 0.0083618022515844093, 0.0083617871115172406, 0.0083617741250265661, 0.0083617552576154656, 0.0083617429491659595, 0.0083617285100721951, 0.0083617146340161513, 0.0083617003102681078, 0.0083616879802554545, 0.0083616773975422297, 0.0083616637463590007, 0.0083616513523414523], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010229141996356992, 0.0099341658793268162, 0.0096881301534946628, 0.0094844541061229245, 0.009315443096943753, 0.0091746869208127711, 0.009056839708989203, 0.0089578902614314941, 0.0088745247409418929, 0.0088040171573136334, 0.0087442848852220464, 0.0086934183049424373, 0.0086499510220456252, 0.0086127373046841049, 0.0085807667315377558, 0.008553203579888426, 0.0085293878251884465, 0.0085087572014670553, 0.0084908417438281387, 0.0084752304599738943, 0.0084615987626673606, 0.0084496755284402762, 0.0084392504654097686, 0.0084300918256075413, 0.0084220465997192143, 0.008414962643793357, 0.0084087062135294894, 0.0084031832428326479, 0.0083982885318048175, 0.0083939583689281658, 0.0083901278328343022, 0.0083867209165926233, 0.0083836987998729337, 0.0083810154786894721, 0.0083786329126246829, 0.0083765156430604861, 0.0083746309919716967, 0.0083729495110688237, 0.0083714500966989309, 0.0083701181334877896, 0.0083689293024504317, 0.0083678688503489966, 0.0083669211666990359, 0.0083660739751783477, 0.0083653157126746969, 0.0083646373678105315, 0.0083640305948633129, 0.0083634895331425076, 0.0083630035565170364, 0.0083625701993312422, 0.0083621769090784035, 0.00836182288938455, 0.0083615091976043093, 0.0083612252329273266, 0.0083609667993150075, 0.0083607358596665699, 0.0083605276184766757, 0.0083603383850924026, 0.0083601698731495776, 0.0083600126417899944, 0.0083598733986052862, 0.0083597467350770647, 0.0083596319682887905, 0.008359525763220849, 0.0083594310278128046, 0.0083593453934622634, 0.0083592681328985424, 0.0083591956908174326, 0.0083591291824740045, 0.0083590701377430597, 0.0083590135059686509, 0.0083589617986466608, 0.0083589169010565706, 0.0083588715007100432, 0.0083588310024102393, 0.0083587921982555876, 0.0083587551481470353, 0.0083587228383297813, 0.0083586909226699146, 0.0083586603959347194, 0.0083586324372812264, 0.0083586063396724752, 0.0083585801972523265, 0.0083585559189634211, 0.0083585342951781969, 0.0083585124724280865, 0.0083584909344361115, 0.0083584711240263631, 0.0083584499293788521, 0.0083584311186519229, 0.0083584127370627051, 0.0083583962844212146, 0.0083583785580843596, 0.0083583609337162957, 0.0083583433646765883, 0.0083583288454982582, 0.0083583129601438998, 0.0083582968858843549, 0.0083582828768357636, 0.0083582664043035, 0.0083582525277457465], 'acc': [0.0084693752301460666, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889]}
[2017-11-18 20:22:43,366 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:95]: done!
[2017-11-18 20:22:43,366 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 20:22:43,366 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 20:22:43,366 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f3550cd8400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:22:43,396 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 20:26:20,051 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 20:26:20,052 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010073535423280889, 0.009802977026031872, 0.0095793998220751325, 0.009394067929676354, 0.0092401699091484782, 0.0091115415496056847, 0.0090037729506932257, 0.0089131352169598693, 0.0088366139060634535, 0.008771948498228441, 0.0087169789103671326, 0.0086701242831624288, 0.0086300655054897119, 0.0085957448967882745, 0.0085662083059565765, 0.0085407511718935368, 0.0085187368266057203, 0.0084996543049768499, 0.0084830772946973745, 0.0084686184833178794, 0.0084560066091909167, 0.0084450010197269307, 0.0084353599369454725, 0.0084269026716029937, 0.0084194756646595072, 0.0084129300023929147, 0.0084071619520343782, 0.0084020723795839337, 0.0083975673980739834, 0.0083935986677214133, 0.008390070965670347, 0.0083869569974265867, 0.0083841968509849492, 0.0083817538820023657, 0.0083795844548844277, 0.0083776612956732652, 0.0083759476162715025, 0.0083744251903438115, 0.0083730797109134881, 0.0083718819294545145, 0.0083708181013433611, 0.0083698688272779726, 0.0083690255990567473, 0.0083682725242982883, 0.0083676008582909238, 0.0083670038206229667, 0.0083664733757706777, 0.0083659989156926965, 0.0083655778771127374, 0.0083652006473169081, 0.0083648620665522453, 0.0083645611809062114, 0.0083642912209198252, 0.0083640495449364815, 0.0083638314049566381, 0.0083636384894089071, 0.0083634649269564848, 0.0083633101706484456, 0.0083631674541062573, 0.0083630367619276745, 0.0083629225337250139, 0.0083628206009655169, 0.0083627280355107695, 0.00836264532475634, 0.0083625728123434898, 0.0083625039855173642, 0.0083624423395613681, 0.0083623856182173523, 0.0083623362197864145, 0.0083622891768725515, 0.0083622472232035838, 0.0083622063504301281, 0.0083621707212663196, 0.0083621377796235883, 0.0083621086224842413, 0.008362078951594366, 0.0083620523060482024, 0.0083620251149202005, 0.0083620024527375509, 0.0083619776291061487, 0.0083619573296282897, 0.0083619357527906918, 0.008361918436557066, 0.0083619009560327983, 0.008361883424509978, 0.0083618641545868053, 0.008361849403683095, 0.0083618337238527147, 0.0083618192731216966, 0.0083618022515844093, 0.0083617871115172406, 0.0083617741250265661, 0.0083617552576154656, 0.0083617429491659595, 0.0083617285100721951, 0.0083617146340161513, 0.0083617003102681078, 0.0083616879802554545, 0.0083616773975422297, 0.0083616637463590007, 0.0083616513523414523], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010229141996356992, 0.0099341658793268162, 0.0096881301534946628, 0.0094844541061229245, 0.009315443096943753, 0.0091746869208127711, 0.009056839708989203, 0.0089578902614314941, 0.0088745247409418929, 0.0088040171573136334, 0.0087442848852220464, 0.0086934183049424373, 0.0086499510220456252, 0.0086127373046841049, 0.0085807667315377558, 0.008553203579888426, 0.0085293878251884465, 0.0085087572014670553, 0.0084908417438281387, 0.0084752304599738943, 0.0084615987626673606, 0.0084496755284402762, 0.0084392504654097686, 0.0084300918256075413, 0.0084220465997192143, 0.008414962643793357, 0.0084087062135294894, 0.0084031832428326479, 0.0083982885318048175, 0.0083939583689281658, 0.0083901278328343022, 0.0083867209165926233, 0.0083836987998729337, 0.0083810154786894721, 0.0083786329126246829, 0.0083765156430604861, 0.0083746309919716967, 0.0083729495110688237, 0.0083714500966989309, 0.0083701181334877896, 0.0083689293024504317, 0.0083678688503489966, 0.0083669211666990359, 0.0083660739751783477, 0.0083653157126746969, 0.0083646373678105315, 0.0083640305948633129, 0.0083634895331425076, 0.0083630035565170364, 0.0083625701993312422, 0.0083621769090784035, 0.00836182288938455, 0.0083615091976043093, 0.0083612252329273266, 0.0083609667993150075, 0.0083607358596665699, 0.0083605276184766757, 0.0083603383850924026, 0.0083601698731495776, 0.0083600126417899944, 0.0083598733986052862, 0.0083597467350770647, 0.0083596319682887905, 0.008359525763220849, 0.0083594310278128046, 0.0083593453934622634, 0.0083592681328985424, 0.0083591956908174326, 0.0083591291824740045, 0.0083590701377430597, 0.0083590135059686509, 0.0083589617986466608, 0.0083589169010565706, 0.0083588715007100432, 0.0083588310024102393, 0.0083587921982555876, 0.0083587551481470353, 0.0083587228383297813, 0.0083586909226699146, 0.0083586603959347194, 0.0083586324372812264, 0.0083586063396724752, 0.0083585801972523265, 0.0083585559189634211, 0.0083585342951781969, 0.0083585124724280865, 0.0083584909344361115, 0.0083584711240263631, 0.0083584499293788521, 0.0083584311186519229, 0.0083584127370627051, 0.0083583962844212146, 0.0083583785580843596, 0.0083583609337162957, 0.0083583433646765883, 0.0083583288454982582, 0.0083583129601438998, 0.0083582968858843549, 0.0083582828768357636, 0.0083582664043035, 0.0083582525277457465], 'acc': [0.0084693752301460666, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889]}
[2017-11-18 20:26:20,052 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 20:26:20,142 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 20:26:20,142 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 20:26:21,026 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:141]: done!
[2017-11-18 20:26:21,026 AE_UNIGRAMA_7L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_7L_FULLDS_UNDER_01 finished!
