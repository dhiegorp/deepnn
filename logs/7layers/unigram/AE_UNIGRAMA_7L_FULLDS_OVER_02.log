[2018-07-21 00:52:16,566 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:145]: >> Initializing execution of experiment AE_UNIGRAMA_7L_FULLDS_OVER_02
[2018-07-21 00:52:16,567 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:146]: >> Printing header log
[2018-07-21 00:52:16,567 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_FULLDS_OVER_02
	layers = 96,134,121,109,96,84,71,59
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiego/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiego/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f13dbef7668>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f13dbef7e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2018-07-21 00:52:16,567 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:148]: >> Loading dataset... 
[2018-07-21 00:52:18,532 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2018-07-21 00:52:18,532 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-07-21 00:52:18,532 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:57]: =======================================
[2018-07-21 00:52:18,532 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f13dbef7668>, 'discard_decoder_function': True}
[2018-07-21 00:52:18,863 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-07-21 00:56:09,908 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:85]: trained and evaluated!
[2018-07-21 00:56:09,909 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:88]: Training history: 
{'val_loss': [0.009511643724268914, 0.008744331173604243, 0.008152933960875653, 0.007702890957936026, 0.007355913810790658, 0.007087769916603525, 0.0068803160812107465, 0.006718453072738457, 0.006591470389962689, 0.0064911181413497025, 0.006411231655315337, 0.006347120794796552, 0.006295204935619352, 0.006252787797959937, 0.006218047838422611, 0.006189583770270866, 0.006166049511504223, 0.006146544877587599, 0.006130306955576846, 0.006116759062387687, 0.006105323158596799, 0.006095709556163327, 0.006087537552769139, 0.006080574317086037, 0.006074638512890508, 0.006069581829971856, 0.006065224419535849, 0.006061489374822814, 0.006058231481730538, 0.00605537593119991, 0.0060528838966460745, 0.006050695885261689, 0.006048788524050374, 0.006047125499731821, 0.006045648807184671, 0.006044336829696621, 0.006043171992960828, 0.006042128564955551, 0.006041197822960104, 0.006040349756293916, 0.006039592083108853, 0.006038893407121032, 0.006038253777104237, 0.0060376713856902745, 0.006037124391208454, 0.006036624920618464, 0.006036153477327388, 0.006035701819335804, 0.006035259433668443, 0.006034834473419528, 0.006034375071520097, 0.006033817430491292, 0.006033356345211762, 0.006032827805959781, 0.006032449252255198, 0.006032077513446224, 0.006031722791211592, 0.0060313798113938635, 0.00603105331463373, 0.006030734872821279, 0.006030419215735203, 0.006030102498375512, 0.006029779820517116, 0.006029454205621229, 0.006029126139543197, 0.0060288022647590235, 0.006028482189623777, 0.006028164826653205, 0.006027846073544215, 0.00602753432435064, 0.006027223267573665, 0.006026921100032785, 0.006026618379551215, 0.006026322734263239, 0.0060260189665143965, 0.006025701412384819, 0.006025392235623305, 0.006025077344542345, 0.006024758456406984, 0.006024429950338078, 0.006024103919324801, 0.006023704856500654, 0.0060232895385721776, 0.006022914534657838, 0.006022570823832322, 0.006022231692437306, 0.0060218925674598925, 0.0060215611503661795, 0.006021227531264461, 0.0060208956630560286, 0.006020555234620624, 0.0060202161952968205, 0.00601987868755541, 0.006019534380235071, 0.00601918483572269, 0.006018838057282851, 0.006018498947108709, 0.006018152509999791, 0.006017809239250718, 0.006017463573366568, 0.006017123416181858], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009961747507560952, 0.009120354543888043, 0.00844550005896345, 0.007930789267164392, 0.00753751683720046, 0.0072335096861359145, 0.006998849066269973, 0.006816812397801716, 0.006674434180742186, 0.006562475368611005, 0.006473716246840964, 0.006402861605860989, 0.006345777609582743, 0.006299442775162035, 0.0062614558785317005, 0.006230387504267315, 0.006204845699958016, 0.006183710061797898, 0.00616615062870558, 0.0061515135276978975, 0.006139260570013287, 0.006128915205823764, 0.006120192369658098, 0.0061127637146945945, 0.006106436632633505, 0.0061010300940056075, 0.0060964176503087945, 0.00609244069491943, 0.0060890200773645676, 0.006086023940109297, 0.006083401948809386, 0.006081110216931882, 0.006079102782616023, 0.0060773532459476, 0.006075818935045439, 0.006074445398289601, 0.006073234943295547, 0.006072155002123233, 0.006071186913512314, 0.006070321928323362, 0.006069535262253064, 0.006068828126409438, 0.006068175371139108, 0.006067580374329733, 0.006067037351767377, 0.006066520414753561, 0.006066037545318331, 0.006065586699398969, 0.0060651463783849445, 0.006064729858166958, 0.006064311020445283, 0.006063803414090218, 0.0060632867073063855, 0.006062813544968502, 0.006062371216415335, 0.00606201226460997, 0.006061663258934173, 0.006061327000328869, 0.006061004982145287, 0.006060692795376383, 0.006060381097017409, 0.006060074637647994, 0.006059760758791604, 0.006059443306740741, 0.006059128052391669, 0.006058805326085135, 0.006058486536322627, 0.006058169851609775, 0.0060578577459472135, 0.006057553861346917, 0.006057248808563806, 0.006056942231621631, 0.006056644447258503, 0.006056347986660615, 0.006056046441912549, 0.006055739699842664, 0.0060554356738349744, 0.006055127735175051, 0.006054816657602531, 0.006054498620545742, 0.006054177577181511, 0.006053822731220373, 0.006053396482871119, 0.006052990499047106, 0.0060526310963842185, 0.006052296454818743, 0.006051963355016808, 0.006051634840552476, 0.006051309854128276, 0.0060509787164825125, 0.006050649769851126, 0.006050319362676856, 0.006049983261425857, 0.0060496441323762366, 0.006049304110528125, 0.006048965883993753, 0.006048629075362849, 0.006048286582829233, 0.006047953543957079, 0.0060476157323282285, 0.006047281586431672], 'acc': [0.49736099171758474, 0.5938382226366989, 0.5938382226513312, 0.5938382226732797, 0.593838222687912, 0.593838222687912, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226366989, 0.5938382226659635, 0.5938382226842539, 0.5938382226659635, 0.5938382226001182, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382227244927, 0.5938382226842539, 0.5938382226842539, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226366989, 0.5938382226513312, 0.593838222687912, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226659635, 0.5938382227025443, 0.5938382226842539, 0.5938382226366989, 0.5938382226001182, 0.593838222687912, 0.5938382227244927, 0.593838222687912, 0.5938382226001182, 0.5938382226842539, 0.5938382227244927, 0.5938382227025443, 0.5938382227025443, 0.5938382227025443, 0.5938382226659635, 0.5938382226366989, 0.5938382226513312, 0.5938382227025443, 0.5938382226293828, 0.5938382226513312, 0.5938382227025443, 0.593838222687912, 0.5938382227025443, 0.5938382226366989, 0.5938382227025443, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382227244927, 0.593838222687912, 0.5938382226732797, 0.593838222687912, 0.593838222687912, 0.5938382227025443, 0.5938382226842539, 0.593838222687912, 0.5938382226732797, 0.5938382226842539, 0.5938382226001182, 0.5938382226293828, 0.5938382227025443, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382226842539, 0.5938382227025443, 0.5938382227025443, 0.5938382226842539, 0.5938382226513312, 0.5938382226476732, 0.5938382226842539, 0.5938382227025443, 0.5938382226842539, 0.5938382226732797, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382226513312, 0.5938382226293828, 0.5938382227244927, 0.5938382226732797, 0.5938382226366989]}
[2018-07-21 00:56:09,909 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:92]: done!
[2018-07-21 00:56:09,909 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:152]: >> Executing classifier part ... 
[2018-07-21 00:56:09,909 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:97]: =======================================
[2018-07-21 00:56:09,909 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f13dbef7e48>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-07-21 00:56:09,961 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:110]: training ... 
[2018-07-21 01:03:26,082 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:122]: trained!
[2018-07-21 01:03:26,083 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:125]: Training history: 
{'val_loss': [0.009511643724268914, 0.008744331173604243, 0.008152933960875653, 0.007702890957936026, 0.007355913810790658, 0.007087769916603525, 0.0068803160812107465, 0.006718453072738457, 0.006591470389962689, 0.0064911181413497025, 0.006411231655315337, 0.006347120794796552, 0.006295204935619352, 0.006252787797959937, 0.006218047838422611, 0.006189583770270866, 0.006166049511504223, 0.006146544877587599, 0.006130306955576846, 0.006116759062387687, 0.006105323158596799, 0.006095709556163327, 0.006087537552769139, 0.006080574317086037, 0.006074638512890508, 0.006069581829971856, 0.006065224419535849, 0.006061489374822814, 0.006058231481730538, 0.00605537593119991, 0.0060528838966460745, 0.006050695885261689, 0.006048788524050374, 0.006047125499731821, 0.006045648807184671, 0.006044336829696621, 0.006043171992960828, 0.006042128564955551, 0.006041197822960104, 0.006040349756293916, 0.006039592083108853, 0.006038893407121032, 0.006038253777104237, 0.0060376713856902745, 0.006037124391208454, 0.006036624920618464, 0.006036153477327388, 0.006035701819335804, 0.006035259433668443, 0.006034834473419528, 0.006034375071520097, 0.006033817430491292, 0.006033356345211762, 0.006032827805959781, 0.006032449252255198, 0.006032077513446224, 0.006031722791211592, 0.0060313798113938635, 0.00603105331463373, 0.006030734872821279, 0.006030419215735203, 0.006030102498375512, 0.006029779820517116, 0.006029454205621229, 0.006029126139543197, 0.0060288022647590235, 0.006028482189623777, 0.006028164826653205, 0.006027846073544215, 0.00602753432435064, 0.006027223267573665, 0.006026921100032785, 0.006026618379551215, 0.006026322734263239, 0.0060260189665143965, 0.006025701412384819, 0.006025392235623305, 0.006025077344542345, 0.006024758456406984, 0.006024429950338078, 0.006024103919324801, 0.006023704856500654, 0.0060232895385721776, 0.006022914534657838, 0.006022570823832322, 0.006022231692437306, 0.0060218925674598925, 0.0060215611503661795, 0.006021227531264461, 0.0060208956630560286, 0.006020555234620624, 0.0060202161952968205, 0.00601987868755541, 0.006019534380235071, 0.00601918483572269, 0.006018838057282851, 0.006018498947108709, 0.006018152509999791, 0.006017809239250718, 0.006017463573366568, 0.006017123416181858], 'val_acc': [0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607, 0.6030871003307607], 'loss': [0.009961747507560952, 0.009120354543888043, 0.00844550005896345, 0.007930789267164392, 0.00753751683720046, 0.0072335096861359145, 0.006998849066269973, 0.006816812397801716, 0.006674434180742186, 0.006562475368611005, 0.006473716246840964, 0.006402861605860989, 0.006345777609582743, 0.006299442775162035, 0.0062614558785317005, 0.006230387504267315, 0.006204845699958016, 0.006183710061797898, 0.00616615062870558, 0.0061515135276978975, 0.006139260570013287, 0.006128915205823764, 0.006120192369658098, 0.0061127637146945945, 0.006106436632633505, 0.0061010300940056075, 0.0060964176503087945, 0.00609244069491943, 0.0060890200773645676, 0.006086023940109297, 0.006083401948809386, 0.006081110216931882, 0.006079102782616023, 0.0060773532459476, 0.006075818935045439, 0.006074445398289601, 0.006073234943295547, 0.006072155002123233, 0.006071186913512314, 0.006070321928323362, 0.006069535262253064, 0.006068828126409438, 0.006068175371139108, 0.006067580374329733, 0.006067037351767377, 0.006066520414753561, 0.006066037545318331, 0.006065586699398969, 0.0060651463783849445, 0.006064729858166958, 0.006064311020445283, 0.006063803414090218, 0.0060632867073063855, 0.006062813544968502, 0.006062371216415335, 0.00606201226460997, 0.006061663258934173, 0.006061327000328869, 0.006061004982145287, 0.006060692795376383, 0.006060381097017409, 0.006060074637647994, 0.006059760758791604, 0.006059443306740741, 0.006059128052391669, 0.006058805326085135, 0.006058486536322627, 0.006058169851609775, 0.0060578577459472135, 0.006057553861346917, 0.006057248808563806, 0.006056942231621631, 0.006056644447258503, 0.006056347986660615, 0.006056046441912549, 0.006055739699842664, 0.0060554356738349744, 0.006055127735175051, 0.006054816657602531, 0.006054498620545742, 0.006054177577181511, 0.006053822731220373, 0.006053396482871119, 0.006052990499047106, 0.0060526310963842185, 0.006052296454818743, 0.006051963355016808, 0.006051634840552476, 0.006051309854128276, 0.0060509787164825125, 0.006050649769851126, 0.006050319362676856, 0.006049983261425857, 0.0060496441323762366, 0.006049304110528125, 0.006048965883993753, 0.006048629075362849, 0.006048286582829233, 0.006047953543957079, 0.0060476157323282285, 0.006047281586431672], 'acc': [0.49736099171758474, 0.5938382226366989, 0.5938382226513312, 0.5938382226732797, 0.593838222687912, 0.593838222687912, 0.5938382226513312, 0.5938382226001182, 0.5938382226513312, 0.5938382226366989, 0.5938382226659635, 0.5938382226842539, 0.5938382226659635, 0.5938382226001182, 0.5938382226001182, 0.5938382226366989, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382227244927, 0.5938382226842539, 0.5938382226842539, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226366989, 0.5938382226513312, 0.593838222687912, 0.5938382227025443, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226513312, 0.5938382226659635, 0.5938382227025443, 0.5938382226842539, 0.5938382226366989, 0.5938382226001182, 0.593838222687912, 0.5938382227244927, 0.593838222687912, 0.5938382226001182, 0.5938382226842539, 0.5938382227244927, 0.5938382227025443, 0.5938382227025443, 0.5938382227025443, 0.5938382226659635, 0.5938382226366989, 0.5938382226513312, 0.5938382227025443, 0.5938382226293828, 0.5938382226513312, 0.5938382227025443, 0.593838222687912, 0.5938382227025443, 0.5938382226366989, 0.5938382227025443, 0.5938382226001182, 0.5938382226513312, 0.5938382226513312, 0.593838222687912, 0.5938382227244927, 0.593838222687912, 0.5938382226732797, 0.593838222687912, 0.593838222687912, 0.5938382227025443, 0.5938382226842539, 0.593838222687912, 0.5938382226732797, 0.5938382226842539, 0.5938382226001182, 0.5938382226293828, 0.5938382227025443, 0.5938382226513312, 0.5938382227025443, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382226842539, 0.5938382227025443, 0.5938382227025443, 0.5938382226842539, 0.5938382226513312, 0.5938382226476732, 0.5938382226842539, 0.5938382227025443, 0.5938382226842539, 0.5938382226732797, 0.5938382226513312, 0.5938382226001182, 0.5938382227025443, 0.5938382226001182, 0.5938382227025443, 0.5938382226513312, 0.5938382226293828, 0.5938382227244927, 0.5938382226732797, 0.5938382226366989]}
[2018-07-21 01:03:26,083 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:129]: evaluating model ... 
[2018-07-21 01:03:26,242 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:133]: evaluated! 
[2018-07-21 01:03:26,243 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:135]: generating reports ... 
[2018-07-21 01:03:27,439 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:138]: done!
[2018-07-21 01:03:27,440 AE_UNIGRAMA_7L_FULLDS_OVER_02.py:154]: >> experiment AE_UNIGRAMA_7L_FULLDS_OVER_02 finished!
