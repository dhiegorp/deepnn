[2017-11-14 07:49:59,521 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_FULLDS_OVER_05
[2017-11-14 07:49:59,521 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-14 07:49:59,521 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0fb1297eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0fb129c400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 07:49:59,521 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-14 07:50:01,694 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-14 07:50:01,694 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-14 07:50:01,694 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-14 07:50:01,695 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0fb1297eb8>, 'discard_decoder_function': True}
[2017-11-14 07:50:01,844 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-14 07:54:46,659 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-14 07:54:46,660 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0098443302674679715, 0.0094352214381876395, 0.0091420507855310851, 0.0089312611772065786, 0.0087781307105767696, 0.0086652589551159797, 0.0085804571148770693, 0.0085156847243989617, 0.0084652813970878347, 0.0084255288547751706, 0.0083936146915353244, 0.0083677056117153741, 0.0083464109970312131, 0.0083288598517472796, 0.0083141125333370501, 0.0083016851784792154, 0.0082910690481956938, 0.0082819575289156851, 0.0082741063372264532, 0.0082661833717477141, 0.0082568872815154785, 0.0082492117860033781, 0.0082427348304253776, 0.008237212068048394, 0.0082324784815870026, 0.0082281429662161426, 0.0082213345778854793, 0.0081955420684366488, 0.0081689094711137542, 0.0081480010106299832, 0.008131438857700863, 0.0081179346872143829, 0.0081063449456028232, 0.0080970719765402158, 0.0080893208597571428, 0.0080826304718107263, 0.0080767652777648941, 0.0080718378416950193, 0.0080675246982600084, 0.0080637897534904471, 0.0080606125939318429, 0.0080578387805624561, 0.0080553356969495643, 0.0080530477252346282, 0.0080509415513827978, 0.008049008631253891, 0.0080472704133334426, 0.0080456739190236173, 0.0080441933878940813, 0.0080428019392576912, 0.008041491580374734, 0.008040238957330503, 0.0080390103888321081, 0.0080378200473432936, 0.0080366767357620012, 0.0080355741655216504, 0.0080345059173076924, 0.0080334618054426193, 0.0080324359948704769, 0.0080314345112928176, 0.0080304380669883185, 0.0080294466171193235, 0.0080284352449564011, 0.0080274097448251175, 0.0080263939878134245, 0.0080254111238418149, 0.0080244640546937463, 0.0080235320362798089, 0.0080225685722947956, 0.0080212647449916571, 0.0080165490552574908, 0.0080122859136792547, 0.008008808789871296, 0.0080057600446699819, 0.0080030555431263844, 0.0080006080424602707, 0.0079981527184791665, 0.0079960683939135808, 0.0079943215514189925, 0.0079927137176321744, 0.0079911829231499275, 0.007989716604529979, 0.0079883097221568992, 0.0079869396631352292, 0.007985608690910832, 0.0079843010144148713, 0.0079830140905651215, 0.0079817412618256069, 0.0079804973188036064, 0.0079792690973691932, 0.0079780434559823966, 0.0079768456457725602, 0.0079756485981451204, 0.007974455747459027, 0.0079732499907162208, 0.0079720397912806471, 0.0079708249612448854, 0.0079696081689627721, 0.0079683991058708027, 0.0079671894992506265, 0.0079659621413688975], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010106668364367735, 0.0096323415260920649, 0.0092861321509548362, 0.0090381042895548488, 0.0088592194543395345, 0.008728611791933719, 0.0086316472909154819, 0.0085583355954977521, 0.0085018776597006341, 0.0084578204459685759, 0.0084228069569841912, 0.0083946252065228658, 0.008371632467766503, 0.0083527277507609472, 0.0083370571001510005, 0.008323899314458625, 0.0083127568734367822, 0.0083032502626790555, 0.0082950839848039606, 0.0082878698564574759, 0.0082791412578548402, 0.0082710202983625677, 0.0082642564469335919, 0.0082585479971787317, 0.0082536825015811707, 0.0082494698503051585, 0.0082439769360524787, 0.0082301198173580919, 0.0081997839743103429, 0.0081751799527329354, 0.0081557114442257824, 0.0081400462258545414, 0.0081268142531801396, 0.0081159702080483807, 0.008107008953760873, 0.0080994123496834023, 0.0080927622184336617, 0.0080870850560645965, 0.0080822093172904924, 0.0080779766131430682, 0.0080743146019095994, 0.0080711731675299405, 0.0080683776170035453, 0.0080658385728564642, 0.0080635176814486242, 0.0080613991530499862, 0.0080594790880973571, 0.0080577330583779892, 0.0080561142192351696, 0.0080546121919721752, 0.0080531995971685425, 0.0080518697632989498, 0.0080505895827432429, 0.0080493389269536194, 0.0080481352040145653, 0.0080469774668280643, 0.0080458662628476365, 0.0080447795297193744, 0.0080437240407659153, 0.0080426848819656529, 0.0080416647761253554, 0.0080406598451730118, 0.0080396484137102691, 0.0080386055050420298, 0.0080375732121022257, 0.0080365578826766988, 0.008035596802934036, 0.0080346505617080646, 0.0080337052999883505, 0.008032595564552842, 0.0080296718171368204, 0.0080247710491971273, 0.0080208261041774323, 0.0080174902799592194, 0.0080145645042559235, 0.0080119556178889478, 0.0080094780318866084, 0.0080071296235376139, 0.0080052271863253355, 0.0080035387793752702, 0.0080019520094742353, 0.0080004379582389352, 0.0079989914464664493, 0.0079976020869436011, 0.0079962475357591607, 0.0079949284467365576, 0.0079936357040716836, 0.007992358268614129, 0.0079911075961345453, 0.007989877520779079, 0.0079886543109411248, 0.0079874452810523716, 0.0079862479549402017, 0.0079850600687145622, 0.0079838677325000298, 0.0079826670550783886, 0.0079814586294576027, 0.0079802535449151127, 0.0079790504383042363, 0.0079778429725275626, 0.0079766239815911612], 'acc': [0.0066282067018534428, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373]}
[2017-11-14 07:54:46,660 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:95]: done!
[2017-11-14 07:54:46,661 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-14 07:54:46,661 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-14 07:54:46,661 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0fb129c400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 07:54:46,695 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-14 08:01:17,758 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:125]: trained!
[2017-11-14 08:01:17,759 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0098443302674679715, 0.0094352214381876395, 0.0091420507855310851, 0.0089312611772065786, 0.0087781307105767696, 0.0086652589551159797, 0.0085804571148770693, 0.0085156847243989617, 0.0084652813970878347, 0.0084255288547751706, 0.0083936146915353244, 0.0083677056117153741, 0.0083464109970312131, 0.0083288598517472796, 0.0083141125333370501, 0.0083016851784792154, 0.0082910690481956938, 0.0082819575289156851, 0.0082741063372264532, 0.0082661833717477141, 0.0082568872815154785, 0.0082492117860033781, 0.0082427348304253776, 0.008237212068048394, 0.0082324784815870026, 0.0082281429662161426, 0.0082213345778854793, 0.0081955420684366488, 0.0081689094711137542, 0.0081480010106299832, 0.008131438857700863, 0.0081179346872143829, 0.0081063449456028232, 0.0080970719765402158, 0.0080893208597571428, 0.0080826304718107263, 0.0080767652777648941, 0.0080718378416950193, 0.0080675246982600084, 0.0080637897534904471, 0.0080606125939318429, 0.0080578387805624561, 0.0080553356969495643, 0.0080530477252346282, 0.0080509415513827978, 0.008049008631253891, 0.0080472704133334426, 0.0080456739190236173, 0.0080441933878940813, 0.0080428019392576912, 0.008041491580374734, 0.008040238957330503, 0.0080390103888321081, 0.0080378200473432936, 0.0080366767357620012, 0.0080355741655216504, 0.0080345059173076924, 0.0080334618054426193, 0.0080324359948704769, 0.0080314345112928176, 0.0080304380669883185, 0.0080294466171193235, 0.0080284352449564011, 0.0080274097448251175, 0.0080263939878134245, 0.0080254111238418149, 0.0080244640546937463, 0.0080235320362798089, 0.0080225685722947956, 0.0080212647449916571, 0.0080165490552574908, 0.0080122859136792547, 0.008008808789871296, 0.0080057600446699819, 0.0080030555431263844, 0.0080006080424602707, 0.0079981527184791665, 0.0079960683939135808, 0.0079943215514189925, 0.0079927137176321744, 0.0079911829231499275, 0.007989716604529979, 0.0079883097221568992, 0.0079869396631352292, 0.007985608690910832, 0.0079843010144148713, 0.0079830140905651215, 0.0079817412618256069, 0.0079804973188036064, 0.0079792690973691932, 0.0079780434559823966, 0.0079768456457725602, 0.0079756485981451204, 0.007974455747459027, 0.0079732499907162208, 0.0079720397912806471, 0.0079708249612448854, 0.0079696081689627721, 0.0079683991058708027, 0.0079671894992506265, 0.0079659621413688975], 'val_acc': [0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010106668364367735, 0.0096323415260920649, 0.0092861321509548362, 0.0090381042895548488, 0.0088592194543395345, 0.008728611791933719, 0.0086316472909154819, 0.0085583355954977521, 0.0085018776597006341, 0.0084578204459685759, 0.0084228069569841912, 0.0083946252065228658, 0.008371632467766503, 0.0083527277507609472, 0.0083370571001510005, 0.008323899314458625, 0.0083127568734367822, 0.0083032502626790555, 0.0082950839848039606, 0.0082878698564574759, 0.0082791412578548402, 0.0082710202983625677, 0.0082642564469335919, 0.0082585479971787317, 0.0082536825015811707, 0.0082494698503051585, 0.0082439769360524787, 0.0082301198173580919, 0.0081997839743103429, 0.0081751799527329354, 0.0081557114442257824, 0.0081400462258545414, 0.0081268142531801396, 0.0081159702080483807, 0.008107008953760873, 0.0080994123496834023, 0.0080927622184336617, 0.0080870850560645965, 0.0080822093172904924, 0.0080779766131430682, 0.0080743146019095994, 0.0080711731675299405, 0.0080683776170035453, 0.0080658385728564642, 0.0080635176814486242, 0.0080613991530499862, 0.0080594790880973571, 0.0080577330583779892, 0.0080561142192351696, 0.0080546121919721752, 0.0080531995971685425, 0.0080518697632989498, 0.0080505895827432429, 0.0080493389269536194, 0.0080481352040145653, 0.0080469774668280643, 0.0080458662628476365, 0.0080447795297193744, 0.0080437240407659153, 0.0080426848819656529, 0.0080416647761253554, 0.0080406598451730118, 0.0080396484137102691, 0.0080386055050420298, 0.0080375732121022257, 0.0080365578826766988, 0.008035596802934036, 0.0080346505617080646, 0.0080337052999883505, 0.008032595564552842, 0.0080296718171368204, 0.0080247710491971273, 0.0080208261041774323, 0.0080174902799592194, 0.0080145645042559235, 0.0080119556178889478, 0.0080094780318866084, 0.0080071296235376139, 0.0080052271863253355, 0.0080035387793752702, 0.0080019520094742353, 0.0080004379582389352, 0.0079989914464664493, 0.0079976020869436011, 0.0079962475357591607, 0.0079949284467365576, 0.0079936357040716836, 0.007992358268614129, 0.0079911075961345453, 0.007989877520779079, 0.0079886543109411248, 0.0079874452810523716, 0.0079862479549402017, 0.0079850600687145622, 0.0079838677325000298, 0.0079826670550783886, 0.0079814586294576027, 0.0079802535449151127, 0.0079790504383042363, 0.0079778429725275626, 0.0079766239815911612], 'acc': [0.0066282067018534428, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373]}
[2017-11-14 08:01:17,760 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-14 08:01:17,965 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-14 08:01:17,965 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-14 08:01:18,817 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:141]: done!
[2017-11-14 08:01:18,817 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_7L_FULLDS_OVER_05 finished!
[2017-11-18 16:23:58,690 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_7L_FULLDS_OVER_05 was already executed!
[2017-11-18 19:40:13,285 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_FULLDS_OVER_05
[2017-11-18 19:40:13,285 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 19:40:13,286 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,74
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f018bc4beb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f018bc50400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:40:13,286 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 19:40:15,645 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:40:15,646 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:40:15,646 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 19:40:15,646 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f018bc4beb8>, 'discard_decoder_function': True}
[2017-11-18 19:40:15,794 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 19:43:38,340 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 19:43:38,342 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0093965729375433855, 0.0086221581219515127, 0.0080075140945607901, 0.007520026413197412, 0.0071315023586364821, 0.0068197740951757664, 0.0065684134398341643, 0.0063645914186699912, 0.0061981572234953144, 0.0060618101331333125, 0.0059493264970285785, 0.0058561987635494372, 0.0057788711663805158, 0.0057142680654290604, 0.0056600551549975033, 0.0056143945071213727, 0.0055757682856572097, 0.0055430232527029508, 0.0055150549868392138, 0.005491142750925459, 0.0054706448802224082, 0.0054529814247434869, 0.005437760212459012, 0.0054246029052958684, 0.005413192741313415, 0.005402421514075475, 0.0053913504858520084, 0.0053818897617647467, 0.0053737558080831551, 0.005366716910655398, 0.0053606456256369232, 0.0053554104127842787, 0.0053508486671462923, 0.0053468587093304419, 0.0053433479918512687, 0.0053402500926869149, 0.0053375143241527452, 0.0053351032755583061, 0.00533296535493589, 0.0053310784230947228, 0.0053293921169953254, 0.0053278834084805292, 0.0053265068819695035, 0.0053252655728174203, 0.0053241546222141225, 0.0053230783180256659, 0.0053220220671358108, 0.0053210251974725722, 0.0053199863993829387, 0.0053189901698542262, 0.0053181752684200645, 0.005317436447243854, 0.0053167245274622545, 0.0053160505732798655, 0.0053154127976081196, 0.0053147699078767447, 0.0053141175796480103, 0.0053135108141771402, 0.0053129381338803206, 0.0053124060391050373, 0.0053118938769774159, 0.0053114066744488157, 0.0053109577406014324, 0.0053105210511130924, 0.0053100993510921653, 0.0053096765569982472, 0.0053092585059409244, 0.0053088423609973174, 0.0053084093501646916, 0.0053079262156264006, 0.0053074444031143662, 0.0053069747684750049, 0.0053065213442734559, 0.0053061086343733467, 0.0053056942244073682, 0.0053052553603783635, 0.0053048039727817946, 0.0053044063064281019, 0.0053040219002116838, 0.0053036539535216498, 0.0053032859465917135, 0.0053029259371933021, 0.0053025634541939183, 0.0053021777714734424, 0.0053017666940404478, 0.0053013251565235233, 0.0053009404384971584, 0.0053005561116023156, 0.0053001674486324877, 0.0052997759742390545, 0.0052993815140343469, 0.0052989775051206396, 0.0052985776013337715, 0.0052981629014632655, 0.0052977366358738631, 0.0052972928592124021, 0.0052968519194738217, 0.0052964058009006059, 0.0052959681980589797, 0.0052955370468766218, 0.0052951037732645381], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098718948387011025, 0.0089995653932218884, 0.0083091712803813646, 0.007762668538235957, 0.007328393051922742, 0.0069813304070904126, 0.0067023811906455439, 0.0064769728453099411, 0.006293822225305337, 0.006144095162208426, 0.0060211344246780107, 0.0059195637823086737, 0.0058354963039780657, 0.0057655025110777223, 0.0057069517026640633, 0.0056577882434195636, 0.0056163404242408682, 0.0055812471252443697, 0.0055514648811631267, 0.0055260018356843117, 0.005504230223721842, 0.0054855379486888397, 0.0054694316388219063, 0.0054555756556734624, 0.0054435730143367325, 0.0054330315152934221, 0.0054218906395268086, 0.0054117359890980569, 0.005403051353962224, 0.0053955534145778321, 0.0053891011142132251, 0.0053835269688441477, 0.0053787105997407728, 0.0053745079353475509, 0.0053708380926937704, 0.0053675985319293672, 0.0053647477280934289, 0.00536222159465846, 0.0053599936539190408, 0.0053580290297480931, 0.0053562903647017589, 0.0053547392050002094, 0.0053533376704380641, 0.0053520654847728152, 0.0053509226221693205, 0.0053498774309777165, 0.0053488350159778862, 0.0053478373679635028, 0.0053468640956913817, 0.0053458492545614697, 0.0053449766422898892, 0.0053442303596901919, 0.0053435342117839502, 0.0053428694959288658, 0.005342242163695725, 0.005341619628625489, 0.005340983605724936, 0.0053403714423210643, 0.0053397892037278759, 0.0053392505912585528, 0.0053387371207835139, 0.0053382437382745269, 0.0053377925973086982, 0.0053373554782518741, 0.0053369399081040882, 0.0053365263392081306, 0.0053361189593719317, 0.0053357170841928578, 0.0053353020499527963, 0.0053348638469059989, 0.0053343895565097915, 0.0053339317016650144, 0.0053334812378999872, 0.005333057252583426, 0.0053326555926019401, 0.0053322357078711248, 0.0053317943639112231, 0.0053313771832967094, 0.0053310009833332462, 0.0053306272490825941, 0.0053302644258926323, 0.0053299108648868637, 0.0053295530765202492, 0.0053291935335359605, 0.0053287931255871857, 0.0053283638016557279, 0.0053279556735149301, 0.0053275846799041536, 0.0053272048749667053, 0.0053268256832137784, 0.0053264370579759485, 0.0053260433310977785, 0.0053256557422949706, 0.0053252526604661557, 0.0053248423057590819, 0.0053244138702249963, 0.0053239742982586179, 0.0053235348349484441, 0.0053231040889410294, 0.0053226719320605062, 0.0053222475839088089], 'acc': [0.57935436355843783, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822264767316, 0.59383822266596353, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822262938279, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124]}
[2017-11-18 19:43:38,342 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:95]: done!
[2017-11-18 19:43:38,342 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 19:43:38,342 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 19:43:38,342 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f018bc50400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:43:38,410 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 19:51:09,331 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:125]: trained!
[2017-11-18 19:51:09,334 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0093965729375433855, 0.0086221581219515127, 0.0080075140945607901, 0.007520026413197412, 0.0071315023586364821, 0.0068197740951757664, 0.0065684134398341643, 0.0063645914186699912, 0.0061981572234953144, 0.0060618101331333125, 0.0059493264970285785, 0.0058561987635494372, 0.0057788711663805158, 0.0057142680654290604, 0.0056600551549975033, 0.0056143945071213727, 0.0055757682856572097, 0.0055430232527029508, 0.0055150549868392138, 0.005491142750925459, 0.0054706448802224082, 0.0054529814247434869, 0.005437760212459012, 0.0054246029052958684, 0.005413192741313415, 0.005402421514075475, 0.0053913504858520084, 0.0053818897617647467, 0.0053737558080831551, 0.005366716910655398, 0.0053606456256369232, 0.0053554104127842787, 0.0053508486671462923, 0.0053468587093304419, 0.0053433479918512687, 0.0053402500926869149, 0.0053375143241527452, 0.0053351032755583061, 0.00533296535493589, 0.0053310784230947228, 0.0053293921169953254, 0.0053278834084805292, 0.0053265068819695035, 0.0053252655728174203, 0.0053241546222141225, 0.0053230783180256659, 0.0053220220671358108, 0.0053210251974725722, 0.0053199863993829387, 0.0053189901698542262, 0.0053181752684200645, 0.005317436447243854, 0.0053167245274622545, 0.0053160505732798655, 0.0053154127976081196, 0.0053147699078767447, 0.0053141175796480103, 0.0053135108141771402, 0.0053129381338803206, 0.0053124060391050373, 0.0053118938769774159, 0.0053114066744488157, 0.0053109577406014324, 0.0053105210511130924, 0.0053100993510921653, 0.0053096765569982472, 0.0053092585059409244, 0.0053088423609973174, 0.0053084093501646916, 0.0053079262156264006, 0.0053074444031143662, 0.0053069747684750049, 0.0053065213442734559, 0.0053061086343733467, 0.0053056942244073682, 0.0053052553603783635, 0.0053048039727817946, 0.0053044063064281019, 0.0053040219002116838, 0.0053036539535216498, 0.0053032859465917135, 0.0053029259371933021, 0.0053025634541939183, 0.0053021777714734424, 0.0053017666940404478, 0.0053013251565235233, 0.0053009404384971584, 0.0053005561116023156, 0.0053001674486324877, 0.0052997759742390545, 0.0052993815140343469, 0.0052989775051206396, 0.0052985776013337715, 0.0052981629014632655, 0.0052977366358738631, 0.0052972928592124021, 0.0052968519194738217, 0.0052964058009006059, 0.0052959681980589797, 0.0052955370468766218, 0.0052951037732645381], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098718948387011025, 0.0089995653932218884, 0.0083091712803813646, 0.007762668538235957, 0.007328393051922742, 0.0069813304070904126, 0.0067023811906455439, 0.0064769728453099411, 0.006293822225305337, 0.006144095162208426, 0.0060211344246780107, 0.0059195637823086737, 0.0058354963039780657, 0.0057655025110777223, 0.0057069517026640633, 0.0056577882434195636, 0.0056163404242408682, 0.0055812471252443697, 0.0055514648811631267, 0.0055260018356843117, 0.005504230223721842, 0.0054855379486888397, 0.0054694316388219063, 0.0054555756556734624, 0.0054435730143367325, 0.0054330315152934221, 0.0054218906395268086, 0.0054117359890980569, 0.005403051353962224, 0.0053955534145778321, 0.0053891011142132251, 0.0053835269688441477, 0.0053787105997407728, 0.0053745079353475509, 0.0053708380926937704, 0.0053675985319293672, 0.0053647477280934289, 0.00536222159465846, 0.0053599936539190408, 0.0053580290297480931, 0.0053562903647017589, 0.0053547392050002094, 0.0053533376704380641, 0.0053520654847728152, 0.0053509226221693205, 0.0053498774309777165, 0.0053488350159778862, 0.0053478373679635028, 0.0053468640956913817, 0.0053458492545614697, 0.0053449766422898892, 0.0053442303596901919, 0.0053435342117839502, 0.0053428694959288658, 0.005342242163695725, 0.005341619628625489, 0.005340983605724936, 0.0053403714423210643, 0.0053397892037278759, 0.0053392505912585528, 0.0053387371207835139, 0.0053382437382745269, 0.0053377925973086982, 0.0053373554782518741, 0.0053369399081040882, 0.0053365263392081306, 0.0053361189593719317, 0.0053357170841928578, 0.0053353020499527963, 0.0053348638469059989, 0.0053343895565097915, 0.0053339317016650144, 0.0053334812378999872, 0.005333057252583426, 0.0053326555926019401, 0.0053322357078711248, 0.0053317943639112231, 0.0053313771832967094, 0.0053310009833332462, 0.0053306272490825941, 0.0053302644258926323, 0.0053299108648868637, 0.0053295530765202492, 0.0053291935335359605, 0.0053287931255871857, 0.0053283638016557279, 0.0053279556735149301, 0.0053275846799041536, 0.0053272048749667053, 0.0053268256832137784, 0.0053264370579759485, 0.0053260433310977785, 0.0053256557422949706, 0.0053252526604661557, 0.0053248423057590819, 0.0053244138702249963, 0.0053239742982586179, 0.0053235348349484441, 0.0053231040889410294, 0.0053226719320605062, 0.0053222475839088089], 'acc': [0.57935436355843783, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822264767316, 0.59383822266596353, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822262938279, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822272449271, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822267327968, 0.59383822270254427, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124]}
[2017-11-18 19:51:09,334 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 19:51:09,568 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 19:51:09,568 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 19:51:10,425 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:141]: done!
[2017-11-18 19:51:10,425 AE_UNIGRAMA_7L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_7L_FULLDS_OVER_05 finished!
