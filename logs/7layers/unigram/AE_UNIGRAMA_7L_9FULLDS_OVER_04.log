[2017-11-18 18:57:46,022 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_9FULLDS_OVER_04
[2017-11-18 18:57:46,022 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 18:57:46,022 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_9FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,59,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2b83f3feb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2b83f44400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:57:46,022 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 18:57:48,289 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:57:48,289 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:57:48,289 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 18:57:48,289 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2b83f3feb8>, 'discard_decoder_function': True}
[2017-11-18 18:57:48,459 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 19:00:23,603 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 19:00:23,604 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0096423574406701556, 0.0089082498673605636, 0.0083435953651903663, 0.0079024127021894673, 0.0075522330740192215, 0.0072703980277704873, 0.0070410259767958823, 0.0068523417177683002, 0.0066956425356401086, 0.006564436766713617, 0.0064537740226606371, 0.0063598892303749792, 0.0062792074910403717, 0.0062094650714590088, 0.0061495748890350952, 0.0060979959120969155, 0.0060534536409322191, 0.0060148645013205241, 0.005981302041220193, 0.0059520712235955489, 0.005926552543862258, 0.0059042208459576025, 0.0058846616129555529, 0.0058674925940131132, 0.0058524422145605041, 0.0058392226413297591, 0.0058275855050341132, 0.005817306083286484, 0.0058082377844247439, 0.0058002189291728058, 0.0057902968876599138, 0.0057803715469855752, 0.0057718373306447452, 0.0057644984770110321, 0.0057581313434804798, 0.0057525769376991064, 0.0057477132724108601, 0.0057434548093509155, 0.0057397440580896917, 0.0057364586294580419, 0.0057335694991182216, 0.0057310151197741853, 0.0057287432406698683, 0.0057267370434065145, 0.0057249342900684095, 0.005723336130091068, 0.0057219067684798142, 0.0057206275065637266, 0.0057194724644594871, 0.0057184342021969359, 0.0057174818528160998, 0.0057166308290039309, 0.0057158519686581356, 0.0057151474571865198, 0.0057144901967302476, 0.0057138892770113364, 0.0057133310161276325, 0.0057127974411107819, 0.005712307744787151, 0.0057118612659724753, 0.0057114273715642436, 0.0057110279419098986, 0.0057106395904933131, 0.0057102795588472111, 0.0057099345743413833, 0.0057095902156802181, 0.0057092628142947398, 0.0057089455927681427, 0.0057086313269328693, 0.0057083192822728439, 0.0057080204734487683, 0.0057077213368135222, 0.0057074267218503467, 0.0057071466081033339, 0.0057068676268493632, 0.005706592821230299, 0.0057063170367983975, 0.0057060507418624081, 0.005705790522428574, 0.0057055222456511524, 0.0057052570028598149, 0.0057050037148652635, 0.0057047389557045016, 0.0057044896095729642, 0.0057042322479406125, 0.0057039785208108668, 0.005703733005475024, 0.0057034845288859342, 0.0057032558125249006, 0.0057030200755626825, 0.0057027734403978679, 0.0057025483505816115, 0.0057023258111208609, 0.0057021058184217599, 0.0057018741524447331, 0.0057016457346305994, 0.0057014173697830838, 0.0057011832339700771, 0.0057009533507176476, 0.0057007199933171238, 0.0057004823526370964], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010070741016221577, 0.0092625041756693449, 0.0086193169189709169, 0.0081209263256649834, 0.0077287408437982713, 0.0074154637741731784, 0.0071619592159593249, 0.0069547473935736631, 0.0067835199809893262, 0.0066408026512271897, 0.0065208938976124937, 0.0064195120948129843, 0.0063332197455522642, 0.0062585243332467589, 0.0061943874616901557, 0.0061392520998590988, 0.0060917195164186646, 0.0060506267130728828, 0.0060149767608473834, 0.0059839860523926399, 0.0059569560044401776, 0.0059333308589600946, 0.0059126687592906688, 0.0058945650454302854, 0.0058787061793520922, 0.0058647764612222916, 0.0058525489461798566, 0.0058417691515029995, 0.0058322535035897393, 0.0058238600709716671, 0.0058155365493909898, 0.0058052382456844969, 0.0057961795625610778, 0.005788394692431067, 0.0057816847170470715, 0.0057758423323718243, 0.0057707373927343587, 0.0057662712013762983, 0.0057623663926786315, 0.0057589467653756171, 0.0057559244351730625, 0.0057532686428194936, 0.0057509114123982371, 0.0057488205223430577, 0.0057469572973892239, 0.0057452955004067873, 0.005743811046641777, 0.0057424835186729228, 0.0057412900636595633, 0.005740215164969688, 0.0057392408383722809, 0.0057383557559006221, 0.0057375613343150309, 0.0057368307439920156, 0.0057361562555943678, 0.0057355334873791233, 0.005734959081235079, 0.0057344155288808398, 0.0057339161480463169, 0.0057334427574218033, 0.0057330067952306293, 0.0057325930846414928, 0.0057322050567555861, 0.0057318381511559293, 0.0057314730839095294, 0.0057311304072147906, 0.0057307922780766175, 0.0057304710834167648, 0.0057301501582540243, 0.0057298418560159181, 0.0057295276161534294, 0.0057292218091213494, 0.00572892751713214, 0.0057286278873282378, 0.0057283377886340669, 0.0057280558661907651, 0.0057277720509803674, 0.0057274945383443123, 0.0057272215983569181, 0.005726947987055934, 0.0057266767149784488, 0.0057264072749669071, 0.0057261418772977281, 0.0057258724671223459, 0.0057256129143682562, 0.0057253515981370955, 0.0057250926120414082, 0.0057248346363741286, 0.005724584140209087, 0.0057243394929029955, 0.0057240943421545797, 0.005723854401759868, 0.0057236130227135548, 0.0057233852064880594, 0.0057231448431857906, 0.0057229120229447825, 0.0057226792020178855, 0.0057224339857099389, 0.0057221937142596024, 0.00572194823754257, 0.0057216990467380885], 'acc': [0.29139560572249734, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822267327968, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822262938279, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124]}
[2017-11-18 19:00:23,604 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 19:00:23,604 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 19:00:23,604 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 19:00:23,604 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2b83f44400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:00:23,653 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 19:05:14,923 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:125]: trained!
[2017-11-18 19:05:14,924 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0096423574406701556, 0.0089082498673605636, 0.0083435953651903663, 0.0079024127021894673, 0.0075522330740192215, 0.0072703980277704873, 0.0070410259767958823, 0.0068523417177683002, 0.0066956425356401086, 0.006564436766713617, 0.0064537740226606371, 0.0063598892303749792, 0.0062792074910403717, 0.0062094650714590088, 0.0061495748890350952, 0.0060979959120969155, 0.0060534536409322191, 0.0060148645013205241, 0.005981302041220193, 0.0059520712235955489, 0.005926552543862258, 0.0059042208459576025, 0.0058846616129555529, 0.0058674925940131132, 0.0058524422145605041, 0.0058392226413297591, 0.0058275855050341132, 0.005817306083286484, 0.0058082377844247439, 0.0058002189291728058, 0.0057902968876599138, 0.0057803715469855752, 0.0057718373306447452, 0.0057644984770110321, 0.0057581313434804798, 0.0057525769376991064, 0.0057477132724108601, 0.0057434548093509155, 0.0057397440580896917, 0.0057364586294580419, 0.0057335694991182216, 0.0057310151197741853, 0.0057287432406698683, 0.0057267370434065145, 0.0057249342900684095, 0.005723336130091068, 0.0057219067684798142, 0.0057206275065637266, 0.0057194724644594871, 0.0057184342021969359, 0.0057174818528160998, 0.0057166308290039309, 0.0057158519686581356, 0.0057151474571865198, 0.0057144901967302476, 0.0057138892770113364, 0.0057133310161276325, 0.0057127974411107819, 0.005712307744787151, 0.0057118612659724753, 0.0057114273715642436, 0.0057110279419098986, 0.0057106395904933131, 0.0057102795588472111, 0.0057099345743413833, 0.0057095902156802181, 0.0057092628142947398, 0.0057089455927681427, 0.0057086313269328693, 0.0057083192822728439, 0.0057080204734487683, 0.0057077213368135222, 0.0057074267218503467, 0.0057071466081033339, 0.0057068676268493632, 0.005706592821230299, 0.0057063170367983975, 0.0057060507418624081, 0.005705790522428574, 0.0057055222456511524, 0.0057052570028598149, 0.0057050037148652635, 0.0057047389557045016, 0.0057044896095729642, 0.0057042322479406125, 0.0057039785208108668, 0.005703733005475024, 0.0057034845288859342, 0.0057032558125249006, 0.0057030200755626825, 0.0057027734403978679, 0.0057025483505816115, 0.0057023258111208609, 0.0057021058184217599, 0.0057018741524447331, 0.0057016457346305994, 0.0057014173697830838, 0.0057011832339700771, 0.0057009533507176476, 0.0057007199933171238, 0.0057004823526370964], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010070741016221577, 0.0092625041756693449, 0.0086193169189709169, 0.0081209263256649834, 0.0077287408437982713, 0.0074154637741731784, 0.0071619592159593249, 0.0069547473935736631, 0.0067835199809893262, 0.0066408026512271897, 0.0065208938976124937, 0.0064195120948129843, 0.0063332197455522642, 0.0062585243332467589, 0.0061943874616901557, 0.0061392520998590988, 0.0060917195164186646, 0.0060506267130728828, 0.0060149767608473834, 0.0059839860523926399, 0.0059569560044401776, 0.0059333308589600946, 0.0059126687592906688, 0.0058945650454302854, 0.0058787061793520922, 0.0058647764612222916, 0.0058525489461798566, 0.0058417691515029995, 0.0058322535035897393, 0.0058238600709716671, 0.0058155365493909898, 0.0058052382456844969, 0.0057961795625610778, 0.005788394692431067, 0.0057816847170470715, 0.0057758423323718243, 0.0057707373927343587, 0.0057662712013762983, 0.0057623663926786315, 0.0057589467653756171, 0.0057559244351730625, 0.0057532686428194936, 0.0057509114123982371, 0.0057488205223430577, 0.0057469572973892239, 0.0057452955004067873, 0.005743811046641777, 0.0057424835186729228, 0.0057412900636595633, 0.005740215164969688, 0.0057392408383722809, 0.0057383557559006221, 0.0057375613343150309, 0.0057368307439920156, 0.0057361562555943678, 0.0057355334873791233, 0.005734959081235079, 0.0057344155288808398, 0.0057339161480463169, 0.0057334427574218033, 0.0057330067952306293, 0.0057325930846414928, 0.0057322050567555861, 0.0057318381511559293, 0.0057314730839095294, 0.0057311304072147906, 0.0057307922780766175, 0.0057304710834167648, 0.0057301501582540243, 0.0057298418560159181, 0.0057295276161534294, 0.0057292218091213494, 0.00572892751713214, 0.0057286278873282378, 0.0057283377886340669, 0.0057280558661907651, 0.0057277720509803674, 0.0057274945383443123, 0.0057272215983569181, 0.005726947987055934, 0.0057266767149784488, 0.0057264072749669071, 0.0057261418772977281, 0.0057258724671223459, 0.0057256129143682562, 0.0057253515981370955, 0.0057250926120414082, 0.0057248346363741286, 0.005724584140209087, 0.0057243394929029955, 0.0057240943421545797, 0.005723854401759868, 0.0057236130227135548, 0.0057233852064880594, 0.0057231448431857906, 0.0057229120229447825, 0.0057226792020178855, 0.0057224339857099389, 0.0057221937142596024, 0.00572194823754257, 0.0057216990467380885], 'acc': [0.29139560572249734, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822267327968, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822262938279, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.59383822264767316, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124]}
[2017-11-18 19:05:14,924 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 19:05:15,116 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 19:05:15,116 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 19:05:15,962 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:141]: done!
[2017-11-18 19:05:15,962 AE_UNIGRAMA_7L_9FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_7L_9FULLDS_OVER_04 finished!
