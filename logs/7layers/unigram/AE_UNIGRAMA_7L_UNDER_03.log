[2017-10-20 01:39:41,456 AE_UNIGRAMA_7L_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_UNDER_03
[2017-10-20 01:39:41,456 AE_UNIGRAMA_7L_UNDER_03.py:149]: >> Printing header log
[2017-10-20 01:39:41,457 AE_UNIGRAMA_7L_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_UNDER_03
	layers = 96,86,78,71,63,55,48,40,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fde5f13b7f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fde5f13b8d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:39:41,457 AE_UNIGRAMA_7L_UNDER_03.py:151]: >> Loading dataset... 
[2017-10-20 01:39:42,065 AE_UNIGRAMA_7L_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:39:42,065 AE_UNIGRAMA_7L_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:39:42,065 AE_UNIGRAMA_7L_UNDER_03.py:60]: =======================================
[2017-10-20 01:39:42,066 AE_UNIGRAMA_7L_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fde5f13b7f0>, 'discard_decoder_function': True}
[2017-10-20 01:39:42,240 AE_UNIGRAMA_7L_UNDER_03.py:76]: training and evaluate autoencoder
[2017-10-20 01:40:24,008 AE_UNIGRAMA_7L_UNDER_03.py:88]: trained and evaluated!
[2017-10-20 01:40:24,009 AE_UNIGRAMA_7L_UNDER_03.py:91]: Training history: 
{'val_loss': [0.010233201948600409, 0.010050945904895275, 0.0098767271230765872, 0.0097115883174383501, 0.0095550053991848207, 0.0094062576008108918, 0.0092647263925647212, 0.00913008616814826, 0.0090018054574284856, 0.0088795969560465406, 0.0087632249355260768, 0.0086519624864800273, 0.0085456529528345759, 0.0084442254709820759, 0.0083473648522810872, 0.008254904691199166, 0.0081665667109745363, 0.0080821585744536278, 0.0080015372561090051, 0.0079243495146359647, 0.0078505895976461893, 0.0077799818059602639, 0.0077123446805492657, 0.0076476052043384776, 0.0075856069289840285, 0.0075261385377399541, 0.0074691564315535319, 0.0074144822188746528, 0.0073620817817913776, 0.0073117757853134414, 0.0072634687931121059, 0.0072170546569179424, 0.0071724629407007674, 0.0071296215760192688, 0.0070884198843601913, 0.0070487911549836505, 0.0070106807410661616, 0.0069740311204556198, 0.0069387498931426095, 0.006904791976536406, 0.0068720858336381307, 0.0068405670006534422, 0.006810207723130967, 0.0067809375200323678, 0.0067527749814563966, 0.0067255925006305863, 0.0066993864717093546, 0.0066740892128153359, 0.0066496811869474594, 0.0066261316535364293, 0.0066033856524327656, 0.0065814036647460277, 0.0065601828289962609, 0.0065396657753666538, 0.0065198612475566922, 0.0065006905228425799, 0.0064821305622426327, 0.0064642043545371317, 0.0064468339127124906, 0.0064300322822090864, 0.0064137848215281524, 0.0063980603296323558, 0.0063828195888396754, 0.0063680836560419283, 0.0063538109177384231, 0.0063399764290252587, 0.006326602498367152, 0.0063136176805126181, 0.0063007120977824063, 0.0062879309141281366, 0.0062755433302441937, 0.0062635526438434104, 0.0062519187786266705, 0.0062406527598606607, 0.0062297284568497242, 0.0062191402124150974, 0.0062088716435886671, 0.0061989129939874748, 0.0061892529440607498, 0.0061798784968384356, 0.0061707740621883634, 0.0061619409834308249, 0.0061533840123882523, 0.0061450587744828053, 0.0061369828453986842, 0.0061291487537822979, 0.0061215346879897065, 0.0061141504615295997, 0.0061069815835074204, 0.0061000234076967917, 0.0060932654783572848, 0.0060866966351977511, 0.0060803066561739465, 0.0060740946186187096, 0.0060680715339500669, 0.0060622137971222401, 0.0060565330531295791, 0.0060510048469646274, 0.006045630078790467, 0.0060404062194950522, 0.0060353360007271229, 0.0060304008583541699], 'loss': [0.010319261091572966, 0.010136183974640495, 0.0099566584606394486, 0.0097860183295483006, 0.0096241833868802289, 0.0094705635187180039, 0.0093245081850811245, 0.0091854867393170395, 0.0090531475078394676, 0.0089270025274195992, 0.0088068193234571955, 0.0086921986928593185, 0.0085825005914848783, 0.0084777873400976554, 0.0083778042800738244, 0.0082823020436405478, 0.0081911149784492134, 0.0081039394344161395, 0.008020618028329719, 0.0079409789111403398, 0.0078647048421520063, 0.0077917818901642524, 0.0077219219874309006, 0.0076549822798304456, 0.007590873302009183, 0.0075294477707685209, 0.0074704974253227462, 0.0074139844638209038, 0.0073597456240418616, 0.0073077074826203318, 0.0072577355412930047, 0.0072097266934349558, 0.0071635661087472271, 0.0071191999299386457, 0.0070765513818557635, 0.0070355089012700571, 0.0069960247998291283, 0.0069580293382439573, 0.0069214724709486478, 0.0068862556743755545, 0.0068523510074163952, 0.00681966637760932, 0.0067881630160047295, 0.0067577847799362954, 0.0067285151311299992, 0.0067003197692101103, 0.0066730851191883081, 0.0066468140883708957, 0.0066214408135910523, 0.0065969448037486757, 0.0065732993813461702, 0.0065504437442422464, 0.0065283499507562065, 0.006507003158113399, 0.0064863488324256712, 0.0064663995396787759, 0.0064470916611532271, 0.0064283751089242646, 0.0064102841358570032, 0.0063927476148372348, 0.0063757667470821849, 0.0063593549529100827, 0.0063434451347366937, 0.0063280307592797772, 0.0063130996326246766, 0.0062986413817154386, 0.0062846268046951835, 0.0062710458461994328, 0.0062577891639778969, 0.0062445094239381134, 0.0062315775128453516, 0.0062190335811778087, 0.0062068796464194529, 0.0061950743763370423, 0.0061836446018359486, 0.0061725410884652648, 0.0061617761426196009, 0.0061513353823200462, 0.0061411988359349927, 0.0061313606307514985, 0.0061218030192644853, 0.0061125233992659466, 0.0061035117906642492, 0.0060947749279462345, 0.0060862663929529843, 0.0060780064647040742, 0.006069996769150196, 0.0060621904920198175, 0.0060546339032158357, 0.0060472817674792102, 0.0060401403564975791, 0.0060331927115565877, 0.0060264457663442173, 0.0060198706899298503, 0.0060134927986032882, 0.0060072847614528468, 0.0060012562697857492, 0.0059953969061837175, 0.0059896879926777244, 0.0059841415786471156, 0.0059787460042423609, 0.0059734965516019612]}
[2017-10-20 01:40:24,009 AE_UNIGRAMA_7L_UNDER_03.py:95]: done!
[2017-10-20 01:40:24,009 AE_UNIGRAMA_7L_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-10-20 01:40:24,009 AE_UNIGRAMA_7L_UNDER_03.py:100]: =======================================
[2017-10-20 01:40:24,009 AE_UNIGRAMA_7L_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fde5f13b8d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:40:24,048 AE_UNIGRAMA_7L_UNDER_03.py:113]: training ... 
[2017-10-20 01:41:38,047 AE_UNIGRAMA_7L_UNDER_03.py:125]: trained!
[2017-10-20 01:41:38,047 AE_UNIGRAMA_7L_UNDER_03.py:128]: Training history: 
{'val_loss': [0.010233201948600409, 0.010050945904895275, 0.0098767271230765872, 0.0097115883174383501, 0.0095550053991848207, 0.0094062576008108918, 0.0092647263925647212, 0.00913008616814826, 0.0090018054574284856, 0.0088795969560465406, 0.0087632249355260768, 0.0086519624864800273, 0.0085456529528345759, 0.0084442254709820759, 0.0083473648522810872, 0.008254904691199166, 0.0081665667109745363, 0.0080821585744536278, 0.0080015372561090051, 0.0079243495146359647, 0.0078505895976461893, 0.0077799818059602639, 0.0077123446805492657, 0.0076476052043384776, 0.0075856069289840285, 0.0075261385377399541, 0.0074691564315535319, 0.0074144822188746528, 0.0073620817817913776, 0.0073117757853134414, 0.0072634687931121059, 0.0072170546569179424, 0.0071724629407007674, 0.0071296215760192688, 0.0070884198843601913, 0.0070487911549836505, 0.0070106807410661616, 0.0069740311204556198, 0.0069387498931426095, 0.006904791976536406, 0.0068720858336381307, 0.0068405670006534422, 0.006810207723130967, 0.0067809375200323678, 0.0067527749814563966, 0.0067255925006305863, 0.0066993864717093546, 0.0066740892128153359, 0.0066496811869474594, 0.0066261316535364293, 0.0066033856524327656, 0.0065814036647460277, 0.0065601828289962609, 0.0065396657753666538, 0.0065198612475566922, 0.0065006905228425799, 0.0064821305622426327, 0.0064642043545371317, 0.0064468339127124906, 0.0064300322822090864, 0.0064137848215281524, 0.0063980603296323558, 0.0063828195888396754, 0.0063680836560419283, 0.0063538109177384231, 0.0063399764290252587, 0.006326602498367152, 0.0063136176805126181, 0.0063007120977824063, 0.0062879309141281366, 0.0062755433302441937, 0.0062635526438434104, 0.0062519187786266705, 0.0062406527598606607, 0.0062297284568497242, 0.0062191402124150974, 0.0062088716435886671, 0.0061989129939874748, 0.0061892529440607498, 0.0061798784968384356, 0.0061707740621883634, 0.0061619409834308249, 0.0061533840123882523, 0.0061450587744828053, 0.0061369828453986842, 0.0061291487537822979, 0.0061215346879897065, 0.0061141504615295997, 0.0061069815835074204, 0.0061000234076967917, 0.0060932654783572848, 0.0060866966351977511, 0.0060803066561739465, 0.0060740946186187096, 0.0060680715339500669, 0.0060622137971222401, 0.0060565330531295791, 0.0060510048469646274, 0.006045630078790467, 0.0060404062194950522, 0.0060353360007271229, 0.0060304008583541699], 'loss': [0.010319261091572966, 0.010136183974640495, 0.0099566584606394486, 0.0097860183295483006, 0.0096241833868802289, 0.0094705635187180039, 0.0093245081850811245, 0.0091854867393170395, 0.0090531475078394676, 0.0089270025274195992, 0.0088068193234571955, 0.0086921986928593185, 0.0085825005914848783, 0.0084777873400976554, 0.0083778042800738244, 0.0082823020436405478, 0.0081911149784492134, 0.0081039394344161395, 0.008020618028329719, 0.0079409789111403398, 0.0078647048421520063, 0.0077917818901642524, 0.0077219219874309006, 0.0076549822798304456, 0.007590873302009183, 0.0075294477707685209, 0.0074704974253227462, 0.0074139844638209038, 0.0073597456240418616, 0.0073077074826203318, 0.0072577355412930047, 0.0072097266934349558, 0.0071635661087472271, 0.0071191999299386457, 0.0070765513818557635, 0.0070355089012700571, 0.0069960247998291283, 0.0069580293382439573, 0.0069214724709486478, 0.0068862556743755545, 0.0068523510074163952, 0.00681966637760932, 0.0067881630160047295, 0.0067577847799362954, 0.0067285151311299992, 0.0067003197692101103, 0.0066730851191883081, 0.0066468140883708957, 0.0066214408135910523, 0.0065969448037486757, 0.0065732993813461702, 0.0065504437442422464, 0.0065283499507562065, 0.006507003158113399, 0.0064863488324256712, 0.0064663995396787759, 0.0064470916611532271, 0.0064283751089242646, 0.0064102841358570032, 0.0063927476148372348, 0.0063757667470821849, 0.0063593549529100827, 0.0063434451347366937, 0.0063280307592797772, 0.0063130996326246766, 0.0062986413817154386, 0.0062846268046951835, 0.0062710458461994328, 0.0062577891639778969, 0.0062445094239381134, 0.0062315775128453516, 0.0062190335811778087, 0.0062068796464194529, 0.0061950743763370423, 0.0061836446018359486, 0.0061725410884652648, 0.0061617761426196009, 0.0061513353823200462, 0.0061411988359349927, 0.0061313606307514985, 0.0061218030192644853, 0.0061125233992659466, 0.0061035117906642492, 0.0060947749279462345, 0.0060862663929529843, 0.0060780064647040742, 0.006069996769150196, 0.0060621904920198175, 0.0060546339032158357, 0.0060472817674792102, 0.0060401403564975791, 0.0060331927115565877, 0.0060264457663442173, 0.0060198706899298503, 0.0060134927986032882, 0.0060072847614528468, 0.0060012562697857492, 0.0059953969061837175, 0.0059896879926777244, 0.0059841415786471156, 0.0059787460042423609, 0.0059734965516019612]}
[2017-10-20 01:41:38,048 AE_UNIGRAMA_7L_UNDER_03.py:132]: evaluating model ... 
[2017-10-20 01:41:38,108 AE_UNIGRAMA_7L_UNDER_03.py:136]: evaluated! 
[2017-10-20 01:41:38,109 AE_UNIGRAMA_7L_UNDER_03.py:138]: generating reports ... 
[2017-10-20 01:41:38,740 AE_UNIGRAMA_7L_UNDER_03.py:141]: done!
[2017-10-20 01:41:38,740 AE_UNIGRAMA_7L_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_7L_UNDER_03 finished!
