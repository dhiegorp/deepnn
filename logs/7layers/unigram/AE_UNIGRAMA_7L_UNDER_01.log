[2017-10-20 01:41:54,196 AE_UNIGRAMA_7L_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_7L_UNDER_01
[2017-10-20 01:41:54,196 AE_UNIGRAMA_7L_UNDER_01.py:149]: >> Printing header log
[2017-10-20 01:41:54,196 AE_UNIGRAMA_7L_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_7L_UNDER_01
	layers = 96,28,26,24,22,20,19,17,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/7layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/7layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/7layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/7layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/7layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5c9592e748>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5c9592e828>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:41:54,197 AE_UNIGRAMA_7L_UNDER_01.py:151]: >> Loading dataset... 
[2017-10-20 01:41:54,761 AE_UNIGRAMA_7L_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:41:54,761 AE_UNIGRAMA_7L_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:41:54,761 AE_UNIGRAMA_7L_UNDER_01.py:60]: =======================================
[2017-10-20 01:41:54,761 AE_UNIGRAMA_7L_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5c9592e748>, 'discard_decoder_function': True}
[2017-10-20 01:41:54,933 AE_UNIGRAMA_7L_UNDER_01.py:76]: training and evaluate autoencoder
[2017-10-20 01:42:28,473 AE_UNIGRAMA_7L_UNDER_01.py:88]: trained and evaluated!
[2017-10-20 01:42:28,474 AE_UNIGRAMA_7L_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010340316439234413, 0.010267750502020454, 0.010194708773222334, 0.010125022170352006, 0.01005853160689533, 0.0099952333160160198, 0.00993495485070248, 0.0098774427077196348, 0.0098223799534945238, 0.0097694491489779996, 0.0097187717850268102, 0.0096704688297106871, 0.0096244099428773374, 0.0095804587498196439, 0.0095384834147297318, 0.0094984251915799199, 0.0094601195167099226, 0.009423497918868597, 0.0093884665248950179, 0.0093549601525954595, 0.009322851906672508, 0.0092921519555068371, 0.0092626908641710165, 0.0092344454049953298, 0.0092073688041211053, 0.0091813878921383381, 0.0091564617843322149, 0.0091325369002262895, 0.0091095703055036562, 0.0090874904060397003, 0.0090662572622908534, 0.0090458640399420122, 0.0090262326325348755, 0.0090073247069707586, 0.0089891465920885691, 0.0089716156425307669, 0.0089547667707763189, 0.0089384960460729308, 0.0089228087136016456, 0.0089076929085205921, 0.0088930871670020121, 0.0088790157865248198, 0.0088654293896817359, 0.0088522896572227373, 0.0088396178052992623, 0.0088273529759625522, 0.0088155102573307473, 0.0088040529746825375, 0.0087929782024878996, 0.0087822425840457137, 0.0087718527182438118, 0.008761796366326428, 0.0087520492688984673, 0.0087426053533212842, 0.0087334460658488669, 0.008724574733622455, 0.0087159819707108253, 0.0087076414404194599, 0.0086995568022575076, 0.0086917127776877136, 0.0086840911037859864, 0.0086766825885023768, 0.0086694925254882493, 0.0086625101924164144, 0.008655729762461992, 0.0086491417215936242, 0.0086427371131886331, 0.0086365085524475714, 0.0086304597092660834, 0.0086245716957991676, 0.0086188361751518058, 0.0086132729595672468, 0.0086078486772302575, 0.0086025781202438145, 0.0085974481600755645, 0.0085924528002545072, 0.0085875807697001882, 0.0085828363736156644, 0.0085782227868068835, 0.0085737213430074517, 0.0085693474246195927, 0.0085650838091000086, 0.0085609214151880549, 0.0085568802247730988, 0.0085529229226331722, 0.0085490754923218913, 0.0085453221290528111, 0.0085416698627533965, 0.0085380968263850561, 0.008534613122547316, 0.0085312157841641659, 0.008527906282656034, 0.0085246785246112754, 0.0085215291430737455, 0.0085184555016042576, 0.0085154511761543483, 0.0085125288157464184, 0.0085096720045217799, 0.0085068794874453638, 0.0085041582563608106, 0.0085015023944269331, 0.0084989055416453286], 'loss': [0.010371727926156312, 0.010299852329690396, 0.010227602812076318, 0.010157137156705147, 0.010089862483227883, 0.010025762460013072, 0.0099647376479119632, 0.0099066089914302269, 0.0098510733997356544, 0.0097977787544739053, 0.0097466096037010803, 0.0096977928083232003, 0.0096512468149353194, 0.0096068637944716727, 0.0095644956300082063, 0.0095240366109947371, 0.0094854133993561244, 0.009448478252529072, 0.0094131652263497456, 0.0093793823036291361, 0.0093470635951554467, 0.0093160984922056184, 0.0092864726912218806, 0.0092580478865087728, 0.0092307933003452202, 0.0092046541472657669, 0.0091795751552504485, 0.0091555131216932463, 0.0091324146349296732, 0.0091102337905451351, 0.0090889167424105903, 0.0090684149117788871, 0.0090487155469149341, 0.0090297550568614691, 0.0090114907753672709, 0.0089939192055364502, 0.0089769782275236232, 0.0089606897288403344, 0.0089449573276174088, 0.0089297844806815411, 0.0089151641221164053, 0.0089010303209237553, 0.0088874152194669664, 0.008874256766018284, 0.0088615397090972686, 0.0088492642341670476, 0.0088373819519505219, 0.0088259062398346414, 0.0088148033750124997, 0.0088040608558952634, 0.0087936516529488352, 0.0087835729470191453, 0.0087738145954481071, 0.0087643502985333913, 0.0087551847231913792, 0.0087462856131477005, 0.0087376717081924273, 0.0087293188838080977, 0.0087212082290519365, 0.0087133469346271902, 0.008705716658573651, 0.0086982949157763494, 0.008691086123577824, 0.0086840834736494326, 0.0086772800363101102, 0.0086706773004166619, 0.0086642599652607746, 0.008658011868074033, 0.0086519329018144419, 0.0086460355732225908, 0.0086402855844986207, 0.0086346921976369513, 0.0086292537632177927, 0.0086239554696632224, 0.0086188021653458326, 0.0086137868381565008, 0.0086089011067644761, 0.0086041358949246766, 0.0085994906668547255, 0.0085949713201677064, 0.0085905675158664801, 0.008586279309475503, 0.0085821034817211671, 0.0085780259013432409, 0.0085740554969031962, 0.0085701799230820646, 0.0085663994752470524, 0.0085627181099449563, 0.0085591238321760504, 0.00855561852118558, 0.0085521933932335894, 0.0085488514563717873, 0.0085455997209920431, 0.0085424288532615945, 0.0085393292743531773, 0.0085363020655626377, 0.0085333492332118083, 0.0085304662134193833, 0.0085276460003728283, 0.0085248946456654203, 0.0085222139100520691, 0.0085195919536580761]}
[2017-10-20 01:42:28,474 AE_UNIGRAMA_7L_UNDER_01.py:95]: done!
[2017-10-20 01:42:28,474 AE_UNIGRAMA_7L_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-10-20 01:42:28,474 AE_UNIGRAMA_7L_UNDER_01.py:100]: =======================================
[2017-10-20 01:42:28,474 AE_UNIGRAMA_7L_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5c9592e828>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:42:28,510 AE_UNIGRAMA_7L_UNDER_01.py:113]: training ... 
[2017-10-20 01:42:57,609 AE_UNIGRAMA_7L_UNDER_01.py:125]: trained!
[2017-10-20 01:42:57,610 AE_UNIGRAMA_7L_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010340316439234413, 0.010267750502020454, 0.010194708773222334, 0.010125022170352006, 0.01005853160689533, 0.0099952333160160198, 0.00993495485070248, 0.0098774427077196348, 0.0098223799534945238, 0.0097694491489779996, 0.0097187717850268102, 0.0096704688297106871, 0.0096244099428773374, 0.0095804587498196439, 0.0095384834147297318, 0.0094984251915799199, 0.0094601195167099226, 0.009423497918868597, 0.0093884665248950179, 0.0093549601525954595, 0.009322851906672508, 0.0092921519555068371, 0.0092626908641710165, 0.0092344454049953298, 0.0092073688041211053, 0.0091813878921383381, 0.0091564617843322149, 0.0091325369002262895, 0.0091095703055036562, 0.0090874904060397003, 0.0090662572622908534, 0.0090458640399420122, 0.0090262326325348755, 0.0090073247069707586, 0.0089891465920885691, 0.0089716156425307669, 0.0089547667707763189, 0.0089384960460729308, 0.0089228087136016456, 0.0089076929085205921, 0.0088930871670020121, 0.0088790157865248198, 0.0088654293896817359, 0.0088522896572227373, 0.0088396178052992623, 0.0088273529759625522, 0.0088155102573307473, 0.0088040529746825375, 0.0087929782024878996, 0.0087822425840457137, 0.0087718527182438118, 0.008761796366326428, 0.0087520492688984673, 0.0087426053533212842, 0.0087334460658488669, 0.008724574733622455, 0.0087159819707108253, 0.0087076414404194599, 0.0086995568022575076, 0.0086917127776877136, 0.0086840911037859864, 0.0086766825885023768, 0.0086694925254882493, 0.0086625101924164144, 0.008655729762461992, 0.0086491417215936242, 0.0086427371131886331, 0.0086365085524475714, 0.0086304597092660834, 0.0086245716957991676, 0.0086188361751518058, 0.0086132729595672468, 0.0086078486772302575, 0.0086025781202438145, 0.0085974481600755645, 0.0085924528002545072, 0.0085875807697001882, 0.0085828363736156644, 0.0085782227868068835, 0.0085737213430074517, 0.0085693474246195927, 0.0085650838091000086, 0.0085609214151880549, 0.0085568802247730988, 0.0085529229226331722, 0.0085490754923218913, 0.0085453221290528111, 0.0085416698627533965, 0.0085380968263850561, 0.008534613122547316, 0.0085312157841641659, 0.008527906282656034, 0.0085246785246112754, 0.0085215291430737455, 0.0085184555016042576, 0.0085154511761543483, 0.0085125288157464184, 0.0085096720045217799, 0.0085068794874453638, 0.0085041582563608106, 0.0085015023944269331, 0.0084989055416453286], 'loss': [0.010371727926156312, 0.010299852329690396, 0.010227602812076318, 0.010157137156705147, 0.010089862483227883, 0.010025762460013072, 0.0099647376479119632, 0.0099066089914302269, 0.0098510733997356544, 0.0097977787544739053, 0.0097466096037010803, 0.0096977928083232003, 0.0096512468149353194, 0.0096068637944716727, 0.0095644956300082063, 0.0095240366109947371, 0.0094854133993561244, 0.009448478252529072, 0.0094131652263497456, 0.0093793823036291361, 0.0093470635951554467, 0.0093160984922056184, 0.0092864726912218806, 0.0092580478865087728, 0.0092307933003452202, 0.0092046541472657669, 0.0091795751552504485, 0.0091555131216932463, 0.0091324146349296732, 0.0091102337905451351, 0.0090889167424105903, 0.0090684149117788871, 0.0090487155469149341, 0.0090297550568614691, 0.0090114907753672709, 0.0089939192055364502, 0.0089769782275236232, 0.0089606897288403344, 0.0089449573276174088, 0.0089297844806815411, 0.0089151641221164053, 0.0089010303209237553, 0.0088874152194669664, 0.008874256766018284, 0.0088615397090972686, 0.0088492642341670476, 0.0088373819519505219, 0.0088259062398346414, 0.0088148033750124997, 0.0088040608558952634, 0.0087936516529488352, 0.0087835729470191453, 0.0087738145954481071, 0.0087643502985333913, 0.0087551847231913792, 0.0087462856131477005, 0.0087376717081924273, 0.0087293188838080977, 0.0087212082290519365, 0.0087133469346271902, 0.008705716658573651, 0.0086982949157763494, 0.008691086123577824, 0.0086840834736494326, 0.0086772800363101102, 0.0086706773004166619, 0.0086642599652607746, 0.008658011868074033, 0.0086519329018144419, 0.0086460355732225908, 0.0086402855844986207, 0.0086346921976369513, 0.0086292537632177927, 0.0086239554696632224, 0.0086188021653458326, 0.0086137868381565008, 0.0086089011067644761, 0.0086041358949246766, 0.0085994906668547255, 0.0085949713201677064, 0.0085905675158664801, 0.008586279309475503, 0.0085821034817211671, 0.0085780259013432409, 0.0085740554969031962, 0.0085701799230820646, 0.0085663994752470524, 0.0085627181099449563, 0.0085591238321760504, 0.00855561852118558, 0.0085521933932335894, 0.0085488514563717873, 0.0085455997209920431, 0.0085424288532615945, 0.0085393292743531773, 0.0085363020655626377, 0.0085333492332118083, 0.0085304662134193833, 0.0085276460003728283, 0.0085248946456654203, 0.0085222139100520691, 0.0085195919536580761]}
[2017-10-20 01:42:57,610 AE_UNIGRAMA_7L_UNDER_01.py:132]: evaluating model ... 
[2017-10-20 01:42:57,668 AE_UNIGRAMA_7L_UNDER_01.py:136]: evaluated! 
[2017-10-20 01:42:57,668 AE_UNIGRAMA_7L_UNDER_01.py:138]: generating reports ... 
[2017-10-20 01:42:58,275 AE_UNIGRAMA_7L_UNDER_01.py:141]: done!
[2017-10-20 01:42:58,275 AE_UNIGRAMA_7L_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_7L_UNDER_01 finished!
