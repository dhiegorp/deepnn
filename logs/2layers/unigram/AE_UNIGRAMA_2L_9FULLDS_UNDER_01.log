[2017-11-18 19:10:35,877 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_9FULLDS_UNDER_01
[2017-11-18 19:10:35,877 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 19:10:35,877 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_9FULLDS_UNDER_01
	layers = 96,28,26,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f74e06bfef0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f74e0724438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:10:35,877 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 19:10:38,174 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:10:38,174 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:10:38,175 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 19:10:38,175 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f74e06bfef0>, 'discard_decoder_function': True}
[2017-11-18 19:10:38,260 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 19:11:51,321 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 19:11:51,321 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0095254888827202289, 0.0090866418184355879, 0.0086690400611062948, 0.0083027413013592802, 0.0079808093661162417, 0.0076824060702153597, 0.0074301796670262427, 0.0072122914396576896, 0.0070247911524338371, 0.0068639727964455131, 0.0067256468129835443, 0.0066060259918045991, 0.0065019364860312697, 0.0064114649795154596, 0.0063325728090238322, 0.0062636742551456107, 0.0062034051762315358, 0.0061502335409988748, 0.0061031666054475594, 0.0060616564233224321, 0.0060250424457873458, 0.0059926498841147945, 0.0059639478218014384, 0.0059385160025303653, 0.0059159187264076459, 0.0058957837541368258, 0.0058778021435839638, 0.0058617043827969458, 0.0058472972971280075, 0.0058343579539312448, 0.0058226543814950144, 0.0058120749316642722, 0.0058024601670456461, 0.0057934306053501559, 0.0057846968549446435, 0.005776585693423558, 0.0057689338818621011, 0.0057618194192104403, 0.0057550797267867963, 0.0057485948889374255, 0.0057421280208903884, 0.0057354020494734953, 0.0057283746655681297, 0.0057202481752167741, 0.005707971671255951, 0.0056906401819608711, 0.005675082489350473, 0.0056613794429886928, 0.0056493476585809171, 0.005638660173277887, 0.0056290588363387632, 0.005619948418832869, 0.0056106311934652712, 0.0056020511312219251, 0.0055942832325776518, 0.0055872491898527861, 0.0055808867783946605, 0.005575096909383237, 0.0055697881865655018, 0.005564898356537922, 0.0055603858744756388, 0.0055561784230609371, 0.005552260152011896, 0.0055485791222968277, 0.0055451048866670084, 0.0055417845697196605, 0.0055385774229261275, 0.0055355101345310265, 0.0055325664000572669, 0.0055297533737633138, 0.0055270688429451559, 0.0055244902193509332, 0.005522001110710743, 0.0055195917893928097, 0.0055172623237659995, 0.0055149990746266083, 0.0055127919907245245, 0.0055106410565719322, 0.0055085386821978923, 0.005506479110498938, 0.0055044533699225174, 0.0055024607497404674, 0.0055005005895386377, 0.0054985686958839691, 0.0054966589176321584, 0.0054947645994719938, 0.0054928844788470106, 0.0054910183835087381, 0.0054891620650038657, 0.0054873168079654158, 0.0054854754658360469, 0.0054836416888628834, 0.0054818090656036369, 0.005479978839447534, 0.0054781487366805477, 0.0054762499925989534, 0.0054739167833702832, 0.0054712752757360558, 0.0054685619594861271, 0.0054657725397037399, 0.0054627240587365412], 'val_acc': [0.60271958838662254, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097748034359226282, 0.0093094348083032456, 0.008883104722490081, 0.0084898416085526073, 0.0081509135789712903, 0.0078382513734940821, 0.0075650395469643323, 0.00733146358998585, 0.0071300030104670554, 0.0069570697814763886, 0.0068086015032651206, 0.0066807061833093666, 0.0065697182574149023, 0.0064732413448034855, 0.0063892761810084965, 0.0063160007406399708, 0.0062519387664174845, 0.0061957686152402918, 0.0061460637523594579, 0.0061021586722905018, 0.0060634725388540502, 0.0060293200689070618, 0.005999092458642958, 0.0059722883431797633, 0.0059485235118309577, 0.0059273890708324527, 0.0059085440895335758, 0.0058917058851833733, 0.0058766159858169133, 0.0058630969520780344, 0.0058509146107530588, 0.0058398953664920306, 0.0058299018520159059, 0.0058207199921367601, 0.0058118384678410148, 0.0058034308982561032, 0.0057955577110361143, 0.0057881783463227298, 0.0057812609762498404, 0.0057746170713264796, 0.0057681314772372412, 0.0057615171351467877, 0.0057546401431145472, 0.0057472230471479497, 0.0057371654211665476, 0.0057219084705716194, 0.0057054051201837668, 0.0056908486866062624, 0.005678074586438272, 0.0056668158426946679, 0.0056567646642387594, 0.0056475875115567804, 0.0056383977781894806, 0.0056295083329077874, 0.0056214189822544926, 0.005614090447439944, 0.0056074477878047214, 0.0056014193940509445, 0.0055959259281722559, 0.0055908783040831021, 0.0055862180880079191, 0.0055818976995600242, 0.0055778705154532916, 0.0055741046395185274, 0.0055705597385836371, 0.0055671933538502085, 0.0055639624067050511, 0.0055608545149704739, 0.0055578776780523679, 0.0055550367649604832, 0.0055523195155481623, 0.0055497127999046894, 0.005547203165523016, 0.0055447727389431548, 0.0055424325896660919, 0.0055401616631370904, 0.005537953869693097, 0.0055357930990082545, 0.0055336836303423211, 0.0055316177845994383, 0.0055295904736284126, 0.0055276006509916752, 0.0055256371018941475, 0.0055237059581238783, 0.0055218012787985136, 0.0055199113236178944, 0.0055180432904126222, 0.0055161885588188775, 0.005514345533573801, 0.0055125101915399132, 0.0055106816430623819, 0.0055088623819754537, 0.0055070378909298353, 0.0055052153884471051, 0.0055033877723209808, 0.0055015471879824055, 0.005499455995164511, 0.0054969406094344002, 0.0054942665839865226, 0.0054915291951093386, 0.0054886199675575386], 'acc': [0.27347489867720176, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822264767316, 0.59383822272449271, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822262938279, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894]}
[2017-11-18 19:11:51,321 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:95]: done!
[2017-11-18 19:11:51,321 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 19:11:51,321 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 19:11:51,322 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f74e0724438>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:11:51,354 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 19:14:34,853 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 19:14:34,853 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0095254888827202289, 0.0090866418184355879, 0.0086690400611062948, 0.0083027413013592802, 0.0079808093661162417, 0.0076824060702153597, 0.0074301796670262427, 0.0072122914396576896, 0.0070247911524338371, 0.0068639727964455131, 0.0067256468129835443, 0.0066060259918045991, 0.0065019364860312697, 0.0064114649795154596, 0.0063325728090238322, 0.0062636742551456107, 0.0062034051762315358, 0.0061502335409988748, 0.0061031666054475594, 0.0060616564233224321, 0.0060250424457873458, 0.0059926498841147945, 0.0059639478218014384, 0.0059385160025303653, 0.0059159187264076459, 0.0058957837541368258, 0.0058778021435839638, 0.0058617043827969458, 0.0058472972971280075, 0.0058343579539312448, 0.0058226543814950144, 0.0058120749316642722, 0.0058024601670456461, 0.0057934306053501559, 0.0057846968549446435, 0.005776585693423558, 0.0057689338818621011, 0.0057618194192104403, 0.0057550797267867963, 0.0057485948889374255, 0.0057421280208903884, 0.0057354020494734953, 0.0057283746655681297, 0.0057202481752167741, 0.005707971671255951, 0.0056906401819608711, 0.005675082489350473, 0.0056613794429886928, 0.0056493476585809171, 0.005638660173277887, 0.0056290588363387632, 0.005619948418832869, 0.0056106311934652712, 0.0056020511312219251, 0.0055942832325776518, 0.0055872491898527861, 0.0055808867783946605, 0.005575096909383237, 0.0055697881865655018, 0.005564898356537922, 0.0055603858744756388, 0.0055561784230609371, 0.005552260152011896, 0.0055485791222968277, 0.0055451048866670084, 0.0055417845697196605, 0.0055385774229261275, 0.0055355101345310265, 0.0055325664000572669, 0.0055297533737633138, 0.0055270688429451559, 0.0055244902193509332, 0.005522001110710743, 0.0055195917893928097, 0.0055172623237659995, 0.0055149990746266083, 0.0055127919907245245, 0.0055106410565719322, 0.0055085386821978923, 0.005506479110498938, 0.0055044533699225174, 0.0055024607497404674, 0.0055005005895386377, 0.0054985686958839691, 0.0054966589176321584, 0.0054947645994719938, 0.0054928844788470106, 0.0054910183835087381, 0.0054891620650038657, 0.0054873168079654158, 0.0054854754658360469, 0.0054836416888628834, 0.0054818090656036369, 0.005479978839447534, 0.0054781487366805477, 0.0054762499925989534, 0.0054739167833702832, 0.0054712752757360558, 0.0054685619594861271, 0.0054657725397037399, 0.0054627240587365412], 'val_acc': [0.60271958838662254, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097748034359226282, 0.0093094348083032456, 0.008883104722490081, 0.0084898416085526073, 0.0081509135789712903, 0.0078382513734940821, 0.0075650395469643323, 0.00733146358998585, 0.0071300030104670554, 0.0069570697814763886, 0.0068086015032651206, 0.0066807061833093666, 0.0065697182574149023, 0.0064732413448034855, 0.0063892761810084965, 0.0063160007406399708, 0.0062519387664174845, 0.0061957686152402918, 0.0061460637523594579, 0.0061021586722905018, 0.0060634725388540502, 0.0060293200689070618, 0.005999092458642958, 0.0059722883431797633, 0.0059485235118309577, 0.0059273890708324527, 0.0059085440895335758, 0.0058917058851833733, 0.0058766159858169133, 0.0058630969520780344, 0.0058509146107530588, 0.0058398953664920306, 0.0058299018520159059, 0.0058207199921367601, 0.0058118384678410148, 0.0058034308982561032, 0.0057955577110361143, 0.0057881783463227298, 0.0057812609762498404, 0.0057746170713264796, 0.0057681314772372412, 0.0057615171351467877, 0.0057546401431145472, 0.0057472230471479497, 0.0057371654211665476, 0.0057219084705716194, 0.0057054051201837668, 0.0056908486866062624, 0.005678074586438272, 0.0056668158426946679, 0.0056567646642387594, 0.0056475875115567804, 0.0056383977781894806, 0.0056295083329077874, 0.0056214189822544926, 0.005614090447439944, 0.0056074477878047214, 0.0056014193940509445, 0.0055959259281722559, 0.0055908783040831021, 0.0055862180880079191, 0.0055818976995600242, 0.0055778705154532916, 0.0055741046395185274, 0.0055705597385836371, 0.0055671933538502085, 0.0055639624067050511, 0.0055608545149704739, 0.0055578776780523679, 0.0055550367649604832, 0.0055523195155481623, 0.0055497127999046894, 0.005547203165523016, 0.0055447727389431548, 0.0055424325896660919, 0.0055401616631370904, 0.005537953869693097, 0.0055357930990082545, 0.0055336836303423211, 0.0055316177845994383, 0.0055295904736284126, 0.0055276006509916752, 0.0055256371018941475, 0.0055237059581238783, 0.0055218012787985136, 0.0055199113236178944, 0.0055180432904126222, 0.0055161885588188775, 0.005514345533573801, 0.0055125101915399132, 0.0055106816430623819, 0.0055088623819754537, 0.0055070378909298353, 0.0055052153884471051, 0.0055033877723209808, 0.0055015471879824055, 0.005499455995164511, 0.0054969406094344002, 0.0054942665839865226, 0.0054915291951093386, 0.0054886199675575386], 'acc': [0.27347489867720176, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822264767316, 0.59383822272449271, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822262938279, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894]}
[2017-11-18 19:14:34,853 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 19:14:34,912 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 19:14:34,912 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 19:14:35,746 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:141]: done!
[2017-11-18 19:14:35,746 AE_UNIGRAMA_2L_9FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_2L_9FULLDS_UNDER_01 finished!
