[2017-10-14 23:14:07,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_2L_OVER_96_134_124_9
[2017-10-14 23:14:07,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:148]: >> Printing header log
[2017-10-14 23:14:07,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_OVER_96_134_124_9
	layers = 96,134,124,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f994c474ef0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f99383c3940>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-14 23:14:07,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:150]: >> Loading dataset... 
[2017-10-14 23:14:07,693 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-14 23:14:07,693 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:152]: >> Executing autoencoder part ... 
[2017-10-14 23:14:07,693 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:60]: =======================================
[2017-10-14 23:14:07,693 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f994c474ef0>, 'discard_decoder_function': True}
[2017-10-14 23:14:07,757 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:76]: training and evaluate autoencoder
[2017-10-14 23:17:22,393 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_2L_OVER_96_134_124_9
[2017-10-14 23:17:22,393 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:148]: >> Printing header log
[2017-10-14 23:17:22,393 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_OVER_96_134_124_9
	layers = 96,134,124,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8eca82cc50>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8eb66c30f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-14 23:17:22,393 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:150]: >> Loading dataset... 
[2017-10-14 23:17:22,905 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-14 23:17:22,905 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:152]: >> Executing autoencoder part ... 
[2017-10-14 23:17:22,905 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:60]: =======================================
[2017-10-14 23:17:22,905 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8eca82cc50>, 'discard_decoder_function': True}
[2017-10-14 23:17:22,968 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:76]: training and evaluate autoencoder
[2017-10-14 23:18:48,961 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_2L_OVER_96_134_124_9
[2017-10-14 23:18:48,961 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:148]: >> Printing header log
[2017-10-14 23:18:48,961 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_OVER_96_134_124_9
	layers = 96,134,124,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fef65115c50>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fef50fc3710>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-14 23:18:48,961 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:150]: >> Loading dataset... 
[2017-10-14 23:18:49,471 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-14 23:18:49,471 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:152]: >> Executing autoencoder part ... 
[2017-10-14 23:18:49,471 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:60]: =======================================
[2017-10-14 23:18:49,471 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fef65115c50>, 'discard_decoder_function': True}
[2017-10-14 23:18:49,536 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:76]: training and evaluate autoencoder
[2017-10-14 23:21:02,993 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_OVER_96_134_124_9
[2017-10-14 23:21:02,993 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:149]: >> Printing header log
[2017-10-14 23:21:02,993 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_OVER_96_134_124_9
	layers = 96,134,124,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f881137bc50>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f87fd203048>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-14 23:21:02,993 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:151]: >> Loading dataset... 
[2017-10-14 23:21:03,507 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-14 23:21:03,507 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:153]: >> Executing autoencoder part ... 
[2017-10-14 23:21:03,507 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:60]: =======================================
[2017-10-14 23:21:03,508 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f881137bc50>, 'discard_decoder_function': True}
[2017-10-14 23:21:03,571 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:76]: training and evaluate autoencoder
[2017-10-14 23:22:51,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_OVER_96_134_124_9
[2017-10-14 23:22:51,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:149]: >> Printing header log
[2017-10-14 23:22:51,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_OVER_96_134_124_9
	layers = 96,134,124,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0c6632cbe0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0c521c3780>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-14 23:22:51,150 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:151]: >> Loading dataset... 
[2017-10-14 23:22:51,664 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-14 23:22:51,664 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:153]: >> Executing autoencoder part ... 
[2017-10-14 23:22:51,664 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:60]: =======================================
[2017-10-14 23:22:51,664 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0c6632cbe0>, 'discard_decoder_function': True}
[2017-10-14 23:22:51,729 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:76]: training and evaluate autoencoder
[2017-10-14 23:23:36,936 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:88]: trained and evaluated!
[2017-10-14 23:23:36,936 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:91]: Training history: 
{'val_loss': [0.0095331664006727771, 0.0093649206960012919, 0.0091971251767364141, 0.0090337011748474767, 0.0088766616696429514, 0.0087263897739932438, 0.0085832031000557894, 0.0084469185719702761, 0.008317056790575884, 0.0081940364199915555, 0.0080777917431189665, 0.0079673846809671274, 0.007862663848609508, 0.0077635129034297617, 0.0076697860363192276, 0.0075810689004795926, 0.0074969680207784958, 0.0074172752241164338, 0.0073417331954138869, 0.0072701222758366274, 0.0072022452379220262, 0.0071378115090268033, 0.0070766349596604978, 0.0070184953060679718, 0.0069632177867798555, 0.0069105624027384037, 0.0068605425109789049, 0.0068130341140366394, 0.0067678292603907085, 0.0067248062930004085, 0.0066837113104816041, 0.0066443576536324832, 0.0066068166482598145, 0.0065709912412034756, 0.0065368732409794095, 0.0065043808019903514, 0.0064733976577876001, 0.0064438448104051855, 0.0064156586027333731, 0.0063887108100031164, 0.0063629738976105658, 0.0063384052861107992, 0.0063149022063081145, 0.0062923863197791091, 0.0062708418615522437, 0.0062501639747458981, 0.0062303121450969943, 0.0062112381515615931, 0.0061928953483811541, 0.006175227767915974, 0.0061582181356902681, 0.0061419116831678885, 0.0061263073076490574, 0.0061113687342926031, 0.0060970792304516725, 0.0060834386576396381, 0.0060703673964317842, 0.006057851059798525, 0.0060458598298377261, 0.0060343606376736577, 0.0060233225142340896, 0.0060127426499715529, 0.006002586643076519, 0.0059928356905270463, 0.005983476835167984, 0.0059744860305274289, 0.0059658310663467445, 0.0059575209684919247, 0.0059495320211278907, 0.0059418515527281616, 0.0059344603240379171, 0.0059273537753849227, 0.005920506516976981, 0.0059139213341264036, 0.005907560705612362, 0.0059014493461047408, 0.0058955604099706644, 0.0058898725564207289, 0.0058843898933145415, 0.0058791059412089865, 0.0058740152973944812, 0.0058691110271531189, 0.0058643711613124185, 0.0058597990685596117, 0.0058553788731338591, 0.0058511187872922112, 0.0058469969180298337, 0.0058430244464108714, 0.0058391859329073627, 0.0058354899861943321, 0.0058319212844574536, 0.005828478276646492, 0.0058251479744468038, 0.0058219323876455816, 0.0058188197968119136, 0.0058158200050679948, 0.0058129090836555545, 0.0058100894941744089, 0.0058073668297532544, 0.0058047268435802157, 0.0058021687116598551, 0.0057996869412662811], 'loss': [0.009613726890262974, 0.0094466480279379126, 0.0092776554688747195, 0.0091109089301492658, 0.0089499460837787186, 0.0087955556746936309, 0.0086480802057863886, 0.0085077285022459367, 0.0083740209306566796, 0.0082469467364466847, 0.008126699159605304, 0.0080128632114940292, 0.0079047977014203782, 0.0078023733180783315, 0.0077054923538807793, 0.007613842213010048, 0.0075270073710452506, 0.007444637003008416, 0.0073665908813137695, 0.0072925688519148869, 0.0072223696094658859, 0.0071557933002705763, 0.0070925589508337517, 0.00703251184168665, 0.0069754357474324305, 0.0069210808294852162, 0.0068693546922883155, 0.0068202070773366813, 0.0067735109884651369, 0.0067290230056004209, 0.0066866011037671575, 0.0066460322476488429, 0.0066072482898483342, 0.006570252244427718, 0.0065349460838187417, 0.006501316529090191, 0.0064692683635278391, 0.006438699046913454, 0.0064095163640017225, 0.00638167510929929, 0.0063550417545035747, 0.006329569594960914, 0.0063052520510232845, 0.0062819874276462588, 0.0062597020404423645, 0.0062383608849628722, 0.0062178650048928313, 0.0061981432090073216, 0.0061792019784986316, 0.0061609286055903023, 0.0061433490648517674, 0.0061264304712085032, 0.0061102184909496045, 0.0060947014178597608, 0.006079836079384845, 0.0060656211575345533, 0.0060520377917388096, 0.0060390165180412075, 0.0060265243958427667, 0.0060145561566167655, 0.0060030610143758248, 0.0059920264300377954, 0.0059814305358395188, 0.0059712632652543845, 0.0059614873344688854, 0.0059521078308397406, 0.0059430772222844128, 0.0059343850169704055, 0.0059260288677015181, 0.0059179857166595049, 0.0059102593034450895, 0.0059028135280032685, 0.0058956508259686794, 0.0058887410641618679, 0.0058820874401045928, 0.005875655796239181, 0.0058694826937025872, 0.0058635138484667108, 0.0058577471654850718, 0.0058521911448649669, 0.00584683364363686, 0.0058416721903900466, 0.0058366794324609932, 0.0058318564943630382, 0.0058272086557850343, 0.0058227009915580172, 0.0058183583136723503, 0.0058141499918043507, 0.0058100976916539504, 0.0058061807698581071, 0.0058024028065993914, 0.0057987533372351194, 0.0057952220914582022, 0.0057918129253562382, 0.005788502299422015, 0.005785302804255218, 0.0057822205229320625, 0.0057792180348313618, 0.0057763150202244356, 0.0057735029140346499, 0.0057707784964159802, 0.0057681341702490591]}
[2017-10-14 23:23:36,936 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:95]: done!
[2017-10-14 23:23:36,937 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:155]: >> Executing classifier part ... 
[2017-10-14 23:23:36,937 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:100]: =======================================
[2017-10-14 23:23:36,937 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0c521c3780>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-14 23:23:36,980 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:113]: training ... 
[2017-10-14 23:24:51,060 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:125]: trained!
[2017-10-14 23:24:51,062 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:128]: Training history: 
{'val_loss': [0.0095331664006727771, 0.0093649206960012919, 0.0091971251767364141, 0.0090337011748474767, 0.0088766616696429514, 0.0087263897739932438, 0.0085832031000557894, 0.0084469185719702761, 0.008317056790575884, 0.0081940364199915555, 0.0080777917431189665, 0.0079673846809671274, 0.007862663848609508, 0.0077635129034297617, 0.0076697860363192276, 0.0075810689004795926, 0.0074969680207784958, 0.0074172752241164338, 0.0073417331954138869, 0.0072701222758366274, 0.0072022452379220262, 0.0071378115090268033, 0.0070766349596604978, 0.0070184953060679718, 0.0069632177867798555, 0.0069105624027384037, 0.0068605425109789049, 0.0068130341140366394, 0.0067678292603907085, 0.0067248062930004085, 0.0066837113104816041, 0.0066443576536324832, 0.0066068166482598145, 0.0065709912412034756, 0.0065368732409794095, 0.0065043808019903514, 0.0064733976577876001, 0.0064438448104051855, 0.0064156586027333731, 0.0063887108100031164, 0.0063629738976105658, 0.0063384052861107992, 0.0063149022063081145, 0.0062923863197791091, 0.0062708418615522437, 0.0062501639747458981, 0.0062303121450969943, 0.0062112381515615931, 0.0061928953483811541, 0.006175227767915974, 0.0061582181356902681, 0.0061419116831678885, 0.0061263073076490574, 0.0061113687342926031, 0.0060970792304516725, 0.0060834386576396381, 0.0060703673964317842, 0.006057851059798525, 0.0060458598298377261, 0.0060343606376736577, 0.0060233225142340896, 0.0060127426499715529, 0.006002586643076519, 0.0059928356905270463, 0.005983476835167984, 0.0059744860305274289, 0.0059658310663467445, 0.0059575209684919247, 0.0059495320211278907, 0.0059418515527281616, 0.0059344603240379171, 0.0059273537753849227, 0.005920506516976981, 0.0059139213341264036, 0.005907560705612362, 0.0059014493461047408, 0.0058955604099706644, 0.0058898725564207289, 0.0058843898933145415, 0.0058791059412089865, 0.0058740152973944812, 0.0058691110271531189, 0.0058643711613124185, 0.0058597990685596117, 0.0058553788731338591, 0.0058511187872922112, 0.0058469969180298337, 0.0058430244464108714, 0.0058391859329073627, 0.0058354899861943321, 0.0058319212844574536, 0.005828478276646492, 0.0058251479744468038, 0.0058219323876455816, 0.0058188197968119136, 0.0058158200050679948, 0.0058129090836555545, 0.0058100894941744089, 0.0058073668297532544, 0.0058047268435802157, 0.0058021687116598551, 0.0057996869412662811], 'loss': [0.009613726890262974, 0.0094466480279379126, 0.0092776554688747195, 0.0091109089301492658, 0.0089499460837787186, 0.0087955556746936309, 0.0086480802057863886, 0.0085077285022459367, 0.0083740209306566796, 0.0082469467364466847, 0.008126699159605304, 0.0080128632114940292, 0.0079047977014203782, 0.0078023733180783315, 0.0077054923538807793, 0.007613842213010048, 0.0075270073710452506, 0.007444637003008416, 0.0073665908813137695, 0.0072925688519148869, 0.0072223696094658859, 0.0071557933002705763, 0.0070925589508337517, 0.00703251184168665, 0.0069754357474324305, 0.0069210808294852162, 0.0068693546922883155, 0.0068202070773366813, 0.0067735109884651369, 0.0067290230056004209, 0.0066866011037671575, 0.0066460322476488429, 0.0066072482898483342, 0.006570252244427718, 0.0065349460838187417, 0.006501316529090191, 0.0064692683635278391, 0.006438699046913454, 0.0064095163640017225, 0.00638167510929929, 0.0063550417545035747, 0.006329569594960914, 0.0063052520510232845, 0.0062819874276462588, 0.0062597020404423645, 0.0062383608849628722, 0.0062178650048928313, 0.0061981432090073216, 0.0061792019784986316, 0.0061609286055903023, 0.0061433490648517674, 0.0061264304712085032, 0.0061102184909496045, 0.0060947014178597608, 0.006079836079384845, 0.0060656211575345533, 0.0060520377917388096, 0.0060390165180412075, 0.0060265243958427667, 0.0060145561566167655, 0.0060030610143758248, 0.0059920264300377954, 0.0059814305358395188, 0.0059712632652543845, 0.0059614873344688854, 0.0059521078308397406, 0.0059430772222844128, 0.0059343850169704055, 0.0059260288677015181, 0.0059179857166595049, 0.0059102593034450895, 0.0059028135280032685, 0.0058956508259686794, 0.0058887410641618679, 0.0058820874401045928, 0.005875655796239181, 0.0058694826937025872, 0.0058635138484667108, 0.0058577471654850718, 0.0058521911448649669, 0.00584683364363686, 0.0058416721903900466, 0.0058366794324609932, 0.0058318564943630382, 0.0058272086557850343, 0.0058227009915580172, 0.0058183583136723503, 0.0058141499918043507, 0.0058100976916539504, 0.0058061807698581071, 0.0058024028065993914, 0.0057987533372351194, 0.0057952220914582022, 0.0057918129253562382, 0.005788502299422015, 0.005785302804255218, 0.0057822205229320625, 0.0057792180348313618, 0.0057763150202244356, 0.0057735029140346499, 0.0057707784964159802, 0.0057681341702490591]}
[2017-10-14 23:24:51,062 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:132]: evaluating model ... 
[2017-10-14 23:24:51,139 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:136]: evaluated! 
[2017-10-14 23:24:51,139 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:138]: generating reports ... 
[2017-10-14 23:24:51,710 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:141]: done!
[2017-10-14 23:24:51,710 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:157]: >> experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 finished!
[2017-10-14 23:24:51,710 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:309]: The experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 was already executed!
[2017-10-14 23:47:25,547 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:146]: The experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 was already executed!
[2017-10-14 23:47:25,547 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:309]: The experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 was already executed!
[2017-10-14 23:49:25,381 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:146]: The experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 was already executed!
[2017-10-14 23:49:25,381 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:309]: The experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 was already executed!
[2017-10-15 01:05:15,408 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_OVER_96_134_124_9
[2017-10-15 01:05:15,409 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:149]: >> Printing header log
[2017-10-15 01:05:15,409 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_OVER_96_134_124_9
	layers = 96,134,124,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6dbd7b1c50>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6da9643518>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 01:05:15,409 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:151]: >> Loading dataset... 
[2017-10-15 01:05:15,930 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 01:05:15,930 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:153]: >> Executing autoencoder part ... 
[2017-10-15 01:05:15,930 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:60]: =======================================
[2017-10-15 01:05:15,930 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6dbd7b1c50>, 'discard_decoder_function': True}
[2017-10-15 01:05:15,995 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:76]: training and evaluate autoencoder
[2017-10-15 01:05:56,513 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:88]: trained and evaluated!
[2017-10-15 01:05:56,513 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:91]: Training history: 
{'val_loss': [0.010136136899401042, 0.010102285404575358, 0.010067678735241793, 0.010030871849216272, 0.0099916530212172793, 0.009950322227130149, 0.0099048704033558258, 0.0098579445763813077, 0.0098094570287762962, 0.009759448198636226, 0.0097112278332829923, 0.009664714281000613, 0.0096198632468410591, 0.0095765700487620772, 0.0095347873554963158, 0.0094943775286461789, 0.0094551428058444343, 0.0094164518507883002, 0.009378831245032828, 0.0093425888443524948, 0.0093077375557010494, 0.0092742365012880145, 0.0092422016048076868, 0.0092116351997597514, 0.0091824065443806939, 0.0091543955188313833, 0.0091274552511182855, 0.0091016990613870911, 0.009077060427585942, 0.009053526875531806, 0.0090309736079996848, 0.0090092424732601782, 0.0089883413027321089, 0.0089682927251305278, 0.0089490714424106266, 0.0089306275024456164, 0.0089129113339469334, 0.0088957857312876934, 0.00887919054280094, 0.0088632019846025013, 0.0088477572356956604, 0.0088328282006057222, 0.0088184166381128654, 0.0088045009754625838, 0.0087910461339919532, 0.0087779799760163493, 0.0087651883885541369, 0.0087523839045246729, 0.0087396567756635544, 0.0087270918284927165, 0.0087147146951559538, 0.0087023374527609703, 0.0086891511697529868, 0.0086743012624602329, 0.0086594398434665116, 0.0086447845393147829, 0.0086304429039137515, 0.0086164598415526088, 0.0086028900804157368, 0.0085897863181273286, 0.0085771173190283944, 0.0085648669373091704, 0.0085530431844210979, 0.0085416301897965844, 0.0085305996138782536, 0.0085199286115657004, 0.0085096039920075899, 0.0084996159157289895, 0.0084899334171198333, 0.0084805249991276224, 0.0084713776059254838, 0.0084624111957044851, 0.0084534976112078108, 0.0084445911206886669, 0.008435807014265025, 0.0084271428580343938, 0.008418553032770365, 0.0084101091620259576, 0.0084018167991149594, 0.0083937366184913542, 0.0083858929280205517, 0.0083782254652462924, 0.0083705651206847243, 0.0083627782218490612, 0.0083551195512446101, 0.0083477051970185408, 0.0083405494336800511, 0.0083336506669018356, 0.0083269864756987892, 0.0083205660763560167, 0.008314374181680852, 0.0083083924646991329, 0.0083026207280674173, 0.0082970341099737749, 0.0082916390310045062, 0.0082864055382330173, 0.0082813395433072486, 0.0082764272685387757, 0.0082716612391118445, 0.0082670362963995526, 0.0082625422114333252, 0.0082581757384328144], 'loss': [0.010147732093508945, 0.010114499857762546, 0.010080367835615226, 0.01004476236269913, 0.010006802037504823, 0.0099669643537528916, 0.00992419579270689, 0.0098781858959544923, 0.0098314161928165673, 0.0097820847675882013, 0.0097333575812407116, 0.0096863438074775241, 0.009641027613242455, 0.0095972868905259048, 0.0095551382422850179, 0.0095144548976007388, 0.009475114474848105, 0.0094366505136455805, 0.00939894025400052, 0.0093625046257856948, 0.0093275218550631003, 0.0092938772838313151, 0.0092616481580568306, 0.009230858481477101, 0.0092014463454686436, 0.0091732679726012154, 0.0091462408953198061, 0.0091202926948510867, 0.0090954818939715711, 0.0090717615298674965, 0.0090490933484784208, 0.0090273094243875449, 0.0090063575697580806, 0.008986221294971463, 0.0089669251738925537, 0.0089484259718599756, 0.0089306707872328535, 0.0089135903924630333, 0.0088970480411191544, 0.0088810609354790394, 0.0088656722174724999, 0.0088507857313351018, 0.0088363988960382753, 0.0088225142576931516, 0.0088091095532825854, 0.008796109317057179, 0.0087834412361407609, 0.008770896114418128, 0.0087583356582145791, 0.0087458834649689291, 0.0087335851322802287, 0.0087214161784427615, 0.0087088704625512096, 0.0086949066297318869, 0.0086799862942834091, 0.0086651669629719558, 0.0086505767570484535, 0.0086363406517596126, 0.0086224808236876008, 0.0086090731656049465, 0.008596135254722654, 0.0085836212953853703, 0.0085715315806706334, 0.008559870247436617, 0.0085486078551285233, 0.0085377194125894462, 0.0085271838027812172, 0.0085169782286215641, 0.0085071044113686212, 0.008497525743805856, 0.0084882110377891562, 0.008479130659859167, 0.0084701783882972642, 0.0084612526270871746, 0.0084523881145036877, 0.0084436454191419274, 0.0084349931284702848, 0.0084264642812572673, 0.0084180736824980007, 0.0084098744937107107, 0.0084018885634825798, 0.0083941355371674881, 0.0083864742715985558, 0.0083787627523901204, 0.0083710226363696485, 0.0083635115272467971, 0.0083562548878501359, 0.0083492441405098577, 0.0083424877106328277, 0.0083359627055431262, 0.008329687848430729, 0.0083236305372813551, 0.0083177861005992847, 0.0083121329691368661, 0.0083066729116628487, 0.0083013941484063256, 0.0082962779607566577, 0.008291317303976949, 0.0082865046702448979, 0.0082818350469042127, 0.0082773065667304073, 0.008272899177953482]}
[2017-10-15 01:05:56,514 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:95]: done!
[2017-10-15 01:05:56,514 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:155]: >> Executing classifier part ... 
[2017-10-15 01:05:56,514 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:100]: =======================================
[2017-10-15 01:05:56,514 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f6da9643518>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 01:05:56,571 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:113]: training ... 
[2017-10-15 01:06:31,444 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:125]: trained!
[2017-10-15 01:06:31,445 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:128]: Training history: 
{'val_loss': [0.010136136899401042, 0.010102285404575358, 0.010067678735241793, 0.010030871849216272, 0.0099916530212172793, 0.009950322227130149, 0.0099048704033558258, 0.0098579445763813077, 0.0098094570287762962, 0.009759448198636226, 0.0097112278332829923, 0.009664714281000613, 0.0096198632468410591, 0.0095765700487620772, 0.0095347873554963158, 0.0094943775286461789, 0.0094551428058444343, 0.0094164518507883002, 0.009378831245032828, 0.0093425888443524948, 0.0093077375557010494, 0.0092742365012880145, 0.0092422016048076868, 0.0092116351997597514, 0.0091824065443806939, 0.0091543955188313833, 0.0091274552511182855, 0.0091016990613870911, 0.009077060427585942, 0.009053526875531806, 0.0090309736079996848, 0.0090092424732601782, 0.0089883413027321089, 0.0089682927251305278, 0.0089490714424106266, 0.0089306275024456164, 0.0089129113339469334, 0.0088957857312876934, 0.00887919054280094, 0.0088632019846025013, 0.0088477572356956604, 0.0088328282006057222, 0.0088184166381128654, 0.0088045009754625838, 0.0087910461339919532, 0.0087779799760163493, 0.0087651883885541369, 0.0087523839045246729, 0.0087396567756635544, 0.0087270918284927165, 0.0087147146951559538, 0.0087023374527609703, 0.0086891511697529868, 0.0086743012624602329, 0.0086594398434665116, 0.0086447845393147829, 0.0086304429039137515, 0.0086164598415526088, 0.0086028900804157368, 0.0085897863181273286, 0.0085771173190283944, 0.0085648669373091704, 0.0085530431844210979, 0.0085416301897965844, 0.0085305996138782536, 0.0085199286115657004, 0.0085096039920075899, 0.0084996159157289895, 0.0084899334171198333, 0.0084805249991276224, 0.0084713776059254838, 0.0084624111957044851, 0.0084534976112078108, 0.0084445911206886669, 0.008435807014265025, 0.0084271428580343938, 0.008418553032770365, 0.0084101091620259576, 0.0084018167991149594, 0.0083937366184913542, 0.0083858929280205517, 0.0083782254652462924, 0.0083705651206847243, 0.0083627782218490612, 0.0083551195512446101, 0.0083477051970185408, 0.0083405494336800511, 0.0083336506669018356, 0.0083269864756987892, 0.0083205660763560167, 0.008314374181680852, 0.0083083924646991329, 0.0083026207280674173, 0.0082970341099737749, 0.0082916390310045062, 0.0082864055382330173, 0.0082813395433072486, 0.0082764272685387757, 0.0082716612391118445, 0.0082670362963995526, 0.0082625422114333252, 0.0082581757384328144], 'loss': [0.010147732093508945, 0.010114499857762546, 0.010080367835615226, 0.01004476236269913, 0.010006802037504823, 0.0099669643537528916, 0.00992419579270689, 0.0098781858959544923, 0.0098314161928165673, 0.0097820847675882013, 0.0097333575812407116, 0.0096863438074775241, 0.009641027613242455, 0.0095972868905259048, 0.0095551382422850179, 0.0095144548976007388, 0.009475114474848105, 0.0094366505136455805, 0.00939894025400052, 0.0093625046257856948, 0.0093275218550631003, 0.0092938772838313151, 0.0092616481580568306, 0.009230858481477101, 0.0092014463454686436, 0.0091732679726012154, 0.0091462408953198061, 0.0091202926948510867, 0.0090954818939715711, 0.0090717615298674965, 0.0090490933484784208, 0.0090273094243875449, 0.0090063575697580806, 0.008986221294971463, 0.0089669251738925537, 0.0089484259718599756, 0.0089306707872328535, 0.0089135903924630333, 0.0088970480411191544, 0.0088810609354790394, 0.0088656722174724999, 0.0088507857313351018, 0.0088363988960382753, 0.0088225142576931516, 0.0088091095532825854, 0.008796109317057179, 0.0087834412361407609, 0.008770896114418128, 0.0087583356582145791, 0.0087458834649689291, 0.0087335851322802287, 0.0087214161784427615, 0.0087088704625512096, 0.0086949066297318869, 0.0086799862942834091, 0.0086651669629719558, 0.0086505767570484535, 0.0086363406517596126, 0.0086224808236876008, 0.0086090731656049465, 0.008596135254722654, 0.0085836212953853703, 0.0085715315806706334, 0.008559870247436617, 0.0085486078551285233, 0.0085377194125894462, 0.0085271838027812172, 0.0085169782286215641, 0.0085071044113686212, 0.008497525743805856, 0.0084882110377891562, 0.008479130659859167, 0.0084701783882972642, 0.0084612526270871746, 0.0084523881145036877, 0.0084436454191419274, 0.0084349931284702848, 0.0084264642812572673, 0.0084180736824980007, 0.0084098744937107107, 0.0084018885634825798, 0.0083941355371674881, 0.0083864742715985558, 0.0083787627523901204, 0.0083710226363696485, 0.0083635115272467971, 0.0083562548878501359, 0.0083492441405098577, 0.0083424877106328277, 0.0083359627055431262, 0.008329687848430729, 0.0083236305372813551, 0.0083177861005992847, 0.0083121329691368661, 0.0083066729116628487, 0.0083013941484063256, 0.0082962779607566577, 0.008291317303976949, 0.0082865046702448979, 0.0082818350469042127, 0.0082773065667304073, 0.008272899177953482]}
[2017-10-15 01:06:31,445 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:132]: evaluating model ... 
[2017-10-15 01:06:31,518 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:136]: evaluated! 
[2017-10-15 01:06:31,518 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:138]: generating reports ... 
[2017-10-15 01:06:32,105 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:141]: done!
[2017-10-15 01:06:32,105 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:157]: >> experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 finished!
[2017-10-15 01:06:32,105 AE_UNIGRAMA_2L_OVER_96_134_124_9.py:309]: The experiment AE_UNIGRAMA_2L_OVER_96_134_124_9 was already executed!
