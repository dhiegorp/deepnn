[2017-11-18 17:53:08,061 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_9FULLDS_OVER_04
[2017-11-18 17:53:08,062 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 17:53:08,062 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_9FULLDS_OVER_04
	layers = 96,134,122,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f183dfd62e8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f183dfd67f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:53:08,062 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 17:53:10,199 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:53:10,200 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:53:10,200 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 17:53:10,200 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f183dfd62e8>, 'discard_decoder_function': True}
[2017-11-18 17:53:10,279 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 17:55:09,665 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 17:55:09,666 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0093935510189502129, 0.0088044704078056278, 0.0082969331622016924, 0.007876956107033959, 0.0075330817303560383, 0.0072549705231717649, 0.0070289482820528543, 0.0068448387979379542, 0.0066917909842185768, 0.0065644187566943025, 0.0064586898945518407, 0.0063704827883222966, 0.0062963507772765253, 0.0062336383285791566, 0.0061802779158693011, 0.0061342977095177643, 0.006093753900691095, 0.0060567865582872339, 0.0060244491426510345, 0.0059968053518312898, 0.0059731011010243674, 0.0059525781019821146, 0.0059347942208639185, 0.0059192584101411894, 0.0059056877713405398, 0.0058937204213801312, 0.0058831147831077089, 0.0058736430731106057, 0.0058651114873881074, 0.0058573996003865045, 0.0058503844894199075, 0.0058439847177564714, 0.0058381301572512818, 0.005832694237196092, 0.0058276676313588115, 0.0058230124863199355, 0.0058186321106192731, 0.0058138900803034466, 0.0058092108599256996, 0.0058049253971534636, 0.0058010055693650244, 0.0057973933847876415, 0.0057940255307709848, 0.0057908730192581595, 0.0057878994551658061, 0.0057850695167760919, 0.0057823633596620081, 0.0057797553626124263, 0.0057772062312420056, 0.0057747394864942686, 0.0057723383953673674, 0.0057699994584706361, 0.0057677062890105274, 0.0057654528215819153, 0.0057632358664648801, 0.0057610367824046573, 0.0057588576057495244, 0.0057566945514826873, 0.0057545421209161673, 0.0057523932670938242, 0.0057502406081461985, 0.0057480726486913245, 0.0057458761474168977, 0.0057436249605477543, 0.0057413086374021602, 0.0057389287836644327, 0.0057364777739384639, 0.0057339064956761455, 0.0057312212836508015, 0.0057284637019401011, 0.0057256701812237083, 0.0057228334808194356, 0.0057199130455824008, 0.005716918752118343, 0.0057139346380853254, 0.0057108352058839211, 0.0057076565932088182, 0.0057044439778472572, 0.0057012159162560718, 0.0056979281554674233, 0.0056946659906473296, 0.0056914536029823298, 0.0056882531630975362, 0.0056850602737368141, 0.0056817029225983981, 0.0056781918860359945, 0.0056745041413687903, 0.0056697785428553018, 0.0056647668814766459, 0.0056601748776097414, 0.0056558985446053681, 0.0056518666624703886, 0.0056480349043917452, 0.0056443639146318081, 0.0056408129821407232, 0.0056373684278400787, 0.0056340041498830545, 0.0056306985791331754, 0.0056274392273624792, 0.0056242168432964817, 0.0056210136709673869], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097297418879042589, 0.0090923082569072892, 0.0085452215807089206, 0.0080816180495438036, 0.0077004304630228044, 0.0073907435603020955, 0.0071396722967689667, 0.0069357270350430779, 0.006768391253404951, 0.0066287899912853164, 0.006513076437479684, 0.0064168820584955813, 0.0063364272439909285, 0.006268724589331396, 0.0062113066209150709, 0.0061622302875433055, 0.0061196475224031014, 0.0060812954382100538, 0.0060469951771901136, 0.0060175150825821635, 0.0059922882770140715, 0.0059705976589076561, 0.0059517991875517916, 0.0059354838680138033, 0.0059212133283467949, 0.0059087069998231788, 0.0058976573448564626, 0.0058878187148001743, 0.0058790214846284024, 0.0058710851761549837, 0.0058638860453942175, 0.0058573482459134615, 0.0058513729039950469, 0.0058458806172162351, 0.0058407752502129366, 0.0058360492728986198, 0.0058316453925879317, 0.0058271934961225888, 0.0058224890498270454, 0.0058180523923230939, 0.0058140111029147184, 0.005810306262788713, 0.0058068733086106021, 0.0058036694442390353, 0.0058006501963060991, 0.0057977970661642333, 0.0057950756562080603, 0.0057924683080037105, 0.0057899290586615852, 0.0057874577766625235, 0.0057850612844845203, 0.0057827178883245456, 0.0057804279021481638, 0.0057781818087348892, 0.005775972117894052, 0.0057737832437188795, 0.0057716149554649741, 0.0057694636538169336, 0.0057673244585621586, 0.0057651878260162924, 0.0057630589691622797, 0.0057609243260938192, 0.0057587628611181141, 0.0057565595369822144, 0.0057542934319080091, 0.0057519543249531799, 0.0057495491629702133, 0.0057470484109618507, 0.0057444008909407294, 0.0057416542652572343, 0.0057388434601083217, 0.0057359960237573964, 0.0057331097247226483, 0.0057301197126823269, 0.0057271485516077409, 0.0057241281869908015, 0.0057210049921642371, 0.0057178431890614083, 0.0057146514385135695, 0.0057114168099178355, 0.0057081588888839227, 0.0057049447860227191, 0.0057017405612737847, 0.0056985585370281765, 0.0056952951418591871, 0.0056918326408522393, 0.0056882043180152058, 0.0056841122934749534, 0.0056789984490584781, 0.0056741814470512818, 0.0056697338634542462, 0.0056655693836295271, 0.0056616222223890428, 0.0056578638153823996, 0.0056542456322098691, 0.0056507406927525407, 0.0056473337418734811, 0.005643998090384913, 0.005640722287317405, 0.0056374877313687174, 0.0056342797345175794], 'acc': [0.30563397572218193, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822264767316, 0.59383822265133124, 0.59383822264767316, 0.59383822265133124, 0.59383822264767316, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822267327968, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822272449271, 0.59383822262206665, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182]}
[2017-11-18 17:55:09,666 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 17:55:09,666 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 17:55:09,667 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 17:55:09,667 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f183dfd67f0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:55:09,716 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 18:00:14,493 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:125]: trained!
[2017-11-18 18:00:14,494 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0093935510189502129, 0.0088044704078056278, 0.0082969331622016924, 0.007876956107033959, 0.0075330817303560383, 0.0072549705231717649, 0.0070289482820528543, 0.0068448387979379542, 0.0066917909842185768, 0.0065644187566943025, 0.0064586898945518407, 0.0063704827883222966, 0.0062963507772765253, 0.0062336383285791566, 0.0061802779158693011, 0.0061342977095177643, 0.006093753900691095, 0.0060567865582872339, 0.0060244491426510345, 0.0059968053518312898, 0.0059731011010243674, 0.0059525781019821146, 0.0059347942208639185, 0.0059192584101411894, 0.0059056877713405398, 0.0058937204213801312, 0.0058831147831077089, 0.0058736430731106057, 0.0058651114873881074, 0.0058573996003865045, 0.0058503844894199075, 0.0058439847177564714, 0.0058381301572512818, 0.005832694237196092, 0.0058276676313588115, 0.0058230124863199355, 0.0058186321106192731, 0.0058138900803034466, 0.0058092108599256996, 0.0058049253971534636, 0.0058010055693650244, 0.0057973933847876415, 0.0057940255307709848, 0.0057908730192581595, 0.0057878994551658061, 0.0057850695167760919, 0.0057823633596620081, 0.0057797553626124263, 0.0057772062312420056, 0.0057747394864942686, 0.0057723383953673674, 0.0057699994584706361, 0.0057677062890105274, 0.0057654528215819153, 0.0057632358664648801, 0.0057610367824046573, 0.0057588576057495244, 0.0057566945514826873, 0.0057545421209161673, 0.0057523932670938242, 0.0057502406081461985, 0.0057480726486913245, 0.0057458761474168977, 0.0057436249605477543, 0.0057413086374021602, 0.0057389287836644327, 0.0057364777739384639, 0.0057339064956761455, 0.0057312212836508015, 0.0057284637019401011, 0.0057256701812237083, 0.0057228334808194356, 0.0057199130455824008, 0.005716918752118343, 0.0057139346380853254, 0.0057108352058839211, 0.0057076565932088182, 0.0057044439778472572, 0.0057012159162560718, 0.0056979281554674233, 0.0056946659906473296, 0.0056914536029823298, 0.0056882531630975362, 0.0056850602737368141, 0.0056817029225983981, 0.0056781918860359945, 0.0056745041413687903, 0.0056697785428553018, 0.0056647668814766459, 0.0056601748776097414, 0.0056558985446053681, 0.0056518666624703886, 0.0056480349043917452, 0.0056443639146318081, 0.0056408129821407232, 0.0056373684278400787, 0.0056340041498830545, 0.0056306985791331754, 0.0056274392273624792, 0.0056242168432964817, 0.0056210136709673869], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097297418879042589, 0.0090923082569072892, 0.0085452215807089206, 0.0080816180495438036, 0.0077004304630228044, 0.0073907435603020955, 0.0071396722967689667, 0.0069357270350430779, 0.006768391253404951, 0.0066287899912853164, 0.006513076437479684, 0.0064168820584955813, 0.0063364272439909285, 0.006268724589331396, 0.0062113066209150709, 0.0061622302875433055, 0.0061196475224031014, 0.0060812954382100538, 0.0060469951771901136, 0.0060175150825821635, 0.0059922882770140715, 0.0059705976589076561, 0.0059517991875517916, 0.0059354838680138033, 0.0059212133283467949, 0.0059087069998231788, 0.0058976573448564626, 0.0058878187148001743, 0.0058790214846284024, 0.0058710851761549837, 0.0058638860453942175, 0.0058573482459134615, 0.0058513729039950469, 0.0058458806172162351, 0.0058407752502129366, 0.0058360492728986198, 0.0058316453925879317, 0.0058271934961225888, 0.0058224890498270454, 0.0058180523923230939, 0.0058140111029147184, 0.005810306262788713, 0.0058068733086106021, 0.0058036694442390353, 0.0058006501963060991, 0.0057977970661642333, 0.0057950756562080603, 0.0057924683080037105, 0.0057899290586615852, 0.0057874577766625235, 0.0057850612844845203, 0.0057827178883245456, 0.0057804279021481638, 0.0057781818087348892, 0.005775972117894052, 0.0057737832437188795, 0.0057716149554649741, 0.0057694636538169336, 0.0057673244585621586, 0.0057651878260162924, 0.0057630589691622797, 0.0057609243260938192, 0.0057587628611181141, 0.0057565595369822144, 0.0057542934319080091, 0.0057519543249531799, 0.0057495491629702133, 0.0057470484109618507, 0.0057444008909407294, 0.0057416542652572343, 0.0057388434601083217, 0.0057359960237573964, 0.0057331097247226483, 0.0057301197126823269, 0.0057271485516077409, 0.0057241281869908015, 0.0057210049921642371, 0.0057178431890614083, 0.0057146514385135695, 0.0057114168099178355, 0.0057081588888839227, 0.0057049447860227191, 0.0057017405612737847, 0.0056985585370281765, 0.0056952951418591871, 0.0056918326408522393, 0.0056882043180152058, 0.0056841122934749534, 0.0056789984490584781, 0.0056741814470512818, 0.0056697338634542462, 0.0056655693836295271, 0.0056616222223890428, 0.0056578638153823996, 0.0056542456322098691, 0.0056507406927525407, 0.0056473337418734811, 0.005643998090384913, 0.005640722287317405, 0.0056374877313687174, 0.0056342797345175794], 'acc': [0.30563397572218193, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.59383822264767316, 0.59383822265133124, 0.59383822264767316, 0.59383822265133124, 0.59383822264767316, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822267327968, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822272449271, 0.59383822262206665, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182]}
[2017-11-18 18:00:14,494 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 18:00:14,590 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 18:00:14,590 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 18:00:15,414 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:141]: done!
[2017-11-18 18:00:15,414 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_2L_9FULLDS_OVER_04 finished!
[2017-11-18 18:00:15,415 AE_UNIGRAMA_2L_9FULLDS_OVER_04.py:309]: The experiment AE_UNIGRAMA_2L_9FULLDS_OVER_04 was already executed!
