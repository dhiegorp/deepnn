[2017-10-20 01:37:35,143 AE_UNIGRAMA_2L_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_03
[2017-10-20 01:37:35,144 AE_UNIGRAMA_2L_UNDER_03.py:149]: >> Printing header log
[2017-10-20 01:37:35,144 AE_UNIGRAMA_2L_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_03
	layers = 96,86,78,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe4e48637b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe4e4863898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:37:35,144 AE_UNIGRAMA_2L_UNDER_03.py:151]: >> Loading dataset... 
[2017-10-20 01:37:35,740 AE_UNIGRAMA_2L_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:37:35,740 AE_UNIGRAMA_2L_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:37:35,740 AE_UNIGRAMA_2L_UNDER_03.py:60]: =======================================
[2017-10-20 01:37:35,740 AE_UNIGRAMA_2L_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe4e48637b8>, 'discard_decoder_function': True}
[2017-10-20 01:37:35,812 AE_UNIGRAMA_2L_UNDER_03.py:76]: training and evaluate autoencoder
[2017-10-20 01:38:01,646 AE_UNIGRAMA_2L_UNDER_03.py:88]: trained and evaluated!
[2017-10-20 01:38:01,646 AE_UNIGRAMA_2L_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0099740553349533488, 0.0098560457100544726, 0.0097406656311679503, 0.0096274116682408019, 0.0095166476775777834, 0.0094086873452404168, 0.0093033716781930412, 0.0092004582175091738, 0.0090998263690329831, 0.009001311364836409, 0.0089048089314127492, 0.0088106079414819252, 0.0087187115213795668, 0.0086293582281714038, 0.0085419687099727113, 0.0084539106475764042, 0.0083674568073567844, 0.00828363236081423, 0.0082023873592841131, 0.0081235266768383933, 0.0080469834850235497, 0.007972625522185325, 0.0079004673276885963, 0.0078302649573377958, 0.0077618028670826365, 0.0076950006065786324, 0.0076300704152389084, 0.0075669901957908531, 0.0075057202683533209, 0.0074460436780435001, 0.0073881067844543983, 0.007331998793747567, 0.0072776112795485438, 0.0072247826366176396, 0.0071734209929257076, 0.0071235186797757128, 0.0070748772908376051, 0.0070276835095483573, 0.006981997918614557, 0.0069378062677621618, 0.0068950508236469612, 0.0068537259360145234, 0.0068137932440688401, 0.0067751675214078348, 0.0067378114389608787, 0.0067016970432020699, 0.0066667241269383285, 0.0066329114654942734, 0.0066001875461061867, 0.0065685151695346524, 0.0065378561775203533, 0.0065081372223517488, 0.0064793605336635526, 0.0064514798049894627, 0.0064244152022504891, 0.006398179542384072, 0.0063727238842158068, 0.0063480063320784982, 0.0063240263285634689, 0.0063007804045806812, 0.0062782530478966946, 0.0062563876261359916, 0.0062351718399549063, 0.0062145867495759493, 0.0061946174503757605, 0.0061752323362436216, 0.0061564012032459215, 0.0061381388313680556, 0.0061203831578275974, 0.0061031663426817789, 0.0060864219210044826, 0.0060701658551106886, 0.0060543724661173649, 0.0060390179654839539, 0.0060241039267647668, 0.0060096126254024782, 0.00599551898666197, 0.0059818177705554488, 0.0059684765954470765, 0.0059555140964437595, 0.0059428947569186135, 0.0059306295432815098, 0.0059187044060640178, 0.005907085738023639, 0.0058957916930262484, 0.0058848295052670854, 0.0058741393935309244, 0.005863735640982381, 0.0058535997492700923, 0.0058437244738123234, 0.005834119155532144, 0.0058247587006525258, 0.005815636714553412, 0.0058067380069827725, 0.0057980775466140314, 0.0057896365685090696, 0.0057814024634603896, 0.0057733536448648206, 0.0057655124938925627, 0.0057578495561688807, 0.0057503513344407745, 0.0057430397511414877], 'loss': [0.010025854824659241, 0.0099102185407141715, 0.0097922725561770396, 0.0096769811924416454, 0.0095639787894829919, 0.0094537628521500511, 0.009346231220023319, 0.0092412701790171234, 0.009138664142552079, 0.00903843522481689, 0.0089403130554839665, 0.0088443655690113015, 0.0087507790218999803, 0.008659516267716591, 0.008570719201784047, 0.008482575695332055, 0.0083945266010620953, 0.008308901531094046, 0.0082258486223865598, 0.0081452300701091163, 0.0080669878792537456, 0.0079909959955675579, 0.0079171725221953652, 0.0078454850740689551, 0.0077757464427576526, 0.0077076834977387503, 0.0076414807837000822, 0.0075771501439508481, 0.0075146387183504118, 0.0074539080931339697, 0.0073948098720379345, 0.0073375487645725088, 0.0072820755534592991, 0.0072282036925541823, 0.0071758739904975079, 0.0071250108659116308, 0.0070755229501560856, 0.0070273579446313824, 0.0069807203616500451, 0.0069355528255593728, 0.0068918885199493914, 0.0068496585787533246, 0.0068088221977926798, 0.0067693502378902443, 0.0067311545430963652, 0.006694214024993728, 0.0066584709899519473, 0.0066238680148077069, 0.0065903951214728324, 0.0065580076202017513, 0.0065266360109757816, 0.0064962665125677284, 0.0064668153514530332, 0.0064382798647474827, 0.0064106230622875265, 0.0063837533247140229, 0.0063577155140700815, 0.0063324335300819819, 0.0063078806800830741, 0.006284065056047285, 0.0062609769769708988, 0.0062385814919261821, 0.0062168506034217729, 0.006195754929289414, 0.0061752612822183672, 0.0061553847531260857, 0.0061360717322917792, 0.0061173097290025394, 0.0060991144589690538, 0.0060814096115543274, 0.0060642351360319577, 0.0060475145394501143, 0.0060312839705192502, 0.0060155071992456875, 0.0060001637299499887, 0.0059852589550871719, 0.0059707616344231657, 0.0059566761500968587, 0.0059429596312179219, 0.0059296109864732096, 0.0059166323598508607, 0.0059040082268274922, 0.0058917193327238755, 0.0058797752320395519, 0.0058681360942774673, 0.005856817429364369, 0.0058458349272521746, 0.0058351128597382614, 0.0058246799561492164, 0.005814514310942355, 0.0058046130875048819, 0.0057949605423638847, 0.0057855652134061845, 0.0057764210441729634, 0.0057674798614745608, 0.0057587644718381332, 0.0057502822820543692, 0.0057419996279891132, 0.0057339011499750962, 0.005726011152268738, 0.0057183017810553622, 0.0057107686790962234]}
[2017-10-20 01:38:01,646 AE_UNIGRAMA_2L_UNDER_03.py:95]: done!
[2017-10-20 01:38:01,646 AE_UNIGRAMA_2L_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-10-20 01:38:01,647 AE_UNIGRAMA_2L_UNDER_03.py:100]: =======================================
[2017-10-20 01:38:01,647 AE_UNIGRAMA_2L_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe4e4863898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:38:01,683 AE_UNIGRAMA_2L_UNDER_03.py:113]: training ... 
[2017-10-20 01:38:48,049 AE_UNIGRAMA_2L_UNDER_03.py:125]: trained!
[2017-10-20 01:38:48,050 AE_UNIGRAMA_2L_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0099740553349533488, 0.0098560457100544726, 0.0097406656311679503, 0.0096274116682408019, 0.0095166476775777834, 0.0094086873452404168, 0.0093033716781930412, 0.0092004582175091738, 0.0090998263690329831, 0.009001311364836409, 0.0089048089314127492, 0.0088106079414819252, 0.0087187115213795668, 0.0086293582281714038, 0.0085419687099727113, 0.0084539106475764042, 0.0083674568073567844, 0.00828363236081423, 0.0082023873592841131, 0.0081235266768383933, 0.0080469834850235497, 0.007972625522185325, 0.0079004673276885963, 0.0078302649573377958, 0.0077618028670826365, 0.0076950006065786324, 0.0076300704152389084, 0.0075669901957908531, 0.0075057202683533209, 0.0074460436780435001, 0.0073881067844543983, 0.007331998793747567, 0.0072776112795485438, 0.0072247826366176396, 0.0071734209929257076, 0.0071235186797757128, 0.0070748772908376051, 0.0070276835095483573, 0.006981997918614557, 0.0069378062677621618, 0.0068950508236469612, 0.0068537259360145234, 0.0068137932440688401, 0.0067751675214078348, 0.0067378114389608787, 0.0067016970432020699, 0.0066667241269383285, 0.0066329114654942734, 0.0066001875461061867, 0.0065685151695346524, 0.0065378561775203533, 0.0065081372223517488, 0.0064793605336635526, 0.0064514798049894627, 0.0064244152022504891, 0.006398179542384072, 0.0063727238842158068, 0.0063480063320784982, 0.0063240263285634689, 0.0063007804045806812, 0.0062782530478966946, 0.0062563876261359916, 0.0062351718399549063, 0.0062145867495759493, 0.0061946174503757605, 0.0061752323362436216, 0.0061564012032459215, 0.0061381388313680556, 0.0061203831578275974, 0.0061031663426817789, 0.0060864219210044826, 0.0060701658551106886, 0.0060543724661173649, 0.0060390179654839539, 0.0060241039267647668, 0.0060096126254024782, 0.00599551898666197, 0.0059818177705554488, 0.0059684765954470765, 0.0059555140964437595, 0.0059428947569186135, 0.0059306295432815098, 0.0059187044060640178, 0.005907085738023639, 0.0058957916930262484, 0.0058848295052670854, 0.0058741393935309244, 0.005863735640982381, 0.0058535997492700923, 0.0058437244738123234, 0.005834119155532144, 0.0058247587006525258, 0.005815636714553412, 0.0058067380069827725, 0.0057980775466140314, 0.0057896365685090696, 0.0057814024634603896, 0.0057733536448648206, 0.0057655124938925627, 0.0057578495561688807, 0.0057503513344407745, 0.0057430397511414877], 'loss': [0.010025854824659241, 0.0099102185407141715, 0.0097922725561770396, 0.0096769811924416454, 0.0095639787894829919, 0.0094537628521500511, 0.009346231220023319, 0.0092412701790171234, 0.009138664142552079, 0.00903843522481689, 0.0089403130554839665, 0.0088443655690113015, 0.0087507790218999803, 0.008659516267716591, 0.008570719201784047, 0.008482575695332055, 0.0083945266010620953, 0.008308901531094046, 0.0082258486223865598, 0.0081452300701091163, 0.0080669878792537456, 0.0079909959955675579, 0.0079171725221953652, 0.0078454850740689551, 0.0077757464427576526, 0.0077076834977387503, 0.0076414807837000822, 0.0075771501439508481, 0.0075146387183504118, 0.0074539080931339697, 0.0073948098720379345, 0.0073375487645725088, 0.0072820755534592991, 0.0072282036925541823, 0.0071758739904975079, 0.0071250108659116308, 0.0070755229501560856, 0.0070273579446313824, 0.0069807203616500451, 0.0069355528255593728, 0.0068918885199493914, 0.0068496585787533246, 0.0068088221977926798, 0.0067693502378902443, 0.0067311545430963652, 0.006694214024993728, 0.0066584709899519473, 0.0066238680148077069, 0.0065903951214728324, 0.0065580076202017513, 0.0065266360109757816, 0.0064962665125677284, 0.0064668153514530332, 0.0064382798647474827, 0.0064106230622875265, 0.0063837533247140229, 0.0063577155140700815, 0.0063324335300819819, 0.0063078806800830741, 0.006284065056047285, 0.0062609769769708988, 0.0062385814919261821, 0.0062168506034217729, 0.006195754929289414, 0.0061752612822183672, 0.0061553847531260857, 0.0061360717322917792, 0.0061173097290025394, 0.0060991144589690538, 0.0060814096115543274, 0.0060642351360319577, 0.0060475145394501143, 0.0060312839705192502, 0.0060155071992456875, 0.0060001637299499887, 0.0059852589550871719, 0.0059707616344231657, 0.0059566761500968587, 0.0059429596312179219, 0.0059296109864732096, 0.0059166323598508607, 0.0059040082268274922, 0.0058917193327238755, 0.0058797752320395519, 0.0058681360942774673, 0.005856817429364369, 0.0058458349272521746, 0.0058351128597382614, 0.0058246799561492164, 0.005814514310942355, 0.0058046130875048819, 0.0057949605423638847, 0.0057855652134061845, 0.0057764210441729634, 0.0057674798614745608, 0.0057587644718381332, 0.0057502822820543692, 0.0057419996279891132, 0.0057339011499750962, 0.005726011152268738, 0.0057183017810553622, 0.0057107686790962234]}
[2017-10-20 01:38:48,050 AE_UNIGRAMA_2L_UNDER_03.py:132]: evaluating model ... 
[2017-10-20 01:38:48,089 AE_UNIGRAMA_2L_UNDER_03.py:136]: evaluated! 
[2017-10-20 01:38:48,089 AE_UNIGRAMA_2L_UNDER_03.py:138]: generating reports ... 
[2017-10-20 01:38:48,709 AE_UNIGRAMA_2L_UNDER_03.py:141]: done!
[2017-10-20 01:38:48,710 AE_UNIGRAMA_2L_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_2L_UNDER_03 finished!
