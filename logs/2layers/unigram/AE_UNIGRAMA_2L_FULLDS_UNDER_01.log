[2017-11-13 16:24:16,660 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_FULLDS_UNDER_01
[2017-11-13 16:24:16,660 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-13 16:24:16,661 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_FULLDS_UNDER_01
	layers = 96,28,26
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f1c54aa1eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f1c54aa6400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 16:24:16,661 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-13 16:24:19,051 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 16:24:19,051 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-13 16:24:19,051 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-13 16:24:19,051 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f1c54aa1eb8>, 'discard_decoder_function': True}
[2017-11-13 16:24:19,114 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-13 16:26:38,498 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-13 16:26:38,499 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0098906312728603944, 0.0096944622073879758, 0.0092235340886379323, 0.0087808577237032601, 0.0083687324696403581, 0.0080132858572032842, 0.0077130574307232294, 0.0074594509986375393, 0.0072481066102517283, 0.00707100538224754, 0.0069211495342674347, 0.0067930526248302934, 0.0066829119281530472, 0.0065882878089840472, 0.0065063703604978989, 0.0064352193454712443, 0.0063733032963436149, 0.0063190041652420939, 0.0062711646240266178, 0.0062288419350034303, 0.0061911263656129912, 0.0061573487831754021, 0.0061269641403096514, 0.0060996344064535883, 0.006075008289196427, 0.0060527457840924143, 0.0060325320336032618, 0.0060141218317216021, 0.0059972728283590512, 0.0059812742238196876, 0.0059657503303293738, 0.0059508791658685065, 0.00593667678599674, 0.0059231276833888683, 0.0059106399784174717, 0.0058992189542246311, 0.0058887603031953974, 0.0058789933792588213, 0.0058695248021644591, 0.0058604880290510503, 0.0058519351124135081, 0.0058437358448162093, 0.0058357170385091904, 0.005827948989350731, 0.0058204216564444501, 0.0058131585330098252, 0.0058061829715069053, 0.0057994597602583596, 0.0057929982317427436, 0.0057868074858646729, 0.0057808879635562705, 0.0057752037739010852, 0.0057697301671129353, 0.0057644461860379857, 0.0057593455077968713, 0.0057544766907990583, 0.0057498453816796696, 0.0057454300825804123, 0.0057412021060449228, 0.0057371471851423396, 0.0057332435422068687, 0.0057294648370846907, 0.0057257830454717712, 0.0057221065383700215, 0.0057183320294190796, 0.0057145396228852306, 0.0057107266896903701, 0.0057069353054379256, 0.0057032920488795397, 0.0056998043721360357, 0.0056964749284157063, 0.0056932799686506275, 0.0056902131015070002, 0.0056872601523818784, 0.0056844049037353041, 0.0056816406345398095, 0.005678963817680684, 0.005676360074304063, 0.0056738283604798306, 0.0056713562028688604, 0.0056689463600137083, 0.0056665899277038708, 0.0056642776325883095, 0.0056620105107248828, 0.0056597829519304524, 0.0056575906678769999, 0.0056554294107957594, 0.0056532967920548249, 0.0056511905510320806, 0.0056491033014940979, 0.005647035371765456, 0.0056449832025578586, 0.0056429466792101294, 0.0056409215829610684, 0.0056389015981190256, 0.0056368870806470595, 0.005634881734015617, 0.0056328802447915298, 0.0056308828509395248, 0.0056288858560057343, 0.0056268892030874101], 'val_acc': [0.0014700477765527381, 0.0011025358324145535, 0.099228224917309815, 0.5773612642410878, 0.60198456449834614, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099287807359117238, 0.0098228360121246413, 0.0094628771144004628, 0.009006620540220861, 0.0085810293153484388, 0.0081980548574066437, 0.0078731153172451, 0.0075983176121267133, 0.0073683191576888697, 0.0071765156012959892, 0.0070150641225940492, 0.006877956585324153, 0.0067605005368696442, 0.0066596246466801489, 0.0065727360326875879, 0.0064974016821686591, 0.0064319043555260951, 0.0063747814886191473, 0.0063245758873013737, 0.0062802596222570417, 0.0062409278615916837, 0.0062057882757946383, 0.0061742415179216019, 0.0061458371483851275, 0.0061202856034842483, 0.0060972319993053171, 0.0060763395245881906, 0.0060573804607893574, 0.0060400733376948165, 0.006023995959300219, 0.0060085210731069894, 0.0059935211615982859, 0.0059792779685433981, 0.0059656653047061572, 0.0059529037891673476, 0.0059412011093188753, 0.0059304998880539174, 0.0059206505368138013, 0.0059112337212934149, 0.0059021519816775392, 0.0058935373376566118, 0.0058853710857881304, 0.0058774489084514967, 0.0058697124182829517, 0.0058622244842431873, 0.0058549936312431751, 0.0058480167800426391, 0.0058413009256205886, 0.005834839001036856, 0.0058286410607342682, 0.0058227047343957063, 0.0058170238192436358, 0.0058115577329568837, 0.0058062829175440211, 0.0058011914018920646, 0.0057962942380118372, 0.0057916244752229552, 0.0057871711514231742, 0.0057829257082072918, 0.0057788572318273976, 0.0057749488614810508, 0.005771179716943564, 0.0057675197343403165, 0.005763923974584949, 0.0057602726315504034, 0.00575653579225758, 0.0057527785452602424, 0.005748987286355622, 0.0057452860955577384, 0.0057417371890326908, 0.0057383494791614217, 0.0057351056924651077, 0.0057319924720610205, 0.0057290004612266382, 0.0057261224511571387, 0.0057233385222149949, 0.0057206471157180789, 0.0057180345435565647, 0.0057154959295760291, 0.0057130250328178015, 0.0057106097301986561, 0.0057082555332917612, 0.0057059514963418902, 0.0057036924237991032, 0.0057014750627218044, 0.0056992929112849771, 0.0056971492681561313, 0.0056950351561949972, 0.0056929479960598642, 0.0056908782802470052, 0.0056888302376033578, 0.0056867946709898429, 0.0056847756453831493, 0.005682773584719668, 0.0056807748371845183, 0.0056787846339366966, 0.0056768021835749269, 0.0056748232911466067, 0.0056728471402726806, 0.0056708751136476613, 0.005668905819946269], 'acc': [0.0019639130968454647, 0.0019639130968454647, 0.012397201425666032, 0.38419049956307788, 0.58659629314329431, 0.59371547808277836, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822263669894, 0.59383822272449271, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822262938279, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822267327968, 0.59383822268059583, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822262206665, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198]}
[2017-11-13 16:26:38,500 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:95]: done!
[2017-11-13 16:26:38,500 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-13 16:26:38,500 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-13 16:26:38,500 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f1c54aa6400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 16:26:38,561 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-13 16:30:02,481 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-13 16:30:02,483 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0098906312728603944, 0.0096944622073879758, 0.0092235340886379323, 0.0087808577237032601, 0.0083687324696403581, 0.0080132858572032842, 0.0077130574307232294, 0.0074594509986375393, 0.0072481066102517283, 0.00707100538224754, 0.0069211495342674347, 0.0067930526248302934, 0.0066829119281530472, 0.0065882878089840472, 0.0065063703604978989, 0.0064352193454712443, 0.0063733032963436149, 0.0063190041652420939, 0.0062711646240266178, 0.0062288419350034303, 0.0061911263656129912, 0.0061573487831754021, 0.0061269641403096514, 0.0060996344064535883, 0.006075008289196427, 0.0060527457840924143, 0.0060325320336032618, 0.0060141218317216021, 0.0059972728283590512, 0.0059812742238196876, 0.0059657503303293738, 0.0059508791658685065, 0.00593667678599674, 0.0059231276833888683, 0.0059106399784174717, 0.0058992189542246311, 0.0058887603031953974, 0.0058789933792588213, 0.0058695248021644591, 0.0058604880290510503, 0.0058519351124135081, 0.0058437358448162093, 0.0058357170385091904, 0.005827948989350731, 0.0058204216564444501, 0.0058131585330098252, 0.0058061829715069053, 0.0057994597602583596, 0.0057929982317427436, 0.0057868074858646729, 0.0057808879635562705, 0.0057752037739010852, 0.0057697301671129353, 0.0057644461860379857, 0.0057593455077968713, 0.0057544766907990583, 0.0057498453816796696, 0.0057454300825804123, 0.0057412021060449228, 0.0057371471851423396, 0.0057332435422068687, 0.0057294648370846907, 0.0057257830454717712, 0.0057221065383700215, 0.0057183320294190796, 0.0057145396228852306, 0.0057107266896903701, 0.0057069353054379256, 0.0057032920488795397, 0.0056998043721360357, 0.0056964749284157063, 0.0056932799686506275, 0.0056902131015070002, 0.0056872601523818784, 0.0056844049037353041, 0.0056816406345398095, 0.005678963817680684, 0.005676360074304063, 0.0056738283604798306, 0.0056713562028688604, 0.0056689463600137083, 0.0056665899277038708, 0.0056642776325883095, 0.0056620105107248828, 0.0056597829519304524, 0.0056575906678769999, 0.0056554294107957594, 0.0056532967920548249, 0.0056511905510320806, 0.0056491033014940979, 0.005647035371765456, 0.0056449832025578586, 0.0056429466792101294, 0.0056409215829610684, 0.0056389015981190256, 0.0056368870806470595, 0.005634881734015617, 0.0056328802447915298, 0.0056308828509395248, 0.0056288858560057343, 0.0056268892030874101], 'val_acc': [0.0014700477765527381, 0.0011025358324145535, 0.099228224917309815, 0.5773612642410878, 0.60198456449834614, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099287807359117238, 0.0098228360121246413, 0.0094628771144004628, 0.009006620540220861, 0.0085810293153484388, 0.0081980548574066437, 0.0078731153172451, 0.0075983176121267133, 0.0073683191576888697, 0.0071765156012959892, 0.0070150641225940492, 0.006877956585324153, 0.0067605005368696442, 0.0066596246466801489, 0.0065727360326875879, 0.0064974016821686591, 0.0064319043555260951, 0.0063747814886191473, 0.0063245758873013737, 0.0062802596222570417, 0.0062409278615916837, 0.0062057882757946383, 0.0061742415179216019, 0.0061458371483851275, 0.0061202856034842483, 0.0060972319993053171, 0.0060763395245881906, 0.0060573804607893574, 0.0060400733376948165, 0.006023995959300219, 0.0060085210731069894, 0.0059935211615982859, 0.0059792779685433981, 0.0059656653047061572, 0.0059529037891673476, 0.0059412011093188753, 0.0059304998880539174, 0.0059206505368138013, 0.0059112337212934149, 0.0059021519816775392, 0.0058935373376566118, 0.0058853710857881304, 0.0058774489084514967, 0.0058697124182829517, 0.0058622244842431873, 0.0058549936312431751, 0.0058480167800426391, 0.0058413009256205886, 0.005834839001036856, 0.0058286410607342682, 0.0058227047343957063, 0.0058170238192436358, 0.0058115577329568837, 0.0058062829175440211, 0.0058011914018920646, 0.0057962942380118372, 0.0057916244752229552, 0.0057871711514231742, 0.0057829257082072918, 0.0057788572318273976, 0.0057749488614810508, 0.005771179716943564, 0.0057675197343403165, 0.005763923974584949, 0.0057602726315504034, 0.00575653579225758, 0.0057527785452602424, 0.005748987286355622, 0.0057452860955577384, 0.0057417371890326908, 0.0057383494791614217, 0.0057351056924651077, 0.0057319924720610205, 0.0057290004612266382, 0.0057261224511571387, 0.0057233385222149949, 0.0057206471157180789, 0.0057180345435565647, 0.0057154959295760291, 0.0057130250328178015, 0.0057106097301986561, 0.0057082555332917612, 0.0057059514963418902, 0.0057036924237991032, 0.0057014750627218044, 0.0056992929112849771, 0.0056971492681561313, 0.0056950351561949972, 0.0056929479960598642, 0.0056908782802470052, 0.0056888302376033578, 0.0056867946709898429, 0.0056847756453831493, 0.005682773584719668, 0.0056807748371845183, 0.0056787846339366966, 0.0056768021835749269, 0.0056748232911466067, 0.0056728471402726806, 0.0056708751136476613, 0.005668905819946269], 'acc': [0.0019639130968454647, 0.0019639130968454647, 0.012397201425666032, 0.38419049956307788, 0.58659629314329431, 0.59371547808277836, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822266596353, 0.59383822263669894, 0.59383822272449271, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822262938279, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822267327968, 0.59383822268059583, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822262206665, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198]}
[2017-11-13 16:30:02,483 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-13 16:30:02,587 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-13 16:30:02,588 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-13 16:30:03,624 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:141]: done!
[2017-11-13 16:30:03,624 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_2L_FULLDS_UNDER_01 finished!
[2017-11-14 07:04:24,291 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_2L_FULLDS_UNDER_01 was already executed!
[2017-11-18 14:56:12,346 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_2L_FULLDS_UNDER_01 was already executed!
[2017-11-18 16:22:41,963 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:146]: The experiment AE_UNIGRAMA_2L_FULLDS_UNDER_01 was already executed!
[2017-11-18 17:43:16,615 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_FULLDS_UNDER_01
[2017-11-18 17:43:16,615 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 17:43:16,615 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_FULLDS_UNDER_01
	layers = 96,28,26
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f7102b27eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f7102b2c400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 17:43:16,615 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 17:43:18,672 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 17:43:18,672 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 17:43:18,672 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 17:43:18,672 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f7102b27eb8>, 'discard_decoder_function': True}
[2017-11-18 17:43:18,728 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 17:44:29,862 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 17:44:29,863 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0094946604612249526, 0.0090580388341606963, 0.008656732645262278, 0.0082950587434032219, 0.007968500726306945, 0.00766111643918513, 0.0073793224775763238, 0.0071383901469228746, 0.0069335739727952447, 0.0067596260815220846, 0.0066114694375691277, 0.006484218804458021, 0.0063736759838454761, 0.0062768445976587811, 0.0061914261530787683, 0.0061157605130237741, 0.006048361696535636, 0.0059881885861173597, 0.0059343156353794712, 0.0058859760362349614, 0.0058422474292761008, 0.0058025199822733745, 0.0057664914881534676, 0.0057337298192315211, 0.0057035602714068222, 0.005675985247943412, 0.0056507234707699238, 0.0056275996765123874, 0.0056064572004387095, 0.0055869299310366653, 0.0055687857175862653, 0.0055518820108308459, 0.0055359069149987757, 0.0055208688996148999, 0.0055069214422584336, 0.0054939069665553581, 0.0054817034820836066, 0.0054702875479057745, 0.0054593940648992667, 0.0054483563562725745, 0.0054369769793295416, 0.0054257275233403233, 0.0054144484396730927, 0.0054029167297945518, 0.0053907293727596109, 0.0053780183673708621, 0.0053654739496122551, 0.0053530721890116132, 0.0053412031729899697, 0.005329059912418917, 0.0053176902588292574, 0.0053072728313168852, 0.0052977118792422373, 0.0052888429200345869, 0.0052803735118167657, 0.0052718602921622056, 0.0052635508687165246, 0.0052556843897830921, 0.0052481969100214715, 0.0052409522763861753, 0.0052336847484221313, 0.0052265529419839359, 0.0052196064734443314, 0.0052126226935587695, 0.0052058999025348801, 0.0051994993536569143, 0.0051933643691349897, 0.0051874987756575361, 0.0051818328808776789, 0.005176362380209471, 0.0051710806772125167, 0.0051659843489084119, 0.0051610689918801201, 0.0051563138659743652, 0.0051517016046435105, 0.0051472024751319876, 0.0051428193153039261, 0.0051385529211132579, 0.005134399626825042, 0.0051303251336873926, 0.0051263387894099777, 0.0051224229958124704, 0.0051185664683525631, 0.0051147378343631518, 0.0051109384261386571, 0.0051071782668628751, 0.0051034656837609972, 0.0050998022242455046, 0.0050961805329730308, 0.0050926040340343662, 0.0050890674335058563, 0.0050855800022570662, 0.0050821414764817205, 0.0050787514745463504, 0.0050754200467598189, 0.0050722179002204186, 0.0050691133295724944, 0.0050660533628069503, 0.0050630176200975353, 0.0050600003523841768, 0.0050569912008852184], 'val_acc': [0.0036751194413818448, 0.078647556045571484, 0.52333700845277475, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096884760370049804, 0.0092789839756105431, 0.0088619049266986695, 0.0084827193937536335, 0.0081409796253002192, 0.0078280655931481577, 0.0075323280214882014, 0.007272149390164121, 0.0070506980832095957, 0.0068622803847312678, 0.0067022182985319928, 0.0065654287884306566, 0.0064474321115083879, 0.0063445069292146173, 0.006254068432220092, 0.0061741082716906519, 0.0061030888564613051, 0.0060397334223880866, 0.0059830971588374351, 0.0059323269112863961, 0.005886660917083994, 0.0058451707790853442, 0.0058075378875737287, 0.0057734017536671478, 0.0057421386210704901, 0.0057134789228256424, 0.005687229298212926, 0.0056631986266252408, 0.0056412316043361081, 0.0056210793709679406, 0.0056023903135532646, 0.0055850177992565571, 0.0055687919915695487, 0.005553375384312503, 0.0055390357396416651, 0.0055256808785134311, 0.0055132071210735158, 0.0055015210236709763, 0.0054904975248421832, 0.005479725702192826, 0.0054685678124419563, 0.005457363215440751, 0.0054462384777213329, 0.0054349627690916747, 0.005423297181705383, 0.0054109185922978234, 0.0053983440726027912, 0.0053859775404331402, 0.0053739234756180389, 0.0053620326474612592, 0.0053502308037070298, 0.0053393912798394352, 0.0053294408524357951, 0.0053202574593667184, 0.0053116225818570142, 0.0053031931747182263, 0.0052947754676979505, 0.005286730526453445, 0.0052791012881333527, 0.0052717833732197307, 0.0052645735082432503, 0.0052573757957288959, 0.0052504114773157832, 0.0052434931206491201, 0.0052366391797365403, 0.0052300864370839056, 0.0052237973212500765, 0.0052177660808866155, 0.005211973179139062, 0.0052063654440272118, 0.0052009521597980125, 0.0051957337852538629, 0.0051906931543718405, 0.0051858223048983588, 0.0051810960683752617, 0.0051764991437110693, 0.0051720254280393741, 0.0051676577113832162, 0.0051634071811021282, 0.0051592602030428635, 0.0051551960415317849, 0.0051512135402748153, 0.0051473056489074282, 0.0051434456912737335, 0.0051396094550444577, 0.0051357856451183818, 0.0051319990147623536, 0.0051282560433956927, 0.0051245659259854977, 0.0051209245562874404, 0.0051173245222450063, 0.0051137741177961389, 0.005110284928916034, 0.0051068457318930571, 0.005103461131441168, 0.0051001765683171708, 0.0050970277766377824, 0.0050939568561345532, 0.0050909198249359982, 0.0050879056920182329, 0.0050849100935857136], 'acc': [0.0046642936068370146, 0.021603044065300111, 0.38934577147521987, 0.58365042347607765, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822267327968, 0.59383822270254427, 0.5938382226842539, 0.59383822262938279, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539]}
[2017-11-18 17:44:29,863 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:95]: done!
[2017-11-18 17:44:29,863 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 17:44:29,863 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 17:44:29,863 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f7102b2c400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 17:44:29,912 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 17:47:39,157 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 17:47:39,158 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0094946604612249526, 0.0090580388341606963, 0.008656732645262278, 0.0082950587434032219, 0.007968500726306945, 0.00766111643918513, 0.0073793224775763238, 0.0071383901469228746, 0.0069335739727952447, 0.0067596260815220846, 0.0066114694375691277, 0.006484218804458021, 0.0063736759838454761, 0.0062768445976587811, 0.0061914261530787683, 0.0061157605130237741, 0.006048361696535636, 0.0059881885861173597, 0.0059343156353794712, 0.0058859760362349614, 0.0058422474292761008, 0.0058025199822733745, 0.0057664914881534676, 0.0057337298192315211, 0.0057035602714068222, 0.005675985247943412, 0.0056507234707699238, 0.0056275996765123874, 0.0056064572004387095, 0.0055869299310366653, 0.0055687857175862653, 0.0055518820108308459, 0.0055359069149987757, 0.0055208688996148999, 0.0055069214422584336, 0.0054939069665553581, 0.0054817034820836066, 0.0054702875479057745, 0.0054593940648992667, 0.0054483563562725745, 0.0054369769793295416, 0.0054257275233403233, 0.0054144484396730927, 0.0054029167297945518, 0.0053907293727596109, 0.0053780183673708621, 0.0053654739496122551, 0.0053530721890116132, 0.0053412031729899697, 0.005329059912418917, 0.0053176902588292574, 0.0053072728313168852, 0.0052977118792422373, 0.0052888429200345869, 0.0052803735118167657, 0.0052718602921622056, 0.0052635508687165246, 0.0052556843897830921, 0.0052481969100214715, 0.0052409522763861753, 0.0052336847484221313, 0.0052265529419839359, 0.0052196064734443314, 0.0052126226935587695, 0.0052058999025348801, 0.0051994993536569143, 0.0051933643691349897, 0.0051874987756575361, 0.0051818328808776789, 0.005176362380209471, 0.0051710806772125167, 0.0051659843489084119, 0.0051610689918801201, 0.0051563138659743652, 0.0051517016046435105, 0.0051472024751319876, 0.0051428193153039261, 0.0051385529211132579, 0.005134399626825042, 0.0051303251336873926, 0.0051263387894099777, 0.0051224229958124704, 0.0051185664683525631, 0.0051147378343631518, 0.0051109384261386571, 0.0051071782668628751, 0.0051034656837609972, 0.0050998022242455046, 0.0050961805329730308, 0.0050926040340343662, 0.0050890674335058563, 0.0050855800022570662, 0.0050821414764817205, 0.0050787514745463504, 0.0050754200467598189, 0.0050722179002204186, 0.0050691133295724944, 0.0050660533628069503, 0.0050630176200975353, 0.0050600003523841768, 0.0050569912008852184], 'val_acc': [0.0036751194413818448, 0.078647556045571484, 0.52333700845277475, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096884760370049804, 0.0092789839756105431, 0.0088619049266986695, 0.0084827193937536335, 0.0081409796253002192, 0.0078280655931481577, 0.0075323280214882014, 0.007272149390164121, 0.0070506980832095957, 0.0068622803847312678, 0.0067022182985319928, 0.0065654287884306566, 0.0064474321115083879, 0.0063445069292146173, 0.006254068432220092, 0.0061741082716906519, 0.0061030888564613051, 0.0060397334223880866, 0.0059830971588374351, 0.0059323269112863961, 0.005886660917083994, 0.0058451707790853442, 0.0058075378875737287, 0.0057734017536671478, 0.0057421386210704901, 0.0057134789228256424, 0.005687229298212926, 0.0056631986266252408, 0.0056412316043361081, 0.0056210793709679406, 0.0056023903135532646, 0.0055850177992565571, 0.0055687919915695487, 0.005553375384312503, 0.0055390357396416651, 0.0055256808785134311, 0.0055132071210735158, 0.0055015210236709763, 0.0054904975248421832, 0.005479725702192826, 0.0054685678124419563, 0.005457363215440751, 0.0054462384777213329, 0.0054349627690916747, 0.005423297181705383, 0.0054109185922978234, 0.0053983440726027912, 0.0053859775404331402, 0.0053739234756180389, 0.0053620326474612592, 0.0053502308037070298, 0.0053393912798394352, 0.0053294408524357951, 0.0053202574593667184, 0.0053116225818570142, 0.0053031931747182263, 0.0052947754676979505, 0.005286730526453445, 0.0052791012881333527, 0.0052717833732197307, 0.0052645735082432503, 0.0052573757957288959, 0.0052504114773157832, 0.0052434931206491201, 0.0052366391797365403, 0.0052300864370839056, 0.0052237973212500765, 0.0052177660808866155, 0.005211973179139062, 0.0052063654440272118, 0.0052009521597980125, 0.0051957337852538629, 0.0051906931543718405, 0.0051858223048983588, 0.0051810960683752617, 0.0051764991437110693, 0.0051720254280393741, 0.0051676577113832162, 0.0051634071811021282, 0.0051592602030428635, 0.0051551960415317849, 0.0051512135402748153, 0.0051473056489074282, 0.0051434456912737335, 0.0051396094550444577, 0.0051357856451183818, 0.0051319990147623536, 0.0051282560433956927, 0.0051245659259854977, 0.0051209245562874404, 0.0051173245222450063, 0.0051137741177961389, 0.005110284928916034, 0.0051068457318930571, 0.005103461131441168, 0.0051001765683171708, 0.0050970277766377824, 0.0050939568561345532, 0.0050909198249359982, 0.0050879056920182329, 0.0050849100935857136], 'acc': [0.0046642936068370146, 0.021603044065300111, 0.38934577147521987, 0.58365042347607765, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822267327968, 0.59383822270254427, 0.5938382226842539, 0.59383822262938279, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539]}
[2017-11-18 17:47:39,158 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 17:47:39,224 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 17:47:39,224 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 17:47:40,049 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:141]: done!
[2017-11-18 17:47:40,049 AE_UNIGRAMA_2L_FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_2L_FULLDS_UNDER_01 finished!
