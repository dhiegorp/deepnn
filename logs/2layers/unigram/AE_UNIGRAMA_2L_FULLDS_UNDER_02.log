[2017-11-13 17:03:59,633 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_FULLDS_UNDER_02
[2017-11-13 17:03:59,634 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-13 17:03:59,634 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_FULLDS_UNDER_02
	layers = 96,76,69
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f41f4c69e48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f41f4c6d390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 17:03:59,634 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-13 17:04:02,285 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 17:04:02,286 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-13 17:04:02,286 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:60]: =======================================
[2017-11-13 17:04:02,286 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f41f4c69e48>, 'discard_decoder_function': True}
[2017-11-13 17:04:02,356 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-13 17:06:15,468 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-13 17:06:15,470 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.009726395538211613, 0.0093192310801179078, 0.0087839462577020671, 0.0083175814703369752, 0.0079136646793554893, 0.0075722043852580901, 0.0072876705785680021, 0.0070495831486466105, 0.0068510561294645583, 0.0066836815782970191, 0.0065420276693484991, 0.0064207481999718303, 0.0063159391056377958, 0.0062245712518001995, 0.0061442369719414821, 0.0060735793498634628, 0.0060114667575309399, 0.0059566451757715024, 0.0059080719715069868, 0.0058648456448503593, 0.0058260330076725418, 0.0057909559340068011, 0.0057589371238747191, 0.0057292279512003658, 0.0057018128686126919, 0.0056769664140739222, 0.0056543947937318191, 0.0056338222942615215, 0.0056149842350537325, 0.0055976641140720752, 0.0055816512995901651, 0.0055667713659451655, 0.0055528437351319874, 0.0055398319893917398, 0.0055276361333965454, 0.0055161514317768109, 0.0055053284155935304, 0.0054950405392098934, 0.0054851716553887507, 0.005475442672322221, 0.0054656680547918073, 0.005455993688951128, 0.0054465910114001558, 0.0054374774559430069, 0.0054286636412314839, 0.0054201389609355834, 0.0054118572528933017, 0.0054038119157012966, 0.0053959477056045113, 0.0053882827827086048, 0.005380800709820454, 0.0053734886746659178, 0.0053663172066699093, 0.0053592586158427383, 0.0053521960936774226, 0.0053450331221601951, 0.0053377986632496969, 0.005330569830352426, 0.0053233585405296612, 0.0053161240615106735, 0.0053088409228552267, 0.0053015947345341667, 0.0052944133011983601, 0.0052873061873868945, 0.0052802481094545708, 0.0052732180763626086, 0.0052661731303010641, 0.0052591146555897262, 0.0052520097702267914, 0.0052447305118253689, 0.0052373834275727827, 0.0052300253409812911, 0.0052226690354886043, 0.0052153512416048082, 0.0052080785622734688, 0.0052008598169927291, 0.0051936831088953651, 0.0051865655454289812, 0.0051795041582381809, 0.0051724967966557851, 0.0051655360332901364, 0.0051586055579310843, 0.0051517174495346449, 0.0051448701551264154, 0.0051380577095014477, 0.0051312731360833169, 0.0051245248922034249, 0.005117803488879265, 0.005111089966756876, 0.0051043627498543404, 0.005097524904938964, 0.0050905572966433235, 0.0050834926256077559, 0.0050762277418245775, 0.0050688340513118484, 0.0050613050581716232, 0.0050536197210083282, 0.0050459263486635712, 0.0050382870196398017, 0.0050307156993261029, 0.0050232138251372366], 'val_acc': [0.0029400955531054761, 0.005512679162072767, 0.57589121646453512, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097986787027867211, 0.0095750702410383991, 0.009055584953642665, 0.0085574697650081036, 0.0081241966155589148, 0.0077529259045941339, 0.0074420075710875224, 0.0071822154927599592, 0.0069657368055046727, 0.0067843364414371336, 0.0066311400453099934, 0.0065005846006988503, 0.0063882344609282604, 0.0062907596286905241, 0.0062053759900821716, 0.0061301987173980671, 0.0060639908151227601, 0.0060056140327971776, 0.0059539982993020825, 0.00590812659798284, 0.0058671204935440598, 0.0058301820773990279, 0.0057966491256978732, 0.0057658212674603117, 0.0057371279522086139, 0.0057109618511810446, 0.0056872280872763813, 0.0056656340107516532, 0.0056459016725169458, 0.0056278266972798509, 0.0056111632789252758, 0.0055957065706694689, 0.0055812885533806566, 0.0055677860226389332, 0.0055551456722585327, 0.005543258679019932, 0.0055320440208313252, 0.0055214360451097833, 0.0055113243755550781, 0.0055015363872354863, 0.0054917374042910937, 0.0054819847360400575, 0.0054724399730649124, 0.0054631745434174459, 0.005454214412958615, 0.0054455484884671163, 0.0054371533343826571, 0.0054290013939825368, 0.0054210610112157744, 0.005413305067528248, 0.0054057395938252092, 0.0053983521120760164, 0.0053911251565243725, 0.0053840413323463076, 0.0053770269110192514, 0.0053699405483098551, 0.0053627611237037501, 0.0053555601207525491, 0.0053483873053702044, 0.0053412209134500888, 0.0053340035923487451, 0.0053267819453472077, 0.0053196226979298463, 0.0053125322580692361, 0.0053055077969888006, 0.0052985189511662806, 0.0052915399701383573, 0.0052845414714322797, 0.0052775182291761097, 0.0052703845358006837, 0.0052630945454747472, 0.0052557672162239491, 0.0052484351935509167, 0.0052411310952940986, 0.0052338667913866222, 0.005226662989895106, 0.0052195152729531107, 0.0052124263076389456, 0.0052053984268316394, 0.0051984225140411944, 0.0051914951478831753, 0.0051846069433421496, 0.0051777520033183264, 0.0051709443052522577, 0.0051641772519232373, 0.0051574451629151537, 0.0051507442966478509, 0.0051440745856184472, 0.0051374221893355047, 0.0051307720464256563, 0.0051240613774938444, 0.0051172027480174088, 0.0051102400145788263, 0.0051031313853493144, 0.0050958308197052195, 0.0050884227127676301, 0.0050808627163433243, 0.0050732146400893829, 0.0050655972188889866, 0.0050580385118211696, 0.005050537551039784], 'acc': [0.0025776359396096722, 0.0028231250767153555, 0.23751074014243223, 0.59126058669708925, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822262938279, 0.59383822272449271, 0.59383822270254427, 0.59383822262938279, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539]}
[2017-11-13 17:06:15,470 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:95]: done!
[2017-11-13 17:06:15,470 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-13 17:06:15,470 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:100]: =======================================
[2017-11-13 17:06:15,470 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f41f4c6d390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 17:06:15,524 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:113]: training ... 
[2017-11-13 17:09:35,373 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:125]: trained!
[2017-11-13 17:09:35,374 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.009726395538211613, 0.0093192310801179078, 0.0087839462577020671, 0.0083175814703369752, 0.0079136646793554893, 0.0075722043852580901, 0.0072876705785680021, 0.0070495831486466105, 0.0068510561294645583, 0.0066836815782970191, 0.0065420276693484991, 0.0064207481999718303, 0.0063159391056377958, 0.0062245712518001995, 0.0061442369719414821, 0.0060735793498634628, 0.0060114667575309399, 0.0059566451757715024, 0.0059080719715069868, 0.0058648456448503593, 0.0058260330076725418, 0.0057909559340068011, 0.0057589371238747191, 0.0057292279512003658, 0.0057018128686126919, 0.0056769664140739222, 0.0056543947937318191, 0.0056338222942615215, 0.0056149842350537325, 0.0055976641140720752, 0.0055816512995901651, 0.0055667713659451655, 0.0055528437351319874, 0.0055398319893917398, 0.0055276361333965454, 0.0055161514317768109, 0.0055053284155935304, 0.0054950405392098934, 0.0054851716553887507, 0.005475442672322221, 0.0054656680547918073, 0.005455993688951128, 0.0054465910114001558, 0.0054374774559430069, 0.0054286636412314839, 0.0054201389609355834, 0.0054118572528933017, 0.0054038119157012966, 0.0053959477056045113, 0.0053882827827086048, 0.005380800709820454, 0.0053734886746659178, 0.0053663172066699093, 0.0053592586158427383, 0.0053521960936774226, 0.0053450331221601951, 0.0053377986632496969, 0.005330569830352426, 0.0053233585405296612, 0.0053161240615106735, 0.0053088409228552267, 0.0053015947345341667, 0.0052944133011983601, 0.0052873061873868945, 0.0052802481094545708, 0.0052732180763626086, 0.0052661731303010641, 0.0052591146555897262, 0.0052520097702267914, 0.0052447305118253689, 0.0052373834275727827, 0.0052300253409812911, 0.0052226690354886043, 0.0052153512416048082, 0.0052080785622734688, 0.0052008598169927291, 0.0051936831088953651, 0.0051865655454289812, 0.0051795041582381809, 0.0051724967966557851, 0.0051655360332901364, 0.0051586055579310843, 0.0051517174495346449, 0.0051448701551264154, 0.0051380577095014477, 0.0051312731360833169, 0.0051245248922034249, 0.005117803488879265, 0.005111089966756876, 0.0051043627498543404, 0.005097524904938964, 0.0050905572966433235, 0.0050834926256077559, 0.0050762277418245775, 0.0050688340513118484, 0.0050613050581716232, 0.0050536197210083282, 0.0050459263486635712, 0.0050382870196398017, 0.0050307156993261029, 0.0050232138251372366], 'val_acc': [0.0029400955531054761, 0.005512679162072767, 0.57589121646453512, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0097986787027867211, 0.0095750702410383991, 0.009055584953642665, 0.0085574697650081036, 0.0081241966155589148, 0.0077529259045941339, 0.0074420075710875224, 0.0071822154927599592, 0.0069657368055046727, 0.0067843364414371336, 0.0066311400453099934, 0.0065005846006988503, 0.0063882344609282604, 0.0062907596286905241, 0.0062053759900821716, 0.0061301987173980671, 0.0060639908151227601, 0.0060056140327971776, 0.0059539982993020825, 0.00590812659798284, 0.0058671204935440598, 0.0058301820773990279, 0.0057966491256978732, 0.0057658212674603117, 0.0057371279522086139, 0.0057109618511810446, 0.0056872280872763813, 0.0056656340107516532, 0.0056459016725169458, 0.0056278266972798509, 0.0056111632789252758, 0.0055957065706694689, 0.0055812885533806566, 0.0055677860226389332, 0.0055551456722585327, 0.005543258679019932, 0.0055320440208313252, 0.0055214360451097833, 0.0055113243755550781, 0.0055015363872354863, 0.0054917374042910937, 0.0054819847360400575, 0.0054724399730649124, 0.0054631745434174459, 0.005454214412958615, 0.0054455484884671163, 0.0054371533343826571, 0.0054290013939825368, 0.0054210610112157744, 0.005413305067528248, 0.0054057395938252092, 0.0053983521120760164, 0.0053911251565243725, 0.0053840413323463076, 0.0053770269110192514, 0.0053699405483098551, 0.0053627611237037501, 0.0053555601207525491, 0.0053483873053702044, 0.0053412209134500888, 0.0053340035923487451, 0.0053267819453472077, 0.0053196226979298463, 0.0053125322580692361, 0.0053055077969888006, 0.0052985189511662806, 0.0052915399701383573, 0.0052845414714322797, 0.0052775182291761097, 0.0052703845358006837, 0.0052630945454747472, 0.0052557672162239491, 0.0052484351935509167, 0.0052411310952940986, 0.0052338667913866222, 0.005226662989895106, 0.0052195152729531107, 0.0052124263076389456, 0.0052053984268316394, 0.0051984225140411944, 0.0051914951478831753, 0.0051846069433421496, 0.0051777520033183264, 0.0051709443052522577, 0.0051641772519232373, 0.0051574451629151537, 0.0051507442966478509, 0.0051440745856184472, 0.0051374221893355047, 0.0051307720464256563, 0.0051240613774938444, 0.0051172027480174088, 0.0051102400145788263, 0.0051031313853493144, 0.0050958308197052195, 0.0050884227127676301, 0.0050808627163433243, 0.0050732146400893829, 0.0050655972188889866, 0.0050580385118211696, 0.005050537551039784], 'acc': [0.0025776359396096722, 0.0028231250767153555, 0.23751074014243223, 0.59126058669708925, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822262938279, 0.59383822272449271, 0.59383822270254427, 0.59383822262938279, 0.59383822270254427, 0.5938382226842539, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822270254427, 0.59383822267327968, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539]}
[2017-11-13 17:09:35,375 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-13 17:09:35,525 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-13 17:09:35,525 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-13 17:09:36,478 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:141]: done!
[2017-11-13 17:09:36,478 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_2L_FULLDS_UNDER_02 finished!
[2017-11-14 07:04:39,225 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_2L_FULLDS_UNDER_02 was already executed!
[2017-11-18 14:56:27,121 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_2L_FULLDS_UNDER_02 was already executed!
[2017-11-18 16:22:56,652 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:146]: The experiment AE_UNIGRAMA_2L_FULLDS_UNDER_02 was already executed!
[2017-11-18 18:09:19,277 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_FULLDS_UNDER_02
[2017-11-18 18:09:19,277 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 18:09:19,277 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_FULLDS_UNDER_02
	layers = 96,76,69
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd833fceeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd833fd3400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:09:19,277 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 18:09:21,748 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:09:21,749 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:09:21,749 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 18:09:21,749 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd833fceeb8>, 'discard_decoder_function': True}
[2017-11-18 18:09:21,814 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 18:10:42,309 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 18:10:42,310 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0096809508248846005, 0.0095505732242038514, 0.0094333864547906446, 0.009327051383797429, 0.0092292997985393716, 0.0091398499350897628, 0.0090579722724917922, 0.0089819137169919617, 0.0089098627578764224, 0.0088428344624784452, 0.0087813872334679792, 0.0087255821181669996, 0.0086748118942568554, 0.0086279781600299543, 0.0085846934353235194, 0.0085448939890594919, 0.0085079988796032558, 0.0084737116975442135, 0.0084420373123885294, 0.0084127576738316674, 0.0083856335798335267, 0.0083604713413112739, 0.0083372268900384766, 0.0083156718154742803, 0.0082956052473234544, 0.008276830210005786, 0.008259178579431363, 0.0082425738906283137, 0.0082269327568546772, 0.0082121695802902656, 0.0081980927265120837, 0.0081845114222539126, 0.0081715006874145193, 0.0081590463615096864, 0.0081471701052336955, 0.008135875987518101, 0.008125085508925255, 0.0081147210438383584, 0.0081047910217364148, 0.0080953288398264139, 0.008086352020389825, 0.0080777818100230513, 0.0080694952549790026, 0.0080615018365390589, 0.0080538195982652085, 0.008046408845142532, 0.0080392662338564739, 0.0080323413774940691, 0.0080256049611285001, 0.008019024807753062, 0.0080126024907929243, 0.0080063719910291216, 0.0080003376156146458, 0.0079944764206768479, 0.0079887652987369884, 0.0079832241635321918, 0.0079778450918039905, 0.0079726152743586978, 0.0079675181349551181, 0.0079625557659030264, 0.0079577246630199473, 0.0079530133221959731, 0.0079484052175039181, 0.0079438916086816518, 0.0079394760519370181, 0.0079351449043013212, 0.0079308858932636318, 0.0079266965726047522, 0.0079225698624248459, 0.007918501445645031, 0.0079144931578709558, 0.0079105446178114221, 0.0079066504353642996, 0.0079028021184147732, 0.0078989970311248662, 0.0078952400676443359, 0.0078915170342885622, 0.0078878345293804421, 0.0078841885914618763, 0.0078805731116591768, 0.0078769846391843236, 0.0078734198338032118, 0.0078698780020724241, 0.0078663598538644391, 0.0078628673486874322, 0.0078593949629531239, 0.0078559335644977444, 0.0078524831389458639, 0.0078490328609132892, 0.007845586367384097, 0.0078421433455215274, 0.0078387006433411621, 0.0078352230228962861, 0.0078316313091039841, 0.0078277930066958813, 0.0078237030048639352, 0.0078191187729711956, 0.0078140770084129153, 0.0078087279303372453, 0.0078032317313611044, 0.0077976946705642187], 'val_acc': [0.0047776552737963983, 0.0047776552737963983, 0.0051451672179345827, 0.005512679162072767, 0.0040426313855200296, 0.0036751194413818448, 0.011760382212421904, 0.012127894156560088, 0.012862918044836457, 0.012862918044836457, 0.013230429988974642, 0.013230429988974642, 0.044836457184858507, 0.046306504961411248, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.047409040793825796, 0.047776552737963981, 0.048144064682102167, 0.048144064682102167, 0.048879088570378537, 0.048879088570378537, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049614112458654908, 0.049614112458654908, 0.049614112458654908, 0.049614112458654908, 0.049614112458654908, 0.049981624402793093, 0.049981624402793093, 0.049981624402793093, 0.050349136346931278, 0.050349136346931278, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051451672179345827, 0.051451672179345827, 0.051451672179345827, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052554208011760382, 0.052554208011760382, 0.052921719955898568, 0.052921719955898568, 0.052921719955898568, 0.053656743844174938, 0.053656743844174938, 0.053656743844174938, 0.053656743844174938, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054759279676589487, 0.054759279676589487, 0.054759279676589487, 0.055126791620727672, 0.055126791620727672, 0.055126791620727672], 'loss': [0.0097456060741355089, 0.0096138633883199147, 0.0094906422595936006, 0.0093796230974692099, 0.0092782396528235649, 0.0091851251090099301, 0.0090998690866863959, 0.009021160582372444, 0.0089468608180622734, 0.0088769902056900427, 0.0088123619910574214, 0.0087535835869314918, 0.0087002480971419219, 0.008651395762853422, 0.0086062119497969155, 0.0085645877091209254, 0.0085262627356514336, 0.0084907086586667249, 0.008457724215094482, 0.0084272686320507814, 0.0083990744525998581, 0.0083729310920986726, 0.0083487301989905137, 0.0083263408616953381, 0.0083055390133983716, 0.0082861012219605356, 0.0082678811772569517, 0.0082507219584641595, 0.0082345649887416369, 0.0082193334516386125, 0.0082049039954405784, 0.0081910521568890737, 0.0081777497570460107, 0.0081650012658482114, 0.0081527986676570852, 0.0081411546247787125, 0.008130046083349874, 0.0081193767011538739, 0.0081091341629443286, 0.0080993481374096402, 0.0080900580337726295, 0.0080812056698074241, 0.0080727195005753701, 0.008064523145050722, 0.0080566453950131432, 0.0080490675387323105, 0.0080417559716616863, 0.0080346980389256525, 0.0080278478571977063, 0.008021179894041405, 0.0080146785151948216, 0.0080083607428157212, 0.0080022369565725011, 0.0079962915356923819, 0.0079905191981462856, 0.0079849127344435028, 0.0079794727697716072, 0.0079741818762696544, 0.0079690361468868348, 0.0079640270021840206, 0.0079591448928754329, 0.0079543866348369754, 0.0079497432373820762, 0.0079451974673278754, 0.0079407451241203433, 0.0079363824421732187, 0.0079320986174816095, 0.0079278867107378092, 0.0079237404333138781, 0.0079196499255022278, 0.0079156114743013997, 0.0079116325636147521, 0.0079077063562748365, 0.0079038302769981177, 0.0078999991707592501, 0.0078962030679369764, 0.0078924530992478519, 0.0078887370948539023, 0.0078850639036913642, 0.0078814249420343062, 0.007877815947027144, 0.007874235823591369, 0.0078706810496883758, 0.0078671512073261417, 0.007863643657719268, 0.0078601609269387737, 0.0078566995268403873, 0.0078532418136796883, 0.007849792234416229, 0.0078463515721063047, 0.007842917098170251, 0.0078394899235763281, 0.0078360502294554987, 0.0078325520118791535, 0.0078288693947193306, 0.0078249330937837699, 0.0078206475779763526, 0.0078158373626094658, 0.0078106820495321121, 0.0078053172838710577, 0.007799864727196678], 'acc': [0.0052780164486867041, 0.0051552718792193444, 0.0046642936050079785, 0.0056462501534307111, 0.0058917392905363936, 0.0047870381735608198, 0.0074874186817233341, 0.0095740763471216395, 0.010187799189885847, 0.010556032895544373, 0.010678777464097214, 0.010801522033564574, 0.025653614829372919, 0.045292745796913045, 0.045906468638762736, 0.046274702345335775, 0.046520191482441464, 0.046765680618632628, 0.047502148030864194, 0.047870381735608196, 0.047993126289528745, 0.048238615442181242, 0.048484104579286924, 0.048852338284945451, 0.048852338284945451, 0.048975082852583771, 0.049097827422051134, 0.049343316560071335, 0.049343316560071335, 0.049343316559156816, 0.049343316559156816, 0.049343316559156816, 0.049343316558242298, 0.049343316558242298, 0.049466061126795142, 0.049466061128624172, 0.049466061126795142, 0.049711550264815343, 0.050079783971388382, 0.050202528539026708, 0.050570762245599747, 0.05057076224377071, 0.050570762245599747, 0.050938995950343756, 0.050938995950343756, 0.050938995949429237, 0.051184485087449438, 0.051429974224555121, 0.051552718793107966, 0.051675463361660803, 0.052043697068233849, 0.052043697067319331, 0.05216644163495765, 0.05216644163495765, 0.05216644163495765, 0.052289186205339531, 0.052411930773892376, 0.052411930757431044, 0.052411930772063339, 0.052534675340616177, 0.052534675325983882, 0.052534675340616177, 0.052534675340616177, 0.05265741991008354, 0.052902909047189223, 0.052902909048103741, 0.052902909047189223, 0.052902909048103741, 0.053025653614827542, 0.053148398184294905, 0.053639376457591752, 0.053762121027059108, 0.053762121027059108, 0.053884865596526471, 0.053884865595611953, 0.054130354731803117, 0.054375843870737836, 0.054375843870737836, 0.054375843869823318, 0.054375843868908799, 0.054498588437461644, 0.054498588437461644, 0.054498588437461644, 0.054498588437461644, 0.054866822143120164, 0.054866822143120164, 0.054866822144034683, 0.055112311280225847, 0.05523505584969321, 0.055603289555351737, 0.055603289539804923, 0.055726034124819093, 0.055971523261924776, 0.056339756966668784, 0.056462501534307104, 0.057076224380729387, 0.057076224362439025, 0.057444458068097545, 0.05756720263665039, 0.057567202651282678, 0.057689947220750042]}
[2017-11-18 18:10:42,310 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:95]: done!
[2017-11-18 18:10:42,310 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 18:10:42,310 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 18:10:42,311 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd833fd3400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:10:42,342 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 18:14:42,409 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 18:14:42,410 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0096809508248846005, 0.0095505732242038514, 0.0094333864547906446, 0.009327051383797429, 0.0092292997985393716, 0.0091398499350897628, 0.0090579722724917922, 0.0089819137169919617, 0.0089098627578764224, 0.0088428344624784452, 0.0087813872334679792, 0.0087255821181669996, 0.0086748118942568554, 0.0086279781600299543, 0.0085846934353235194, 0.0085448939890594919, 0.0085079988796032558, 0.0084737116975442135, 0.0084420373123885294, 0.0084127576738316674, 0.0083856335798335267, 0.0083604713413112739, 0.0083372268900384766, 0.0083156718154742803, 0.0082956052473234544, 0.008276830210005786, 0.008259178579431363, 0.0082425738906283137, 0.0082269327568546772, 0.0082121695802902656, 0.0081980927265120837, 0.0081845114222539126, 0.0081715006874145193, 0.0081590463615096864, 0.0081471701052336955, 0.008135875987518101, 0.008125085508925255, 0.0081147210438383584, 0.0081047910217364148, 0.0080953288398264139, 0.008086352020389825, 0.0080777818100230513, 0.0080694952549790026, 0.0080615018365390589, 0.0080538195982652085, 0.008046408845142532, 0.0080392662338564739, 0.0080323413774940691, 0.0080256049611285001, 0.008019024807753062, 0.0080126024907929243, 0.0080063719910291216, 0.0080003376156146458, 0.0079944764206768479, 0.0079887652987369884, 0.0079832241635321918, 0.0079778450918039905, 0.0079726152743586978, 0.0079675181349551181, 0.0079625557659030264, 0.0079577246630199473, 0.0079530133221959731, 0.0079484052175039181, 0.0079438916086816518, 0.0079394760519370181, 0.0079351449043013212, 0.0079308858932636318, 0.0079266965726047522, 0.0079225698624248459, 0.007918501445645031, 0.0079144931578709558, 0.0079105446178114221, 0.0079066504353642996, 0.0079028021184147732, 0.0078989970311248662, 0.0078952400676443359, 0.0078915170342885622, 0.0078878345293804421, 0.0078841885914618763, 0.0078805731116591768, 0.0078769846391843236, 0.0078734198338032118, 0.0078698780020724241, 0.0078663598538644391, 0.0078628673486874322, 0.0078593949629531239, 0.0078559335644977444, 0.0078524831389458639, 0.0078490328609132892, 0.007845586367384097, 0.0078421433455215274, 0.0078387006433411621, 0.0078352230228962861, 0.0078316313091039841, 0.0078277930066958813, 0.0078237030048639352, 0.0078191187729711956, 0.0078140770084129153, 0.0078087279303372453, 0.0078032317313611044, 0.0077976946705642187], 'val_acc': [0.0047776552737963983, 0.0047776552737963983, 0.0051451672179345827, 0.005512679162072767, 0.0040426313855200296, 0.0036751194413818448, 0.011760382212421904, 0.012127894156560088, 0.012862918044836457, 0.012862918044836457, 0.013230429988974642, 0.013230429988974642, 0.044836457184858507, 0.046306504961411248, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.046674016905549433, 0.047409040793825796, 0.047776552737963981, 0.048144064682102167, 0.048144064682102167, 0.048879088570378537, 0.048879088570378537, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049246600514516722, 0.049614112458654908, 0.049614112458654908, 0.049614112458654908, 0.049614112458654908, 0.049614112458654908, 0.049981624402793093, 0.049981624402793093, 0.049981624402793093, 0.050349136346931278, 0.050349136346931278, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051084160235207642, 0.051451672179345827, 0.051451672179345827, 0.051451672179345827, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.051819184123484012, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052186696067622197, 0.052554208011760382, 0.052554208011760382, 0.052921719955898568, 0.052921719955898568, 0.052921719955898568, 0.053656743844174938, 0.053656743844174938, 0.053656743844174938, 0.053656743844174938, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054024255788313123, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054391767732451302, 0.054759279676589487, 0.054759279676589487, 0.054759279676589487, 0.055126791620727672, 0.055126791620727672, 0.055126791620727672], 'loss': [0.0097456060741355089, 0.0096138633883199147, 0.0094906422595936006, 0.0093796230974692099, 0.0092782396528235649, 0.0091851251090099301, 0.0090998690866863959, 0.009021160582372444, 0.0089468608180622734, 0.0088769902056900427, 0.0088123619910574214, 0.0087535835869314918, 0.0087002480971419219, 0.008651395762853422, 0.0086062119497969155, 0.0085645877091209254, 0.0085262627356514336, 0.0084907086586667249, 0.008457724215094482, 0.0084272686320507814, 0.0083990744525998581, 0.0083729310920986726, 0.0083487301989905137, 0.0083263408616953381, 0.0083055390133983716, 0.0082861012219605356, 0.0082678811772569517, 0.0082507219584641595, 0.0082345649887416369, 0.0082193334516386125, 0.0082049039954405784, 0.0081910521568890737, 0.0081777497570460107, 0.0081650012658482114, 0.0081527986676570852, 0.0081411546247787125, 0.008130046083349874, 0.0081193767011538739, 0.0081091341629443286, 0.0080993481374096402, 0.0080900580337726295, 0.0080812056698074241, 0.0080727195005753701, 0.008064523145050722, 0.0080566453950131432, 0.0080490675387323105, 0.0080417559716616863, 0.0080346980389256525, 0.0080278478571977063, 0.008021179894041405, 0.0080146785151948216, 0.0080083607428157212, 0.0080022369565725011, 0.0079962915356923819, 0.0079905191981462856, 0.0079849127344435028, 0.0079794727697716072, 0.0079741818762696544, 0.0079690361468868348, 0.0079640270021840206, 0.0079591448928754329, 0.0079543866348369754, 0.0079497432373820762, 0.0079451974673278754, 0.0079407451241203433, 0.0079363824421732187, 0.0079320986174816095, 0.0079278867107378092, 0.0079237404333138781, 0.0079196499255022278, 0.0079156114743013997, 0.0079116325636147521, 0.0079077063562748365, 0.0079038302769981177, 0.0078999991707592501, 0.0078962030679369764, 0.0078924530992478519, 0.0078887370948539023, 0.0078850639036913642, 0.0078814249420343062, 0.007877815947027144, 0.007874235823591369, 0.0078706810496883758, 0.0078671512073261417, 0.007863643657719268, 0.0078601609269387737, 0.0078566995268403873, 0.0078532418136796883, 0.007849792234416229, 0.0078463515721063047, 0.007842917098170251, 0.0078394899235763281, 0.0078360502294554987, 0.0078325520118791535, 0.0078288693947193306, 0.0078249330937837699, 0.0078206475779763526, 0.0078158373626094658, 0.0078106820495321121, 0.0078053172838710577, 0.007799864727196678], 'acc': [0.0052780164486867041, 0.0051552718792193444, 0.0046642936050079785, 0.0056462501534307111, 0.0058917392905363936, 0.0047870381735608198, 0.0074874186817233341, 0.0095740763471216395, 0.010187799189885847, 0.010556032895544373, 0.010678777464097214, 0.010801522033564574, 0.025653614829372919, 0.045292745796913045, 0.045906468638762736, 0.046274702345335775, 0.046520191482441464, 0.046765680618632628, 0.047502148030864194, 0.047870381735608196, 0.047993126289528745, 0.048238615442181242, 0.048484104579286924, 0.048852338284945451, 0.048852338284945451, 0.048975082852583771, 0.049097827422051134, 0.049343316560071335, 0.049343316560071335, 0.049343316559156816, 0.049343316559156816, 0.049343316559156816, 0.049343316558242298, 0.049343316558242298, 0.049466061126795142, 0.049466061128624172, 0.049466061126795142, 0.049711550264815343, 0.050079783971388382, 0.050202528539026708, 0.050570762245599747, 0.05057076224377071, 0.050570762245599747, 0.050938995950343756, 0.050938995950343756, 0.050938995949429237, 0.051184485087449438, 0.051429974224555121, 0.051552718793107966, 0.051675463361660803, 0.052043697068233849, 0.052043697067319331, 0.05216644163495765, 0.05216644163495765, 0.05216644163495765, 0.052289186205339531, 0.052411930773892376, 0.052411930757431044, 0.052411930772063339, 0.052534675340616177, 0.052534675325983882, 0.052534675340616177, 0.052534675340616177, 0.05265741991008354, 0.052902909047189223, 0.052902909048103741, 0.052902909047189223, 0.052902909048103741, 0.053025653614827542, 0.053148398184294905, 0.053639376457591752, 0.053762121027059108, 0.053762121027059108, 0.053884865596526471, 0.053884865595611953, 0.054130354731803117, 0.054375843870737836, 0.054375843870737836, 0.054375843869823318, 0.054375843868908799, 0.054498588437461644, 0.054498588437461644, 0.054498588437461644, 0.054498588437461644, 0.054866822143120164, 0.054866822143120164, 0.054866822144034683, 0.055112311280225847, 0.05523505584969321, 0.055603289555351737, 0.055603289539804923, 0.055726034124819093, 0.055971523261924776, 0.056339756966668784, 0.056462501534307104, 0.057076224380729387, 0.057076224362439025, 0.057444458068097545, 0.05756720263665039, 0.057567202651282678, 0.057689947220750042]}
[2017-11-18 18:14:42,410 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 18:14:42,484 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 18:14:42,485 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 18:14:43,392 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:141]: done!
[2017-11-18 18:14:43,393 AE_UNIGRAMA_2L_FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_2L_FULLDS_UNDER_02 finished!
