[2017-10-15 01:00:45,729 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:146]: >> Initializing execution of experiment AE_UNIGRAMA_2L_OVER_96_172-162_9
[2017-10-15 01:00:45,729 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:147]: >> Printing header log
[2017-10-15 01:00:45,729 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_OVER_96_172-162_9
	layers = 96,172,162,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5b9570e7f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5b815fb860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 01:00:45,730 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:149]: >> Loading dataset... 
[2017-10-15 01:00:46,241 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:54]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 01:00:46,241 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:151]: >> Executing autoencoder part ... 
[2017-10-15 01:00:46,241 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:59]: =======================================
[2017-10-15 01:00:46,241 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:64]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5b9570e7f0>, 'discard_decoder_function': True}
[2017-10-15 01:00:46,305 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:75]: training and evaluate autoencoder
[2017-10-15 01:01:43,138 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:86]: trained and evaluated!
[2017-10-15 01:01:43,140 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:89]: Training history: 
{'val_loss': [0.0098794981816499646, 0.0097112926623358162, 0.0095472804835017733, 0.0093893912139601417, 0.0092375674925495258, 0.0090913773275440955, 0.0089508132233551002, 0.0088169176380762816, 0.0086898209014734367, 0.0085691547637535299, 0.0084547237545030268, 0.008346330855720327, 0.0082436503382004988, 0.0081461371791628663, 0.0080533606401855841, 0.0079650999268440735, 0.0078813167787451285, 0.0078016695684189029, 0.0077259683302953342, 0.007654089395815444, 0.007585734378227957, 0.0075202187519783645, 0.0074573139431557472, 0.0073970003593643802, 0.0073392629973091823, 0.0072841209577583473, 0.0072316508774808346, 0.0071816949457705684, 0.0071341548786675174, 0.0070888965934182632, 0.0070457702336424342, 0.0070047026299300246, 0.0069654942957552831, 0.0069280460521883459, 0.0068921971751106934, 0.0068578044520379439, 0.0068248743347158886, 0.0067933692136384737, 0.0067631463541001861, 0.0067340590433671126, 0.0067061436099439967, 0.0066793480382532876, 0.0066536550468948696, 0.0066290170570565419, 0.0066054089212977092, 0.0065827038966562446, 0.0065609009808351784, 0.0065399746524800158, 0.0065198990474818587, 0.0065005871010286433, 0.0064820471396288904, 0.0064642153157537536, 0.0064470861020556837, 0.006430592458889055, 0.006414739305991333, 0.006399473983822148, 0.0063847640103428561, 0.0063706045783363755, 0.006356949329403918, 0.0063437953691749547, 0.006331103734436642, 0.0063188809929173228, 0.0063070906499283017, 0.0062957232883788621, 0.0062847589488837135, 0.0062741764533752404, 0.0062639454577021218, 0.0062540744043554294, 0.006244544531859208, 0.0062353372812741972, 0.0062264558585658396, 0.0062178765115463155, 0.0062095849951348337, 0.0062015800040949231, 0.0061938280783261287, 0.0061863380688550748, 0.0061790924536611292, 0.0061720937566630898, 0.0061653156567461872, 0.0061587682738207753, 0.0061524198580962574, 0.0061462788347528769, 0.0061403269495219548, 0.0061345739207026243, 0.0061290013555395781, 0.0061236044710508957, 0.0061183741755894347, 0.006113304147240619, 0.0061084022416584335, 0.0061036419905860628, 0.006099022092249203, 0.0060945472551932126, 0.0060901916603173468, 0.0060859546619277021, 0.0060818306928618251, 0.0060778354159573642, 0.0060739475544749804, 0.0060701554166810888, 0.0060664604566852843, 0.0060628672618571267, 0.0060593705991331534, 0.0060559553146140727], 'loss': [0.0099600350745274163, 0.0097902771514813518, 0.0096229700710493953, 0.0094608189973158195, 0.0093048968075899966, 0.0091549208537705772, 0.009010498516133357, 0.0088719803881135983, 0.0087403571977295539, 0.0086154030325702891, 0.0084968183215961696, 0.0083843752393784072, 0.0082777818583625179, 0.0081766208229654032, 0.0080803531939284013, 0.0079886961708872245, 0.0079016150109877444, 0.0078188983435023025, 0.0077401852546020488, 0.0076653505666908414, 0.0075942527547996144, 0.0075264255079476837, 0.0074612280023619122, 0.0073987360715696655, 0.0073388974163990373, 0.0072816708583107702, 0.0072270713940597083, 0.0071750990997773226, 0.0071255813442060714, 0.0070784331915285338, 0.0070335115214492658, 0.0069906558957667569, 0.0069498138870876776, 0.0069107856840747005, 0.0068734059099980344, 0.0068376184027291696, 0.0068032708489545006, 0.0067703572348602799, 0.0067388431813634273, 0.0067085407582153445, 0.0066793835535874455, 0.0066513777733394064, 0.0066244927041470714, 0.0065986931996022766, 0.0065739483632074039, 0.006550206952186252, 0.0065273371074044163, 0.006505379573509015, 0.0064842860654028521, 0.0064640253628864561, 0.0064445231015408744, 0.006425795403779121, 0.0064077483660117318, 0.0063903990156431098, 0.0063736914827636623, 0.0063576088793525394, 0.0063421128262761695, 0.0063271598524649265, 0.006312766292126141, 0.0062988584766138092, 0.0062854511118949049, 0.0062725159199936995, 0.0062600224262839566, 0.0062479652861074835, 0.0062363436414110893, 0.0062251163448522485, 0.006214285908197067, 0.0062037915613596143, 0.0061936530072216837, 0.0061838654157280303, 0.0061743987281134179, 0.0061652626514265381, 0.0061564267986209649, 0.0061478606306735401, 0.0061395873236066373, 0.0061315711013533144, 0.0061238096061276559, 0.0061163067003138496, 0.006109046510500306, 0.0061020011868792657, 0.00609518877203681, 0.0060885783694753191, 0.0060821772139741555, 0.006075960587133146, 0.0060699620660790545, 0.006064133195420607, 0.0060584834678363017, 0.0060529978287571697, 0.0060476791491410305, 0.0060425314536523105, 0.0060375352984279413, 0.006032659292688162, 0.0060279453445177874, 0.0060233474404567692, 0.0060188677949005462, 0.0060145078858299976, 0.006010280662750311, 0.0060061586705353011, 0.0060021284110180128, 0.0059982207079990989, 0.0059943898771583261, 0.0059906631065893192]}
[2017-10-15 01:01:43,140 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:93]: done!
[2017-10-15 01:01:43,140 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:153]: >> Executing classifier part ... 
[2017-10-15 01:01:43,140 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:98]: =======================================
[2017-10-15 01:01:43,140 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:102]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5b815fb860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 01:01:43,198 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:111]: training ... 
[2017-10-15 01:03:18,772 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:123]: trained!
[2017-10-15 01:03:18,773 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:126]: Training history: 
{'val_loss': [0.0098794981816499646, 0.0097112926623358162, 0.0095472804835017733, 0.0093893912139601417, 0.0092375674925495258, 0.0090913773275440955, 0.0089508132233551002, 0.0088169176380762816, 0.0086898209014734367, 0.0085691547637535299, 0.0084547237545030268, 0.008346330855720327, 0.0082436503382004988, 0.0081461371791628663, 0.0080533606401855841, 0.0079650999268440735, 0.0078813167787451285, 0.0078016695684189029, 0.0077259683302953342, 0.007654089395815444, 0.007585734378227957, 0.0075202187519783645, 0.0074573139431557472, 0.0073970003593643802, 0.0073392629973091823, 0.0072841209577583473, 0.0072316508774808346, 0.0071816949457705684, 0.0071341548786675174, 0.0070888965934182632, 0.0070457702336424342, 0.0070047026299300246, 0.0069654942957552831, 0.0069280460521883459, 0.0068921971751106934, 0.0068578044520379439, 0.0068248743347158886, 0.0067933692136384737, 0.0067631463541001861, 0.0067340590433671126, 0.0067061436099439967, 0.0066793480382532876, 0.0066536550468948696, 0.0066290170570565419, 0.0066054089212977092, 0.0065827038966562446, 0.0065609009808351784, 0.0065399746524800158, 0.0065198990474818587, 0.0065005871010286433, 0.0064820471396288904, 0.0064642153157537536, 0.0064470861020556837, 0.006430592458889055, 0.006414739305991333, 0.006399473983822148, 0.0063847640103428561, 0.0063706045783363755, 0.006356949329403918, 0.0063437953691749547, 0.006331103734436642, 0.0063188809929173228, 0.0063070906499283017, 0.0062957232883788621, 0.0062847589488837135, 0.0062741764533752404, 0.0062639454577021218, 0.0062540744043554294, 0.006244544531859208, 0.0062353372812741972, 0.0062264558585658396, 0.0062178765115463155, 0.0062095849951348337, 0.0062015800040949231, 0.0061938280783261287, 0.0061863380688550748, 0.0061790924536611292, 0.0061720937566630898, 0.0061653156567461872, 0.0061587682738207753, 0.0061524198580962574, 0.0061462788347528769, 0.0061403269495219548, 0.0061345739207026243, 0.0061290013555395781, 0.0061236044710508957, 0.0061183741755894347, 0.006113304147240619, 0.0061084022416584335, 0.0061036419905860628, 0.006099022092249203, 0.0060945472551932126, 0.0060901916603173468, 0.0060859546619277021, 0.0060818306928618251, 0.0060778354159573642, 0.0060739475544749804, 0.0060701554166810888, 0.0060664604566852843, 0.0060628672618571267, 0.0060593705991331534, 0.0060559553146140727], 'loss': [0.0099600350745274163, 0.0097902771514813518, 0.0096229700710493953, 0.0094608189973158195, 0.0093048968075899966, 0.0091549208537705772, 0.009010498516133357, 0.0088719803881135983, 0.0087403571977295539, 0.0086154030325702891, 0.0084968183215961696, 0.0083843752393784072, 0.0082777818583625179, 0.0081766208229654032, 0.0080803531939284013, 0.0079886961708872245, 0.0079016150109877444, 0.0078188983435023025, 0.0077401852546020488, 0.0076653505666908414, 0.0075942527547996144, 0.0075264255079476837, 0.0074612280023619122, 0.0073987360715696655, 0.0073388974163990373, 0.0072816708583107702, 0.0072270713940597083, 0.0071750990997773226, 0.0071255813442060714, 0.0070784331915285338, 0.0070335115214492658, 0.0069906558957667569, 0.0069498138870876776, 0.0069107856840747005, 0.0068734059099980344, 0.0068376184027291696, 0.0068032708489545006, 0.0067703572348602799, 0.0067388431813634273, 0.0067085407582153445, 0.0066793835535874455, 0.0066513777733394064, 0.0066244927041470714, 0.0065986931996022766, 0.0065739483632074039, 0.006550206952186252, 0.0065273371074044163, 0.006505379573509015, 0.0064842860654028521, 0.0064640253628864561, 0.0064445231015408744, 0.006425795403779121, 0.0064077483660117318, 0.0063903990156431098, 0.0063736914827636623, 0.0063576088793525394, 0.0063421128262761695, 0.0063271598524649265, 0.006312766292126141, 0.0062988584766138092, 0.0062854511118949049, 0.0062725159199936995, 0.0062600224262839566, 0.0062479652861074835, 0.0062363436414110893, 0.0062251163448522485, 0.006214285908197067, 0.0062037915613596143, 0.0061936530072216837, 0.0061838654157280303, 0.0061743987281134179, 0.0061652626514265381, 0.0061564267986209649, 0.0061478606306735401, 0.0061395873236066373, 0.0061315711013533144, 0.0061238096061276559, 0.0061163067003138496, 0.006109046510500306, 0.0061020011868792657, 0.00609518877203681, 0.0060885783694753191, 0.0060821772139741555, 0.006075960587133146, 0.0060699620660790545, 0.006064133195420607, 0.0060584834678363017, 0.0060529978287571697, 0.0060476791491410305, 0.0060425314536523105, 0.0060375352984279413, 0.006032659292688162, 0.0060279453445177874, 0.0060233474404567692, 0.0060188677949005462, 0.0060145078858299976, 0.006010280662750311, 0.0060061586705353011, 0.0060021284110180128, 0.0059982207079990989, 0.0059943898771583261, 0.0059906631065893192]}
[2017-10-15 01:03:18,773 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:130]: evaluating model ... 
[2017-10-15 01:03:18,839 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:134]: evaluated! 
[2017-10-15 01:03:18,839 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:136]: generating reports ... 
[2017-10-15 01:03:19,382 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:139]: done!
[2017-10-15 01:03:19,382 AE_UNIGRAMA_2L_OVER_96_172-162_9.py:155]: >> experiment AE_UNIGRAMA_2L_OVER_96_172-162_9 finished!
