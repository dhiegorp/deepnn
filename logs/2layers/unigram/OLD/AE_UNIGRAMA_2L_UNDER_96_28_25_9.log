[2017-10-15 01:06:41,776 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_96_28_25_9
[2017-10-15 01:06:41,777 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:148]: >> Printing header log
[2017-10-15 01:06:41,777 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_96_28_25_9
	layers = 96,28,25,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7feb4f422860>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7feb3b2fa748>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 01:06:41,777 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:150]: >> Loading dataset... 
[2017-10-15 01:06:42,304 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 01:06:42,304 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:152]: >> Executing autoencoder part ... 
[2017-10-15 01:06:42,304 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:60]: =======================================
[2017-10-15 01:06:42,305 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7feb4f422860>, 'discard_decoder_function': True}
[2017-10-15 01:06:42,369 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:76]: training and evaluate autoencoder
[2017-10-15 01:07:08,859 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:87]: trained and evaluated!
[2017-10-15 01:07:08,859 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:90]: Training history: 
{'val_loss': [0.010227622021141991, 0.010183508542529047, 0.010138453614506802, 0.010094624871325758, 0.010051933778484515, 0.010010119032488659, 0.0099694616919501124, 0.0099302856216975741, 0.009892602880454196, 0.009856330223907769, 0.0098213610381275747, 0.009787666538667944, 0.0097552920106562975, 0.0097242908718472958, 0.0096945647067186117, 0.0096660492401639334, 0.0096386713547057384, 0.0096123673672680512, 0.0095870610686593777, 0.0095626870066370662, 0.0095392268559580402, 0.0095166453579267601, 0.0094948313597132718, 0.0094736509655211059, 0.0094531052174621349, 0.0094333349425885765, 0.0094142564707418355, 0.0093958709998312497, 0.0093781458123909055, 0.0093610087534253487, 0.0093445036539524014, 0.0093285637010982938, 0.0093131632609881436, 0.0092982680200976511, 0.0092838921213737203, 0.0092700051393041372, 0.0092565523439734395, 0.0092435261740117271, 0.0092308884313447772, 0.0092186349129034246, 0.0092067156492500503, 0.0091951274101840525, 0.0091838470476655262, 0.009172783548282425, 0.0091618155527402913, 0.0091508964637509061, 0.0091401352495176641, 0.0091296508873650126, 0.0091194530678947623, 0.0091095379758003026, 0.0090998735998975306, 0.0090903965721675448, 0.0090810998886491287, 0.0090719692159762621, 0.0090630255902677658, 0.0090543106232932515, 0.0090458380425397344, 0.0090375845510941907, 0.0090295455719735535, 0.0090217250970548862, 0.009014108405209607, 0.0090066951363724848, 0.0089994720685326914, 0.0089924282647087673, 0.0089855785464320933, 0.0089789120528888534, 0.0089724072217110366, 0.0089660612658552519, 0.0089598723296006808, 0.0089538404025608278, 0.0089479455426612307, 0.0089422003037147365, 0.0089365868382571354, 0.0089311141167597707, 0.0089257714930630963, 0.0089205629694306711, 0.0089154808113843086, 0.0089105184546578332, 0.008905674594014772, 0.0089009442231635181, 0.0088963308596644256, 0.0088918143987212483, 0.0088874080519583138, 0.0088831005188667635, 0.0088788917648249394, 0.0088747821395115788, 0.0088707664289051271, 0.0088668325985175964, 0.0088629979937991689, 0.008859246830736394, 0.0088555774371032372, 0.0088519911735308217, 0.0088484880781029684, 0.0088450598520084835, 0.0088417007203549693, 0.0088384080138126722, 0.0088351953733144632, 0.0088320507332128664, 0.0088289675742498561, 0.0088259495040020983, 0.008822992392105905, 0.0088200939396832507], 'loss': [0.01024678239877065, 0.010204557089001105, 0.010160112621282132, 0.010115996561830001, 0.010073176076831485, 0.010031278426034837, 0.0099903034188251732, 0.0099506217713874762, 0.0099124751416090513, 0.0098757542384709397, 0.0098403755966951743, 0.0098062979421488471, 0.0097735071487234787, 0.009742019759272422, 0.0097118650374736024, 0.0096829390461249231, 0.009655189023255276, 0.0096285251520468774, 0.0096028839342740327, 0.0095781929133838869, 0.0095544340885768079, 0.009531570924188399, 0.0095095301702957467, 0.0094881912066012205, 0.0094674847998324901, 0.0094474510060189396, 0.0094281801897814904, 0.0094095745153116098, 0.0093916366391969229, 0.0093743389199894851, 0.0093576045198561809, 0.0093414816157073796, 0.0093259002261216386, 0.0093108458540642203, 0.0092962819678776461, 0.0092822319971650521, 0.0092686577851769005, 0.0092554955766722333, 0.0092427475806085256, 0.0092303654208742703, 0.0092183446188783009, 0.009206656256682608, 0.009195274461607993, 0.0091841609670008408, 0.0091731901095691241, 0.0091622674742687232, 0.0091514434137672969, 0.0091408404527940704, 0.0091305264330754712, 0.0091204994524695712, 0.0091107278872228654, 0.0091011844908551864, 0.0090918122906954515, 0.0090826140852907199, 0.009073578948916361, 0.0090647524362401349, 0.0090561612682633404, 0.0090478096682791269, 0.0090396760035015428, 0.0090317515377012509, 0.0090240341059968886, 0.0090165212641675624, 0.0090092077625763146, 0.0090020780932998541, 0.0089951209121766681, 0.0089883566716687045, 0.0089817675186599326, 0.008975333586843489, 0.008969060125856328, 0.0089629396862626887, 0.0089569639159250859, 0.0089511386981461771, 0.0089454569498371266, 0.0089399027200238283, 0.0089344926797810618, 0.0089292027578261567, 0.0089240545096687541, 0.0089190258714928541, 0.0089141087613418268, 0.0089093143390588918, 0.0089046296422594737, 0.0089000569634739429, 0.0088955850861897924, 0.0088912111059628023, 0.0088869378585471424, 0.0088827577433889457, 0.0088786766872945636, 0.0088746878046590486, 0.0088707807959820424, 0.0088669723781316864, 0.008863248704911451, 0.0088596024104584635, 0.0088560363900582698, 0.0088525577691585724, 0.0088491413665599955, 0.0088458018636155804, 0.0088425242761636554, 0.0088393226318569662, 0.0088361902780643101, 0.0088331137000186421, 0.0088301053592395994, 0.0088271538222686012]}
[2017-10-15 01:07:08,859 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:94]: done!
[2017-10-15 01:07:08,859 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:154]: >> Executing classifier part ... 
[2017-10-15 01:07:08,859 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:99]: =======================================
[2017-10-15 01:07:08,859 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7feb3b2fa748>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 01:07:08,890 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:112]: training ... 
[2017-10-15 01:08:03,102 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:124]: trained!
[2017-10-15 01:08:03,103 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:127]: Training history: 
{'val_loss': [0.010227622021141991, 0.010183508542529047, 0.010138453614506802, 0.010094624871325758, 0.010051933778484515, 0.010010119032488659, 0.0099694616919501124, 0.0099302856216975741, 0.009892602880454196, 0.009856330223907769, 0.0098213610381275747, 0.009787666538667944, 0.0097552920106562975, 0.0097242908718472958, 0.0096945647067186117, 0.0096660492401639334, 0.0096386713547057384, 0.0096123673672680512, 0.0095870610686593777, 0.0095626870066370662, 0.0095392268559580402, 0.0095166453579267601, 0.0094948313597132718, 0.0094736509655211059, 0.0094531052174621349, 0.0094333349425885765, 0.0094142564707418355, 0.0093958709998312497, 0.0093781458123909055, 0.0093610087534253487, 0.0093445036539524014, 0.0093285637010982938, 0.0093131632609881436, 0.0092982680200976511, 0.0092838921213737203, 0.0092700051393041372, 0.0092565523439734395, 0.0092435261740117271, 0.0092308884313447772, 0.0092186349129034246, 0.0092067156492500503, 0.0091951274101840525, 0.0091838470476655262, 0.009172783548282425, 0.0091618155527402913, 0.0091508964637509061, 0.0091401352495176641, 0.0091296508873650126, 0.0091194530678947623, 0.0091095379758003026, 0.0090998735998975306, 0.0090903965721675448, 0.0090810998886491287, 0.0090719692159762621, 0.0090630255902677658, 0.0090543106232932515, 0.0090458380425397344, 0.0090375845510941907, 0.0090295455719735535, 0.0090217250970548862, 0.009014108405209607, 0.0090066951363724848, 0.0089994720685326914, 0.0089924282647087673, 0.0089855785464320933, 0.0089789120528888534, 0.0089724072217110366, 0.0089660612658552519, 0.0089598723296006808, 0.0089538404025608278, 0.0089479455426612307, 0.0089422003037147365, 0.0089365868382571354, 0.0089311141167597707, 0.0089257714930630963, 0.0089205629694306711, 0.0089154808113843086, 0.0089105184546578332, 0.008905674594014772, 0.0089009442231635181, 0.0088963308596644256, 0.0088918143987212483, 0.0088874080519583138, 0.0088831005188667635, 0.0088788917648249394, 0.0088747821395115788, 0.0088707664289051271, 0.0088668325985175964, 0.0088629979937991689, 0.008859246830736394, 0.0088555774371032372, 0.0088519911735308217, 0.0088484880781029684, 0.0088450598520084835, 0.0088417007203549693, 0.0088384080138126722, 0.0088351953733144632, 0.0088320507332128664, 0.0088289675742498561, 0.0088259495040020983, 0.008822992392105905, 0.0088200939396832507], 'loss': [0.01024678239877065, 0.010204557089001105, 0.010160112621282132, 0.010115996561830001, 0.010073176076831485, 0.010031278426034837, 0.0099903034188251732, 0.0099506217713874762, 0.0099124751416090513, 0.0098757542384709397, 0.0098403755966951743, 0.0098062979421488471, 0.0097735071487234787, 0.009742019759272422, 0.0097118650374736024, 0.0096829390461249231, 0.009655189023255276, 0.0096285251520468774, 0.0096028839342740327, 0.0095781929133838869, 0.0095544340885768079, 0.009531570924188399, 0.0095095301702957467, 0.0094881912066012205, 0.0094674847998324901, 0.0094474510060189396, 0.0094281801897814904, 0.0094095745153116098, 0.0093916366391969229, 0.0093743389199894851, 0.0093576045198561809, 0.0093414816157073796, 0.0093259002261216386, 0.0093108458540642203, 0.0092962819678776461, 0.0092822319971650521, 0.0092686577851769005, 0.0092554955766722333, 0.0092427475806085256, 0.0092303654208742703, 0.0092183446188783009, 0.009206656256682608, 0.009195274461607993, 0.0091841609670008408, 0.0091731901095691241, 0.0091622674742687232, 0.0091514434137672969, 0.0091408404527940704, 0.0091305264330754712, 0.0091204994524695712, 0.0091107278872228654, 0.0091011844908551864, 0.0090918122906954515, 0.0090826140852907199, 0.009073578948916361, 0.0090647524362401349, 0.0090561612682633404, 0.0090478096682791269, 0.0090396760035015428, 0.0090317515377012509, 0.0090240341059968886, 0.0090165212641675624, 0.0090092077625763146, 0.0090020780932998541, 0.0089951209121766681, 0.0089883566716687045, 0.0089817675186599326, 0.008975333586843489, 0.008969060125856328, 0.0089629396862626887, 0.0089569639159250859, 0.0089511386981461771, 0.0089454569498371266, 0.0089399027200238283, 0.0089344926797810618, 0.0089292027578261567, 0.0089240545096687541, 0.0089190258714928541, 0.0089141087613418268, 0.0089093143390588918, 0.0089046296422594737, 0.0089000569634739429, 0.0088955850861897924, 0.0088912111059628023, 0.0088869378585471424, 0.0088827577433889457, 0.0088786766872945636, 0.0088746878046590486, 0.0088707807959820424, 0.0088669723781316864, 0.008863248704911451, 0.0088596024104584635, 0.0088560363900582698, 0.0088525577691585724, 0.0088491413665599955, 0.0088458018636155804, 0.0088425242761636554, 0.0088393226318569662, 0.0088361902780643101, 0.0088331137000186421, 0.0088301053592395994, 0.0088271538222686012]}
[2017-10-15 01:08:03,103 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:131]: evaluating model ... 
[2017-10-15 01:08:03,171 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:135]: evaluated! 
[2017-10-15 01:08:03,171 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:137]: generating reports ... 
[2017-10-15 01:08:03,737 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:140]: done!
[2017-10-15 01:08:03,737 AE_UNIGRAMA_2L_UNDER_96_28_25_9.py:156]: >> experiment AE_UNIGRAMA_2L_UNDER_96_28_25_9 finished!
