[2017-10-14 23:56:39,598 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_96_86_76_9
[2017-10-14 23:56:39,599 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:150]: >> Printing header log
[2017-10-14 23:56:39,599 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:40]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_96_86_76_9
	layers = 96,86,76,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f61978ff7f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f61837badd8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-14 23:56:39,599 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:152]: >> Loading dataset... 
[2017-10-14 23:56:40,127 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:57]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-14 23:56:40,128 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:154]: >> Executing autoencoder part ... 
[2017-10-14 23:56:40,128 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:62]: =======================================
[2017-10-14 23:56:40,128 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:67]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f61978ff7f0>, 'discard_decoder_function': True}
[2017-10-14 23:56:40,191 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:78]: training and evaluate autoencoder
[2017-10-14 23:58:54,776 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:149]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_96_86_76_9
[2017-10-14 23:58:54,776 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:150]: >> Printing header log
[2017-10-14 23:58:54,776 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:40]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_96_86_76_9
	layers = 96,86,76,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8297766860>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f828363a7b8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-14 23:58:54,776 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:152]: >> Loading dataset... 
[2017-10-14 23:58:55,300 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:57]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-14 23:58:55,300 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:154]: >> Executing autoencoder part ... 
[2017-10-14 23:58:55,300 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:62]: =======================================
[2017-10-14 23:58:55,300 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:67]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8297766860>, 'discard_decoder_function': True}
[2017-10-14 23:58:55,365 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:78]: training and evaluate autoencoder
[2017-10-14 23:59:31,770 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:89]: trained and evaluated!
[2017-10-14 23:59:31,771 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:92]: Training history: 
{'val_loss': [0.0099979547167466914, 0.0098730505766090847, 0.0097468134542047762, 0.009619155867530732, 0.009492277226594301, 0.0093668076663267659, 0.0092440538599976377, 0.0091245426592108936, 0.0090076163563475725, 0.0088923856906842121, 0.0087793997755502683, 0.0086686082364347342, 0.0085608919937038945, 0.0084564224141736449, 0.0083555787469374639, 0.0082583593041895709, 0.0081646498379238704, 0.0080746831458934406, 0.0079884874534041916, 0.0079058702294212743, 0.0078264626338524004, 0.0077500706746287951, 0.0076765754834842281, 0.007605688767611537, 0.0075372443620987982, 0.007470733003143817, 0.0074061694568833235, 0.0073437980033429582, 0.0072837261877760125, 0.0072259721536618625, 0.0071704508563621341, 0.0071172169427003119, 0.0070660895612575528, 0.0070169824296712436, 0.0069697593723087948, 0.0069243148796703513, 0.006880608745625582, 0.0068385318842574564, 0.0067979169916015355, 0.0067588085218654691, 0.0067211628673411209, 0.0066849424341021858, 0.0066500233268178303, 0.0066163941740047978, 0.0065839723857001962, 0.0065527183460729497, 0.0065225679946710182, 0.0064934722120184663, 0.0064653706006345697, 0.0064381627092435683, 0.006411876664479647, 0.0063864656353584013, 0.0063619061639760954, 0.0063381608572120338, 0.0063152610390104329, 0.0062931676630664712, 0.0062718536033118527, 0.0062513141338903884, 0.0062315069229020061, 0.0062124004732942049, 0.0061939799946950933, 0.0061761991027396409, 0.0061590244896626827, 0.0061424594341351422, 0.0061264280402915181, 0.0061109726192588925, 0.0060960452546639067, 0.0060816071962169109, 0.0060676747472562086, 0.0060541938443332355, 0.0060411686680130802, 0.0060285942639366182, 0.006016427401771776, 0.006004646531268123, 0.005993262487273234, 0.0059822348420781714, 0.0059715663463735889, 0.0059612276894646281, 0.005951202410484446, 0.0059415070447364484, 0.0059321278855066096, 0.005923051139526762, 0.0059142309763783856, 0.0059056928966429818, 0.0058974085070996034, 0.0058893655637992362, 0.0058815621590885755, 0.0058739864298568336, 0.0058666186088689194, 0.0058594465110326345, 0.0058524949254544255, 0.0058457283372384912, 0.0058391440407023331, 0.0058327379331795919, 0.0058264925601618665, 0.0058203972356747078, 0.0058144520583898384, 0.0058086380937230186, 0.0058029667252750871, 0.0057974012887112274, 0.005791923356654476, 0.0057865481366676909], 'loss': [0.010055386100694784, 0.0099329546021816179, 0.0098061710063736714, 0.0096781573893150886, 0.0095497320898989997, 0.0094227603371652927, 0.0092978716931536518, 0.0091760701762618798, 0.009057334268187443, 0.0089407887735667955, 0.008826192060271399, 0.0087137890094690848, 0.0086040953540580355, 0.0084975679904753694, 0.0083944370092042184, 0.008295014086760439, 0.0081991657022828703, 0.0081069170129293676, 0.0080184477427774001, 0.0079336702679389821, 0.0078523197344698339, 0.0077740612846799772, 0.0076987392720711985, 0.0076261928817915568, 0.0075562143722376213, 0.0074884018897392046, 0.0074223920914156163, 0.0073584352706380978, 0.0072967447194522079, 0.0072373700669904244, 0.0071802497781314001, 0.0071253745934565923, 0.0070727614954356668, 0.0070222070006757849, 0.0069736290397380092, 0.0069268756115622478, 0.0068818854924220397, 0.0068385945469914911, 0.0067968322207421963, 0.0067565333225249732, 0.0067177459013149756, 0.0066803939278181996, 0.0066444322492036634, 0.0066097494888508069, 0.0065763218602544523, 0.0065440926949831887, 0.0065130112356704918, 0.0064830060947523869, 0.0064540352362088436, 0.0064260130364633293, 0.0063988668354687216, 0.0063726464761552741, 0.0063472812031936665, 0.0063227635705826396, 0.0062990542389589838, 0.006276188104298394, 0.0062540928133692966, 0.0062327824049865678, 0.0062122318221653396, 0.0061923980921250437, 0.0061732725212814143, 0.006154829218924119, 0.0061370121107906673, 0.0061197876286267616, 0.0061031762724049667, 0.0060870921028607378, 0.0060715859929888474, 0.0060565927313193085, 0.006042083852123595, 0.006028093613704784, 0.0060145414386290341, 0.0060014470921716002, 0.0059887967049530588, 0.0059765613481594726, 0.005964701345846396, 0.0059532259909187675, 0.0059421170890999854, 0.0059313561235564251, 0.0059209298837607123, 0.0059108188611666484, 0.0059010389600963444, 0.0058915730518275741, 0.0058824036023668261, 0.0058734920147758326, 0.0058648657158461353, 0.0058564906413240457, 0.0058483642419501361, 0.0058404626084357664, 0.0058327963299243338, 0.005825335515368805, 0.0058180576533230265, 0.0058110090145485202, 0.0058041521927345253, 0.0057974593549595882, 0.0057909657503807371, 0.005784627927676732, 0.0057784345693034523, 0.0057724044622753795, 0.0057664990334095551, 0.0057607350619675816, 0.005755074667963574, 0.0057495105796972704]}
[2017-10-14 23:59:31,771 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:96]: done!
[2017-10-14 23:59:31,771 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:156]: >> Executing classifier part ... 
[2017-10-14 23:59:31,771 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:101]: =======================================
[2017-10-14 23:59:31,771 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:105]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f828363a7b8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-14 23:59:31,801 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:114]: training ... 
[2017-10-15 01:00:36,021 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:126]: trained!
[2017-10-15 01:00:36,022 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:129]: Training history: 
{'val_loss': [0.0099979547167466914, 0.0098730505766090847, 0.0097468134542047762, 0.009619155867530732, 0.009492277226594301, 0.0093668076663267659, 0.0092440538599976377, 0.0091245426592108936, 0.0090076163563475725, 0.0088923856906842121, 0.0087793997755502683, 0.0086686082364347342, 0.0085608919937038945, 0.0084564224141736449, 0.0083555787469374639, 0.0082583593041895709, 0.0081646498379238704, 0.0080746831458934406, 0.0079884874534041916, 0.0079058702294212743, 0.0078264626338524004, 0.0077500706746287951, 0.0076765754834842281, 0.007605688767611537, 0.0075372443620987982, 0.007470733003143817, 0.0074061694568833235, 0.0073437980033429582, 0.0072837261877760125, 0.0072259721536618625, 0.0071704508563621341, 0.0071172169427003119, 0.0070660895612575528, 0.0070169824296712436, 0.0069697593723087948, 0.0069243148796703513, 0.006880608745625582, 0.0068385318842574564, 0.0067979169916015355, 0.0067588085218654691, 0.0067211628673411209, 0.0066849424341021858, 0.0066500233268178303, 0.0066163941740047978, 0.0065839723857001962, 0.0065527183460729497, 0.0065225679946710182, 0.0064934722120184663, 0.0064653706006345697, 0.0064381627092435683, 0.006411876664479647, 0.0063864656353584013, 0.0063619061639760954, 0.0063381608572120338, 0.0063152610390104329, 0.0062931676630664712, 0.0062718536033118527, 0.0062513141338903884, 0.0062315069229020061, 0.0062124004732942049, 0.0061939799946950933, 0.0061761991027396409, 0.0061590244896626827, 0.0061424594341351422, 0.0061264280402915181, 0.0061109726192588925, 0.0060960452546639067, 0.0060816071962169109, 0.0060676747472562086, 0.0060541938443332355, 0.0060411686680130802, 0.0060285942639366182, 0.006016427401771776, 0.006004646531268123, 0.005993262487273234, 0.0059822348420781714, 0.0059715663463735889, 0.0059612276894646281, 0.005951202410484446, 0.0059415070447364484, 0.0059321278855066096, 0.005923051139526762, 0.0059142309763783856, 0.0059056928966429818, 0.0058974085070996034, 0.0058893655637992362, 0.0058815621590885755, 0.0058739864298568336, 0.0058666186088689194, 0.0058594465110326345, 0.0058524949254544255, 0.0058457283372384912, 0.0058391440407023331, 0.0058327379331795919, 0.0058264925601618665, 0.0058203972356747078, 0.0058144520583898384, 0.0058086380937230186, 0.0058029667252750871, 0.0057974012887112274, 0.005791923356654476, 0.0057865481366676909], 'loss': [0.010055386100694784, 0.0099329546021816179, 0.0098061710063736714, 0.0096781573893150886, 0.0095497320898989997, 0.0094227603371652927, 0.0092978716931536518, 0.0091760701762618798, 0.009057334268187443, 0.0089407887735667955, 0.008826192060271399, 0.0087137890094690848, 0.0086040953540580355, 0.0084975679904753694, 0.0083944370092042184, 0.008295014086760439, 0.0081991657022828703, 0.0081069170129293676, 0.0080184477427774001, 0.0079336702679389821, 0.0078523197344698339, 0.0077740612846799772, 0.0076987392720711985, 0.0076261928817915568, 0.0075562143722376213, 0.0074884018897392046, 0.0074223920914156163, 0.0073584352706380978, 0.0072967447194522079, 0.0072373700669904244, 0.0071802497781314001, 0.0071253745934565923, 0.0070727614954356668, 0.0070222070006757849, 0.0069736290397380092, 0.0069268756115622478, 0.0068818854924220397, 0.0068385945469914911, 0.0067968322207421963, 0.0067565333225249732, 0.0067177459013149756, 0.0066803939278181996, 0.0066444322492036634, 0.0066097494888508069, 0.0065763218602544523, 0.0065440926949831887, 0.0065130112356704918, 0.0064830060947523869, 0.0064540352362088436, 0.0064260130364633293, 0.0063988668354687216, 0.0063726464761552741, 0.0063472812031936665, 0.0063227635705826396, 0.0062990542389589838, 0.006276188104298394, 0.0062540928133692966, 0.0062327824049865678, 0.0062122318221653396, 0.0061923980921250437, 0.0061732725212814143, 0.006154829218924119, 0.0061370121107906673, 0.0061197876286267616, 0.0061031762724049667, 0.0060870921028607378, 0.0060715859929888474, 0.0060565927313193085, 0.006042083852123595, 0.006028093613704784, 0.0060145414386290341, 0.0060014470921716002, 0.0059887967049530588, 0.0059765613481594726, 0.005964701345846396, 0.0059532259909187675, 0.0059421170890999854, 0.0059313561235564251, 0.0059209298837607123, 0.0059108188611666484, 0.0059010389600963444, 0.0058915730518275741, 0.0058824036023668261, 0.0058734920147758326, 0.0058648657158461353, 0.0058564906413240457, 0.0058483642419501361, 0.0058404626084357664, 0.0058327963299243338, 0.005825335515368805, 0.0058180576533230265, 0.0058110090145485202, 0.0058041521927345253, 0.0057974593549595882, 0.0057909657503807371, 0.005784627927676732, 0.0057784345693034523, 0.0057724044622753795, 0.0057664990334095551, 0.0057607350619675816, 0.005755074667963574, 0.0057495105796972704]}
[2017-10-15 01:00:36,022 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:133]: evaluating model ... 
[2017-10-15 01:00:36,083 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:137]: evaluated! 
[2017-10-15 01:00:36,083 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:139]: generating reports ... 
[2017-10-15 01:00:36,629 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:142]: done!
[2017-10-15 01:00:36,629 AE_UNIGRAMA_2L_UNDER_96_86_76_9.py:158]: >> experiment AE_UNIGRAMA_2L_UNDER_96_86_76_9 finished!
