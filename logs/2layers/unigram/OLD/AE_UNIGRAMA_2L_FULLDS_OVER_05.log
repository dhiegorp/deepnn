[2017-11-14 08:15:57,748 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_FULLDS_OVER_05
[2017-11-14 08:15:57,748 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-14 08:15:57,748 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_FULLDS_OVER_05
	layers = 96,172,156
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5cfd9c4eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5cfd9c9400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-14 08:15:57,748 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-14 08:15:59,906 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-14 08:15:59,906 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-14 08:15:59,907 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-14 08:15:59,907 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5cfd9c4eb8>, 'discard_decoder_function': True}
[2017-11-14 08:15:59,965 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-14 08:18:50,503 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-14 08:18:50,504 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0095264416982757619, 0.0090368803544671646, 0.0084424861256705407, 0.0079352430007031995, 0.0075072301164932085, 0.0071524099305816996, 0.0068516884673727714, 0.0065947743257639803, 0.0063781250699141562, 0.006196506407682793, 0.006043609516480879, 0.0059144532967540919, 0.0058046904531502954, 0.0057112117820254738, 0.0056310057563406721, 0.0055616491694805634, 0.0055011437298988089, 0.005447946941084374, 0.0054008515543300618, 0.005358843810552405, 0.0053211828766138083, 0.005287126051683016, 0.0052561958220153117, 0.0052277999010227295, 0.0052015216899943323, 0.0051770962558950967, 0.00515428070656309, 0.005132893827794827, 0.0051128184063464832, 0.0050939166509723979, 0.0050761744461971436, 0.0050593932484061304, 0.0050434951952157848, 0.0050283226566009281, 0.0050137843917001101, 0.0049997976821433456, 0.0049861953379870426, 0.0049728877435635827, 0.0049595186340176626, 0.0049463024766631739, 0.0049334390130673028, 0.0049208350133394512, 0.0049082737776099299, 0.0048958683274864315, 0.0048837345397255245, 0.0048718628447396066, 0.0048602755702258481, 0.0048489393541457258, 0.0048378422088443257, 0.00482696862614076, 0.0048162597744975163, 0.0048056483105816238, 0.0047950869612156171, 0.0047846143711522604, 0.0047742115896371789, 0.004763854707247937, 0.0047534613664549849, 0.0047428862959966586, 0.0047319580769855686, 0.0047203168307712734, 0.0047078702278956852, 0.0046942766168993682, 0.0046799487613335949, 0.0046652644798734618, 0.0046505979726071175, 0.0046362461136651963, 0.004622246478199931, 0.0046085032038198966, 0.0045949269378936352, 0.0045813040379831856, 0.0045676303103132166, 0.0045540178765723187, 0.0045404957172018295, 0.0045271175452300961, 0.0045138754515173804, 0.0045007655065224667, 0.0044878285626536157, 0.0044750474058454452, 0.0044624555176750336, 0.0044500348540669867, 0.0044377907557506761, 0.0044256970778385569, 0.0044137118127537929, 0.0044018089043428984, 0.0043898777457283388, 0.0043777589176571662, 0.0043654300080621204, 0.0043524025925885217, 0.0043387461644664093, 0.0043250415248276778, 0.0043114320928992781, 0.0042979898178852061, 0.0042847557167410687, 0.0042717817578483913, 0.004259096263373563, 0.0042466428910389962, 0.0042344550724500345, 0.0042225406503456128, 0.0042108873292825673, 0.0041994738529611874, 0.0041882682722424684], 'val_acc': [0.048511576626240352, 0.068724733553840497, 0.54391767732451302, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096119949500401928, 0.0093214965514711572, 0.0087346195468384832, 0.0081882641662282124, 0.0077233074284491872, 0.0073358927884499096, 0.007012231662737763, 0.0067356100538088215, 0.0065009623795210022, 0.0063038316301085133, 0.0061384272552218238, 0.0059990131107483724, 0.0058808742400052556, 0.0057803006791633717, 0.0056944224197310956, 0.0056204666584529868, 0.0055562527242687173, 0.0055000559088815293, 0.0054504734531892716, 0.0054064526571763602, 0.0053671030188213687, 0.0053316999223493415, 0.0052995698713863594, 0.0052702554060452345, 0.0052432271359735055, 0.0052181492639975097, 0.0051947925363261382, 0.0051729205702694993, 0.0051523871908227955, 0.0051330870071251587, 0.0051149489057190989, 0.005097876318101797, 0.0050817137922233371, 0.0050663503159074875, 0.0050516512700598546, 0.0050375496952508592, 0.0050239272426955131, 0.0050106378720518388, 0.0049974579324394124, 0.0049842145589226129, 0.0049712500417550404, 0.004958611687653775, 0.0049461149488833761, 0.0049336981332967315, 0.0049215187238602718, 0.0049096069842422888, 0.0048979730010938029, 0.0048865940743844441, 0.0048754690309301268, 0.0048645712368142737, 0.0048538753305582072, 0.0048433008022003704, 0.0048327849615112401, 0.004822342588078234, 0.0048119891690401465, 0.0048016990322107085, 0.004791420577666676, 0.0047810218691102481, 0.0047703489578452829, 0.0047591582754686543, 0.0047471394382414458, 0.0047340883447409016, 0.0047200691506835424, 0.0047055450285236992, 0.0046908226644599036, 0.004676357144718514, 0.0046622463369041739, 0.0046484353237070813, 0.0046348427893893179, 0.0046213646745143474, 0.0046078025331834794, 0.0045942771821808077, 0.0045808272992288301, 0.0045674873110260377, 0.0045543113360504966, 0.0045412708721104776, 0.0045283942827910309, 0.0045157004999641821, 0.0045031844199319238, 0.0044908553688947309, 0.0044787012628078778, 0.0044666934319798918, 0.0044548112853453415, 0.0044430245445750641, 0.0044312826503533241, 0.0044194052569276427, 0.0044073287667520276, 0.0043948363562252742, 0.0043816422651280313, 0.0043681424275283888, 0.0043547010920359742, 0.0043413764411338682, 0.0043282263362520714, 0.0043152933598490191, 0.004302635616245055, 0.004290238612897194, 0.0042780727492200696, 0.00426617890352442, 0.0042545612372971936, 0.0042431853458169185, 0.0042320266750102628], 'acc': [0.051061740521640149, 0.052289186205339531, 0.32993740021150886, 0.58622805941568734, 0.5937154781047268, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822262206665, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822264767316, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124]}
[2017-11-14 08:18:50,504 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:95]: done!
[2017-11-14 08:18:50,504 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-14 08:18:50,504 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-14 08:18:50,504 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5cfd9c9400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-14 08:18:50,539 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-14 08:23:11,911 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:125]: trained!
[2017-11-14 08:23:11,912 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0095264416982757619, 0.0090368803544671646, 0.0084424861256705407, 0.0079352430007031995, 0.0075072301164932085, 0.0071524099305816996, 0.0068516884673727714, 0.0065947743257639803, 0.0063781250699141562, 0.006196506407682793, 0.006043609516480879, 0.0059144532967540919, 0.0058046904531502954, 0.0057112117820254738, 0.0056310057563406721, 0.0055616491694805634, 0.0055011437298988089, 0.005447946941084374, 0.0054008515543300618, 0.005358843810552405, 0.0053211828766138083, 0.005287126051683016, 0.0052561958220153117, 0.0052277999010227295, 0.0052015216899943323, 0.0051770962558950967, 0.00515428070656309, 0.005132893827794827, 0.0051128184063464832, 0.0050939166509723979, 0.0050761744461971436, 0.0050593932484061304, 0.0050434951952157848, 0.0050283226566009281, 0.0050137843917001101, 0.0049997976821433456, 0.0049861953379870426, 0.0049728877435635827, 0.0049595186340176626, 0.0049463024766631739, 0.0049334390130673028, 0.0049208350133394512, 0.0049082737776099299, 0.0048958683274864315, 0.0048837345397255245, 0.0048718628447396066, 0.0048602755702258481, 0.0048489393541457258, 0.0048378422088443257, 0.00482696862614076, 0.0048162597744975163, 0.0048056483105816238, 0.0047950869612156171, 0.0047846143711522604, 0.0047742115896371789, 0.004763854707247937, 0.0047534613664549849, 0.0047428862959966586, 0.0047319580769855686, 0.0047203168307712734, 0.0047078702278956852, 0.0046942766168993682, 0.0046799487613335949, 0.0046652644798734618, 0.0046505979726071175, 0.0046362461136651963, 0.004622246478199931, 0.0046085032038198966, 0.0045949269378936352, 0.0045813040379831856, 0.0045676303103132166, 0.0045540178765723187, 0.0045404957172018295, 0.0045271175452300961, 0.0045138754515173804, 0.0045007655065224667, 0.0044878285626536157, 0.0044750474058454452, 0.0044624555176750336, 0.0044500348540669867, 0.0044377907557506761, 0.0044256970778385569, 0.0044137118127537929, 0.0044018089043428984, 0.0043898777457283388, 0.0043777589176571662, 0.0043654300080621204, 0.0043524025925885217, 0.0043387461644664093, 0.0043250415248276778, 0.0043114320928992781, 0.0042979898178852061, 0.0042847557167410687, 0.0042717817578483913, 0.004259096263373563, 0.0042466428910389962, 0.0042344550724500345, 0.0042225406503456128, 0.0042108873292825673, 0.0041994738529611874, 0.0041882682722424684], 'val_acc': [0.048511576626240352, 0.068724733553840497, 0.54391767732451302, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096119949500401928, 0.0093214965514711572, 0.0087346195468384832, 0.0081882641662282124, 0.0077233074284491872, 0.0073358927884499096, 0.007012231662737763, 0.0067356100538088215, 0.0065009623795210022, 0.0063038316301085133, 0.0061384272552218238, 0.0059990131107483724, 0.0058808742400052556, 0.0057803006791633717, 0.0056944224197310956, 0.0056204666584529868, 0.0055562527242687173, 0.0055000559088815293, 0.0054504734531892716, 0.0054064526571763602, 0.0053671030188213687, 0.0053316999223493415, 0.0052995698713863594, 0.0052702554060452345, 0.0052432271359735055, 0.0052181492639975097, 0.0051947925363261382, 0.0051729205702694993, 0.0051523871908227955, 0.0051330870071251587, 0.0051149489057190989, 0.005097876318101797, 0.0050817137922233371, 0.0050663503159074875, 0.0050516512700598546, 0.0050375496952508592, 0.0050239272426955131, 0.0050106378720518388, 0.0049974579324394124, 0.0049842145589226129, 0.0049712500417550404, 0.004958611687653775, 0.0049461149488833761, 0.0049336981332967315, 0.0049215187238602718, 0.0049096069842422888, 0.0048979730010938029, 0.0048865940743844441, 0.0048754690309301268, 0.0048645712368142737, 0.0048538753305582072, 0.0048433008022003704, 0.0048327849615112401, 0.004822342588078234, 0.0048119891690401465, 0.0048016990322107085, 0.004791420577666676, 0.0047810218691102481, 0.0047703489578452829, 0.0047591582754686543, 0.0047471394382414458, 0.0047340883447409016, 0.0047200691506835424, 0.0047055450285236992, 0.0046908226644599036, 0.004676357144718514, 0.0046622463369041739, 0.0046484353237070813, 0.0046348427893893179, 0.0046213646745143474, 0.0046078025331834794, 0.0045942771821808077, 0.0045808272992288301, 0.0045674873110260377, 0.0045543113360504966, 0.0045412708721104776, 0.0045283942827910309, 0.0045157004999641821, 0.0045031844199319238, 0.0044908553688947309, 0.0044787012628078778, 0.0044666934319798918, 0.0044548112853453415, 0.0044430245445750641, 0.0044312826503533241, 0.0044194052569276427, 0.0044073287667520276, 0.0043948363562252742, 0.0043816422651280313, 0.0043681424275283888, 0.0043547010920359742, 0.0043413764411338682, 0.0043282263362520714, 0.0043152933598490191, 0.004302635616245055, 0.004290238612897194, 0.0042780727492200696, 0.00426617890352442, 0.0042545612372971936, 0.0042431853458169185, 0.0042320266750102628], 'acc': [0.051061740521640149, 0.052289186205339531, 0.32993740021150886, 0.58622805941568734, 0.5937154781047268, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.5938382226001182, 0.59383822262206665, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822264767316, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124]}
[2017-11-14 08:23:11,912 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-14 08:23:12,023 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-14 08:23:12,024 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-14 08:23:12,855 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:141]: done!
[2017-11-14 08:23:12,855 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_2L_FULLDS_OVER_05 finished!
[2017-11-18 16:24:09,947 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_2L_FULLDS_OVER_05 was already executed!
[2017-11-18 20:06:25,332 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_FULLDS_OVER_05
[2017-11-18 20:06:25,332 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 20:06:25,332 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_FULLDS_OVER_05
	layers = 96,172,156
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdd2e2aaeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdd2e2af400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 20:06:25,332 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 20:06:27,538 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 20:06:27,539 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 20:06:27,539 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 20:06:27,539 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fdd2e2aaeb8>, 'discard_decoder_function': True}
[2017-11-18 20:06:27,595 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 20:08:30,303 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 20:08:30,304 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0089638637907964603, 0.0084389799539080577, 0.0080252571915540236, 0.00769722866591303, 0.0074355154088090797, 0.0072233787123750495, 0.0070501661115695297, 0.0069053893542969352, 0.0067828017665509327, 0.006677310247226142, 0.006584791839841544, 0.0065025171706194892, 0.0064280514339397866, 0.0063573037531228244, 0.0062944944067462837, 0.0062401922420865195, 0.0061929674074840992, 0.0061508877543771543, 0.006113422198976824, 0.0060798794520421258, 0.0060495961446709349, 0.0060219210027472325, 0.0059965946821982597, 0.0059732231228499071, 0.0059515839159038249, 0.0059314992833124098, 0.0059127475752658492, 0.0058951053408326055, 0.0058783441207836112, 0.0058622697412930719, 0.0058466542140984254, 0.0058307561719463576, 0.005813249312317254, 0.0057948785291513025, 0.0057757769261912268, 0.0057554599153543991, 0.0057349082616283444, 0.0057149531458528802, 0.005695827753436764, 0.0056776803152691138, 0.0056603966778481724, 0.0056437023004735328, 0.0056271733801184888, 0.0056110116885376028, 0.0055947375268350572, 0.0055785079575487737, 0.0055626206727543053, 0.005547172166164095, 0.0055320469775668067, 0.0055171865977597439, 0.0055025440771837792, 0.0054879185344198309, 0.0054729354664688817, 0.0054570715650245245, 0.0054398814800857009, 0.005420985481900651, 0.0053999597087429916, 0.0053795308232525117, 0.0053602889935235815, 0.0053420082317889063, 0.0053243883818700141, 0.0053072236007704471, 0.0052904634001791117, 0.0052734185064102646, 0.0052566584891912439, 0.0052402088145983164, 0.0052237814024141422, 0.005206625196002547, 0.0051894314511474089, 0.0051727534636467672, 0.0051568379910277374, 0.0051417211716695494, 0.0051273273335593842, 0.0051135647957593483, 0.0051003495609994948, 0.0050875915492344364, 0.0050751498638686833, 0.0050625679344493309, 0.0050499092593949283, 0.0050373555956670559, 0.0050250063637474829, 0.0050128927554980397, 0.0050009134699080865, 0.004988794713799637, 0.0049766430538695323, 0.0049646143667681913, 0.0049527706160801864, 0.0049410720244741418, 0.0049295738620600722, 0.0049182788174714411, 0.0049071971731632124, 0.0048963195744947076, 0.0048856331492941564, 0.0048751380207795389, 0.0048648702907069657, 0.0048548030355197022, 0.0048449357706459237, 0.0048352468364181679, 0.0048257042704343807, 0.0048163082927755686, 0.0048070425145089824], 'val_acc': [0.014332965821389196, 0.59867695700110257, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0092832306478818644, 0.0086952317161987387, 0.0082306889516470753, 0.0078633139853604515, 0.0075713090588409209, 0.0073362692721998333, 0.0071450791906872251, 0.0069873203463784728, 0.0068542352503519295, 0.0067406770998660742, 0.0066420294973613793, 0.0065545940319469654, 0.0064760412418638927, 0.0064029714109873799, 0.0063351214083390136, 0.006276077972294067, 0.0062249195748832423, 0.0061799186317068825, 0.0061397987839812602, 0.0061040517893038316, 0.0060719315607818168, 0.0060427843234569798, 0.0060161632566622606, 0.0059917814469707294, 0.0059692607859335453, 0.0059483935637531012, 0.0059290043532421281, 0.0059108331152942705, 0.0058936777359922489, 0.0058773230466128814, 0.0058615642518712301, 0.0058460131074834949, 0.0058294506374885107, 0.0058115238691444073, 0.0057930379526510631, 0.0057732493031806111, 0.005752914526929746, 0.0057327204602936836, 0.0057133352318811783, 0.0056948224602721437, 0.0056772587878159272, 0.0056604390457040245, 0.0056439663447111358, 0.005627761618671471, 0.0056116815786856743, 0.0055955134047421884, 0.0055795491788967503, 0.0055640131162304164, 0.0055488577053454755, 0.0055339977193664481, 0.0055193984594113319, 0.0055049654023546458, 0.0054903355965166059, 0.0054750694500400607, 0.005458699283295813, 0.0054408455518698152, 0.0054208225962947458, 0.0053999681779420879, 0.0053801594244443571, 0.0053614722429925028, 0.0053436503441195203, 0.0053263740741860523, 0.0053095915506255397, 0.0052928684988188621, 0.0052761400120870799, 0.0052597866554466646, 0.0052436390194693918, 0.0052271017185041395, 0.0052100994911813492, 0.0051933328896130839, 0.005177186597749084, 0.0051618224901869769, 0.0051472327799177457, 0.0051332987185690624, 0.0051199246661028123, 0.0051070420771432102, 0.0050945391957248568, 0.0050821370687310578, 0.0050695723147768578, 0.0050570256918910182, 0.0050446338584294263, 0.0050324608905169335, 0.0050204910354043342, 0.0050085143726746615, 0.0049964188856676424, 0.0049843984057369355, 0.0049725475235109064, 0.0049608591233512855, 0.0049493380734104602, 0.004938016545699208, 0.0049269037562757051, 0.0049160099418577097, 0.004905310903033519, 0.0048947945876522334, 0.0048844928819948182, 0.0048744270489547124, 0.0048645516602354236, 0.0048548651939070275, 0.0048453416146623319, 0.0048359735773761308, 0.0048267414707178803], 'acc': [0.0031913587823738801, 0.35092672153647081, 0.59248803239359182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822262206665, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427]}
[2017-11-18 20:08:30,304 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:95]: done!
[2017-11-18 20:08:30,304 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 20:08:30,304 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 20:08:30,304 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fdd2e2af400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 20:08:30,349 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 20:13:52,603 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:125]: trained!
[2017-11-18 20:13:52,604 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0089638637907964603, 0.0084389799539080577, 0.0080252571915540236, 0.00769722866591303, 0.0074355154088090797, 0.0072233787123750495, 0.0070501661115695297, 0.0069053893542969352, 0.0067828017665509327, 0.006677310247226142, 0.006584791839841544, 0.0065025171706194892, 0.0064280514339397866, 0.0063573037531228244, 0.0062944944067462837, 0.0062401922420865195, 0.0061929674074840992, 0.0061508877543771543, 0.006113422198976824, 0.0060798794520421258, 0.0060495961446709349, 0.0060219210027472325, 0.0059965946821982597, 0.0059732231228499071, 0.0059515839159038249, 0.0059314992833124098, 0.0059127475752658492, 0.0058951053408326055, 0.0058783441207836112, 0.0058622697412930719, 0.0058466542140984254, 0.0058307561719463576, 0.005813249312317254, 0.0057948785291513025, 0.0057757769261912268, 0.0057554599153543991, 0.0057349082616283444, 0.0057149531458528802, 0.005695827753436764, 0.0056776803152691138, 0.0056603966778481724, 0.0056437023004735328, 0.0056271733801184888, 0.0056110116885376028, 0.0055947375268350572, 0.0055785079575487737, 0.0055626206727543053, 0.005547172166164095, 0.0055320469775668067, 0.0055171865977597439, 0.0055025440771837792, 0.0054879185344198309, 0.0054729354664688817, 0.0054570715650245245, 0.0054398814800857009, 0.005420985481900651, 0.0053999597087429916, 0.0053795308232525117, 0.0053602889935235815, 0.0053420082317889063, 0.0053243883818700141, 0.0053072236007704471, 0.0052904634001791117, 0.0052734185064102646, 0.0052566584891912439, 0.0052402088145983164, 0.0052237814024141422, 0.005206625196002547, 0.0051894314511474089, 0.0051727534636467672, 0.0051568379910277374, 0.0051417211716695494, 0.0051273273335593842, 0.0051135647957593483, 0.0051003495609994948, 0.0050875915492344364, 0.0050751498638686833, 0.0050625679344493309, 0.0050499092593949283, 0.0050373555956670559, 0.0050250063637474829, 0.0050128927554980397, 0.0050009134699080865, 0.004988794713799637, 0.0049766430538695323, 0.0049646143667681913, 0.0049527706160801864, 0.0049410720244741418, 0.0049295738620600722, 0.0049182788174714411, 0.0049071971731632124, 0.0048963195744947076, 0.0048856331492941564, 0.0048751380207795389, 0.0048648702907069657, 0.0048548030355197022, 0.0048449357706459237, 0.0048352468364181679, 0.0048257042704343807, 0.0048163082927755686, 0.0048070425145089824], 'val_acc': [0.014332965821389196, 0.59867695700110257, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0092832306478818644, 0.0086952317161987387, 0.0082306889516470753, 0.0078633139853604515, 0.0075713090588409209, 0.0073362692721998333, 0.0071450791906872251, 0.0069873203463784728, 0.0068542352503519295, 0.0067406770998660742, 0.0066420294973613793, 0.0065545940319469654, 0.0064760412418638927, 0.0064029714109873799, 0.0063351214083390136, 0.006276077972294067, 0.0062249195748832423, 0.0061799186317068825, 0.0061397987839812602, 0.0061040517893038316, 0.0060719315607818168, 0.0060427843234569798, 0.0060161632566622606, 0.0059917814469707294, 0.0059692607859335453, 0.0059483935637531012, 0.0059290043532421281, 0.0059108331152942705, 0.0058936777359922489, 0.0058773230466128814, 0.0058615642518712301, 0.0058460131074834949, 0.0058294506374885107, 0.0058115238691444073, 0.0057930379526510631, 0.0057732493031806111, 0.005752914526929746, 0.0057327204602936836, 0.0057133352318811783, 0.0056948224602721437, 0.0056772587878159272, 0.0056604390457040245, 0.0056439663447111358, 0.005627761618671471, 0.0056116815786856743, 0.0055955134047421884, 0.0055795491788967503, 0.0055640131162304164, 0.0055488577053454755, 0.0055339977193664481, 0.0055193984594113319, 0.0055049654023546458, 0.0054903355965166059, 0.0054750694500400607, 0.005458699283295813, 0.0054408455518698152, 0.0054208225962947458, 0.0053999681779420879, 0.0053801594244443571, 0.0053614722429925028, 0.0053436503441195203, 0.0053263740741860523, 0.0053095915506255397, 0.0052928684988188621, 0.0052761400120870799, 0.0052597866554466646, 0.0052436390194693918, 0.0052271017185041395, 0.0052100994911813492, 0.0051933328896130839, 0.005177186597749084, 0.0051618224901869769, 0.0051472327799177457, 0.0051332987185690624, 0.0051199246661028123, 0.0051070420771432102, 0.0050945391957248568, 0.0050821370687310578, 0.0050695723147768578, 0.0050570256918910182, 0.0050446338584294263, 0.0050324608905169335, 0.0050204910354043342, 0.0050085143726746615, 0.0049964188856676424, 0.0049843984057369355, 0.0049725475235109064, 0.0049608591233512855, 0.0049493380734104602, 0.004938016545699208, 0.0049269037562757051, 0.0049160099418577097, 0.004905310903033519, 0.0048947945876522334, 0.0048844928819948182, 0.0048744270489547124, 0.0048645516602354236, 0.0048548651939070275, 0.0048453416146623319, 0.0048359735773761308, 0.0048267414707178803], 'acc': [0.0031913587823738801, 0.35092672153647081, 0.59248803239359182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822262938279, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822262206665, 0.59383822268791198, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822267327968, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427]}
[2017-11-18 20:13:52,605 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 20:13:52,715 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 20:13:52,715 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 20:13:53,560 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:141]: done!
[2017-11-18 20:13:53,561 AE_UNIGRAMA_2L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_2L_FULLDS_OVER_05 finished!
