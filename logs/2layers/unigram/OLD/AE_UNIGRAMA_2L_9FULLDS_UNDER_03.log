[2017-11-18 16:51:55,514 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_9FULLDS_UNDER_03
[2017-11-18 16:51:55,514 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 16:51:55,514 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_9FULLDS_UNDER_03
	layers = 96,86,78,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0e1f6fceb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0e1f701400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:51:55,514 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 16:51:57,794 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:51:57,794 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:51:57,794 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 16:51:57,795 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f0e1f6fceb8>, 'discard_decoder_function': True}
[2017-11-18 16:51:57,884 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 16:53:34,780 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 16:53:34,781 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0098531610742813736, 0.009259390683748165, 0.0086536255067173988, 0.0081653384712909085, 0.0077660286738148775, 0.0074339940553912343, 0.0071557165752960802, 0.0069215546790969062, 0.006725638297594227, 0.0065590555290871251, 0.0064197509225768692, 0.0063008557296933406, 0.0061997816581669226, 0.0061139737523528137, 0.0060391288263691081, 0.0059730737103516895, 0.0059163432126096045, 0.0058665594583372453, 0.0058236877580790433, 0.0057867796081386971, 0.0057548786753440157, 0.005727323661967345, 0.0057033750354197697, 0.0056811337072938924, 0.0056602547871231626, 0.005642134612131808, 0.0056263744978775647, 0.0056125298454756519, 0.0056003292612471327, 0.00558951074500164, 0.0055798667773791959, 0.0055712245763934951, 0.0055634608497047025, 0.005556413659535674, 0.0055500232343839526, 0.0055441971976434605, 0.0055388404180161249, 0.0055338903386741387, 0.0055292968763855175, 0.005525019308976563, 0.0055210314456096898, 0.0055172712260940053, 0.0055137125042584428, 0.0055103357502241171, 0.0055071056406474023, 0.0055040066223386204, 0.0055010140958546396, 0.0054981225769684811, 0.005495316616712341, 0.005492587482439644, 0.0054899186621707938, 0.0054873240955388919, 0.0054847950517798571, 0.0054823282533809567, 0.0054799042579138464, 0.0054775086789946754, 0.0054751538257574945, 0.0054728107045834851, 0.0054704830542826963, 0.00546816408220721, 0.0054658508117871006, 0.0054635343246931369, 0.0054612084418858339, 0.0054588724595680425, 0.0054565206792504036, 0.0054541463655300194, 0.0054517556714336907, 0.0054493557266618552, 0.0054469445794930313, 0.0054445145617470899, 0.0054420642259550229, 0.0054395980763330219, 0.0054371135102435041, 0.0054346009498843374, 0.0054320628965805386, 0.0054294940831056855, 0.0054269030871426293, 0.005424301622956389, 0.005421690333676372, 0.0054190626759999371, 0.0054164233684912185, 0.00541374290651905, 0.0054110123392383446, 0.0054082583919446816, 0.0054054967513994523, 0.0054027256940055784, 0.0053999463235052392, 0.0053971568105392531, 0.005394361780830431, 0.0053915544056211406, 0.0053887473304134077, 0.0053859329603589152, 0.0053831090284179447, 0.0053802724336902037, 0.0053774268904277145, 0.0053745668077001462, 0.0053716916033881073, 0.0053687999103709822, 0.0053658876513315449, 0.0053629531150800819, 0.0053600042437000261], 'val_acc': [0.0014700477765527381, 0.4994487320837927, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099632763026602962, 0.0095910731056249917, 0.0089545513675754473, 0.0084147294585452323, 0.0079760050622405005, 0.0076146882479045342, 0.0073135095902017739, 0.0070599420393386274, 0.0068479573583440489, 0.0066691616621420355, 0.0065183153711954401, 0.0063913513157423897, 0.0062828880128987631, 0.0061911177957834924, 0.0061122912095524246, 0.006043083973551756, 0.0059828665327544602, 0.0059307366878213119, 0.0058853272879062961, 0.0058463617668998002, 0.0058127194731614588, 0.0057836798079379526, 0.0057585711937433838, 0.0057362162768022293, 0.0057149273664037249, 0.0056959096194516192, 0.0056793916453445623, 0.0056649908382041814, 0.0056523187237453231, 0.0056411203688459376, 0.0056311671195817649, 0.0056222739643851122, 0.0056142941811977648, 0.0056071024845562659, 0.0056005680020905441, 0.0055946250279469804, 0.005589186388526418, 0.0055841724089368203, 0.005579528240428679, 0.0055752114077994097, 0.0055711814797376729, 0.0055674082280413404, 0.0055638359495721792, 0.0055604456236641531, 0.0055572121452466539, 0.0055541089940891611, 0.0055511283774669186, 0.0055482373787797794, 0.0055454247905488089, 0.0055426937229935925, 0.0055400336277171029, 0.00553744257697192, 0.0055349249346679022, 0.005532466921986441, 0.0055300676777370831, 0.0055277057904171674, 0.0055253712811459384, 0.0055230701917457084, 0.0055207784318039247, 0.0055184970975422423, 0.0055162235257118974, 0.0055139443030158145, 0.0055116643503054976, 0.0055093705917411244, 0.0055070663207317256, 0.0055047451634848464, 0.005502407073188581, 0.0055000570584881909, 0.005497693098412546, 0.0054953166094361796, 0.0054929226041192242, 0.0054905062618642421, 0.005488067263104246, 0.0054856115563806799, 0.0054831201365743189, 0.0054806023530343806, 0.005478051540065601, 0.0054754889721072121, 0.0054729118793690676, 0.00547032589025405, 0.00546772536355602, 0.0054651038644384269, 0.0054624286405714735, 0.0054597173001476812, 0.0054569941157973758, 0.0054542575736498235, 0.0054515103817080277, 0.005448746698714973, 0.0054459752855273505, 0.0054431986455818517, 0.0054404090798346886, 0.0054376188547198313, 0.0054348193039189157, 0.0054320138525316081, 0.0054291918959751646, 0.0054263663506202786, 0.0054235218519307661, 0.0054206683919907376, 0.0054177945016547118, 0.005414901642951663, 0.0054119876252101606], 'acc': [0.0027003805081625139, 0.11108383453300544, 0.57346262427155947, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822262206665, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822266596353, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182]}
[2017-11-18 16:53:34,781 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:95]: done!
[2017-11-18 16:53:34,781 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 16:53:34,781 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 16:53:34,782 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f0e1f701400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:53:34,843 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 16:57:46,212 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 16:57:46,214 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0098531610742813736, 0.009259390683748165, 0.0086536255067173988, 0.0081653384712909085, 0.0077660286738148775, 0.0074339940553912343, 0.0071557165752960802, 0.0069215546790969062, 0.006725638297594227, 0.0065590555290871251, 0.0064197509225768692, 0.0063008557296933406, 0.0061997816581669226, 0.0061139737523528137, 0.0060391288263691081, 0.0059730737103516895, 0.0059163432126096045, 0.0058665594583372453, 0.0058236877580790433, 0.0057867796081386971, 0.0057548786753440157, 0.005727323661967345, 0.0057033750354197697, 0.0056811337072938924, 0.0056602547871231626, 0.005642134612131808, 0.0056263744978775647, 0.0056125298454756519, 0.0056003292612471327, 0.00558951074500164, 0.0055798667773791959, 0.0055712245763934951, 0.0055634608497047025, 0.005556413659535674, 0.0055500232343839526, 0.0055441971976434605, 0.0055388404180161249, 0.0055338903386741387, 0.0055292968763855175, 0.005525019308976563, 0.0055210314456096898, 0.0055172712260940053, 0.0055137125042584428, 0.0055103357502241171, 0.0055071056406474023, 0.0055040066223386204, 0.0055010140958546396, 0.0054981225769684811, 0.005495316616712341, 0.005492587482439644, 0.0054899186621707938, 0.0054873240955388919, 0.0054847950517798571, 0.0054823282533809567, 0.0054799042579138464, 0.0054775086789946754, 0.0054751538257574945, 0.0054728107045834851, 0.0054704830542826963, 0.00546816408220721, 0.0054658508117871006, 0.0054635343246931369, 0.0054612084418858339, 0.0054588724595680425, 0.0054565206792504036, 0.0054541463655300194, 0.0054517556714336907, 0.0054493557266618552, 0.0054469445794930313, 0.0054445145617470899, 0.0054420642259550229, 0.0054395980763330219, 0.0054371135102435041, 0.0054346009498843374, 0.0054320628965805386, 0.0054294940831056855, 0.0054269030871426293, 0.005424301622956389, 0.005421690333676372, 0.0054190626759999371, 0.0054164233684912185, 0.00541374290651905, 0.0054110123392383446, 0.0054082583919446816, 0.0054054967513994523, 0.0054027256940055784, 0.0053999463235052392, 0.0053971568105392531, 0.005394361780830431, 0.0053915544056211406, 0.0053887473304134077, 0.0053859329603589152, 0.0053831090284179447, 0.0053802724336902037, 0.0053774268904277145, 0.0053745668077001462, 0.0053716916033881073, 0.0053687999103709822, 0.0053658876513315449, 0.0053629531150800819, 0.0053600042437000261], 'val_acc': [0.0014700477765527381, 0.4994487320837927, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099632763026602962, 0.0095910731056249917, 0.0089545513675754473, 0.0084147294585452323, 0.0079760050622405005, 0.0076146882479045342, 0.0073135095902017739, 0.0070599420393386274, 0.0068479573583440489, 0.0066691616621420355, 0.0065183153711954401, 0.0063913513157423897, 0.0062828880128987631, 0.0061911177957834924, 0.0061122912095524246, 0.006043083973551756, 0.0059828665327544602, 0.0059307366878213119, 0.0058853272879062961, 0.0058463617668998002, 0.0058127194731614588, 0.0057836798079379526, 0.0057585711937433838, 0.0057362162768022293, 0.0057149273664037249, 0.0056959096194516192, 0.0056793916453445623, 0.0056649908382041814, 0.0056523187237453231, 0.0056411203688459376, 0.0056311671195817649, 0.0056222739643851122, 0.0056142941811977648, 0.0056071024845562659, 0.0056005680020905441, 0.0055946250279469804, 0.005589186388526418, 0.0055841724089368203, 0.005579528240428679, 0.0055752114077994097, 0.0055711814797376729, 0.0055674082280413404, 0.0055638359495721792, 0.0055604456236641531, 0.0055572121452466539, 0.0055541089940891611, 0.0055511283774669186, 0.0055482373787797794, 0.0055454247905488089, 0.0055426937229935925, 0.0055400336277171029, 0.00553744257697192, 0.0055349249346679022, 0.005532466921986441, 0.0055300676777370831, 0.0055277057904171674, 0.0055253712811459384, 0.0055230701917457084, 0.0055207784318039247, 0.0055184970975422423, 0.0055162235257118974, 0.0055139443030158145, 0.0055116643503054976, 0.0055093705917411244, 0.0055070663207317256, 0.0055047451634848464, 0.005502407073188581, 0.0055000570584881909, 0.005497693098412546, 0.0054953166094361796, 0.0054929226041192242, 0.0054905062618642421, 0.005488067263104246, 0.0054856115563806799, 0.0054831201365743189, 0.0054806023530343806, 0.005478051540065601, 0.0054754889721072121, 0.0054729118793690676, 0.00547032589025405, 0.00546772536355602, 0.0054651038644384269, 0.0054624286405714735, 0.0054597173001476812, 0.0054569941157973758, 0.0054542575736498235, 0.0054515103817080277, 0.005448746698714973, 0.0054459752855273505, 0.0054431986455818517, 0.0054404090798346886, 0.0054376188547198313, 0.0054348193039189157, 0.0054320138525316081, 0.0054291918959751646, 0.0054263663506202786, 0.0054235218519307661, 0.0054206683919907376, 0.0054177945016547118, 0.005414901642951663, 0.0054119876252101606], 'acc': [0.0027003805081625139, 0.11108383453300544, 0.57346262427155947, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822262206665, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822267327968, 0.59383822266596353, 0.59383822272449271, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822272449271, 0.59383822266596353, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182]}
[2017-11-18 16:57:46,214 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 16:57:46,341 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 16:57:46,341 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 16:57:47,193 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:141]: done!
[2017-11-18 16:57:47,193 AE_UNIGRAMA_2L_9FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_2L_9FULLDS_UNDER_03 finished!
