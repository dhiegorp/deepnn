[2017-10-15 01:03:28,681 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:147]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_96_76_66_9
[2017-10-15 01:03:28,681 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:148]: >> Printing header log
[2017-10-15 01:03:28,681 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_96_76_66_9
	layers = 96,76,66,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc466bfd860>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc452aa8208>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-15 01:03:28,681 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:150]: >> Loading dataset... 
[2017-10-15 01:03:29,234 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-15 01:03:29,234 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:152]: >> Executing autoencoder part ... 
[2017-10-15 01:03:29,234 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:60]: =======================================
[2017-10-15 01:03:29,234 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fc466bfd860>, 'discard_decoder_function': True}
[2017-10-15 01:03:29,298 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:76]: training and evaluate autoencoder
[2017-10-15 01:04:01,275 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:87]: trained and evaluated!
[2017-10-15 01:04:01,276 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:90]: Training history: 
{'val_loss': [0.0098054810326726471, 0.0096853802735366781, 0.0095582591321277787, 0.0094340172385083704, 0.0093138567950978163, 0.00919717769432799, 0.0090842646993281231, 0.0089753181171572348, 0.0088700700246600855, 0.0087682106826440544, 0.0086698494193777724, 0.0085748782326020723, 0.0084829732020936053, 0.0083943784970887097, 0.0083092232355951815, 0.008227425646452324, 0.0081485455066353414, 0.0080726303430239503, 0.0079996692324853513, 0.0079294195274050346, 0.0078618123618449647, 0.0077968778739576005, 0.0077345190278936497, 0.0076745551591912171, 0.007616851935820952, 0.0075613455241026707, 0.0075078823233237944, 0.0074564004853561686, 0.0074067492017238553, 0.0073588660686211074, 0.0073126388166695278, 0.0072680523975658818, 0.0072249800389196346, 0.0071833957727569188, 0.0071431486780814081, 0.0071041872863377336, 0.0070665637533211577, 0.007030191157899492, 0.0069950659773191336, 0.0069611228908997265, 0.0069283028427497605, 0.0068965742007922725, 0.0068658412915401741, 0.0068360970677551723, 0.0068073165031724706, 0.0067795219426095262, 0.0067526176779575953, 0.006726575258869996, 0.0067013944706924566, 0.0066770059039269235, 0.0066533955264157967, 0.0066305156849103125, 0.0066083422273425143, 0.006586837417837302, 0.0065659923447801503, 0.0065457682578814076, 0.0065261467920830927, 0.0065071214956394135, 0.0064886700825897295, 0.0064707622589841212, 0.0064533771202660625, 0.0064365279022950443, 0.0064201559681016053, 0.0064042767849110315, 0.0063888596363891898, 0.0063738931614393196, 0.0063593346819447762, 0.0063452066881339786, 0.0063314459470124934, 0.0063180359094282511, 0.0063049578589134498, 0.006292217677687624, 0.0062797954859952947, 0.0062676902036407625, 0.0062559040239060009, 0.0062444215834306961, 0.006233229350340189, 0.0062223533860868239, 0.0062117740463423906, 0.0062014718010301485, 0.0061914447338413791, 0.006181683657919386, 0.0061721709075636582, 0.0061629190590911194, 0.0061538973078824107, 0.0061451135736415819, 0.0061365492281860575, 0.006128210448019456, 0.0061200974287541387, 0.0061121936714394389, 0.006104493756054946, 0.0060969971580825556, 0.006089692580475572, 0.0060825873422522972, 0.006075659640424203, 0.0060689152533458515, 0.0060623334166784266, 0.006055928046596981, 0.0060496745167168539, 0.0060435902832775314, 0.006037648195975554, 0.0060318456062541572], 'loss': [0.0098658212384446012, 0.0097552096172388737, 0.00963000994869442, 0.0095030139689805983, 0.0093798688678706291, 0.0092605065672298325, 0.009144681072539176, 0.009032741261699959, 0.0089247383122328383, 0.0088203103197412244, 0.0087193193156833142, 0.0086218553492782221, 0.0085276315228002674, 0.0084365089443989086, 0.0083488563142062044, 0.0082646891361385227, 0.0081837053388384637, 0.0081056601075385707, 0.0080305408725323824, 0.0079583494684166093, 0.0078888000209472921, 0.007821979644275015, 0.0077578000791288437, 0.0076961587732697857, 0.0076368350862481326, 0.0075797187982982262, 0.0075247636432378808, 0.0074718021521529097, 0.0074207838398611062, 0.0073715419689972996, 0.0073240555999726144, 0.0072781925058746783, 0.0072339435572236245, 0.0071911965891805875, 0.0071499007370508403, 0.0071098996536976804, 0.0070711837651593855, 0.0070337984975960884, 0.0069976638199460419, 0.0069627454120851249, 0.0069289881900323818, 0.0068963404118639231, 0.0068647653930869182, 0.0068341782691498697, 0.0068045844711459485, 0.0067759328704961579, 0.0067482720453752353, 0.0067214718616276188, 0.0066955305676570723, 0.0066704376481619984, 0.0066461176368205841, 0.0066225655095281961, 0.0065997226178627771, 0.0065775672818139683, 0.0065560785271616606, 0.0065352376756506163, 0.0065150137947209419, 0.0064953722932090336, 0.0064763222965878364, 0.0064578414222050389, 0.0064398951347077009, 0.0064224723209045965, 0.006405584093700744, 0.0063891674065075189, 0.0063732480535829772, 0.0063577886429267861, 0.0063427707739059881, 0.0063281625568793456, 0.0063139730798264879, 0.0063001437942121355, 0.0062866655525252836, 0.0062735216390426242, 0.0062607127257817974, 0.0062482198580101215, 0.0062360381158028709, 0.0062241876891687671, 0.0062126379786946505, 0.0062013815335137164, 0.0061904353226438285, 0.0061797954542213195, 0.0061694243018410658, 0.0061593331592918795, 0.0061494978571215615, 0.0061399241979219607, 0.0061305973912945868, 0.0061215140224854013, 0.0061126659053578726, 0.0061040445924670731, 0.0060956463370570651, 0.0060874745447232117, 0.0060795009715486027, 0.0060717396451859806, 0.0060641732500189456, 0.0060567975710543957, 0.0060496251737056665, 0.0060426218237111962, 0.006035810525082029, 0.0060291545094662306, 0.006022676901368638, 0.0060163530971587033, 0.0060102009339247772, 0.0060041859610316462]}
[2017-10-15 01:04:01,276 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:94]: done!
[2017-10-15 01:04:01,276 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:154]: >> Executing classifier part ... 
[2017-10-15 01:04:01,276 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:99]: =======================================
[2017-10-15 01:04:01,277 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:103]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fc452aa8208>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-15 01:04:01,328 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:112]: training ... 
[2017-10-15 01:05:05,566 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:124]: trained!
[2017-10-15 01:05:05,567 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:127]: Training history: 
{'val_loss': [0.0098054810326726471, 0.0096853802735366781, 0.0095582591321277787, 0.0094340172385083704, 0.0093138567950978163, 0.00919717769432799, 0.0090842646993281231, 0.0089753181171572348, 0.0088700700246600855, 0.0087682106826440544, 0.0086698494193777724, 0.0085748782326020723, 0.0084829732020936053, 0.0083943784970887097, 0.0083092232355951815, 0.008227425646452324, 0.0081485455066353414, 0.0080726303430239503, 0.0079996692324853513, 0.0079294195274050346, 0.0078618123618449647, 0.0077968778739576005, 0.0077345190278936497, 0.0076745551591912171, 0.007616851935820952, 0.0075613455241026707, 0.0075078823233237944, 0.0074564004853561686, 0.0074067492017238553, 0.0073588660686211074, 0.0073126388166695278, 0.0072680523975658818, 0.0072249800389196346, 0.0071833957727569188, 0.0071431486780814081, 0.0071041872863377336, 0.0070665637533211577, 0.007030191157899492, 0.0069950659773191336, 0.0069611228908997265, 0.0069283028427497605, 0.0068965742007922725, 0.0068658412915401741, 0.0068360970677551723, 0.0068073165031724706, 0.0067795219426095262, 0.0067526176779575953, 0.006726575258869996, 0.0067013944706924566, 0.0066770059039269235, 0.0066533955264157967, 0.0066305156849103125, 0.0066083422273425143, 0.006586837417837302, 0.0065659923447801503, 0.0065457682578814076, 0.0065261467920830927, 0.0065071214956394135, 0.0064886700825897295, 0.0064707622589841212, 0.0064533771202660625, 0.0064365279022950443, 0.0064201559681016053, 0.0064042767849110315, 0.0063888596363891898, 0.0063738931614393196, 0.0063593346819447762, 0.0063452066881339786, 0.0063314459470124934, 0.0063180359094282511, 0.0063049578589134498, 0.006292217677687624, 0.0062797954859952947, 0.0062676902036407625, 0.0062559040239060009, 0.0062444215834306961, 0.006233229350340189, 0.0062223533860868239, 0.0062117740463423906, 0.0062014718010301485, 0.0061914447338413791, 0.006181683657919386, 0.0061721709075636582, 0.0061629190590911194, 0.0061538973078824107, 0.0061451135736415819, 0.0061365492281860575, 0.006128210448019456, 0.0061200974287541387, 0.0061121936714394389, 0.006104493756054946, 0.0060969971580825556, 0.006089692580475572, 0.0060825873422522972, 0.006075659640424203, 0.0060689152533458515, 0.0060623334166784266, 0.006055928046596981, 0.0060496745167168539, 0.0060435902832775314, 0.006037648195975554, 0.0060318456062541572], 'loss': [0.0098658212384446012, 0.0097552096172388737, 0.00963000994869442, 0.0095030139689805983, 0.0093798688678706291, 0.0092605065672298325, 0.009144681072539176, 0.009032741261699959, 0.0089247383122328383, 0.0088203103197412244, 0.0087193193156833142, 0.0086218553492782221, 0.0085276315228002674, 0.0084365089443989086, 0.0083488563142062044, 0.0082646891361385227, 0.0081837053388384637, 0.0081056601075385707, 0.0080305408725323824, 0.0079583494684166093, 0.0078888000209472921, 0.007821979644275015, 0.0077578000791288437, 0.0076961587732697857, 0.0076368350862481326, 0.0075797187982982262, 0.0075247636432378808, 0.0074718021521529097, 0.0074207838398611062, 0.0073715419689972996, 0.0073240555999726144, 0.0072781925058746783, 0.0072339435572236245, 0.0071911965891805875, 0.0071499007370508403, 0.0071098996536976804, 0.0070711837651593855, 0.0070337984975960884, 0.0069976638199460419, 0.0069627454120851249, 0.0069289881900323818, 0.0068963404118639231, 0.0068647653930869182, 0.0068341782691498697, 0.0068045844711459485, 0.0067759328704961579, 0.0067482720453752353, 0.0067214718616276188, 0.0066955305676570723, 0.0066704376481619984, 0.0066461176368205841, 0.0066225655095281961, 0.0065997226178627771, 0.0065775672818139683, 0.0065560785271616606, 0.0065352376756506163, 0.0065150137947209419, 0.0064953722932090336, 0.0064763222965878364, 0.0064578414222050389, 0.0064398951347077009, 0.0064224723209045965, 0.006405584093700744, 0.0063891674065075189, 0.0063732480535829772, 0.0063577886429267861, 0.0063427707739059881, 0.0063281625568793456, 0.0063139730798264879, 0.0063001437942121355, 0.0062866655525252836, 0.0062735216390426242, 0.0062607127257817974, 0.0062482198580101215, 0.0062360381158028709, 0.0062241876891687671, 0.0062126379786946505, 0.0062013815335137164, 0.0061904353226438285, 0.0061797954542213195, 0.0061694243018410658, 0.0061593331592918795, 0.0061494978571215615, 0.0061399241979219607, 0.0061305973912945868, 0.0061215140224854013, 0.0061126659053578726, 0.0061040445924670731, 0.0060956463370570651, 0.0060874745447232117, 0.0060795009715486027, 0.0060717396451859806, 0.0060641732500189456, 0.0060567975710543957, 0.0060496251737056665, 0.0060426218237111962, 0.006035810525082029, 0.0060291545094662306, 0.006022676901368638, 0.0060163530971587033, 0.0060102009339247772, 0.0060041859610316462]}
[2017-10-15 01:05:05,567 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:131]: evaluating model ... 
[2017-10-15 01:05:05,608 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:135]: evaluated! 
[2017-10-15 01:05:05,608 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:137]: generating reports ... 
[2017-10-15 01:05:06,147 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:140]: done!
[2017-10-15 01:05:06,147 AE_UNIGRAMA_2L_UNDER_96_76_66_9.py:156]: >> experiment AE_UNIGRAMA_2L_UNDER_96_76_66_9 finished!
