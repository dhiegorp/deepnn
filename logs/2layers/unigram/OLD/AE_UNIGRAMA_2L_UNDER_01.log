[2017-10-20 01:36:14,016 AE_UNIGRAMA_2L_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_UNDER_01
[2017-10-20 01:36:14,016 AE_UNIGRAMA_2L_UNDER_01.py:149]: >> Printing header log
[2017-10-20 01:36:14,016 AE_UNIGRAMA_2L_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_UNDER_01
	layers = 96,28,26,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe01b67db00>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe01b67dc88>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:36:14,017 AE_UNIGRAMA_2L_UNDER_01.py:151]: >> Loading dataset... 
[2017-10-20 01:36:14,566 AE_UNIGRAMA_2L_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:36:14,566 AE_UNIGRAMA_2L_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:36:14,566 AE_UNIGRAMA_2L_UNDER_01.py:60]: =======================================
[2017-10-20 01:36:14,566 AE_UNIGRAMA_2L_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe01b67db00>, 'discard_decoder_function': True}
[2017-10-20 01:36:14,631 AE_UNIGRAMA_2L_UNDER_01.py:76]: training and evaluate autoencoder
[2017-10-20 01:36:35,912 AE_UNIGRAMA_2L_UNDER_01.py:88]: trained and evaluated!
[2017-10-20 01:36:35,913 AE_UNIGRAMA_2L_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010138078336517385, 0.010100864161318342, 0.010063942057880327, 0.010027116635419622, 0.009990700828707795, 0.0099546820458481754, 0.0099181718154910774, 0.0098793867830062436, 0.0098411126276928256, 0.0098037394213742919, 0.0097676016300307332, 0.0097325648385408192, 0.0096984812332019492, 0.0096640609183996137, 0.0096142159006298699, 0.0095103789349415494, 0.009404489313525782, 0.0093010276950701905, 0.0092000151676260855, 0.0091008851893218477, 0.0090030033979218681, 0.0089067546166064129, 0.0088124524760423532, 0.0087205676126491175, 0.0086316937047531163, 0.0085459887690592876, 0.0084632533986716916, 0.0083831387838577253, 0.0083056949477185761, 0.0082306514397180435, 0.0081581413835896434, 0.0080880329140970916, 0.0080198338134110422, 0.0079539219890357622, 0.0078904678314564176, 0.0078295300918939381, 0.0077709539457601687, 0.0077145718778985585, 0.0076602205848771403, 0.0076078301119067637, 0.0075572999834765068, 0.0075085064964057341, 0.0074613756538268357, 0.007415797189224276, 0.0073716932817684232, 0.0073290498819908465, 0.0072877874310547314, 0.007247850191554394, 0.0072091116940388002, 0.0071714705870691061, 0.007134948780960975, 0.0070994954009204548, 0.0070650506259174149, 0.0070315803380399163, 0.006999051163741647, 0.0069674760117074373, 0.0069367629493202422, 0.0069067711356791866, 0.0068776438317389738, 0.0068493509305066333, 0.0068218987712075716, 0.0067952630182790495, 0.0067693745495827672, 0.0067441301960428851, 0.0067195692774753143, 0.0066957015641116741, 0.0066725487758485134, 0.0066500929527012389, 0.0066283422047930139, 0.0066071898039416531, 0.0065866542138768615, 0.0065667138687684635, 0.0065473651419978825, 0.0065285524917717977, 0.0065102908071338244, 0.0064925422569993042, 0.0064752951894495566, 0.0064584741050370559, 0.0064420629756656725, 0.0064260660615303037, 0.0064104522741140046, 0.0063951608991478903, 0.0063801484431752929, 0.0063654178836587191, 0.0063509785026644242, 0.0063368661093722934, 0.0063231089931383008, 0.0063097146080052097, 0.0062966543824505405, 0.0062839274630504469, 0.0062715694633724518, 0.0062595562105756042, 0.0062478793089080697, 0.0062365231993971705, 0.0062254843004324843, 0.0062147521562735831, 0.0062043091946984309, 0.0061941414787589841, 0.0061842162892582469, 0.0061745421933252576, 0.0061651157322564756, 0.0061559378650718017], 'loss': [0.010151499651083935, 0.010114623127206382, 0.010078148359401906, 0.010041862765135908, 0.010005857607724114, 0.0099702972464249702, 0.0099348774066477658, 0.0098978016822019021, 0.0098598550944448832, 0.0098226638745514249, 0.0097865092367181109, 0.0097515341289428452, 0.0097175311164377515, 0.0096841139018251695, 0.009646318183173486, 0.0095683673732142992, 0.0094614292677553721, 0.0093563978257460243, 0.0092537934985183548, 0.0091534006050441562, 0.0090546745585979461, 0.0089572596500530951, 0.0088615873525149259, 0.0087681115394860013, 0.0086772722342654315, 0.0085896120716364901, 0.0085051456516689883, 0.0084235081706738723, 0.0083444135775303067, 0.0082678629810101576, 0.0081937480391619678, 0.0081220819347508858, 0.0080526065225607051, 0.0079851072864319615, 0.0079200139278391424, 0.0078574456658028861, 0.0077973584053189606, 0.0077395719921384658, 0.0076838964667942855, 0.0076301737511604937, 0.0075783808429432959, 0.0075284148309981997, 0.007480138383311183, 0.0074334710566802079, 0.0073883218416565203, 0.0073446203850337935, 0.0073023649624056001, 0.0072614556898551261, 0.0072218251784378464, 0.0071833341430526942, 0.0071459551514701644, 0.0071096888871562394, 0.0070744680862395255, 0.0070402451980339283, 0.0070069801092683612, 0.0069746477678234988, 0.006943233679526685, 0.0069126002854005318, 0.0068827592750602545, 0.0068537919594921729, 0.006825646999754016, 0.0067983469965890025, 0.00677183386683693, 0.0067460090680403909, 0.0067208355493596269, 0.0066963654654312327, 0.0066725957887413204, 0.0066495283787867451, 0.0066271476191711812, 0.006605451408837771, 0.0065843483639769964, 0.0065638514486906826, 0.0065439398713597651, 0.0065246072126130018, 0.0065058120168612716, 0.0064875571255829153, 0.006469802788133059, 0.0064525327544496811, 0.0064356524526463857, 0.0064192076680750186, 0.0064031528160159177, 0.0063874617000880349, 0.0063720861410913321, 0.006356995319232079, 0.0063421702777741321, 0.0063276701462560989, 0.0063135062782843747, 0.006299711505698696, 0.0062862609486772775, 0.0062731457576522013, 0.0062603686848047438, 0.0062479560049370931, 0.0062358832984507886, 0.006224145018051996, 0.0062127306553081234, 0.0062016336749334718, 0.0061908316573548259, 0.0061803100763441745, 0.006170062208004392, 0.0061600585740011534, 0.0061503100691485714, 0.0061408079025514779]}
[2017-10-20 01:36:35,913 AE_UNIGRAMA_2L_UNDER_01.py:95]: done!
[2017-10-20 01:36:35,913 AE_UNIGRAMA_2L_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-10-20 01:36:35,913 AE_UNIGRAMA_2L_UNDER_01.py:100]: =======================================
[2017-10-20 01:36:35,913 AE_UNIGRAMA_2L_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe01b67dc88>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:36:35,950 AE_UNIGRAMA_2L_UNDER_01.py:113]: training ... 
[2017-10-20 01:37:18,359 AE_UNIGRAMA_2L_UNDER_01.py:125]: trained!
[2017-10-20 01:37:18,360 AE_UNIGRAMA_2L_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010138078336517385, 0.010100864161318342, 0.010063942057880327, 0.010027116635419622, 0.009990700828707795, 0.0099546820458481754, 0.0099181718154910774, 0.0098793867830062436, 0.0098411126276928256, 0.0098037394213742919, 0.0097676016300307332, 0.0097325648385408192, 0.0096984812332019492, 0.0096640609183996137, 0.0096142159006298699, 0.0095103789349415494, 0.009404489313525782, 0.0093010276950701905, 0.0092000151676260855, 0.0091008851893218477, 0.0090030033979218681, 0.0089067546166064129, 0.0088124524760423532, 0.0087205676126491175, 0.0086316937047531163, 0.0085459887690592876, 0.0084632533986716916, 0.0083831387838577253, 0.0083056949477185761, 0.0082306514397180435, 0.0081581413835896434, 0.0080880329140970916, 0.0080198338134110422, 0.0079539219890357622, 0.0078904678314564176, 0.0078295300918939381, 0.0077709539457601687, 0.0077145718778985585, 0.0076602205848771403, 0.0076078301119067637, 0.0075572999834765068, 0.0075085064964057341, 0.0074613756538268357, 0.007415797189224276, 0.0073716932817684232, 0.0073290498819908465, 0.0072877874310547314, 0.007247850191554394, 0.0072091116940388002, 0.0071714705870691061, 0.007134948780960975, 0.0070994954009204548, 0.0070650506259174149, 0.0070315803380399163, 0.006999051163741647, 0.0069674760117074373, 0.0069367629493202422, 0.0069067711356791866, 0.0068776438317389738, 0.0068493509305066333, 0.0068218987712075716, 0.0067952630182790495, 0.0067693745495827672, 0.0067441301960428851, 0.0067195692774753143, 0.0066957015641116741, 0.0066725487758485134, 0.0066500929527012389, 0.0066283422047930139, 0.0066071898039416531, 0.0065866542138768615, 0.0065667138687684635, 0.0065473651419978825, 0.0065285524917717977, 0.0065102908071338244, 0.0064925422569993042, 0.0064752951894495566, 0.0064584741050370559, 0.0064420629756656725, 0.0064260660615303037, 0.0064104522741140046, 0.0063951608991478903, 0.0063801484431752929, 0.0063654178836587191, 0.0063509785026644242, 0.0063368661093722934, 0.0063231089931383008, 0.0063097146080052097, 0.0062966543824505405, 0.0062839274630504469, 0.0062715694633724518, 0.0062595562105756042, 0.0062478793089080697, 0.0062365231993971705, 0.0062254843004324843, 0.0062147521562735831, 0.0062043091946984309, 0.0061941414787589841, 0.0061842162892582469, 0.0061745421933252576, 0.0061651157322564756, 0.0061559378650718017], 'loss': [0.010151499651083935, 0.010114623127206382, 0.010078148359401906, 0.010041862765135908, 0.010005857607724114, 0.0099702972464249702, 0.0099348774066477658, 0.0098978016822019021, 0.0098598550944448832, 0.0098226638745514249, 0.0097865092367181109, 0.0097515341289428452, 0.0097175311164377515, 0.0096841139018251695, 0.009646318183173486, 0.0095683673732142992, 0.0094614292677553721, 0.0093563978257460243, 0.0092537934985183548, 0.0091534006050441562, 0.0090546745585979461, 0.0089572596500530951, 0.0088615873525149259, 0.0087681115394860013, 0.0086772722342654315, 0.0085896120716364901, 0.0085051456516689883, 0.0084235081706738723, 0.0083444135775303067, 0.0082678629810101576, 0.0081937480391619678, 0.0081220819347508858, 0.0080526065225607051, 0.0079851072864319615, 0.0079200139278391424, 0.0078574456658028861, 0.0077973584053189606, 0.0077395719921384658, 0.0076838964667942855, 0.0076301737511604937, 0.0075783808429432959, 0.0075284148309981997, 0.007480138383311183, 0.0074334710566802079, 0.0073883218416565203, 0.0073446203850337935, 0.0073023649624056001, 0.0072614556898551261, 0.0072218251784378464, 0.0071833341430526942, 0.0071459551514701644, 0.0071096888871562394, 0.0070744680862395255, 0.0070402451980339283, 0.0070069801092683612, 0.0069746477678234988, 0.006943233679526685, 0.0069126002854005318, 0.0068827592750602545, 0.0068537919594921729, 0.006825646999754016, 0.0067983469965890025, 0.00677183386683693, 0.0067460090680403909, 0.0067208355493596269, 0.0066963654654312327, 0.0066725957887413204, 0.0066495283787867451, 0.0066271476191711812, 0.006605451408837771, 0.0065843483639769964, 0.0065638514486906826, 0.0065439398713597651, 0.0065246072126130018, 0.0065058120168612716, 0.0064875571255829153, 0.006469802788133059, 0.0064525327544496811, 0.0064356524526463857, 0.0064192076680750186, 0.0064031528160159177, 0.0063874617000880349, 0.0063720861410913321, 0.006356995319232079, 0.0063421702777741321, 0.0063276701462560989, 0.0063135062782843747, 0.006299711505698696, 0.0062862609486772775, 0.0062731457576522013, 0.0062603686848047438, 0.0062479560049370931, 0.0062358832984507886, 0.006224145018051996, 0.0062127306553081234, 0.0062016336749334718, 0.0061908316573548259, 0.0061803100763441745, 0.006170062208004392, 0.0061600585740011534, 0.0061503100691485714, 0.0061408079025514779]}
[2017-10-20 01:37:18,360 AE_UNIGRAMA_2L_UNDER_01.py:132]: evaluating model ... 
[2017-10-20 01:37:18,407 AE_UNIGRAMA_2L_UNDER_01.py:136]: evaluated! 
[2017-10-20 01:37:18,407 AE_UNIGRAMA_2L_UNDER_01.py:138]: generating reports ... 
[2017-10-20 01:37:19,066 AE_UNIGRAMA_2L_UNDER_01.py:141]: done!
[2017-10-20 01:37:19,067 AE_UNIGRAMA_2L_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_2L_UNDER_01 finished!
