[2017-11-18 18:00:19,729 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_2L_9FULLDS_OVER_05
[2017-11-18 18:00:19,729 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 18:00:19,729 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_2L_9FULLDS_OVER_05
	layers = 96,172,156,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/2layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/2layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/2layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/2layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/2layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f15ce79beb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f15ce7a0400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:00:19,729 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 18:00:21,871 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:00:21,871 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:00:21,871 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 18:00:21,871 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f15ce79beb8>, 'discard_decoder_function': True}
[2017-11-18 18:00:21,950 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 18:02:39,708 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 18:02:39,709 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0098690910826860559, 0.0092903819538923977, 0.0085850760606978362, 0.0079837802296811745, 0.0074856257319754317, 0.0070737255843289848, 0.0067357200633245701, 0.0064571624966074728, 0.0062252367930182174, 0.0060307229324854921, 0.0058689384847175697, 0.0057337774507679488, 0.0056202877388198515, 0.0055241784113721128, 0.0054420468375019695, 0.0053713513140007715, 0.0053101414650300769, 0.0052571520764649032, 0.0052113887617410391, 0.0051718045375866075, 0.0051373250667657465, 0.0051071113803776826, 0.0050805915594244709, 0.0050573125497863454, 0.0050368163969473165, 0.0050185031062645793, 0.0050012086775155246, 0.0049849421732115345, 0.0049698514341370223, 0.0049561351946377438, 0.0049436419888391672, 0.0049321572935514674, 0.0049214505657070385, 0.0049111962924071016, 0.0049009357494511222, 0.0048907114769058636, 0.0048807884897805343, 0.0048713342717738167, 0.004862151315157842, 0.0048531520211037545, 0.0048442458307274023, 0.0048354468370853856, 0.0048267497892092084, 0.0048181349432143122, 0.0048096348068278824, 0.0048012636872833319, 0.004792982021254959, 0.0047847937402520462, 0.004776703868487775, 0.0047687204227464816, 0.0047608378946709965, 0.0047530381532487941, 0.0047453173262692466, 0.0047376689855187296, 0.0047300332891578537, 0.0047224058630338534, 0.0047148178039424643, 0.0047072432989145752, 0.0046996752843938465, 0.0046921192272369452, 0.0046845821682391132, 0.0046770702343288976, 0.0046695670364024127, 0.0046620485186303021, 0.0046545252798981512, 0.0046469137894529786, 0.0046391545709165054, 0.0046313119266190401, 0.0046233880152711584, 0.0046153720465715656, 0.0046073268154839331, 0.0045992808200169778, 0.0045911175695489935, 0.00458251823147828, 0.0045726573588795484, 0.0045631500542025567, 0.0045539859092928875, 0.0045450708558642606, 0.0045363207610213813, 0.0045276776047112697, 0.0045190976807458795, 0.0045105338559798466, 0.0045019488274528809, 0.0044930026020997783, 0.0044837957850490714, 0.0044744646969312601, 0.0044649255135805459, 0.0044552398572505775, 0.0044454311250251384, 0.0044351384516970382, 0.0044245051943708332, 0.0044138090238687051, 0.0044031751236270119, 0.0043926513300748598, 0.0043822215535965136, 0.0043718301034294605, 0.0043615222975213969, 0.0043512788457123067, 0.0043410915712911863, 0.004330930270407608, 0.0043207454253915657], 'val_acc': [0.0047776552737963983, 0.012495406100698273, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010046670875224333, 0.0096320885913639739, 0.0089339250770703958, 0.0082821134115247264, 0.0077362681115559417, 0.007283613866916866, 0.0069117751061674917, 0.0066059650001631083, 0.0063532509204748764, 0.0061419134081298005, 0.0059655668899052028, 0.0058187299401274021, 0.0056958801548151142, 0.0055924082323277786, 0.0055043686147469659, 0.0054290273924232097, 0.0053639219015492855, 0.0053075634787181298, 0.0052588865808192407, 0.0052168305208342963, 0.0051803877900696476, 0.0051485789491418563, 0.0051207110487867516, 0.005096291169241607, 0.0050748227819401651, 0.0050558359395907861, 0.0050384657341098439, 0.0050219278463667864, 0.0050064526472368264, 0.0049922957123482766, 0.0049794283054213012, 0.0049676708868513029, 0.0049568029642754413, 0.0049465444678930184, 0.0049365135024635395, 0.0049264390043053758, 0.0049165562889227198, 0.004907080098473124, 0.0048979643612964705, 0.004889081474254142, 0.0048803190236706099, 0.0048716610352546102, 0.0048630960696396637, 0.0048546128141772303, 0.0048462227925981051, 0.0048379552658869987, 0.0048297894165208839, 0.0048217129163929656, 0.0048137215804102884, 0.0048058270527342774, 0.004798029275578806, 0.0047903138254470215, 0.0047826845766671252, 0.0047751356691201619, 0.0047676250977802676, 0.0047601096562588981, 0.0047526157161487722, 0.0047451549438741166, 0.0047377069042662916, 0.0047302689878616407, 0.0047228534003358226, 0.004715469473776524, 0.0047081119035203402, 0.0047007416033980395, 0.004693369553630756, 0.0046859683316441943, 0.0046784356678284478, 0.0046708127349691462, 0.0046630976365553837, 0.0046552912529539197, 0.0046474341010121325, 0.0046395759521882397, 0.004631688061228695, 0.0046235849957730717, 0.0046145791669490619, 0.0046051895693795027, 0.0045961610090028216, 0.0045874004031741739, 0.0045788312658125259, 0.0045703911017093814, 0.0045620030346273377, 0.0045536636358658109, 0.0045453095796050592, 0.0045367937920974257, 0.0045278660905718566, 0.0045187843429539461, 0.004509530676355282, 0.0045000768569952538, 0.0044905359438563693, 0.0044806758306220468, 0.0044703674354061541, 0.004459859589493167, 0.0044493772417793422, 0.0044389403128167254, 0.0044286072780200404, 0.0044183413521766777, 0.0044081030324114251, 0.0043979404994636513, 0.0043878455912575217, 0.0043777853128872607, 0.0043677148426106384], 'acc': [0.0049097827421136619, 0.0088376089358045903, 0.31754019878767187, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124]}
[2017-11-18 18:02:39,709 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:95]: done!
[2017-11-18 18:02:39,709 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 18:02:39,709 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 18:02:39,709 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f15ce7a0400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:02:39,754 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 18:07:42,123 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:125]: trained!
[2017-11-18 18:07:42,125 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0098690910826860559, 0.0092903819538923977, 0.0085850760606978362, 0.0079837802296811745, 0.0074856257319754317, 0.0070737255843289848, 0.0067357200633245701, 0.0064571624966074728, 0.0062252367930182174, 0.0060307229324854921, 0.0058689384847175697, 0.0057337774507679488, 0.0056202877388198515, 0.0055241784113721128, 0.0054420468375019695, 0.0053713513140007715, 0.0053101414650300769, 0.0052571520764649032, 0.0052113887617410391, 0.0051718045375866075, 0.0051373250667657465, 0.0051071113803776826, 0.0050805915594244709, 0.0050573125497863454, 0.0050368163969473165, 0.0050185031062645793, 0.0050012086775155246, 0.0049849421732115345, 0.0049698514341370223, 0.0049561351946377438, 0.0049436419888391672, 0.0049321572935514674, 0.0049214505657070385, 0.0049111962924071016, 0.0049009357494511222, 0.0048907114769058636, 0.0048807884897805343, 0.0048713342717738167, 0.004862151315157842, 0.0048531520211037545, 0.0048442458307274023, 0.0048354468370853856, 0.0048267497892092084, 0.0048181349432143122, 0.0048096348068278824, 0.0048012636872833319, 0.004792982021254959, 0.0047847937402520462, 0.004776703868487775, 0.0047687204227464816, 0.0047608378946709965, 0.0047530381532487941, 0.0047453173262692466, 0.0047376689855187296, 0.0047300332891578537, 0.0047224058630338534, 0.0047148178039424643, 0.0047072432989145752, 0.0046996752843938465, 0.0046921192272369452, 0.0046845821682391132, 0.0046770702343288976, 0.0046695670364024127, 0.0046620485186303021, 0.0046545252798981512, 0.0046469137894529786, 0.0046391545709165054, 0.0046313119266190401, 0.0046233880152711584, 0.0046153720465715656, 0.0046073268154839331, 0.0045992808200169778, 0.0045911175695489935, 0.00458251823147828, 0.0045726573588795484, 0.0045631500542025567, 0.0045539859092928875, 0.0045450708558642606, 0.0045363207610213813, 0.0045276776047112697, 0.0045190976807458795, 0.0045105338559798466, 0.0045019488274528809, 0.0044930026020997783, 0.0044837957850490714, 0.0044744646969312601, 0.0044649255135805459, 0.0044552398572505775, 0.0044454311250251384, 0.0044351384516970382, 0.0044245051943708332, 0.0044138090238687051, 0.0044031751236270119, 0.0043926513300748598, 0.0043822215535965136, 0.0043718301034294605, 0.0043615222975213969, 0.0043512788457123067, 0.0043410915712911863, 0.004330930270407608, 0.0043207454253915657], 'val_acc': [0.0047776552737963983, 0.012495406100698273, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010046670875224333, 0.0096320885913639739, 0.0089339250770703958, 0.0082821134115247264, 0.0077362681115559417, 0.007283613866916866, 0.0069117751061674917, 0.0066059650001631083, 0.0063532509204748764, 0.0061419134081298005, 0.0059655668899052028, 0.0058187299401274021, 0.0056958801548151142, 0.0055924082323277786, 0.0055043686147469659, 0.0054290273924232097, 0.0053639219015492855, 0.0053075634787181298, 0.0052588865808192407, 0.0052168305208342963, 0.0051803877900696476, 0.0051485789491418563, 0.0051207110487867516, 0.005096291169241607, 0.0050748227819401651, 0.0050558359395907861, 0.0050384657341098439, 0.0050219278463667864, 0.0050064526472368264, 0.0049922957123482766, 0.0049794283054213012, 0.0049676708868513029, 0.0049568029642754413, 0.0049465444678930184, 0.0049365135024635395, 0.0049264390043053758, 0.0049165562889227198, 0.004907080098473124, 0.0048979643612964705, 0.004889081474254142, 0.0048803190236706099, 0.0048716610352546102, 0.0048630960696396637, 0.0048546128141772303, 0.0048462227925981051, 0.0048379552658869987, 0.0048297894165208839, 0.0048217129163929656, 0.0048137215804102884, 0.0048058270527342774, 0.004798029275578806, 0.0047903138254470215, 0.0047826845766671252, 0.0047751356691201619, 0.0047676250977802676, 0.0047601096562588981, 0.0047526157161487722, 0.0047451549438741166, 0.0047377069042662916, 0.0047302689878616407, 0.0047228534003358226, 0.004715469473776524, 0.0047081119035203402, 0.0047007416033980395, 0.004693369553630756, 0.0046859683316441943, 0.0046784356678284478, 0.0046708127349691462, 0.0046630976365553837, 0.0046552912529539197, 0.0046474341010121325, 0.0046395759521882397, 0.004631688061228695, 0.0046235849957730717, 0.0046145791669490619, 0.0046051895693795027, 0.0045961610090028216, 0.0045874004031741739, 0.0045788312658125259, 0.0045703911017093814, 0.0045620030346273377, 0.0045536636358658109, 0.0045453095796050592, 0.0045367937920974257, 0.0045278660905718566, 0.0045187843429539461, 0.004509530676355282, 0.0045000768569952538, 0.0044905359438563693, 0.0044806758306220468, 0.0044703674354061541, 0.004459859589493167, 0.0044493772417793422, 0.0044389403128167254, 0.0044286072780200404, 0.0044183413521766777, 0.0044081030324114251, 0.0043979404994636513, 0.0043878455912575217, 0.0043777853128872607, 0.0043677148426106384], 'acc': [0.0049097827421136619, 0.0088376089358045903, 0.31754019878767187, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.59383822263669894, 0.59383822270254427, 0.59383822264767316, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124]}
[2017-11-18 18:07:42,125 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 18:07:42,262 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 18:07:42,263 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 18:07:43,154 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:141]: done!
[2017-11-18 18:07:43,155 AE_UNIGRAMA_2L_9FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_2L_9FULLDS_OVER_05 finished!
