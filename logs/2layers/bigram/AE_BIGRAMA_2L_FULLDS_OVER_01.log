[2018-05-28 01:22:51,072 AE_BIGRAMA_2L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_01
[2018-05-28 01:22:51,072 AE_BIGRAMA_2L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-05-28 01:22:51,072 AE_BIGRAMA_2L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_01
	layers = 9216,9216,8295
	using GLOBAL obj = 
		{'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'store_history': True, 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'batch': 32, 'numpy_seed': 666, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'shuffle_batches': True, 'autoencoder_configs': {'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6c5b9e2898>, 'hidden_layer_activation': 'relu'}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'mlp_configs': {'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x7f6c5b9e2908>}, 'data_dir': '/home/dhiego/malware_dataset/', 'epochs': 1000}
	=======================================
	
[2018-05-28 01:22:51,072 AE_BIGRAMA_2L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-05-28 01:24:56,180 AE_BIGRAMA_2L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:24:56,180 AE_BIGRAMA_2L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:24:56,180 AE_BIGRAMA_2L_FULLDS_OVER_01.py:57]: =======================================
[2018-05-28 01:24:56,180 AE_BIGRAMA_2L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f6c5b9e2898>, 'hidden_layer_activation': 'relu'}
[2018-05-28 01:24:56,255 AE_BIGRAMA_2L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:03,979 AE_BIGRAMA_2L_FULLDS_OVER_01.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_01
[2018-05-28 01:27:03,979 AE_BIGRAMA_2L_FULLDS_OVER_01.py:146]: >> Printing header log
[2018-05-28 01:27:03,979 AE_BIGRAMA_2L_FULLDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_01
	layers = 9216,9216,8295
	using GLOBAL obj = 
		{'numpy_seed': 666, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'shuffle_batches': True, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'epochs': 1000, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'mlp_configs': {'optimizer': <keras.optimizers.SGD object at 0x7ff8f98c6908>, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9}, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'batch': 32, 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'autoencoder_configs': {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8f98c6898>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}, 'data_dir': '/home/dhiego/malware_dataset/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'store_history': True}
	=======================================
	
[2018-05-28 01:27:03,979 AE_BIGRAMA_2L_FULLDS_OVER_01.py:148]: >> Loading dataset... 
[2018-05-28 01:33:55,397 AE_BIGRAMA_2L_FULLDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:33:55,398 AE_BIGRAMA_2L_FULLDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:33:55,398 AE_BIGRAMA_2L_FULLDS_OVER_01.py:57]: =======================================
[2018-05-28 01:33:55,399 AE_BIGRAMA_2L_FULLDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff8f98c6898>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}
[2018-05-28 01:33:56,168 AE_BIGRAMA_2L_FULLDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-05-29 18:09:17,654 AE_BIGRAMA_2L_FULLDS_OVER_01.py:85]: trained and evaluated!
[2018-05-29 18:09:17,656 AE_BIGRAMA_2L_FULLDS_OVER_01.py:88]: Training history: 
{'loss': [0.00010770966577974174, 0.00010769732720956929, 0.00010768438323631945, 0.00010767076770477431, 0.00010765630331448445, 0.00010764066114340332, 0.00010762334462059676, 0.00010760392104941123, 0.00010758216785359676, 0.00010755803720223867, 0.00010753132438613107, 0.00010750148777020018, 0.00010746826535209748, 0.00010743187240800206, 0.00010739326253222427, 0.00010735328599368888, 0.00010731224167376659, 0.0001072705510626894, 0.00010722858800196381, 0.00010718652298673702, 0.000107144334165916, 0.00010710202717843488, 0.0001070597276249873, 0.00010701746841662199, 0.00010697524201392146, 0.00010693305816757987, 0.00010689093886711831, 0.00010684886690458893, 0.00010680683930780722, 0.00010676486436906074, 0.0001067229917215082, 0.00010668120061076412, 0.00010663943856008935, 0.00010659778467174458, 0.0001065561463489657, 0.00010651461040668923, 0.00010647313469580264, 0.00010643173805234645, 0.00010639038246933302, 0.00010634911268314005, 0.00010630790726510332, 0.00010626678163075059, 0.00010622570180626282, 0.0001061847233316582, 0.00010614379595308437, 0.00010610293614437396, 0.00010606213768340877, 0.00010602140931169773, 0.00010598076024497751, 0.00010594019497724819, 0.0001058996561573167, 0.00010585921095941007, 0.00010581883986517144, 0.00010577852352325063, 0.0001057382768606583, 0.00010569811240290143, 0.00010565802223814642, 0.00010561798150917853, 0.00010557802263674325, 0.00010553814941466257, 0.00010549833353841649, 0.00010545858561427388, 0.00010541891460880088, 0.00010537930315150831, 0.0001053397691621322, 0.00010530030823330162, 0.00010526091479663611, 0.00010522161980197133, 0.00010518237190053363, 0.00010514320728545645, 0.00010510411902819197, 0.00010506510124599405, 0.00010502614533935418, 0.00010498727981998793, 0.00010494846310410514, 0.00010490972424998897, 0.00010487107039248974, 0.00010483248700201928, 0.00010479396882813517, 0.0001047555207720839, 0.0001047171415210316, 0.00010467883557969534, 0.00010464062137686923, 0.00010460247827426866, 0.00010456440144388005, 0.00010452639916102229, 0.00010448846940196644, 0.00010445060482823896, 0.00010441282675776158, 0.00010437510279122286, 0.00010433746218517066, 0.00010429988768343054, 0.00010426239512306606, 0.00010422497058267944, 0.00010418758737780554, 0.00010415029379304589, 0.0001041130744887849, 0.00010407590893122886, 0.000104038834222671, 0.00010400182564968321, 0.00010396488037047129], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0003682337056585246, 0.0003682337056585246, 0.0007364674113170492, 0.0012274456855284155, 0.0046642936050079785, 0.008346630661593225, 0.014729348226340984, 0.024426169142929985, 0.03645513686202297, 0.053148398184294905, 0.07867926844420046, 0.10924266601202896, 0.1401742972910031, 0.1771204124254084, 0.21750337546466098, 0.26782864860424865, 0.31790843255551765, 0.36209647725283095, 0.39818338032688877, 0.4280103105876553, 0.450963544870456, 0.46606112682074585, 0.4762489260106317, 0.4839818338258026, 0.4869277034930193, 0.4898735730358614, 0.4909782742186823, 0.49196023076344697, 0.4922057198859203, 0.4928194427323426, 0.4928194427323426, 0.49306493186944833, 0.4930649319206613, 0.49306493190237094, 0.4930649318182353, 0.49318767646726575, 0.4931876764745819, 0.49318767645263345, 0.4931876764709238, 0.4931876764709238, 0.4931876764892142, 0.4931876764160527, 0.49318767643800115, 0.4931876764745819, 0.49318767645263345, 0.49318767645263345, 0.4931876764892142, 0.4931876764709238, 0.49318767651116263, 0.49318767643800115, 0.4931876764160527, 0.49318767643800115, 0.4931876764709238, 0.4931876764343431, 0.4931876764709238, 0.4931876764709238, 0.4931876764160527, 0.4931876764892142, 0.4931876764709238, 0.4931876764892142, 0.4931876764343431, 0.4931876764709238, 0.49318767643800115, 0.49318767645263345, 0.4931876764709238, 0.49318767643800115, 0.4931876764343431, 0.4931876764343431, 0.4931876764709238, 0.4931876764709238], 'val_loss': [0.00010764565140114004, 0.00010763317724644576, 0.00010762007183490992, 0.00010760617232252562, 0.00010759125710143277, 0.00010757487476009719, 0.00010755664103383196, 0.00010753623998670615, 0.00010751340113813742, 0.0001074879405729884, 0.00010745943830993648, 0.00010742752253177097, 0.00010739235067834208, 0.00010735445695628714, 0.00010731469854347196, 0.0001072737431219842, 0.00010723200990036007, 0.00010718994338853639, 0.0001071477087622492, 0.0001071053954187109, 0.00010706288418837832, 0.00010702035112749889, 0.00010697786936198694, 0.00010693543002752806, 0.00010689303894809717, 0.00010685070112675071, 0.00010680842167083127, 0.00010676618510589311, 0.00010672400151559527, 0.00010668192004006016, 0.00010663992244259871, 0.00010659795539560243, 0.00010655609737298832, 0.00010651425550401622, 0.00010647251695310744, 0.00010643083534238296, 0.00010638923228312149, 0.00010634766894882375, 0.00010630619683808132, 0.00010626478575874522, 0.00010622345282977193, 0.00010618216962920135, 0.00010614097920845484, 0.00010609984108850032, 0.00010605877699025056, 0.00010601776979742308, 0.00010597683184518598, 0.00010593598264037899, 0.00010589521336681967, 0.00010585446934385491, 0.00010581381964628701, 0.00010577323733890057, 0.00010573271626881856, 0.0001056922535106835, 0.00010565187628850295, 0.00010561157041402583, 0.0001055713182843014, 0.000105531144700692, 0.00010549105712900931, 0.0001054510234411274, 0.00010541106083622279, 0.00010537117218082491, 0.00010533133992278905, 0.00010529158667881845, 0.00010525190609281192, 0.00010521229344248314, 0.00010517278528677827, 0.00010513332210510174, 0.00010509394020236959, 0.00010505463276255243, 0.00010501539892194781, 0.00010497622466076679, 0.0001049371472706319, 0.00010489811372609679, 0.00010485915830251047, 0.00010482029094983191, 0.00010478149865102263, 0.00010474276761625777, 0.0001047041089961229, 0.0001046655121721587, 0.00010462699135400828, 0.00010458856493345274, 0.00010455020344834546, 0.00010451191115034853, 0.00010447369911517549, 0.00010443554811943076, 0.00010439746814248731, 0.00010435946809411757, 0.00010432152333874728, 0.00010428366312192898, 0.00010424587072313238, 0.00010420815318032897, 0.00010417051447510671, 0.00010413291119505405, 0.00010409540010387118, 0.00010405796826473968, 0.00010402058355755559, 0.00010398329697819824, 0.00010394607291164394, 0.00010390891245690724, 0.00010387180973118523], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0011025358324145535, 0.0011025358324145535, 0.0025725836089672913, 0.006615214994487321, 0.012862918044836457, 0.023153252480705624, 0.033443586916574786, 0.047409040793825796, 0.0687247335538405, 0.09812568908489526, 0.12936420433664095, 0.16391032708563028, 0.20066152149944874, 0.2484380742374127, 0.29768467475192945, 0.3399485483278207, 0.3774347666299155, 0.41271591326718116, 0.43697170158030135, 0.45828739434031607, 0.4726203601617053, 0.4796030871003308, 0.48438074237412715, 0.48805586181550903, 0.49099595736861446, 0.4924660051451672, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436]}
[2018-05-29 18:09:17,656 AE_BIGRAMA_2L_FULLDS_OVER_01.py:92]: done!
[2018-05-29 18:09:17,656 AE_BIGRAMA_2L_FULLDS_OVER_01.py:152]: >> Executing classifier part ... 
[2018-05-29 18:09:17,689 AE_BIGRAMA_2L_FULLDS_OVER_01.py:97]: =======================================
[2018-05-29 18:09:17,689 AE_BIGRAMA_2L_FULLDS_OVER_01.py:101]: setting configurations for classifier: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7ff8f98c6908>, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2018-05-29 18:09:18,136 AE_BIGRAMA_2L_FULLDS_OVER_01.py:110]: training ... 
[2018-05-31 18:27:11,820 AE_BIGRAMA_2L_FULLDS_OVER_01.py:122]: trained!
[2018-05-31 18:27:11,822 AE_BIGRAMA_2L_FULLDS_OVER_01.py:125]: Training history: 
{'loss': [0.00010770966577974174, 0.00010769732720956929, 0.00010768438323631945, 0.00010767076770477431, 0.00010765630331448445, 0.00010764066114340332, 0.00010762334462059676, 0.00010760392104941123, 0.00010758216785359676, 0.00010755803720223867, 0.00010753132438613107, 0.00010750148777020018, 0.00010746826535209748, 0.00010743187240800206, 0.00010739326253222427, 0.00010735328599368888, 0.00010731224167376659, 0.0001072705510626894, 0.00010722858800196381, 0.00010718652298673702, 0.000107144334165916, 0.00010710202717843488, 0.0001070597276249873, 0.00010701746841662199, 0.00010697524201392146, 0.00010693305816757987, 0.00010689093886711831, 0.00010684886690458893, 0.00010680683930780722, 0.00010676486436906074, 0.0001067229917215082, 0.00010668120061076412, 0.00010663943856008935, 0.00010659778467174458, 0.0001065561463489657, 0.00010651461040668923, 0.00010647313469580264, 0.00010643173805234645, 0.00010639038246933302, 0.00010634911268314005, 0.00010630790726510332, 0.00010626678163075059, 0.00010622570180626282, 0.0001061847233316582, 0.00010614379595308437, 0.00010610293614437396, 0.00010606213768340877, 0.00010602140931169773, 0.00010598076024497751, 0.00010594019497724819, 0.0001058996561573167, 0.00010585921095941007, 0.00010581883986517144, 0.00010577852352325063, 0.0001057382768606583, 0.00010569811240290143, 0.00010565802223814642, 0.00010561798150917853, 0.00010557802263674325, 0.00010553814941466257, 0.00010549833353841649, 0.00010545858561427388, 0.00010541891460880088, 0.00010537930315150831, 0.0001053397691621322, 0.00010530030823330162, 0.00010526091479663611, 0.00010522161980197133, 0.00010518237190053363, 0.00010514320728545645, 0.00010510411902819197, 0.00010506510124599405, 0.00010502614533935418, 0.00010498727981998793, 0.00010494846310410514, 0.00010490972424998897, 0.00010487107039248974, 0.00010483248700201928, 0.00010479396882813517, 0.0001047555207720839, 0.0001047171415210316, 0.00010467883557969534, 0.00010464062137686923, 0.00010460247827426866, 0.00010456440144388005, 0.00010452639916102229, 0.00010448846940196644, 0.00010445060482823896, 0.00010441282675776158, 0.00010437510279122286, 0.00010433746218517066, 0.00010429988768343054, 0.00010426239512306606, 0.00010422497058267944, 0.00010418758737780554, 0.00010415029379304589, 0.0001041130744887849, 0.00010407590893122886, 0.000104038834222671, 0.00010400182564968321, 0.00010396488037047129], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.00012274456855284154, 0.00012274456855284154, 0.0003682337056585246, 0.0003682337056585246, 0.0007364674113170492, 0.0012274456855284155, 0.0046642936050079785, 0.008346630661593225, 0.014729348226340984, 0.024426169142929985, 0.03645513686202297, 0.053148398184294905, 0.07867926844420046, 0.10924266601202896, 0.1401742972910031, 0.1771204124254084, 0.21750337546466098, 0.26782864860424865, 0.31790843255551765, 0.36209647725283095, 0.39818338032688877, 0.4280103105876553, 0.450963544870456, 0.46606112682074585, 0.4762489260106317, 0.4839818338258026, 0.4869277034930193, 0.4898735730358614, 0.4909782742186823, 0.49196023076344697, 0.4922057198859203, 0.4928194427323426, 0.4928194427323426, 0.49306493186944833, 0.4930649319206613, 0.49306493190237094, 0.4930649318182353, 0.49318767646726575, 0.4931876764745819, 0.49318767645263345, 0.4931876764709238, 0.4931876764709238, 0.4931876764892142, 0.4931876764160527, 0.49318767643800115, 0.4931876764745819, 0.49318767645263345, 0.49318767645263345, 0.4931876764892142, 0.4931876764709238, 0.49318767651116263, 0.49318767643800115, 0.4931876764160527, 0.49318767643800115, 0.4931876764709238, 0.4931876764343431, 0.4931876764709238, 0.4931876764709238, 0.4931876764160527, 0.4931876764892142, 0.4931876764709238, 0.4931876764892142, 0.4931876764343431, 0.4931876764709238, 0.49318767643800115, 0.49318767645263345, 0.4931876764709238, 0.49318767643800115, 0.4931876764343431, 0.4931876764343431, 0.4931876764709238, 0.4931876764709238], 'val_loss': [0.00010764565140114004, 0.00010763317724644576, 0.00010762007183490992, 0.00010760617232252562, 0.00010759125710143277, 0.00010757487476009719, 0.00010755664103383196, 0.00010753623998670615, 0.00010751340113813742, 0.0001074879405729884, 0.00010745943830993648, 0.00010742752253177097, 0.00010739235067834208, 0.00010735445695628714, 0.00010731469854347196, 0.0001072737431219842, 0.00010723200990036007, 0.00010718994338853639, 0.0001071477087622492, 0.0001071053954187109, 0.00010706288418837832, 0.00010702035112749889, 0.00010697786936198694, 0.00010693543002752806, 0.00010689303894809717, 0.00010685070112675071, 0.00010680842167083127, 0.00010676618510589311, 0.00010672400151559527, 0.00010668192004006016, 0.00010663992244259871, 0.00010659795539560243, 0.00010655609737298832, 0.00010651425550401622, 0.00010647251695310744, 0.00010643083534238296, 0.00010638923228312149, 0.00010634766894882375, 0.00010630619683808132, 0.00010626478575874522, 0.00010622345282977193, 0.00010618216962920135, 0.00010614097920845484, 0.00010609984108850032, 0.00010605877699025056, 0.00010601776979742308, 0.00010597683184518598, 0.00010593598264037899, 0.00010589521336681967, 0.00010585446934385491, 0.00010581381964628701, 0.00010577323733890057, 0.00010573271626881856, 0.0001056922535106835, 0.00010565187628850295, 0.00010561157041402583, 0.0001055713182843014, 0.000105531144700692, 0.00010549105712900931, 0.0001054510234411274, 0.00010541106083622279, 0.00010537117218082491, 0.00010533133992278905, 0.00010529158667881845, 0.00010525190609281192, 0.00010521229344248314, 0.00010517278528677827, 0.00010513332210510174, 0.00010509394020236959, 0.00010505463276255243, 0.00010501539892194781, 0.00010497622466076679, 0.0001049371472706319, 0.00010489811372609679, 0.00010485915830251047, 0.00010482029094983191, 0.00010478149865102263, 0.00010474276761625777, 0.0001047041089961229, 0.0001046655121721587, 0.00010462699135400828, 0.00010458856493345274, 0.00010455020344834546, 0.00010451191115034853, 0.00010447369911517549, 0.00010443554811943076, 0.00010439746814248731, 0.00010435946809411757, 0.00010432152333874728, 0.00010428366312192898, 0.00010424587072313238, 0.00010420815318032897, 0.00010417051447510671, 0.00010413291119505405, 0.00010409540010387118, 0.00010405796826473968, 0.00010402058355755559, 0.00010398329697819824, 0.00010394607291164394, 0.00010390891245690724, 0.00010387180973118523], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0011025358324145535, 0.0011025358324145535, 0.0025725836089672913, 0.006615214994487321, 0.012862918044836457, 0.023153252480705624, 0.033443586916574786, 0.047409040793825796, 0.0687247335538405, 0.09812568908489526, 0.12936420433664095, 0.16391032708563028, 0.20066152149944874, 0.2484380742374127, 0.29768467475192945, 0.3399485483278207, 0.3774347666299155, 0.41271591326718116, 0.43697170158030135, 0.45828739434031607, 0.4726203601617053, 0.4796030871003308, 0.48438074237412715, 0.48805586181550903, 0.49099595736861446, 0.4924660051451672, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436]}
[2018-05-31 18:27:11,822 AE_BIGRAMA_2L_FULLDS_OVER_01.py:129]: evaluating model ... 
[2018-05-31 18:27:56,241 AE_BIGRAMA_2L_FULLDS_OVER_01.py:133]: evaluated! 
[2018-05-31 18:27:56,243 AE_BIGRAMA_2L_FULLDS_OVER_01.py:135]: generating reports ... 
[2018-05-31 18:27:59,372 AE_BIGRAMA_2L_FULLDS_OVER_01.py:138]: done!
[2018-05-31 18:27:59,373 AE_BIGRAMA_2L_FULLDS_OVER_01.py:154]: >> experiment AE_BIGRAMA_2L_FULLDS_OVER_01 finished!
