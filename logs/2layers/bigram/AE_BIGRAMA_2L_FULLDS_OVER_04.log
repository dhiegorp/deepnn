[2018-05-28 01:22:51,082 AE_BIGRAMA_2L_FULLDS_OVER_04.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_04
[2018-05-28 01:22:51,083 AE_BIGRAMA_2L_FULLDS_OVER_04.py:146]: >> Printing header log
[2018-05-28 01:22:51,083 AE_BIGRAMA_2L_FULLDS_OVER_04.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_04
	layers = 9216,16589,14931
	using GLOBAL obj = 
		{'numpy_seed': 666, 'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'mlp_configs': {'optimizer': <keras.optimizers.SGD object at 0x7f36a23f1908>, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'classifier_dim': 9, 'use_last_dim_as_classifier': False}, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'store_history': True, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'epochs': 1000, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f36a23f1898>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'batch': 32, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/'}
	=======================================
	
[2018-05-28 01:22:51,083 AE_BIGRAMA_2L_FULLDS_OVER_04.py:148]: >> Loading dataset... 
[2018-05-28 01:24:58,245 AE_BIGRAMA_2L_FULLDS_OVER_04.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:24:58,246 AE_BIGRAMA_2L_FULLDS_OVER_04.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:24:58,246 AE_BIGRAMA_2L_FULLDS_OVER_04.py:57]: =======================================
[2018-05-28 01:24:58,246 AE_BIGRAMA_2L_FULLDS_OVER_04.py:62]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f36a23f1898>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2018-05-28 01:24:58,349 AE_BIGRAMA_2L_FULLDS_OVER_04.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_FULLDS_OVER_04.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_04
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_FULLDS_OVER_04.py:146]: >> Printing header log
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_FULLDS_OVER_04.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_04
	layers = 9216,16589,14931
	using GLOBAL obj = 
		{'batch': 32, 'autoencoder_configs': {'discard_decoder_function': True, 'loss_function': 'mse', 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f42e828e898>}, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'mlp_configs': {'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x7f42e828e908>}, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'shuffle_batches': True, 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'data_dir': '/home/dhiego/malware_dataset/', 'store_history': True, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'epochs': 1000, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'numpy_seed': 666, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/'}
	=======================================
	
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_FULLDS_OVER_04.py:148]: >> Loading dataset... 
[2018-05-28 01:33:16,454 AE_BIGRAMA_2L_FULLDS_OVER_04.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:33:16,454 AE_BIGRAMA_2L_FULLDS_OVER_04.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:33:16,454 AE_BIGRAMA_2L_FULLDS_OVER_04.py:57]: =======================================
[2018-05-28 01:33:16,455 AE_BIGRAMA_2L_FULLDS_OVER_04.py:62]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'loss_function': 'mse', 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f42e828e898>}
[2018-05-28 01:33:16,682 AE_BIGRAMA_2L_FULLDS_OVER_04.py:73]: training and evaluate autoencoder
[2018-05-30 20:17:31,087 AE_BIGRAMA_2L_FULLDS_OVER_04.py:85]: trained and evaluated!
[2018-05-30 20:17:31,089 AE_BIGRAMA_2L_FULLDS_OVER_04.py:88]: Training history: 
{'loss': [0.00010739677762977936, 0.00010736658871264167, 0.00010733250705726187, 0.00010729550857969875, 0.00010725646342893313, 0.00010721624430995302, 0.00010717536816941041, 0.0001071341385961232, 0.00010709264899956226, 0.00010705110048980382, 0.00010700946049427809, 0.00010696777872384217, 0.00010692609295238868, 0.00010688442140419541, 0.00010684283459273153, 0.00010680127986710651, 0.00010675975418547531, 0.00010671831845439952, 0.00010667694461495728, 0.00010663560696150383, 0.00010659437206900667, 0.00010655321540265453, 0.0001065120927110145, 0.00010647105370137133, 0.0001064300569301491, 0.00010638911824423522, 0.00010634826136841357, 0.0001063074733020563, 0.00010626674196619854, 0.00010622607248446481, 0.00010618546558025336, 0.00010614491091700677, 0.00010610442743972181, 0.0001060639998284308, 0.00010602365289390806, 0.00010598336079297382, 0.00010594312786780385, 0.00010590298282569919, 0.0001058628993733656, 0.00010582289055161973, 0.00010578292509983257, 0.00010574305330132823, 0.00010570322502639311, 0.00010566347954304982, 0.00010562378897277955, 0.00010558418334554115, 0.00010554466172806154, 0.00010550522015326035, 0.00010546581996309153, 0.00010542653160047061, 0.00010538729079548058, 0.00010534813455128234, 0.0001053090550855395, 0.00010527004102125143, 0.0001052310936614281, 0.00010519223512419472, 0.0001051534499091806, 0.00010511474913707114, 0.00010507611725658981, 0.00010503754054371052, 0.00010499906788318738, 0.00010496065945149937, 0.00010492231638822201, 0.00010488404116809185, 0.00010484585419987079, 0.00010480773205170665, 0.00010476969305236806, 0.0001047317441723778, 0.00010469385743408471, 0.00010465603581235251, 0.00010461828349485337, 0.00010458062249075625, 0.0001045430114145357, 0.00010450546931478631, 0.00010446798715796056, 0.00010443057803935327, 0.00010439326833174312, 0.00010435602973596865, 0.00010431883873801386, 0.00010428174082266103, 0.00010424470159455539, 0.00010420774499550024, 0.00010417083306137601, 0.00010413400509860795, 0.00010409722660556423, 0.00010406053123812587, 0.0001040239071843602, 0.00010398736911585575, 0.0001039509031612275, 0.00010391449556429833, 0.00010387815771993054, 0.0001038418816421645, 0.00010380566916360918, 0.00010376952808178338, 0.00010373343585702611, 0.00010369744419177239, 0.000103661496411787, 0.00010362562906207863, 0.00010358984684384291, 0.00010355412850524634, 0.00010351846823677572], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0011025358324145535, 0.001470047776552738, 0.002940095553105476, 0.007717750826901874, 0.016905549430356485, 0.022418228592429253, 0.03234105108416024, 0.04777655273796398, 0.06762219772142594, 0.10694597574421169, 0.14737228959941198, 0.19625137816979052, 0.2466005145167218, 0.29070194781330394, 0.3480338110988607, 0.38515251745681733, 0.4185961043733921, 0.4406468210216832, 0.45791988239617787, 0.4696802646085998, 0.47813303932377804, 0.48511576626240355, 0.48768834987137083, 0.4902609334803381, 0.49209849320102905, 0.4924660051451672, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'val_loss': [0.00010731600846719864, 0.00010728300462452266, 0.00010724671991056897, 0.00010720805102494299, 0.00010716785647716317, 0.0001071268038236391, 0.00010708529511384049, 0.00010704345045321101, 0.00010700152612605996, 0.0001069595393930659, 0.00010691752286902306, 0.00010687550113335161, 0.00010683349740440512, 0.00010679154982413852, 0.00010674964057568095, 0.00010670776472282598, 0.00010666597094309377, 0.00010662424889077319, 0.00010658256660887437, 0.00010654097391136805, 0.00010649947239998102, 0.00010645800258887973, 0.00010641662150649052, 0.00010637528665223629, 0.00010633400591442092, 0.00010629280524690132, 0.00010625167650466946, 0.00010621060647013677, 0.000106169596720964, 0.00010612864685070299, 0.00010608775562931311, 0.00010604693244253903, 0.00010600616324385176, 0.00010596546927819186, 0.00010592482437243434, 0.00010588423731602155, 0.00010584372548461413, 0.00010580328541270634, 0.00010576291216943976, 0.00010572259086864897, 0.00010568235895437459, 0.0001056421692759512, 0.00010560206475377409, 0.00010556200863904303, 0.0001055220409749279, 0.00010548215832266301, 0.00010544235769806287, 0.00010540259821297315, 0.00010536295191301166, 0.0001053233523626154, 0.00010528384036169661, 0.00010524440649242265, 0.00010520504451100039, 0.00010516574229350782, 0.00010512653267935524, 0.00010508739611624494, 0.00010504834527359524, 0.00010500936413413815, 0.00010497043951237314, 0.0001049316146896857, 0.00010489286020125521, 0.00010485416319315725, 0.00010481554068273631, 0.00010477700871132634, 0.00010473854068331013, 0.000104700153345958, 0.00010466186058001085, 0.00010462362653780687, 0.00010458546326572205, 0.00010454736914865957, 0.0001045093640063173, 0.00010447141537097108, 0.00010443353546280701, 0.00010439571672777132, 0.00010435797095286188, 0.000104320322942115, 0.00010428274907875096, 0.00010424522142212986, 0.00010420778336594527, 0.00010417040972912667, 0.0001041331140260768, 0.0001040958686236659, 0.00010405870920376772, 0.00010402159046077774, 0.00010398456474629397, 0.00010394760975914534, 0.00010391073031788223, 0.00010387393310750797, 0.00010383719793129051, 0.00010380052534809616, 0.0001037639178019621, 0.00010372737872095807, 0.00010369090193616297, 0.00010365448200598411, 0.00010361816296320137, 0.00010358188697184, 0.00010354569141711261, 0.00010350957897836849, 0.0001034735267955703, 0.00010343753998408259, 0.00010340162863826037], 'acc': [0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891380202014, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0006137228427642077, 0.001350190254081257, 0.002700380508162514, 0.003927826193690929, 0.008101141524487541, 0.013010924266601203, 0.0209893212225359, 0.03166809868663312, 0.04517000122744569, 0.06309070823707506, 0.08665766539922064, 0.11992144346149389, 0.16337302074566112, 0.21062967964033416, 0.25702712653501786, 0.30673867680257677, 0.35902786306095835, 0.3951147661972034, 0.42604639743593875, 0.4489996317553201, 0.4629925126252152, 0.47440775739820334, 0.48226340985143057, 0.4863139806136743, 0.4887688719993634, 0.49024180684394597, 0.49146925245631295, 0.49196023075247275, 0.4920829753173675, 0.4920829753722386, 0.49232846440691824, 0.4928194427469749, 0.4930649318840806, 0.49318767643800115, 0.4931876764160527, 0.4931876763867881, 0.49318767645263345, 0.49318767645263345, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115, 0.49318767645263345, 0.49318767646726575, 0.4931876764343431, 0.4931876763867881, 0.4931876764343431, 0.49318767645263345, 0.4931876764892142, 0.4931876764745819, 0.4931876764892142, 0.4931876764709238, 0.49318767645263345, 0.49318767646726575, 0.4931876764343431, 0.4931876764343431, 0.4931876764709238, 0.4931876764160527, 0.49318767643800115, 0.49318767643800115, 0.4931876763867881, 0.4931876763867881, 0.49318767646726575, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.4931876764892142, 0.49318767645263345, 0.49318767643800115, 0.4931876764160527, 0.4931876764745819, 0.49318767643800115, 0.49318767645263345, 0.49318767646726575, 0.4931876764160527, 0.4931876764709238, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876764745819, 0.4931876764745819, 0.4931876764892142, 0.4931876764745819, 0.4931876764892142, 0.49318767645263345, 0.4931876764709238, 0.49318767643800115, 0.49318767645263345]}
[2018-05-30 20:17:31,089 AE_BIGRAMA_2L_FULLDS_OVER_04.py:92]: done!
[2018-05-30 20:17:31,089 AE_BIGRAMA_2L_FULLDS_OVER_04.py:152]: >> Executing classifier part ... 
[2018-05-30 20:17:31,090 AE_BIGRAMA_2L_FULLDS_OVER_04.py:97]: =======================================
[2018-05-30 20:17:31,090 AE_BIGRAMA_2L_FULLDS_OVER_04.py:101]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x7f42e828e908>}
[2018-05-30 20:17:31,219 AE_BIGRAMA_2L_FULLDS_OVER_04.py:110]: training ... 
[2018-06-02 20:25:40,946 AE_BIGRAMA_2L_FULLDS_OVER_04.py:122]: trained!
[2018-06-02 20:25:40,948 AE_BIGRAMA_2L_FULLDS_OVER_04.py:125]: Training history: 
{'loss': [0.00010739677762977936, 0.00010736658871264167, 0.00010733250705726187, 0.00010729550857969875, 0.00010725646342893313, 0.00010721624430995302, 0.00010717536816941041, 0.0001071341385961232, 0.00010709264899956226, 0.00010705110048980382, 0.00010700946049427809, 0.00010696777872384217, 0.00010692609295238868, 0.00010688442140419541, 0.00010684283459273153, 0.00010680127986710651, 0.00010675975418547531, 0.00010671831845439952, 0.00010667694461495728, 0.00010663560696150383, 0.00010659437206900667, 0.00010655321540265453, 0.0001065120927110145, 0.00010647105370137133, 0.0001064300569301491, 0.00010638911824423522, 0.00010634826136841357, 0.0001063074733020563, 0.00010626674196619854, 0.00010622607248446481, 0.00010618546558025336, 0.00010614491091700677, 0.00010610442743972181, 0.0001060639998284308, 0.00010602365289390806, 0.00010598336079297382, 0.00010594312786780385, 0.00010590298282569919, 0.0001058628993733656, 0.00010582289055161973, 0.00010578292509983257, 0.00010574305330132823, 0.00010570322502639311, 0.00010566347954304982, 0.00010562378897277955, 0.00010558418334554115, 0.00010554466172806154, 0.00010550522015326035, 0.00010546581996309153, 0.00010542653160047061, 0.00010538729079548058, 0.00010534813455128234, 0.0001053090550855395, 0.00010527004102125143, 0.0001052310936614281, 0.00010519223512419472, 0.0001051534499091806, 0.00010511474913707114, 0.00010507611725658981, 0.00010503754054371052, 0.00010499906788318738, 0.00010496065945149937, 0.00010492231638822201, 0.00010488404116809185, 0.00010484585419987079, 0.00010480773205170665, 0.00010476969305236806, 0.0001047317441723778, 0.00010469385743408471, 0.00010465603581235251, 0.00010461828349485337, 0.00010458062249075625, 0.0001045430114145357, 0.00010450546931478631, 0.00010446798715796056, 0.00010443057803935327, 0.00010439326833174312, 0.00010435602973596865, 0.00010431883873801386, 0.00010428174082266103, 0.00010424470159455539, 0.00010420774499550024, 0.00010417083306137601, 0.00010413400509860795, 0.00010409722660556423, 0.00010406053123812587, 0.0001040239071843602, 0.00010398736911585575, 0.0001039509031612275, 0.00010391449556429833, 0.00010387815771993054, 0.0001038418816421645, 0.00010380566916360918, 0.00010376952808178338, 0.00010373343585702611, 0.00010369744419177239, 0.000103661496411787, 0.00010362562906207863, 0.00010358984684384291, 0.00010355412850524634, 0.00010351846823677572], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0011025358324145535, 0.001470047776552738, 0.002940095553105476, 0.007717750826901874, 0.016905549430356485, 0.022418228592429253, 0.03234105108416024, 0.04777655273796398, 0.06762219772142594, 0.10694597574421169, 0.14737228959941198, 0.19625137816979052, 0.2466005145167218, 0.29070194781330394, 0.3480338110988607, 0.38515251745681733, 0.4185961043733921, 0.4406468210216832, 0.45791988239617787, 0.4696802646085998, 0.47813303932377804, 0.48511576626240355, 0.48768834987137083, 0.4902609334803381, 0.49209849320102905, 0.4924660051451672, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'val_loss': [0.00010731600846719864, 0.00010728300462452266, 0.00010724671991056897, 0.00010720805102494299, 0.00010716785647716317, 0.0001071268038236391, 0.00010708529511384049, 0.00010704345045321101, 0.00010700152612605996, 0.0001069595393930659, 0.00010691752286902306, 0.00010687550113335161, 0.00010683349740440512, 0.00010679154982413852, 0.00010674964057568095, 0.00010670776472282598, 0.00010666597094309377, 0.00010662424889077319, 0.00010658256660887437, 0.00010654097391136805, 0.00010649947239998102, 0.00010645800258887973, 0.00010641662150649052, 0.00010637528665223629, 0.00010633400591442092, 0.00010629280524690132, 0.00010625167650466946, 0.00010621060647013677, 0.000106169596720964, 0.00010612864685070299, 0.00010608775562931311, 0.00010604693244253903, 0.00010600616324385176, 0.00010596546927819186, 0.00010592482437243434, 0.00010588423731602155, 0.00010584372548461413, 0.00010580328541270634, 0.00010576291216943976, 0.00010572259086864897, 0.00010568235895437459, 0.0001056421692759512, 0.00010560206475377409, 0.00010556200863904303, 0.0001055220409749279, 0.00010548215832266301, 0.00010544235769806287, 0.00010540259821297315, 0.00010536295191301166, 0.0001053233523626154, 0.00010528384036169661, 0.00010524440649242265, 0.00010520504451100039, 0.00010516574229350782, 0.00010512653267935524, 0.00010508739611624494, 0.00010504834527359524, 0.00010500936413413815, 0.00010497043951237314, 0.0001049316146896857, 0.00010489286020125521, 0.00010485416319315725, 0.00010481554068273631, 0.00010477700871132634, 0.00010473854068331013, 0.000104700153345958, 0.00010466186058001085, 0.00010462362653780687, 0.00010458546326572205, 0.00010454736914865957, 0.0001045093640063173, 0.00010447141537097108, 0.00010443353546280701, 0.00010439571672777132, 0.00010435797095286188, 0.000104320322942115, 0.00010428274907875096, 0.00010424522142212986, 0.00010420778336594527, 0.00010417040972912667, 0.0001041331140260768, 0.0001040958686236659, 0.00010405870920376772, 0.00010402159046077774, 0.00010398456474629397, 0.00010394760975914534, 0.00010391073031788223, 0.00010387393310750797, 0.00010383719793129051, 0.00010380052534809616, 0.0001037639178019621, 0.00010372737872095807, 0.00010369090193616297, 0.00010365448200598411, 0.00010361816296320137, 0.00010358188697184, 0.00010354569141711261, 0.00010350957897836849, 0.0001034735267955703, 0.00010343753998408259, 0.00010340162863826037], 'acc': [0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891371056831, 0.0002454891380202014, 0.0002454891371056831, 0.0002454891371056831, 0.0003682337056585246, 0.0006137228427642077, 0.001350190254081257, 0.002700380508162514, 0.003927826193690929, 0.008101141524487541, 0.013010924266601203, 0.0209893212225359, 0.03166809868663312, 0.04517000122744569, 0.06309070823707506, 0.08665766539922064, 0.11992144346149389, 0.16337302074566112, 0.21062967964033416, 0.25702712653501786, 0.30673867680257677, 0.35902786306095835, 0.3951147661972034, 0.42604639743593875, 0.4489996317553201, 0.4629925126252152, 0.47440775739820334, 0.48226340985143057, 0.4863139806136743, 0.4887688719993634, 0.49024180684394597, 0.49146925245631295, 0.49196023075247275, 0.4920829753173675, 0.4920829753722386, 0.49232846440691824, 0.4928194427469749, 0.4930649318840806, 0.49318767643800115, 0.4931876764160527, 0.4931876763867881, 0.49318767645263345, 0.49318767645263345, 0.49318767643800115, 0.49318767643800115, 0.49318767643800115, 0.49318767645263345, 0.49318767646726575, 0.4931876764343431, 0.4931876763867881, 0.4931876764343431, 0.49318767645263345, 0.4931876764892142, 0.4931876764745819, 0.4931876764892142, 0.4931876764709238, 0.49318767645263345, 0.49318767646726575, 0.4931876764343431, 0.4931876764343431, 0.4931876764709238, 0.4931876764160527, 0.49318767643800115, 0.49318767643800115, 0.4931876763867881, 0.4931876763867881, 0.49318767646726575, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.4931876764892142, 0.49318767645263345, 0.49318767643800115, 0.4931876764160527, 0.4931876764745819, 0.49318767643800115, 0.49318767645263345, 0.49318767646726575, 0.4931876764160527, 0.4931876764709238, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876764745819, 0.4931876764745819, 0.4931876764892142, 0.4931876764745819, 0.4931876764892142, 0.49318767645263345, 0.4931876764709238, 0.49318767643800115, 0.49318767645263345]}
[2018-06-02 20:25:40,948 AE_BIGRAMA_2L_FULLDS_OVER_04.py:129]: evaluating model ... 
[2018-06-02 20:26:17,053 AE_BIGRAMA_2L_FULLDS_OVER_04.py:133]: evaluated! 
[2018-06-02 20:26:17,054 AE_BIGRAMA_2L_FULLDS_OVER_04.py:135]: generating reports ... 
[2018-06-02 20:26:18,972 AE_BIGRAMA_2L_FULLDS_OVER_04.py:138]: done!
[2018-06-02 20:26:18,972 AE_BIGRAMA_2L_FULLDS_OVER_04.py:154]: >> experiment AE_BIGRAMA_2L_FULLDS_OVER_04 finished!
