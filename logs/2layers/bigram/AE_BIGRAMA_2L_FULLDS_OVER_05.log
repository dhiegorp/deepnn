[2018-05-28 01:22:51,094 AE_BIGRAMA_2L_FULLDS_OVER_05.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_05
[2018-05-28 01:22:51,094 AE_BIGRAMA_2L_FULLDS_OVER_05.py:146]: >> Printing header log
[2018-05-28 01:22:51,094 AE_BIGRAMA_2L_FULLDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_05
	layers = 9216,18432,16590
	using GLOBAL obj = 
		{'fullds_data_dir': '/home/dhiego/malware_dataset/', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'numpy_seed': 666, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'shuffle_batches': True, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'store_history': True, 'mlp_configs': {'classifier_dim': 9, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'optimizer': <keras.optimizers.SGD object at 0x7fce51422908>, 'loss_function': 'categorical_crossentropy'}, 'batch': 32, 'epochs': 1000, 'autoencoder_configs': {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7fce51422898>}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s'}
	=======================================
	
[2018-05-28 01:22:51,094 AE_BIGRAMA_2L_FULLDS_OVER_05.py:148]: >> Loading dataset... 
[2018-05-28 01:24:40,904 AE_BIGRAMA_2L_FULLDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:24:40,904 AE_BIGRAMA_2L_FULLDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:24:40,904 AE_BIGRAMA_2L_FULLDS_OVER_05.py:57]: =======================================
[2018-05-28 01:24:40,904 AE_BIGRAMA_2L_FULLDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7fce51422898>}
[2018-05-28 01:24:40,976 AE_BIGRAMA_2L_FULLDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:04,015 AE_BIGRAMA_2L_FULLDS_OVER_05.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_05
[2018-05-28 01:27:04,015 AE_BIGRAMA_2L_FULLDS_OVER_05.py:146]: >> Printing header log
[2018-05-28 01:27:04,016 AE_BIGRAMA_2L_FULLDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_05
	layers = 9216,18432,16590
	using GLOBAL obj = 
		{'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'numpy_seed': 666, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'batch': 32, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'autoencoder_configs': {'loss_function': 'mse', 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f7383012898>}, 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'store_history': True, 'mlp_configs': {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x7f7383012908>}, 'epochs': 1000, 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'shuffle_batches': True}
	=======================================
	
[2018-05-28 01:27:04,016 AE_BIGRAMA_2L_FULLDS_OVER_05.py:148]: >> Loading dataset... 
[2018-05-28 01:33:33,210 AE_BIGRAMA_2L_FULLDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:33:33,211 AE_BIGRAMA_2L_FULLDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:33:33,211 AE_BIGRAMA_2L_FULLDS_OVER_05.py:57]: =======================================
[2018-05-28 01:33:33,211 AE_BIGRAMA_2L_FULLDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'loss_function': 'mse', 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f7383012898>}
[2018-05-28 01:33:33,500 AE_BIGRAMA_2L_FULLDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-05-31 03:44:45,618 AE_BIGRAMA_2L_FULLDS_OVER_05.py:85]: trained and evaluated!
[2018-05-31 03:44:45,619 AE_BIGRAMA_2L_FULLDS_OVER_05.py:88]: Training history: 
{'val_loss': [0.00010681414710610125, 0.00010677354329707014, 0.00010673021414588527, 0.0001066850473675076, 0.00010663918266943524, 0.000106593028296799, 0.00010654661911055418, 0.00010649995676055961, 0.0001064532121903722, 0.00010640639848922846, 0.0001063595827665397, 0.00010631278700794486, 0.00010626606329496781, 0.00010621936278162628, 0.00010617272039839962, 0.00010612608890370638, 0.00010607950021442641, 0.00010603299092159386, 0.0001059865208376428, 0.0001059401225746934, 0.00010589379287046408, 0.00010584751596171696, 0.00010580130138126681, 0.00010575515508144059, 0.00010570906537685246, 0.00010566302779657224, 0.00010561707775239949, 0.0001055711775435895, 0.00010552537366835135, 0.00010547961092460165, 0.00010543394237522273, 0.00010538832793426068, 0.00010534280660737289, 0.00010529734431976043, 0.00010525198318961822, 0.00010520670502036721, 0.00010516149856783183, 0.00010511637299314062, 0.00010507133691994787, 0.00010502636253596576, 0.00010498149404511026, 0.00010493671320267029, 0.00010489202057820814, 0.00010484739256564008, 0.00010480287308008993, 0.00010475841274879718, 0.00010471404808524993, 0.00010466976892022117, 0.00010462555350605805, 0.00010458141957406343, 0.00010453739483491303, 0.00010449347843827446, 0.00010444962479509906, 0.0001044058580141828, 0.0001043621541471698, 0.00010431851502307696, 0.00010427500276162913, 0.00010423156633218498, 0.00010418820744610532, 0.00010414494458608739, 0.0001041017416317212, 0.00010405865265131363, 0.00010401563875151536, 0.00010397270879931477, 0.00010392981498089415, 0.00010388702682831, 0.00010384432829755439, 0.00010380170441154583, 0.00010375916701878425, 0.00010371671018031269, 0.00010367433639097437, 0.00010363205882824786, 0.00010358985627393259, 0.00010354771164650811, 0.00010350566355320558, 0.00010346370223926815, 0.00010342180902947056, 0.00010337998357084462, 0.00010333825563839512, 0.00010329661305204601, 0.00010325502505543402, 0.00010321354242784437, 0.00010317214246433179, 0.00010313082980428857, 0.00010308957660066488, 0.00010304839624485939, 0.0001030072928173981, 0.0001029662797979217, 0.00010292533990970766, 0.00010288449376663217, 0.00010284370691418813, 0.00010280302753787949, 0.00010276241717754512, 0.00010272185687986362, 0.00010268138643932275, 0.00010264099985278955, 0.00010260066738804321, 0.0001025604323826233, 0.00010252024461878484, 0.00010248014937004435, 0.00010244012566955739], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0007364674113170492, 0.0011047011169755738, 0.002454891371056831, 0.004418804468816814, 0.00896035350527195, 0.013379157972259727, 0.022094022339511476, 0.03436847919571015, 0.05437584386982332, 0.08322081746419427, 0.12090339999528432, 0.1660734012519946, 0.20645636429490524, 0.24573462621352418, 0.2824352522419174, 0.3161900085774875, 0.35043574320738835, 0.38345403214810275, 0.4121762612260484, 0.43795262060385476, 0.4605376212541583, 0.47723088257734475, 0.4858230023211726, 0.4898735731017067, 0.49183748619855217, 0.4920829753210256, 0.49269669811257677, 0.4929421872972374, 0.4929421872972374, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876763867881, 0.4931876764709238, 0.49318767645263345, 0.49318767643800115, 0.49318767642336886, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764709238, 0.4931876764709238, 0.4931876763867881, 0.49318767645263345, 0.4931876764343431, 0.4931876764709238, 0.49318767645263345, 0.49318767643800115, 0.49318767646726575, 0.4931876764343431, 0.4931876764343431, 0.49318767651116263, 0.4931876764745819, 0.49318767645263345, 0.49318767645263345, 0.4931876764709238, 0.4931876764709238, 0.4931876764709238, 0.49318767646726575, 0.4931876764343431, 0.49318767651116263, 0.4931876764709238, 0.4931876764343431, 0.4931876764709238, 0.4931876764745819, 0.49318767643800115, 0.4931876764709238, 0.4931876763867881, 0.4931876764892142, 0.4931876764160527, 0.4931876764892142, 0.49318767645263345, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.49318767645263345, 0.49318767643800115, 0.4931876764343431, 0.49318767646726575, 0.4931876764709238, 0.4931876764709238, 0.4931876764709238, 0.49318767643800115, 0.4931876764343431, 0.49318767643800115, 0.4931876764709238, 0.4931876764892142], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.001470047776552738, 0.002940095553105476, 0.004777655273796398, 0.008820286659316428, 0.015803013597941933, 0.027563395810363836, 0.04152884968761485, 0.06688717383314957, 0.11356119073869901, 0.15361999264976112, 0.18853362734288864, 0.22675486953325982, 0.2752664461595002, 0.30687247335538403, 0.3432561558250643, 0.37596471885336274, 0.4005880191106211, 0.43329658213891953, 0.45350973906651965, 0.47739801543550164, 0.48695332598309443, 0.4902609334803381, 0.49099595736861446, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.00010687874981354338, 0.00010684011542796066, 0.00010679876839712229, 0.00010675501355659185, 0.00010670986429981679, 0.00010666416653121901, 0.00010661817586134288, 0.00010657194902961872, 0.00010652550151498327, 0.00010647899895599142, 0.00010643240055119483, 0.000106385806329605, 0.00010633925494837491, 0.00010629277422440058, 0.00010624630922853346, 0.00010619989337373567, 0.00010615350412213236, 0.0001061071501768298, 0.00010606089275428987, 0.0001060146593798303, 0.00010596848389330746, 0.0001059223868508422, 0.00010587633973536044, 0.00010583036218310617, 0.0001057844393688804, 0.00010573858392446715, 0.0001056927766003279, 0.00010564706468348899, 0.00010560139075309678, 0.00010555583319515835, 0.00010551031208041697, 0.00010546488604164167, 0.00010541951506329829, 0.0001053742294137992, 0.00010532901602821445, 0.00010528389195462987, 0.00010523885260705767, 0.00010519388236277457, 0.00010514900206458148, 0.00010510420533228427, 0.00010505946378634388, 0.00010501483528879758, 0.00010497029253180742, 0.00010492583743550457, 0.00010488144302963693, 0.00010483716093179652, 0.00010479293408640115, 0.00010474879914384342, 0.00010470475908881099, 0.00010466077715927573, 0.00010461687507326109, 0.00010457307925177238, 0.0001045294037707109, 0.00010448578071012422, 0.00010444224941841253, 0.00010439877201094077, 0.00010435536922780512, 0.0001043120932269136, 0.00010426888894247578, 0.00010422575586989906, 0.00010418272206274677, 0.00010413974762605111, 0.00010409688662445505, 0.00010405410155734975, 0.0001040113975983724, 0.00010396873146240733, 0.00010392617424342849, 0.00010388370407783966, 0.00010384130409527884, 0.00010379900060779501, 0.00010375677753987117, 0.00010371462512384459, 0.00010367258065134236, 0.00010363060667534072, 0.00010358869341388756, 0.00010354686735229024, 0.00010350513748480051, 0.00010346346905615062, 0.00010342186724533629, 0.00010338036633786296, 0.00010333895015818819, 0.00010329758920148667, 0.00010325633022518578, 0.00010321514736735101, 0.00010317405392511417, 0.00010313302783482817, 0.00010309206867585031, 0.00010305118897547376, 0.00010301039871212917, 0.00010296968069394417, 0.00010292905733018947, 0.00010288848845439967, 0.0001028480349258029, 0.00010280764340494066, 0.00010276730397500509, 0.00010272705850825261, 0.00010268689030311412, 0.00010264677786126487, 0.00010260676082939521, 0.000102566792971639, 0.0001025269150537212]}
[2018-05-31 03:44:45,619 AE_BIGRAMA_2L_FULLDS_OVER_05.py:92]: done!
[2018-05-31 03:44:45,620 AE_BIGRAMA_2L_FULLDS_OVER_05.py:152]: >> Executing classifier part ... 
[2018-05-31 03:44:45,620 AE_BIGRAMA_2L_FULLDS_OVER_05.py:97]: =======================================
[2018-05-31 03:44:45,620 AE_BIGRAMA_2L_FULLDS_OVER_05.py:101]: setting configurations for classifier: 
	 {'loss_function': 'categorical_crossentropy', 'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x7f7383012908>}
[2018-05-31 03:44:45,776 AE_BIGRAMA_2L_FULLDS_OVER_05.py:110]: training ... 
[2018-06-04 07:34:13,921 AE_BIGRAMA_2L_FULLDS_OVER_05.py:122]: trained!
[2018-06-04 07:34:13,923 AE_BIGRAMA_2L_FULLDS_OVER_05.py:125]: Training history: 
{'val_loss': [0.00010681414710610125, 0.00010677354329707014, 0.00010673021414588527, 0.0001066850473675076, 0.00010663918266943524, 0.000106593028296799, 0.00010654661911055418, 0.00010649995676055961, 0.0001064532121903722, 0.00010640639848922846, 0.0001063595827665397, 0.00010631278700794486, 0.00010626606329496781, 0.00010621936278162628, 0.00010617272039839962, 0.00010612608890370638, 0.00010607950021442641, 0.00010603299092159386, 0.0001059865208376428, 0.0001059401225746934, 0.00010589379287046408, 0.00010584751596171696, 0.00010580130138126681, 0.00010575515508144059, 0.00010570906537685246, 0.00010566302779657224, 0.00010561707775239949, 0.0001055711775435895, 0.00010552537366835135, 0.00010547961092460165, 0.00010543394237522273, 0.00010538832793426068, 0.00010534280660737289, 0.00010529734431976043, 0.00010525198318961822, 0.00010520670502036721, 0.00010516149856783183, 0.00010511637299314062, 0.00010507133691994787, 0.00010502636253596576, 0.00010498149404511026, 0.00010493671320267029, 0.00010489202057820814, 0.00010484739256564008, 0.00010480287308008993, 0.00010475841274879718, 0.00010471404808524993, 0.00010466976892022117, 0.00010462555350605805, 0.00010458141957406343, 0.00010453739483491303, 0.00010449347843827446, 0.00010444962479509906, 0.0001044058580141828, 0.0001043621541471698, 0.00010431851502307696, 0.00010427500276162913, 0.00010423156633218498, 0.00010418820744610532, 0.00010414494458608739, 0.0001041017416317212, 0.00010405865265131363, 0.00010401563875151536, 0.00010397270879931477, 0.00010392981498089415, 0.00010388702682831, 0.00010384432829755439, 0.00010380170441154583, 0.00010375916701878425, 0.00010371671018031269, 0.00010367433639097437, 0.00010363205882824786, 0.00010358985627393259, 0.00010354771164650811, 0.00010350566355320558, 0.00010346370223926815, 0.00010342180902947056, 0.00010337998357084462, 0.00010333825563839512, 0.00010329661305204601, 0.00010325502505543402, 0.00010321354242784437, 0.00010317214246433179, 0.00010313082980428857, 0.00010308957660066488, 0.00010304839624485939, 0.0001030072928173981, 0.0001029662797979217, 0.00010292533990970766, 0.00010288449376663217, 0.00010284370691418813, 0.00010280302753787949, 0.00010276241717754512, 0.00010272185687986362, 0.00010268138643932275, 0.00010264099985278955, 0.00010260066738804321, 0.0001025604323826233, 0.00010252024461878484, 0.00010248014937004435, 0.00010244012566955739], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0007364674113170492, 0.0011047011169755738, 0.002454891371056831, 0.004418804468816814, 0.00896035350527195, 0.013379157972259727, 0.022094022339511476, 0.03436847919571015, 0.05437584386982332, 0.08322081746419427, 0.12090339999528432, 0.1660734012519946, 0.20645636429490524, 0.24573462621352418, 0.2824352522419174, 0.3161900085774875, 0.35043574320738835, 0.38345403214810275, 0.4121762612260484, 0.43795262060385476, 0.4605376212541583, 0.47723088257734475, 0.4858230023211726, 0.4898735731017067, 0.49183748619855217, 0.4920829753210256, 0.49269669811257677, 0.4929421872972374, 0.4929421872972374, 0.4931876764709238, 0.4931876764892142, 0.4931876764709238, 0.4931876763867881, 0.4931876764709238, 0.49318767645263345, 0.49318767643800115, 0.49318767642336886, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764709238, 0.4931876764709238, 0.4931876763867881, 0.49318767645263345, 0.4931876764343431, 0.4931876764709238, 0.49318767645263345, 0.49318767643800115, 0.49318767646726575, 0.4931876764343431, 0.4931876764343431, 0.49318767651116263, 0.4931876764745819, 0.49318767645263345, 0.49318767645263345, 0.4931876764709238, 0.4931876764709238, 0.4931876764709238, 0.49318767646726575, 0.4931876764343431, 0.49318767651116263, 0.4931876764709238, 0.4931876764343431, 0.4931876764709238, 0.4931876764745819, 0.49318767643800115, 0.4931876764709238, 0.4931876763867881, 0.4931876764892142, 0.4931876764160527, 0.4931876764892142, 0.49318767645263345, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.49318767645263345, 0.49318767643800115, 0.4931876764343431, 0.49318767646726575, 0.4931876764709238, 0.4931876764709238, 0.4931876764709238, 0.49318767643800115, 0.4931876764343431, 0.49318767643800115, 0.4931876764709238, 0.4931876764892142], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.001470047776552738, 0.002940095553105476, 0.004777655273796398, 0.008820286659316428, 0.015803013597941933, 0.027563395810363836, 0.04152884968761485, 0.06688717383314957, 0.11356119073869901, 0.15361999264976112, 0.18853362734288864, 0.22675486953325982, 0.2752664461595002, 0.30687247335538403, 0.3432561558250643, 0.37596471885336274, 0.4005880191106211, 0.43329658213891953, 0.45350973906651965, 0.47739801543550164, 0.48695332598309443, 0.4902609334803381, 0.49099595736861446, 0.4924660051451672, 0.4928335170893054, 0.4928335170893054, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'loss': [0.00010687874981354338, 0.00010684011542796066, 0.00010679876839712229, 0.00010675501355659185, 0.00010670986429981679, 0.00010666416653121901, 0.00010661817586134288, 0.00010657194902961872, 0.00010652550151498327, 0.00010647899895599142, 0.00010643240055119483, 0.000106385806329605, 0.00010633925494837491, 0.00010629277422440058, 0.00010624630922853346, 0.00010619989337373567, 0.00010615350412213236, 0.0001061071501768298, 0.00010606089275428987, 0.0001060146593798303, 0.00010596848389330746, 0.0001059223868508422, 0.00010587633973536044, 0.00010583036218310617, 0.0001057844393688804, 0.00010573858392446715, 0.0001056927766003279, 0.00010564706468348899, 0.00010560139075309678, 0.00010555583319515835, 0.00010551031208041697, 0.00010546488604164167, 0.00010541951506329829, 0.0001053742294137992, 0.00010532901602821445, 0.00010528389195462987, 0.00010523885260705767, 0.00010519388236277457, 0.00010514900206458148, 0.00010510420533228427, 0.00010505946378634388, 0.00010501483528879758, 0.00010497029253180742, 0.00010492583743550457, 0.00010488144302963693, 0.00010483716093179652, 0.00010479293408640115, 0.00010474879914384342, 0.00010470475908881099, 0.00010466077715927573, 0.00010461687507326109, 0.00010457307925177238, 0.0001045294037707109, 0.00010448578071012422, 0.00010444224941841253, 0.00010439877201094077, 0.00010435536922780512, 0.0001043120932269136, 0.00010426888894247578, 0.00010422575586989906, 0.00010418272206274677, 0.00010413974762605111, 0.00010409688662445505, 0.00010405410155734975, 0.0001040113975983724, 0.00010396873146240733, 0.00010392617424342849, 0.00010388370407783966, 0.00010384130409527884, 0.00010379900060779501, 0.00010375677753987117, 0.00010371462512384459, 0.00010367258065134236, 0.00010363060667534072, 0.00010358869341388756, 0.00010354686735229024, 0.00010350513748480051, 0.00010346346905615062, 0.00010342186724533629, 0.00010338036633786296, 0.00010333895015818819, 0.00010329758920148667, 0.00010325633022518578, 0.00010321514736735101, 0.00010317405392511417, 0.00010313302783482817, 0.00010309206867585031, 0.00010305118897547376, 0.00010301039871212917, 0.00010296968069394417, 0.00010292905733018947, 0.00010288848845439967, 0.0001028480349258029, 0.00010280764340494066, 0.00010276730397500509, 0.00010272705850825261, 0.00010268689030311412, 0.00010264677786126487, 0.00010260676082939521, 0.000102566792971639, 0.0001025269150537212]}
[2018-06-04 07:34:13,923 AE_BIGRAMA_2L_FULLDS_OVER_05.py:129]: evaluating model ... 
[2018-06-04 07:35:04,331 AE_BIGRAMA_2L_FULLDS_OVER_05.py:133]: evaluated! 
[2018-06-04 07:35:04,333 AE_BIGRAMA_2L_FULLDS_OVER_05.py:135]: generating reports ... 
[2018-06-04 07:35:06,105 AE_BIGRAMA_2L_FULLDS_OVER_05.py:138]: done!
[2018-06-04 07:35:06,105 AE_BIGRAMA_2L_FULLDS_OVER_05.py:154]: >> experiment AE_BIGRAMA_2L_FULLDS_OVER_05 finished!
