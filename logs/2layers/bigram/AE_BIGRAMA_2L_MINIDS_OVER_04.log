[2018-05-28 01:22:51,167 AE_BIGRAMA_2L_MINIDS_OVER_04.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_04
[2018-05-28 01:22:51,167 AE_BIGRAMA_2L_MINIDS_OVER_04.py:146]: >> Printing header log
[2018-05-28 01:22:51,167 AE_BIGRAMA_2L_MINIDS_OVER_04.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_04
	layers = 9216,16589,14931
	using GLOBAL obj = 
		{'data_dir': '/home/dhiego/malware_dataset/', 'epochs': 200, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'shuffle_batches': True, 'numpy_seed': 666, 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x7f5bfd8dd898>, 'hidden_layer_activation': 'relu', 'loss_function': 'mse', 'output_layer_activation': 'relu', 'discard_decoder_function': True}, 'mlp_configs': {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x7f5bfd8dd908>, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'use_last_dim_as_classifier': False}, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'batch': 32, 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'store_history': True, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/'}
	=======================================
	
[2018-05-28 01:22:51,168 AE_BIGRAMA_2L_MINIDS_OVER_04.py:148]: >> Loading dataset... 
[2018-05-28 01:23:09,263 AE_BIGRAMA_2L_MINIDS_OVER_04.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:23:09,263 AE_BIGRAMA_2L_MINIDS_OVER_04.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:23:09,263 AE_BIGRAMA_2L_MINIDS_OVER_04.py:57]: =======================================
[2018-05-28 01:23:09,264 AE_BIGRAMA_2L_MINIDS_OVER_04.py:62]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7f5bfd8dd898>, 'hidden_layer_activation': 'relu', 'loss_function': 'mse', 'output_layer_activation': 'relu', 'discard_decoder_function': True}
[2018-05-28 01:23:09,338 AE_BIGRAMA_2L_MINIDS_OVER_04.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:03,967 AE_BIGRAMA_2L_MINIDS_OVER_04.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_04
[2018-05-28 01:27:03,967 AE_BIGRAMA_2L_MINIDS_OVER_04.py:146]: >> Printing header log
[2018-05-28 01:27:03,968 AE_BIGRAMA_2L_MINIDS_OVER_04.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_04
	layers = 9216,16589,14931
	using GLOBAL obj = 
		{'data_dir': '/home/dhiego/malware_dataset/', 'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'epochs': 200, 'numpy_seed': 666, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'store_history': True, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'batch': 32, 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x7fa3fd359898>, 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa3fd359908>, 'classifier_dim': 9, 'use_last_dim_as_classifier': False}, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/'}
	=======================================
	
[2018-05-28 01:27:03,968 AE_BIGRAMA_2L_MINIDS_OVER_04.py:148]: >> Loading dataset... 
[2018-05-28 01:27:21,855 AE_BIGRAMA_2L_MINIDS_OVER_04.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:27:21,855 AE_BIGRAMA_2L_MINIDS_OVER_04.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:27:21,855 AE_BIGRAMA_2L_MINIDS_OVER_04.py:57]: =======================================
[2018-05-28 01:27:21,855 AE_BIGRAMA_2L_MINIDS_OVER_04.py:62]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'discard_decoder_function': True, 'optimizer': <keras.optimizers.SGD object at 0x7fa3fd359898>, 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}
[2018-05-28 01:27:21,926 AE_BIGRAMA_2L_MINIDS_OVER_04.py:73]: training and evaluate autoencoder
[2018-05-28 18:29:53,633 AE_BIGRAMA_2L_MINIDS_OVER_04.py:85]: trained and evaluated!
[2018-05-28 18:29:53,634 AE_BIGRAMA_2L_MINIDS_OVER_04.py:88]: Training history: 
{'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.00010709192938699344, 0.00010708848476631302, 0.00010708499069772409, 0.00010708144047733451, 0.00010707781824820471, 0.00010707406083285507, 0.00010707026172823476, 0.0001070663048765629, 0.00010706220756494269, 0.00010705799673408206, 0.00010705368405769187, 0.00010704927770558205, 0.00010704474424767704, 0.00010704008368397685, 0.0001070353456232834, 0.00010703050276734787, 0.00010702551866487396, 0.00010702046582515921, 0.00010701524059709244, 0.00010700989237495101, 0.00010700435742706687, 0.00010699875701344125, 0.00010699306496207921, 0.00010698726305627111, 0.00010698137099652137, 0.0001069754086442278, 0.00010696936030334425, 0.00010696317178854509, 0.00010695688518239597, 0.00010695056437745837, 0.00010694417072355939, 0.00010693770579387908, 0.00010693123848655167, 0.00010692469334256714, 0.00010691807520660487, 0.00010691139478701526, 0.00010690474338187088, 0.00010689800296691578, 0.00010689118514435265, 0.00010688434123917979, 0.00010687748015416598, 0.00010687064456181939, 0.0001068637318121434, 0.00010685681341332097, 0.00010684990556195552, 0.00010684292709625941, 0.00010683593636690994, 0.0001068289616017623, 0.00010682194695292562, 0.00010681489404721107, 0.00010680786125317298, 0.00010680082077200522, 0.00010679375225962974, 0.00010678668095843514, 0.00010677956748528964, 0.00010677248474278576, 0.00010676543110411234, 0.0001067583217963185, 0.00010675122189185071, 0.00010674408741317648, 0.00010673696485849176, 0.00010672985204679694, 0.00010672270113911768, 0.00010671554613759494, 0.00010670838729250737, 0.00010670119188886127, 0.00010669404798898393, 0.00010668692477284851, 0.00010667974245519989, 0.00010667255270070023, 0.00010666537553164079, 0.00010665819149779576, 0.00010665101425722814, 0.00010664384150379898, 0.0001066366460286447, 0.00010662943600157519, 0.0001066222629263592, 0.00010661508740198796, 0.00010660790803405188, 0.0001066006599109979, 0.00010659349378995272, 0.00010658629227235698, 0.00010657911740943643, 0.00010657192626052722, 0.00010656477958970779, 0.00010655760317148425, 0.00010655040973431318, 0.00010654321263234774, 0.00010653605738054636, 0.00010652888830978862, 0.00010652175038084457, 0.00010651455106212545, 0.00010650742042701604, 0.00010650025822104387, 0.00010649307844193574, 0.00010648591788065178, 0.00010647874448364898, 0.00010647154999173222, 0.00010646439064608735, 0.00010645723310602412, 0.00010645009780500578], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00010747609404825791, 0.00010747254729147314, 0.00010746893128274002, 0.00010746527522068975, 0.00010746153101764153, 0.00010745771016818638, 0.00010745375801969156, 0.0001074497450091148, 0.00010744554746887686, 0.00010744120701650728, 0.00010743679456296756, 0.00010743226567040582, 0.00010742755997444409, 0.00010742271904521152, 0.00010741772067563225, 0.000107412625822589, 0.00010740743107325474, 0.00010740214870432664, 0.0001073967661310051, 0.00010739123611881607, 0.00010738559997718666, 0.00010737984597452397, 0.00010737401494625137, 0.00010736809608508326, 0.00010736208806380914, 0.00010735595891087587, 0.00010734978273677023, 0.00010734348095166997, 0.00010733707659215748, 0.00010733058572696001, 0.00010732408400707657, 0.00010731756017491804, 0.00010731094924456983, 0.00010730435990509259, 0.0001072976776371795, 0.00010729095356213535, 0.00010728416139645204, 0.00010727734380046737, 0.00010727045292350242, 0.00010726346876259881, 0.00010725643703541855, 0.00010724940395732759, 0.00010724238889137926, 0.0001072353112332353, 0.00010722822447421927, 0.00010722114164943439, 0.00010721399585325089, 0.00010720684316031277, 0.00010719971447566475, 0.00010719253542811795, 0.00010718532753744275, 0.00010717814474526629, 0.00010717093754189653, 0.00010716370955346219, 0.0001071564764694875, 0.00010714920008526994, 0.0001071419619057549, 0.00010713474716572546, 0.00010712747545044486, 0.00010712020797749787, 0.000107112896445902, 0.00010710559991652492, 0.0001070983113267107, 0.0001070909983257032, 0.00010708368371308293, 0.000107076373437597, 0.00010706903429528249, 0.00010706175042180562, 0.00010705446422571037, 0.00010704712536779811, 0.00010703977859402319, 0.00010703244760457323, 0.00010702509902958404, 0.00010701776180698473, 0.0001070104297984267, 0.00010700307439778346, 0.00010699570311801447, 0.00010698836838393487, 0.00010698102241596631, 0.00010697368218344318, 0.00010696626935724521, 0.00010695893464686579, 0.00010695156829673584, 0.00010694422782721083, 0.00010693687242656759, 0.0001069295664645158, 0.00010692221743922304, 0.00010691486192007886, 0.00010690749857987274, 0.00010690017562478641, 0.00010689284198091544, 0.0001068855434607226, 0.00010687817578338214, 0.00010687087816379643, 0.00010686355046867257, 0.00010685620495100758, 0.00010684887927039966, 0.00010684154200039998, 0.000106834179560801, 0.00010682685525480397, 0.00010681953270262083]}
[2018-05-28 18:29:53,634 AE_BIGRAMA_2L_MINIDS_OVER_04.py:92]: done!
[2018-05-28 18:29:53,634 AE_BIGRAMA_2L_MINIDS_OVER_04.py:152]: >> Executing classifier part ... 
[2018-05-28 18:29:53,634 AE_BIGRAMA_2L_MINIDS_OVER_04.py:97]: =======================================
[2018-05-28 18:29:53,634 AE_BIGRAMA_2L_MINIDS_OVER_04.py:101]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa3fd359908>, 'classifier_dim': 9, 'use_last_dim_as_classifier': False}
[2018-05-28 18:29:53,910 AE_BIGRAMA_2L_MINIDS_OVER_04.py:110]: training ... 
[2018-05-29 08:51:02,858 AE_BIGRAMA_2L_MINIDS_OVER_04.py:122]: trained!
[2018-05-29 08:51:02,860 AE_BIGRAMA_2L_MINIDS_OVER_04.py:125]: Training history: 
{'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.00010709192938699344, 0.00010708848476631302, 0.00010708499069772409, 0.00010708144047733451, 0.00010707781824820471, 0.00010707406083285507, 0.00010707026172823476, 0.0001070663048765629, 0.00010706220756494269, 0.00010705799673408206, 0.00010705368405769187, 0.00010704927770558205, 0.00010704474424767704, 0.00010704008368397685, 0.0001070353456232834, 0.00010703050276734787, 0.00010702551866487396, 0.00010702046582515921, 0.00010701524059709244, 0.00010700989237495101, 0.00010700435742706687, 0.00010699875701344125, 0.00010699306496207921, 0.00010698726305627111, 0.00010698137099652137, 0.0001069754086442278, 0.00010696936030334425, 0.00010696317178854509, 0.00010695688518239597, 0.00010695056437745837, 0.00010694417072355939, 0.00010693770579387908, 0.00010693123848655167, 0.00010692469334256714, 0.00010691807520660487, 0.00010691139478701526, 0.00010690474338187088, 0.00010689800296691578, 0.00010689118514435265, 0.00010688434123917979, 0.00010687748015416598, 0.00010687064456181939, 0.0001068637318121434, 0.00010685681341332097, 0.00010684990556195552, 0.00010684292709625941, 0.00010683593636690994, 0.0001068289616017623, 0.00010682194695292562, 0.00010681489404721107, 0.00010680786125317298, 0.00010680082077200522, 0.00010679375225962974, 0.00010678668095843514, 0.00010677956748528964, 0.00010677248474278576, 0.00010676543110411234, 0.0001067583217963185, 0.00010675122189185071, 0.00010674408741317648, 0.00010673696485849176, 0.00010672985204679694, 0.00010672270113911768, 0.00010671554613759494, 0.00010670838729250737, 0.00010670119188886127, 0.00010669404798898393, 0.00010668692477284851, 0.00010667974245519989, 0.00010667255270070023, 0.00010666537553164079, 0.00010665819149779576, 0.00010665101425722814, 0.00010664384150379898, 0.0001066366460286447, 0.00010662943600157519, 0.0001066222629263592, 0.00010661508740198796, 0.00010660790803405188, 0.0001066006599109979, 0.00010659349378995272, 0.00010658629227235698, 0.00010657911740943643, 0.00010657192626052722, 0.00010656477958970779, 0.00010655760317148425, 0.00010655040973431318, 0.00010654321263234774, 0.00010653605738054636, 0.00010652888830978862, 0.00010652175038084457, 0.00010651455106212545, 0.00010650742042701604, 0.00010650025822104387, 0.00010649307844193574, 0.00010648591788065178, 0.00010647874448364898, 0.00010647154999173222, 0.00010646439064608735, 0.00010645723310602412, 0.00010645009780500578], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'loss': [0.00010747609404825791, 0.00010747254729147314, 0.00010746893128274002, 0.00010746527522068975, 0.00010746153101764153, 0.00010745771016818638, 0.00010745375801969156, 0.0001074497450091148, 0.00010744554746887686, 0.00010744120701650728, 0.00010743679456296756, 0.00010743226567040582, 0.00010742755997444409, 0.00010742271904521152, 0.00010741772067563225, 0.000107412625822589, 0.00010740743107325474, 0.00010740214870432664, 0.0001073967661310051, 0.00010739123611881607, 0.00010738559997718666, 0.00010737984597452397, 0.00010737401494625137, 0.00010736809608508326, 0.00010736208806380914, 0.00010735595891087587, 0.00010734978273677023, 0.00010734348095166997, 0.00010733707659215748, 0.00010733058572696001, 0.00010732408400707657, 0.00010731756017491804, 0.00010731094924456983, 0.00010730435990509259, 0.0001072976776371795, 0.00010729095356213535, 0.00010728416139645204, 0.00010727734380046737, 0.00010727045292350242, 0.00010726346876259881, 0.00010725643703541855, 0.00010724940395732759, 0.00010724238889137926, 0.0001072353112332353, 0.00010722822447421927, 0.00010722114164943439, 0.00010721399585325089, 0.00010720684316031277, 0.00010719971447566475, 0.00010719253542811795, 0.00010718532753744275, 0.00010717814474526629, 0.00010717093754189653, 0.00010716370955346219, 0.0001071564764694875, 0.00010714920008526994, 0.0001071419619057549, 0.00010713474716572546, 0.00010712747545044486, 0.00010712020797749787, 0.000107112896445902, 0.00010710559991652492, 0.0001070983113267107, 0.0001070909983257032, 0.00010708368371308293, 0.000107076373437597, 0.00010706903429528249, 0.00010706175042180562, 0.00010705446422571037, 0.00010704712536779811, 0.00010703977859402319, 0.00010703244760457323, 0.00010702509902958404, 0.00010701776180698473, 0.0001070104297984267, 0.00010700307439778346, 0.00010699570311801447, 0.00010698836838393487, 0.00010698102241596631, 0.00010697368218344318, 0.00010696626935724521, 0.00010695893464686579, 0.00010695156829673584, 0.00010694422782721083, 0.00010693687242656759, 0.0001069295664645158, 0.00010692221743922304, 0.00010691486192007886, 0.00010690749857987274, 0.00010690017562478641, 0.00010689284198091544, 0.0001068855434607226, 0.00010687817578338214, 0.00010687087816379643, 0.00010686355046867257, 0.00010685620495100758, 0.00010684887927039966, 0.00010684154200039998, 0.000106834179560801, 0.00010682685525480397, 0.00010681953270262083]}
[2018-05-29 08:51:02,860 AE_BIGRAMA_2L_MINIDS_OVER_04.py:129]: evaluating model ... 
[2018-05-29 08:51:23,661 AE_BIGRAMA_2L_MINIDS_OVER_04.py:133]: evaluated! 
[2018-05-29 08:51:23,662 AE_BIGRAMA_2L_MINIDS_OVER_04.py:135]: generating reports ... 
[2018-05-29 08:51:26,528 AE_BIGRAMA_2L_MINIDS_OVER_04.py:138]: done!
[2018-05-29 08:51:26,529 AE_BIGRAMA_2L_MINIDS_OVER_04.py:154]: >> experiment AE_BIGRAMA_2L_MINIDS_OVER_04 finished!
