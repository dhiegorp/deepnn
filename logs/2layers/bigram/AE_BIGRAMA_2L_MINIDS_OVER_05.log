[2018-05-28 01:22:51,101 AE_BIGRAMA_2L_MINIDS_OVER_05.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_05
[2018-05-28 01:22:51,101 AE_BIGRAMA_2L_MINIDS_OVER_05.py:146]: >> Printing header log
[2018-05-28 01:22:51,101 AE_BIGRAMA_2L_MINIDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_05
	layers = 9216,18432,16590
	using GLOBAL obj = 
		{'batch': 32, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x7faedc9ef8d0>, 'discard_decoder_function': True, 'loss_function': 'mse', 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu'}, 'mlp_configs': {'optimizer': <keras.optimizers.SGD object at 0x7faedc9ef940>, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9, 'activation': 'sigmoid'}, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'shuffle_batches': True, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'store_history': True, 'numpy_seed': 666, 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/'}
	=======================================
	
[2018-05-28 01:22:51,101 AE_BIGRAMA_2L_MINIDS_OVER_05.py:148]: >> Loading dataset... 
[2018-05-28 01:23:09,046 AE_BIGRAMA_2L_MINIDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:23:09,046 AE_BIGRAMA_2L_MINIDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:23:09,046 AE_BIGRAMA_2L_MINIDS_OVER_05.py:57]: =======================================
[2018-05-28 01:23:09,046 AE_BIGRAMA_2L_MINIDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7faedc9ef8d0>, 'discard_decoder_function': True, 'loss_function': 'mse', 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu'}
[2018-05-28 01:23:09,117 AE_BIGRAMA_2L_MINIDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:03,978 AE_BIGRAMA_2L_MINIDS_OVER_05.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_05
[2018-05-28 01:27:03,978 AE_BIGRAMA_2L_MINIDS_OVER_05.py:146]: >> Printing header log
[2018-05-28 01:27:03,978 AE_BIGRAMA_2L_MINIDS_OVER_05.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_05
	layers = 9216,18432,16590
	using GLOBAL obj = 
		{'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'numpy_seed': 666, 'epochs': 200, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'mlp_configs': {'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x7f75fa556908>}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'shuffle_batches': True, 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x7f75fa556898>, 'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}, 'data_dir': '/home/dhiego/malware_dataset/', 'store_history': True, 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'batch': 32, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/'}
	=======================================
	
[2018-05-28 01:27:03,978 AE_BIGRAMA_2L_MINIDS_OVER_05.py:148]: >> Loading dataset... 
[2018-05-28 01:27:21,851 AE_BIGRAMA_2L_MINIDS_OVER_05.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:27:21,852 AE_BIGRAMA_2L_MINIDS_OVER_05.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:27:21,852 AE_BIGRAMA_2L_MINIDS_OVER_05.py:57]: =======================================
[2018-05-28 01:27:21,852 AE_BIGRAMA_2L_MINIDS_OVER_05.py:62]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7f75fa556898>, 'discard_decoder_function': True, 'loss_function': 'mse', 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu'}
[2018-05-28 01:27:21,922 AE_BIGRAMA_2L_MINIDS_OVER_05.py:73]: training and evaluate autoencoder
[2018-05-28 20:34:31,720 AE_BIGRAMA_2L_MINIDS_OVER_05.py:85]: trained and evaluated!
[2018-05-28 20:34:31,723 AE_BIGRAMA_2L_MINIDS_OVER_05.py:88]: Training history: 
{'loss': [0.00010773413780476013, 0.00010773285571940802, 0.00010773156849111519, 0.00010773027524297468, 0.00010772898178153249, 0.00010772767978802274, 0.00010772637985642933, 0.00010772507482929555, 0.00010772375352013286, 0.00010772244489057056, 0.00010772112867694821, 0.00010771980544807032, 0.00010771847750285507, 0.00010771715813710776, 0.00010771582876988125, 0.00010771449013588136, 0.00010771316105305711, 0.00010771182931581185, 0.00010771049523224799, 0.00010770915930006951, 0.00010770781094899268, 0.00010770645501385579, 0.00010770509988452529, 0.00010770374053656139, 0.00010770237450514455, 0.00010770099823524666, 0.00010769962139654425, 0.00010769823742408535, 0.00010769684707627598, 0.00010769545113522232, 0.00010769406040820994, 0.00010769265927681517, 0.00010769126378606508, 0.00010768985549721363, 0.00010768845235130292, 0.00010768704953719482, 0.00010768563098616212, 0.00010768419657970387, 0.00010768276293165163, 0.00010768130897253855, 0.00010767985638803636, 0.00010767838861171386, 0.00010767691493404465, 0.00010767544436110001, 0.00010767396129815648, 0.00010767248207464334, 0.00010767100003080788, 0.00010766951964598556, 0.00010766802762437108, 0.00010766653501025192, 0.00010766503699248997, 0.0001076635257263231, 0.00010766201668797388, 0.0001076604941405177, 0.00010765898069393356, 0.00010765745610826124, 0.00010765591355784665, 0.00010765437340115103, 0.00010765282186836532, 0.00010765126182721224, 0.0001076496972830235, 0.00010764813901938449, 0.00010764655857236983, 0.00010764496774467297, 0.00010764336610969052, 0.00010764177258017228, 0.00010764016378773315, 0.00010763855132176495, 0.00010763692785890967, 0.00010763530138613055, 0.00010763366197304897, 0.00010763202263106795, 0.00010763037923635484, 0.00010762873010619632, 0.00010762706554721561, 0.0001076253819806844, 0.00010762369777424813, 0.00010762199152663733, 0.00010762027786086778, 0.00010761855300860965, 0.0001076168324223853, 0.00010761509877735756, 0.00010761336849775645, 0.00010761163229310843, 0.00010760986985235266, 0.00010760810321666367, 0.00010760632992122195, 0.00010760455330775395, 0.00010760274868066414, 0.0001076009129589281, 0.00010759907534117705, 0.00010759723748642411, 0.00010759538811337998, 0.00010759352023048927, 0.00010759162513978313, 0.00010758973206359292, 0.00010758781817863796, 0.00010758589268059102, 0.000107583944691066, 0.00010758199208000438, 0.0001075800149866489], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.0001073209470891936, 0.0001073196816446342, 0.00010731841391181294, 0.00010731715304377724, 0.00010731588400593165, 0.00010731461192898827, 0.0001073133362587587, 0.00010731204710923666, 0.00010731076793510613, 0.0001073094808235673, 0.00010730819069080773, 0.00010730688804411615, 0.00010730559708901249, 0.00010730429664119753, 0.00010730299040121976, 0.00010730169045396209, 0.00010730039131117147, 0.0001072990890577749, 0.00010729778253176439, 0.00010729646865828809, 0.00010729514758036237, 0.00010729382716388732, 0.00010729250020441355, 0.00010729117299466113, 0.00010728983818716427, 0.00010728850436290492, 0.00010728715932973791, 0.00010728581086417812, 0.00010728445953829099, 0.00010728310862357594, 0.00010728174961055915, 0.00010728039444110721, 0.0001072790216985193, 0.0001072776593961261, 0.00010727629906020793, 0.00010727492751538209, 0.00010727354469014039, 0.00010727216667382399, 0.00010727076509556131, 0.0001072693685049944, 0.00010726795058711192, 0.00010726652676980434, 0.00010726510958488074, 0.00010726367604246029, 0.0001072622457715392, 0.00010726080895761938, 0.00010725937402078937, 0.00010725793370296859, 0.00010725648462539539, 0.000107255031954536, 0.0001072535682535394, 0.00010725210977264014, 0.00010725063756216977, 0.00010724917132263266, 0.00010724770327751394, 0.00010724621937545565, 0.00010724474167673224, 0.00010724325343055184, 0.00010724175774752041, 0.00010724025201758928, 0.00010723874946977229, 0.00010723723621360491, 0.00010723571101557098, 0.00010723418549575021, 0.00010723265677593827, 0.00010723111727626775, 0.00010722957965368703, 0.00010722802256300349, 0.0001072264609851815, 0.00010722488085098601, 0.00010722330742068269, 0.00010722173218479773, 0.00010722015564388845, 0.00010721857214880837, 0.00010721697664035356, 0.00010721537662688323, 0.00010721375299783548, 0.00010721210770180829, 0.00010721043837903164, 0.00010720877264954117, 0.00010720708444860423, 0.00010720540066329757, 0.00010720371475062248, 0.00010720201353519625, 0.00010720030357789464, 0.00010719858234017716, 0.00010719685489912483, 0.00010719509442129197, 0.00010719330975581624, 0.00010719152319537366, 0.00010718973059248962, 0.00010718791637625728, 0.0001071860707500556, 0.00010718419323120431, 0.00010718233223074329, 0.00010718043990969813, 0.0001071785299261318, 0.0001071766071783548, 0.00010717468108757025, 0.0001071727404448705, 0.0001071707684100784], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-05-28 20:34:31,723 AE_BIGRAMA_2L_MINIDS_OVER_05.py:92]: done!
[2018-05-28 20:34:31,723 AE_BIGRAMA_2L_MINIDS_OVER_05.py:152]: >> Executing classifier part ... 
[2018-05-28 20:34:31,723 AE_BIGRAMA_2L_MINIDS_OVER_05.py:97]: =======================================
[2018-05-28 20:34:31,723 AE_BIGRAMA_2L_MINIDS_OVER_05.py:101]: setting configurations for classifier: 
	 {'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x7f75fa556908>}
[2018-05-28 20:34:31,937 AE_BIGRAMA_2L_MINIDS_OVER_05.py:110]: training ... 
[2018-05-29 12:04:31,983 AE_BIGRAMA_2L_MINIDS_OVER_05.py:122]: trained!
[2018-05-29 12:04:31,985 AE_BIGRAMA_2L_MINIDS_OVER_05.py:125]: Training history: 
{'loss': [0.00010773413780476013, 0.00010773285571940802, 0.00010773156849111519, 0.00010773027524297468, 0.00010772898178153249, 0.00010772767978802274, 0.00010772637985642933, 0.00010772507482929555, 0.00010772375352013286, 0.00010772244489057056, 0.00010772112867694821, 0.00010771980544807032, 0.00010771847750285507, 0.00010771715813710776, 0.00010771582876988125, 0.00010771449013588136, 0.00010771316105305711, 0.00010771182931581185, 0.00010771049523224799, 0.00010770915930006951, 0.00010770781094899268, 0.00010770645501385579, 0.00010770509988452529, 0.00010770374053656139, 0.00010770237450514455, 0.00010770099823524666, 0.00010769962139654425, 0.00010769823742408535, 0.00010769684707627598, 0.00010769545113522232, 0.00010769406040820994, 0.00010769265927681517, 0.00010769126378606508, 0.00010768985549721363, 0.00010768845235130292, 0.00010768704953719482, 0.00010768563098616212, 0.00010768419657970387, 0.00010768276293165163, 0.00010768130897253855, 0.00010767985638803636, 0.00010767838861171386, 0.00010767691493404465, 0.00010767544436110001, 0.00010767396129815648, 0.00010767248207464334, 0.00010767100003080788, 0.00010766951964598556, 0.00010766802762437108, 0.00010766653501025192, 0.00010766503699248997, 0.0001076635257263231, 0.00010766201668797388, 0.0001076604941405177, 0.00010765898069393356, 0.00010765745610826124, 0.00010765591355784665, 0.00010765437340115103, 0.00010765282186836532, 0.00010765126182721224, 0.0001076496972830235, 0.00010764813901938449, 0.00010764655857236983, 0.00010764496774467297, 0.00010764336610969052, 0.00010764177258017228, 0.00010764016378773315, 0.00010763855132176495, 0.00010763692785890967, 0.00010763530138613055, 0.00010763366197304897, 0.00010763202263106795, 0.00010763037923635484, 0.00010762873010619632, 0.00010762706554721561, 0.0001076253819806844, 0.00010762369777424813, 0.00010762199152663733, 0.00010762027786086778, 0.00010761855300860965, 0.0001076168324223853, 0.00010761509877735756, 0.00010761336849775645, 0.00010761163229310843, 0.00010760986985235266, 0.00010760810321666367, 0.00010760632992122195, 0.00010760455330775395, 0.00010760274868066414, 0.0001076009129589281, 0.00010759907534117705, 0.00010759723748642411, 0.00010759538811337998, 0.00010759352023048927, 0.00010759162513978313, 0.00010758973206359292, 0.00010758781817863796, 0.00010758589268059102, 0.000107583944691066, 0.00010758199208000438, 0.0001075800149866489], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.0001073209470891936, 0.0001073196816446342, 0.00010731841391181294, 0.00010731715304377724, 0.00010731588400593165, 0.00010731461192898827, 0.0001073133362587587, 0.00010731204710923666, 0.00010731076793510613, 0.0001073094808235673, 0.00010730819069080773, 0.00010730688804411615, 0.00010730559708901249, 0.00010730429664119753, 0.00010730299040121976, 0.00010730169045396209, 0.00010730039131117147, 0.0001072990890577749, 0.00010729778253176439, 0.00010729646865828809, 0.00010729514758036237, 0.00010729382716388732, 0.00010729250020441355, 0.00010729117299466113, 0.00010728983818716427, 0.00010728850436290492, 0.00010728715932973791, 0.00010728581086417812, 0.00010728445953829099, 0.00010728310862357594, 0.00010728174961055915, 0.00010728039444110721, 0.0001072790216985193, 0.0001072776593961261, 0.00010727629906020793, 0.00010727492751538209, 0.00010727354469014039, 0.00010727216667382399, 0.00010727076509556131, 0.0001072693685049944, 0.00010726795058711192, 0.00010726652676980434, 0.00010726510958488074, 0.00010726367604246029, 0.0001072622457715392, 0.00010726080895761938, 0.00010725937402078937, 0.00010725793370296859, 0.00010725648462539539, 0.000107255031954536, 0.0001072535682535394, 0.00010725210977264014, 0.00010725063756216977, 0.00010724917132263266, 0.00010724770327751394, 0.00010724621937545565, 0.00010724474167673224, 0.00010724325343055184, 0.00010724175774752041, 0.00010724025201758928, 0.00010723874946977229, 0.00010723723621360491, 0.00010723571101557098, 0.00010723418549575021, 0.00010723265677593827, 0.00010723111727626775, 0.00010722957965368703, 0.00010722802256300349, 0.0001072264609851815, 0.00010722488085098601, 0.00010722330742068269, 0.00010722173218479773, 0.00010722015564388845, 0.00010721857214880837, 0.00010721697664035356, 0.00010721537662688323, 0.00010721375299783548, 0.00010721210770180829, 0.00010721043837903164, 0.00010720877264954117, 0.00010720708444860423, 0.00010720540066329757, 0.00010720371475062248, 0.00010720201353519625, 0.00010720030357789464, 0.00010719858234017716, 0.00010719685489912483, 0.00010719509442129197, 0.00010719330975581624, 0.00010719152319537366, 0.00010718973059248962, 0.00010718791637625728, 0.0001071860707500556, 0.00010718419323120431, 0.00010718233223074329, 0.00010718043990969813, 0.0001071785299261318, 0.0001071766071783548, 0.00010717468108757025, 0.0001071727404448705, 0.0001071707684100784], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-05-29 12:04:31,985 AE_BIGRAMA_2L_MINIDS_OVER_05.py:129]: evaluating model ... 
[2018-05-29 12:04:52,703 AE_BIGRAMA_2L_MINIDS_OVER_05.py:133]: evaluated! 
[2018-05-29 12:04:52,704 AE_BIGRAMA_2L_MINIDS_OVER_05.py:135]: generating reports ... 
[2018-05-29 12:04:55,680 AE_BIGRAMA_2L_MINIDS_OVER_05.py:138]: done!
[2018-05-29 12:04:55,681 AE_BIGRAMA_2L_MINIDS_OVER_05.py:154]: >> experiment AE_BIGRAMA_2L_MINIDS_OVER_05 finished!
