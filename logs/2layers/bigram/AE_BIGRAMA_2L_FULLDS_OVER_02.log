[2018-05-28 01:22:51,008 AE_BIGRAMA_2L_FULLDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_02
[2018-05-28 01:22:51,008 AE_BIGRAMA_2L_FULLDS_OVER_02.py:146]: >> Printing header log
[2018-05-28 01:22:51,008 AE_BIGRAMA_2L_FULLDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_02
	layers = 9216,14746,13272
	using GLOBAL obj = 
		{'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'mlp_configs': {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x7f43dc2df898>, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'store_history': True, 'epochs': 1000, 'shuffle_batches': True, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'batch': 32, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f43dc2df828>, 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'numpy_seed': 666, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'data_dir': '/home/dhiego/malware_dataset/'}
	=======================================
	
[2018-05-28 01:22:51,009 AE_BIGRAMA_2L_FULLDS_OVER_02.py:148]: >> Loading dataset... 
[2018-05-28 01:24:40,011 AE_BIGRAMA_2L_FULLDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:24:40,012 AE_BIGRAMA_2L_FULLDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:24:40,012 AE_BIGRAMA_2L_FULLDS_OVER_02.py:57]: =======================================
[2018-05-28 01:24:40,012 AE_BIGRAMA_2L_FULLDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f43dc2df828>, 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2018-05-28 01:24:40,076 AE_BIGRAMA_2L_FULLDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:03,950 AE_BIGRAMA_2L_FULLDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_FULLDS_OVER_02
[2018-05-28 01:27:03,950 AE_BIGRAMA_2L_FULLDS_OVER_02.py:146]: >> Printing header log
[2018-05-28 01:27:03,951 AE_BIGRAMA_2L_FULLDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_FULLDS_OVER_02
	layers = 9216,14746,13272
	using GLOBAL obj = 
		{'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'shuffle_batches': True, 'mlp_configs': {'optimizer': <keras.optimizers.SGD object at 0x7f1b8d618908>, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'classifier_dim': 9, 'use_last_dim_as_classifier': False}, 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'numpy_seed': 666, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'epochs': 1000, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'data_dir': '/home/dhiego/malware_dataset/', 'store_history': True, 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x7f1b8d618898>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'batch': 32, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/'}
	=======================================
	
[2018-05-28 01:27:03,951 AE_BIGRAMA_2L_FULLDS_OVER_02.py:148]: >> Loading dataset... 
[2018-05-28 01:33:30,894 AE_BIGRAMA_2L_FULLDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (8147, 9216)
	trainy shape = (8147, 9)
	valx shape = (2721, 9216)
	valy shape = (2721, 9)
	=======================================
	
[2018-05-28 01:33:30,895 AE_BIGRAMA_2L_FULLDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:33:30,895 AE_BIGRAMA_2L_FULLDS_OVER_02.py:57]: =======================================
[2018-05-28 01:33:30,895 AE_BIGRAMA_2L_FULLDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7f1b8d618898>, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2018-05-28 01:33:31,158 AE_BIGRAMA_2L_FULLDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-05-30 13:35:25,680 AE_BIGRAMA_2L_FULLDS_OVER_02.py:85]: trained and evaluated!
[2018-05-30 13:35:25,685 AE_BIGRAMA_2L_FULLDS_OVER_02.py:88]: Training history: 
{'val_loss': [0.00010730979283667915, 0.00010730007588753846, 0.00010729024530671132, 0.000107280305672088, 0.00010727021117535178, 0.00010725998420324173, 0.00010724953909679934, 0.00010723884694204822, 0.00010722781558755463, 0.00010721639635045036, 0.0001072044376309041, 0.00010719184674268184, 0.00010717845319948087, 0.0001071639661073927, 0.00010714792324924373, 0.00010712989124429071, 0.000107108958905189, 0.00010708369383627709, 0.00010705374126710276, 0.00010702037354632603, 0.00010698420923463014, 0.00010694602920725299, 0.00010690608978593991, 0.00010686421376997085, 0.00010682087659143399, 0.000106776611077182, 0.0001067317746315584, 0.00010668668801171855, 0.00010664149795883332, 0.00010659629318824477, 0.00010655110444829419, 0.00010650591075074514, 0.00010646074502859799, 0.00010641561896723854, 0.00010637055365384127, 0.00010632555811850865, 0.00010628062102882307, 0.00010623576265371458, 0.00010619095273151016, 0.00010614619267408252, 0.00010610153064286958, 0.00010605691820368525, 0.00010601237089782528, 0.0001059678883723215, 0.00010592344625632579, 0.00010587906346304955, 0.0001058347432922104, 0.00010579047107691108, 0.00010574626030214028, 0.00010570211748978724, 0.0001056580107096021, 0.0001056139678407227, 0.00010556996466471903, 0.00010552602008410645, 0.00010548211649860824, 0.00010543828465121767, 0.00010539447223846875, 0.00010535072332790336, 0.00010530704802189855, 0.00010526341523518886, 0.0001052198386934231, 0.00010517631752755084, 0.00010513284799129624, 0.00010508942526610889, 0.00010504605148316785, 0.00010500273549876551, 0.00010495947701341375, 0.00010491624925501124, 0.0001048731122174518, 0.00010483004336960023, 0.00010478702773704908, 0.00010474405466390308, 0.00010470113574998, 0.00010465827066637764, 0.00010461546253365557, 0.00010457273165015787, 0.00010453003947282941, 0.00010448740636953828, 0.00010444483882206372, 0.00010440232168753621, 0.00010435987731258482, 0.00010431748005621086, 0.00010427511929728101, 0.0001042328123446059, 0.00010419054325311559, 0.00010414832635813121, 0.00010410617651907815, 0.00010406403169645156, 0.00010402194500126585, 0.00010397993815710781, 0.00010393795205250407, 0.0001038959749432408, 0.00010385404406211249, 0.000103812140990598, 0.00010377025293894896, 0.00010372836391128944, 0.0001036865197506982, 0.00010364470243440631, 0.00010360291100244727, 0.00010356114680786576, 0.0001035193843513851], 'loss': [0.00010737613758403313, 0.00010736634273758361, 0.00010735645007607853, 0.00010734644316140866, 0.00010733631325295818, 0.00010732603537473215, 0.00010731558189827534, 0.00010730491725918564, 0.00010729398210308191, 0.00010728266122387846, 0.00010727089252899774, 0.00010725852192299915, 0.00010724539741276247, 0.000107231185761751, 0.00010721556333854943, 0.00010719817034808079, 0.00010717826380316922, 0.00010715483103733787, 0.00010712678012913182, 0.00010709472746299273, 0.00010705967537241235, 0.00010702222106016824, 0.00010698291908694292, 0.00010694197929449763, 0.00010689941096108494, 0.00010685565860690113, 0.00010681119395995502, 0.00010676640162341865, 0.00010672146061246322, 0.0001066764602346235, 0.00010663144947646522, 0.00010658645834115469, 0.0001065414719525871, 0.00010649651655940246, 0.00010645160441293092, 0.0001064067522058107, 0.00010636196570825934, 0.00010631723867761771, 0.00010627258028943372, 0.00010622797399574874, 0.00010618341763708501, 0.00010613894384049047, 0.00010609452805686446, 0.00010605017634489073, 0.00010600588170457472, 0.00010596162305912746, 0.00010591742830403637, 0.00010587329336237173, 0.0001058292036420295, 0.00010578518471915727, 0.00010574122452104175, 0.0001056972963507146, 0.00010565343730243134, 0.00010560962587340178, 0.00010556587337721758, 0.00010552216795550567, 0.00010547852754318455, 0.00010543491249535, 0.0001053913436110418, 0.00010534785249472636, 0.00010530439593541399, 0.0001052610077926089, 0.00010521767258558825, 0.00010517439913623851, 0.00010513116409844358, 0.00010508797860985749, 0.00010504485690535053, 0.00010500178931014075, 0.0001049587560852794, 0.00010491581699864564, 0.00010487295811991092, 0.00010483014754631863, 0.00010478738024712502, 0.00010474465808887627, 0.00010470199489830315, 0.0001046593922642026, 0.00010461686830904077, 0.00010457437021402731, 0.00010453193196994984, 0.00010448956859044814, 0.00010444725258102966, 0.00010440500716456484, 0.00010436281560822668, 0.00010432065077743555, 0.00010427853905658026, 0.00010423647425212136, 0.00010419445335525792, 0.00010415249962547686, 0.00010411055185078178, 0.00010406865320286665, 0.00010402682259279111, 0.00010398502715862602, 0.0001039432262954016, 0.00010390148785251664, 0.00010385977159295206, 0.00010381807309683378, 0.00010377637117395112, 0.00010373470577910852, 0.00010369306720537297, 0.00010365144591728361, 0.00010360985834133959], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.001470047776552738, 0.001470047776552738, 0.0018375597206909224, 0.0033076074972436605, 0.006982726938625505, 0.013597941933112825, 0.02352076442484381, 0.03528114663726571, 0.05769937522969496, 0.08599779492833518, 0.12274898934215361, 0.16758544652701213, 0.21168687982359427, 0.25725836089672915, 0.30025725836089673, 0.34472620360161704, 0.3939728041161338, 0.4384417493568541, 0.46343256155825063, 0.4807056229327453, 0.4884233737596472, 0.5012862918044837, 0.5273796398382947, 0.49503858875413453, 0.4954061006982727, 0.49467107680999634, 0.49503858875413453, 0.49503858875413453, 0.49430356486585814, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.0002454891371056831, 0.0003682337056585246, 0.0008592119798698908, 0.001841168528292623, 0.003682337056585246, 0.00638271756474776, 0.011783478581072787, 0.019025408125690438, 0.030931631275316066, 0.04823861544126672, 0.07671535534735499, 0.11525714987203273, 0.1626365533361731, 0.20915674479940968, 0.25371302318774924, 0.30011047010072334, 0.33963422119302866, 0.38063090707138736, 0.42334601690948587, 0.4535411807954333, 0.47403952374375785, 0.4848410457910402, 0.4941696329352109, 0.5220326500844996, 0.5156499325160938, 0.4946606112386868, 0.49466061129355793, 0.49429237760618977, 0.49441512212352956, 0.49416963300105615, 0.494046888366658, 0.4940468884507937, 0.4939241438785828, 0.49392414382736977, 0.49380139933197836, 0.4935559101436597, 0.49343316560802947, 0.49331042103947664, 0.49331042103947664, 0.4931876764709238, 0.49318767643800115, 0.4931876764343431, 0.4931876763867881, 0.49318767645263345, 0.4931876763867881, 0.4931876764892142, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.4931876764745819, 0.4931876763867881, 0.49318767646726575, 0.49318767645263345, 0.4931876763867881, 0.4931876764343431, 0.49318767645263345, 0.4931876764892142, 0.49318767642336886, 0.4931876764709238, 0.4931876764745819, 0.4931876764892142, 0.4931876764892142, 0.4931876764709238]}
[2018-05-30 13:35:25,686 AE_BIGRAMA_2L_FULLDS_OVER_02.py:92]: done!
[2018-05-30 13:35:25,686 AE_BIGRAMA_2L_FULLDS_OVER_02.py:152]: >> Executing classifier part ... 
[2018-05-30 13:35:25,686 AE_BIGRAMA_2L_FULLDS_OVER_02.py:97]: =======================================
[2018-05-30 13:35:25,686 AE_BIGRAMA_2L_FULLDS_OVER_02.py:101]: setting configurations for classifier: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7f1b8d618908>, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'classifier_dim': 9, 'use_last_dim_as_classifier': False}
[2018-05-30 13:35:25,924 AE_BIGRAMA_2L_FULLDS_OVER_02.py:110]: training ... 
[2018-06-02 21:56:55,640 AE_BIGRAMA_2L_FULLDS_OVER_02.py:122]: trained!
[2018-06-02 21:56:55,641 AE_BIGRAMA_2L_FULLDS_OVER_02.py:125]: Training history: 
{'val_loss': [0.00010730979283667915, 0.00010730007588753846, 0.00010729024530671132, 0.000107280305672088, 0.00010727021117535178, 0.00010725998420324173, 0.00010724953909679934, 0.00010723884694204822, 0.00010722781558755463, 0.00010721639635045036, 0.0001072044376309041, 0.00010719184674268184, 0.00010717845319948087, 0.0001071639661073927, 0.00010714792324924373, 0.00010712989124429071, 0.000107108958905189, 0.00010708369383627709, 0.00010705374126710276, 0.00010702037354632603, 0.00010698420923463014, 0.00010694602920725299, 0.00010690608978593991, 0.00010686421376997085, 0.00010682087659143399, 0.000106776611077182, 0.0001067317746315584, 0.00010668668801171855, 0.00010664149795883332, 0.00010659629318824477, 0.00010655110444829419, 0.00010650591075074514, 0.00010646074502859799, 0.00010641561896723854, 0.00010637055365384127, 0.00010632555811850865, 0.00010628062102882307, 0.00010623576265371458, 0.00010619095273151016, 0.00010614619267408252, 0.00010610153064286958, 0.00010605691820368525, 0.00010601237089782528, 0.0001059678883723215, 0.00010592344625632579, 0.00010587906346304955, 0.0001058347432922104, 0.00010579047107691108, 0.00010574626030214028, 0.00010570211748978724, 0.0001056580107096021, 0.0001056139678407227, 0.00010556996466471903, 0.00010552602008410645, 0.00010548211649860824, 0.00010543828465121767, 0.00010539447223846875, 0.00010535072332790336, 0.00010530704802189855, 0.00010526341523518886, 0.0001052198386934231, 0.00010517631752755084, 0.00010513284799129624, 0.00010508942526610889, 0.00010504605148316785, 0.00010500273549876551, 0.00010495947701341375, 0.00010491624925501124, 0.0001048731122174518, 0.00010483004336960023, 0.00010478702773704908, 0.00010474405466390308, 0.00010470113574998, 0.00010465827066637764, 0.00010461546253365557, 0.00010457273165015787, 0.00010453003947282941, 0.00010448740636953828, 0.00010444483882206372, 0.00010440232168753621, 0.00010435987731258482, 0.00010431748005621086, 0.00010427511929728101, 0.0001042328123446059, 0.00010419054325311559, 0.00010414832635813121, 0.00010410617651907815, 0.00010406403169645156, 0.00010402194500126585, 0.00010397993815710781, 0.00010393795205250407, 0.0001038959749432408, 0.00010385404406211249, 0.000103812140990598, 0.00010377025293894896, 0.00010372836391128944, 0.0001036865197506982, 0.00010364470243440631, 0.00010360291100244727, 0.00010356114680786576, 0.0001035193843513851], 'loss': [0.00010737613758403313, 0.00010736634273758361, 0.00010735645007607853, 0.00010734644316140866, 0.00010733631325295818, 0.00010732603537473215, 0.00010731558189827534, 0.00010730491725918564, 0.00010729398210308191, 0.00010728266122387846, 0.00010727089252899774, 0.00010725852192299915, 0.00010724539741276247, 0.000107231185761751, 0.00010721556333854943, 0.00010719817034808079, 0.00010717826380316922, 0.00010715483103733787, 0.00010712678012913182, 0.00010709472746299273, 0.00010705967537241235, 0.00010702222106016824, 0.00010698291908694292, 0.00010694197929449763, 0.00010689941096108494, 0.00010685565860690113, 0.00010681119395995502, 0.00010676640162341865, 0.00010672146061246322, 0.0001066764602346235, 0.00010663144947646522, 0.00010658645834115469, 0.0001065414719525871, 0.00010649651655940246, 0.00010645160441293092, 0.0001064067522058107, 0.00010636196570825934, 0.00010631723867761771, 0.00010627258028943372, 0.00010622797399574874, 0.00010618341763708501, 0.00010613894384049047, 0.00010609452805686446, 0.00010605017634489073, 0.00010600588170457472, 0.00010596162305912746, 0.00010591742830403637, 0.00010587329336237173, 0.0001058292036420295, 0.00010578518471915727, 0.00010574122452104175, 0.0001056972963507146, 0.00010565343730243134, 0.00010560962587340178, 0.00010556587337721758, 0.00010552216795550567, 0.00010547852754318455, 0.00010543491249535, 0.0001053913436110418, 0.00010534785249472636, 0.00010530439593541399, 0.0001052610077926089, 0.00010521767258558825, 0.00010517439913623851, 0.00010513116409844358, 0.00010508797860985749, 0.00010504485690535053, 0.00010500178931014075, 0.0001049587560852794, 0.00010491581699864564, 0.00010487295811991092, 0.00010483014754631863, 0.00010478738024712502, 0.00010474465808887627, 0.00010470199489830315, 0.0001046593922642026, 0.00010461686830904077, 0.00010457437021402731, 0.00010453193196994984, 0.00010448956859044814, 0.00010444725258102966, 0.00010440500716456484, 0.00010436281560822668, 0.00010432065077743555, 0.00010427853905658026, 0.00010423647425212136, 0.00010419445335525792, 0.00010415249962547686, 0.00010411055185078178, 0.00010406865320286665, 0.00010402682259279111, 0.00010398502715862602, 0.0001039432262954016, 0.00010390148785251664, 0.00010385977159295206, 0.00010381807309683378, 0.00010377637117395112, 0.00010373470577910852, 0.00010369306720537297, 0.00010365144591728361, 0.00010360985834133959], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.0003675119441381845, 0.000735023888276369, 0.001470047776552738, 0.001470047776552738, 0.0018375597206909224, 0.0033076074972436605, 0.006982726938625505, 0.013597941933112825, 0.02352076442484381, 0.03528114663726571, 0.05769937522969496, 0.08599779492833518, 0.12274898934215361, 0.16758544652701213, 0.21168687982359427, 0.25725836089672915, 0.30025725836089673, 0.34472620360161704, 0.3939728041161338, 0.4384417493568541, 0.46343256155825063, 0.4807056229327453, 0.4884233737596472, 0.5012862918044837, 0.5273796398382947, 0.49503858875413453, 0.4954061006982727, 0.49467107680999634, 0.49503858875413453, 0.49503858875413453, 0.49430356486585814, 0.4935685409775818, 0.4935685409775818, 0.4935685409775818, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436, 0.4932010290334436], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012274456855284154, 0.0002454891371056831, 0.0003682337056585246, 0.0008592119798698908, 0.001841168528292623, 0.003682337056585246, 0.00638271756474776, 0.011783478581072787, 0.019025408125690438, 0.030931631275316066, 0.04823861544126672, 0.07671535534735499, 0.11525714987203273, 0.1626365533361731, 0.20915674479940968, 0.25371302318774924, 0.30011047010072334, 0.33963422119302866, 0.38063090707138736, 0.42334601690948587, 0.4535411807954333, 0.47403952374375785, 0.4848410457910402, 0.4941696329352109, 0.5220326500844996, 0.5156499325160938, 0.4946606112386868, 0.49466061129355793, 0.49429237760618977, 0.49441512212352956, 0.49416963300105615, 0.494046888366658, 0.4940468884507937, 0.4939241438785828, 0.49392414382736977, 0.49380139933197836, 0.4935559101436597, 0.49343316560802947, 0.49331042103947664, 0.49331042103947664, 0.4931876764709238, 0.49318767643800115, 0.4931876764343431, 0.4931876763867881, 0.49318767645263345, 0.4931876763867881, 0.4931876764892142, 0.4931876764709238, 0.49318767645263345, 0.4931876764892142, 0.4931876764343431, 0.4931876764745819, 0.4931876763867881, 0.49318767646726575, 0.49318767645263345, 0.4931876763867881, 0.4931876764343431, 0.49318767645263345, 0.4931876764892142, 0.49318767642336886, 0.4931876764709238, 0.4931876764745819, 0.4931876764892142, 0.4931876764892142, 0.4931876764709238]}
[2018-06-02 21:56:55,641 AE_BIGRAMA_2L_FULLDS_OVER_02.py:129]: evaluating model ... 
[2018-06-02 21:57:11,767 AE_BIGRAMA_2L_FULLDS_OVER_02.py:133]: evaluated! 
[2018-06-02 21:57:11,768 AE_BIGRAMA_2L_FULLDS_OVER_02.py:135]: generating reports ... 
[2018-06-02 21:57:13,361 AE_BIGRAMA_2L_FULLDS_OVER_02.py:138]: done!
[2018-06-02 21:57:13,361 AE_BIGRAMA_2L_FULLDS_OVER_02.py:154]: >> experiment AE_BIGRAMA_2L_FULLDS_OVER_02 finished!
