[2018-05-28 01:22:51,117 AE_BIGRAMA_2L_MINIDS_OVER_01.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_01
[2018-05-28 01:22:51,117 AE_BIGRAMA_2L_MINIDS_OVER_01.py:146]: >> Printing header log
[2018-05-28 01:22:51,117 AE_BIGRAMA_2L_MINIDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_01
	layers = 9216,9216,8295
	using GLOBAL obj = 
		{'batch': 32, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'epochs': 200, 'store_history': True, 'data_dir': '/home/dhiego/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'numpy_seed': 666, 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x7f9f3afc9898>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'mlp_configs': {'use_last_dim_as_classifier': False, 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x7f9f3afc9908>, 'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy'}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'shuffle_batches': True}
	=======================================
	
[2018-05-28 01:22:51,117 AE_BIGRAMA_2L_MINIDS_OVER_01.py:148]: >> Loading dataset... 
[2018-05-28 01:23:09,051 AE_BIGRAMA_2L_MINIDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:23:09,051 AE_BIGRAMA_2L_MINIDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:23:09,051 AE_BIGRAMA_2L_MINIDS_OVER_01.py:57]: =======================================
[2018-05-28 01:23:09,051 AE_BIGRAMA_2L_MINIDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7f9f3afc9898>, 'output_layer_activation': 'relu', 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2018-05-28 01:23:09,121 AE_BIGRAMA_2L_MINIDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:04,023 AE_BIGRAMA_2L_MINIDS_OVER_01.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_01
[2018-05-28 01:27:04,023 AE_BIGRAMA_2L_MINIDS_OVER_01.py:146]: >> Printing header log
[2018-05-28 01:27:04,023 AE_BIGRAMA_2L_MINIDS_OVER_01.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_01
	layers = 9216,9216,8295
	using GLOBAL obj = 
		{'data_dir': '/home/dhiego/malware_dataset/', 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'numpy_seed': 666, 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'batch': 32, 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'shuffle_batches': True, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'store_history': True, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7fa188d3c898>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}, 'mlp_configs': {'optimizer': <keras.optimizers.SGD object at 0x7fa188d3c908>, 'classifier_dim': 9, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}, 'epochs': 200}
	=======================================
	
[2018-05-28 01:27:04,024 AE_BIGRAMA_2L_MINIDS_OVER_01.py:148]: >> Loading dataset... 
[2018-05-28 01:27:22,331 AE_BIGRAMA_2L_MINIDS_OVER_01.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:27:22,331 AE_BIGRAMA_2L_MINIDS_OVER_01.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:27:22,331 AE_BIGRAMA_2L_MINIDS_OVER_01.py:57]: =======================================
[2018-05-28 01:27:22,331 AE_BIGRAMA_2L_MINIDS_OVER_01.py:62]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7fa188d3c898>, 'hidden_layer_activation': 'relu', 'discard_decoder_function': True, 'loss_function': 'mse'}
[2018-05-28 01:27:22,403 AE_BIGRAMA_2L_MINIDS_OVER_01.py:73]: training and evaluate autoencoder
[2018-05-28 09:51:12,361 AE_BIGRAMA_2L_MINIDS_OVER_01.py:85]: trained and evaluated!
[2018-05-28 09:51:12,363 AE_BIGRAMA_2L_MINIDS_OVER_01.py:88]: Training history: 
{'loss': [0.00010755254108919868, 0.00010754668109929674, 0.00010754080624937713, 0.00010753489836139592, 0.00010752899808117495, 0.00010752311984212851, 0.00010751722953968654, 0.00010751130776339536, 0.00010750540219803252, 0.00010749944278584332, 0.00010749348417946049, 0.0001074875328016349, 0.00010748153947447714, 0.0001074755678329911, 0.00010746965364075996, 0.00010746368605200601, 0.00010745772306108847, 0.00010745179242092709, 0.00010744579222071492, 0.00010743980574291138, 0.00010743381663438704, 0.00010742782427893696, 0.0001074218000230343, 0.00010741580368595271, 0.00010740981763475256, 0.00010740378145765549, 0.00010739775784165789, 0.00010739175885015528, 0.0001073857744105679, 0.00010737976425627689, 0.0001073737406402793, 0.00010736770901361826, 0.00010736168139228895, 0.00010735570470266293, 0.00010734967703393323, 0.00010734372330978908, 0.00010733770303551794, 0.00010733174170361352, 0.00010732574467922649, 0.00010731975974193517, 0.00010731376191174174, 0.00010730774846312466, 0.0001073017291842614, 0.00010729573180437154, 0.00010728971565393307, 0.00010728373242305525, 0.00010727777156515459, 0.00010727180802913274, 0.00010726575914873508, 0.00010725976300125499, 0.00010725377294472313, 0.00010724776416504301, 0.00010724180942179077, 0.000107235787298905, 0.0001072297661714271, 0.00010722376680072148, 0.00010721780776773528, 0.00010721181399027395, 0.00010720586026612979, 0.00010719989559249891, 0.0001071939016254361, 0.00010718789983731133, 0.00010718194713227524, 0.00010717595996716627, 0.00010717000754653243, 0.00010716405360908658, 0.00010715807670615886, 0.00010715207131560558, 0.00010714609576358857, 0.00010714016922355967, 0.0001071341778161171, 0.00010712821020366297, 0.00010712228254972523, 0.00010711628206511079, 0.00010711032310322516, 0.00010710434115215748, 0.00010709839676588725, 0.00010709242472149801, 0.00010708645300891141, 0.00010708048698436985, 0.000107074508043226, 0.00010706853019229079, 0.00010706256359894472, 0.00010705660989850073, 0.00010705062716532686, 0.00010704465516833801, 0.00010703868973630113, 0.00010703276923982008, 0.00010702676477357411, 0.00010702080213815939, 0.00010701483291409249, 0.00010700888658440687, 0.00010700294442595429, 0.00010699702952271751, 0.00010699109423731936, 0.00010698510835202053, 0.00010697916019742047, 0.00010697320448246054, 0.00010696728749360726, 0.00010696134467154942, 0.00010695538471425589], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.007371007371007371, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284], 'val_loss': [0.00010713838453502428, 0.00010713260654870338, 0.0001071267991367652, 0.00010712099074158951, 0.00010711520801785149, 0.0001071094232382532, 0.00010710360969448833, 0.00010709781486799034, 0.00010709197009302657, 0.00010708611387675354, 0.0001070802647755447, 0.00010707438460403037, 0.00010706851971739015, 0.00010706271100042763, 0.00010705685675062963, 0.00010705100666618327, 0.00010704518568556737, 0.00010703929603921882, 0.00010703341922858909, 0.00010702753374759218, 0.000107021650894521, 0.00010701573239462061, 0.00010700984668122211, 0.00010700397126500196, 0.00010699805120979859, 0.00010699214170205221, 0.00010698625974283332, 0.0001069803902081612, 0.00010697449289256001, 0.000106968588211616, 0.00010696267117763337, 0.00010695673805430957, 0.00010695085300236176, 0.00010694491946786591, 0.00010693905901473304, 0.00010693313643886623, 0.0001069272701041853, 0.00010692136869474065, 0.00010691548021040005, 0.00010690957889034063, 0.000106903661463063, 0.0001068977417475235, 0.00010689183804981699, 0.00010688592414431736, 0.00010688004424095872, 0.00010687418060571171, 0.00010686831141070347, 0.00010686236046396507, 0.00010685646184333955, 0.00010685056796013115, 0.00010684465282111536, 0.00010683879474562957, 0.00010683287175859071, 0.00010682694803859297, 0.00010682104671853354, 0.00010681518406652404, 0.00010680929027270087, 0.00010680342753130613, 0.0001067975582647897, 0.00010679165792796779, 0.0001067857543196465, 0.00010677989322293998, 0.00010677400261123095, 0.00010676814151452443, 0.00010676227927368697, 0.00010675639643849284, 0.00010675048466036165, 0.00010674459960841384, 0.00010673876427253021, 0.00010673286507983923, 0.0001067269905753484, 0.0001067211536841618, 0.00010671524787696389, 0.00010670938039815205, 0.00010670349044789371, 0.00010669763875451323, 0.0001066917622120392, 0.00010668588313102466, 0.00010668000862653383, 0.0001066741257913397, 0.0001066682417226294, 0.00010666236877344156, 0.0001066565046555143, 0.00010665061969295172, 0.00010664474003987171, 0.00010663887306161715, 0.00010663304777263323, 0.00010662713869393596, 0.00010662127146540274, 0.00010661540277095177, 0.00010660954961165356, 0.00010660370388920636, 0.00010659788678790939, 0.00010659204473025658, 0.00010658615780121896, 0.00010658030734135465, 0.00010657444910497544, 0.00010656863077016231, 0.00010656278079297823, 0.00010655691864152601, 0.00010655106777048965], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286645193829988, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.004071661237785016, 0.004071661237785016, 0.004071661237785016, 0.004071661237785016, 0.004885993485342019, 0.004885993485342019, 0.004885993485342019, 0.004885993485342019, 0.004885993485342019, 0.004885993509611011, 0.005700325732899023, 0.005700325757168015, 0.0065146580047250185, 0.006514657980456026, 0.006514657980456026, 0.006514657980456026]}
[2018-05-28 09:51:12,363 AE_BIGRAMA_2L_MINIDS_OVER_01.py:92]: done!
[2018-05-28 09:51:12,363 AE_BIGRAMA_2L_MINIDS_OVER_01.py:152]: >> Executing classifier part ... 
[2018-05-28 09:51:12,363 AE_BIGRAMA_2L_MINIDS_OVER_01.py:97]: =======================================
[2018-05-28 09:51:12,363 AE_BIGRAMA_2L_MINIDS_OVER_01.py:101]: setting configurations for classifier: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7fa188d3c908>, 'classifier_dim': 9, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}
[2018-05-28 09:51:12,819 AE_BIGRAMA_2L_MINIDS_OVER_01.py:110]: training ... 
[2018-05-28 18:14:01,219 AE_BIGRAMA_2L_MINIDS_OVER_01.py:122]: trained!
[2018-05-28 18:14:01,223 AE_BIGRAMA_2L_MINIDS_OVER_01.py:125]: Training history: 
{'loss': [0.00010755254108919868, 0.00010754668109929674, 0.00010754080624937713, 0.00010753489836139592, 0.00010752899808117495, 0.00010752311984212851, 0.00010751722953968654, 0.00010751130776339536, 0.00010750540219803252, 0.00010749944278584332, 0.00010749348417946049, 0.0001074875328016349, 0.00010748153947447714, 0.0001074755678329911, 0.00010746965364075996, 0.00010746368605200601, 0.00010745772306108847, 0.00010745179242092709, 0.00010744579222071492, 0.00010743980574291138, 0.00010743381663438704, 0.00010742782427893696, 0.0001074218000230343, 0.00010741580368595271, 0.00010740981763475256, 0.00010740378145765549, 0.00010739775784165789, 0.00010739175885015528, 0.0001073857744105679, 0.00010737976425627689, 0.0001073737406402793, 0.00010736770901361826, 0.00010736168139228895, 0.00010735570470266293, 0.00010734967703393323, 0.00010734372330978908, 0.00010733770303551794, 0.00010733174170361352, 0.00010732574467922649, 0.00010731975974193517, 0.00010731376191174174, 0.00010730774846312466, 0.0001073017291842614, 0.00010729573180437154, 0.00010728971565393307, 0.00010728373242305525, 0.00010727777156515459, 0.00010727180802913274, 0.00010726575914873508, 0.00010725976300125499, 0.00010725377294472313, 0.00010724776416504301, 0.00010724180942179077, 0.000107235787298905, 0.0001072297661714271, 0.00010722376680072148, 0.00010721780776773528, 0.00010721181399027395, 0.00010720586026612979, 0.00010719989559249891, 0.0001071939016254361, 0.00010718789983731133, 0.00010718194713227524, 0.00010717595996716627, 0.00010717000754653243, 0.00010716405360908658, 0.00010715807670615886, 0.00010715207131560558, 0.00010714609576358857, 0.00010714016922355967, 0.0001071341778161171, 0.00010712821020366297, 0.00010712228254972523, 0.00010711628206511079, 0.00010711032310322516, 0.00010710434115215748, 0.00010709839676588725, 0.00010709242472149801, 0.00010708645300891141, 0.00010708048698436985, 0.000107074508043226, 0.00010706853019229079, 0.00010706256359894472, 0.00010705660989850073, 0.00010705062716532686, 0.00010704465516833801, 0.00010703868973630113, 0.00010703276923982008, 0.00010702676477357411, 0.00010702080213815939, 0.00010701483291409249, 0.00010700888658440687, 0.00010700294442595429, 0.00010699702952271751, 0.00010699109423731936, 0.00010698510835202053, 0.00010697916019742047, 0.00010697320448246054, 0.00010696728749360726, 0.00010696134467154942, 0.00010695538471425589], 'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.002457002457002457, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.004914004914004914, 0.007371007371007371, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.009828009828009828, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284, 0.012285012285012284], 'val_loss': [0.00010713838453502428, 0.00010713260654870338, 0.0001071267991367652, 0.00010712099074158951, 0.00010711520801785149, 0.0001071094232382532, 0.00010710360969448833, 0.00010709781486799034, 0.00010709197009302657, 0.00010708611387675354, 0.0001070802647755447, 0.00010707438460403037, 0.00010706851971739015, 0.00010706271100042763, 0.00010705685675062963, 0.00010705100666618327, 0.00010704518568556737, 0.00010703929603921882, 0.00010703341922858909, 0.00010702753374759218, 0.000107021650894521, 0.00010701573239462061, 0.00010700984668122211, 0.00010700397126500196, 0.00010699805120979859, 0.00010699214170205221, 0.00010698625974283332, 0.0001069803902081612, 0.00010697449289256001, 0.000106968588211616, 0.00010696267117763337, 0.00010695673805430957, 0.00010695085300236176, 0.00010694491946786591, 0.00010693905901473304, 0.00010693313643886623, 0.0001069272701041853, 0.00010692136869474065, 0.00010691548021040005, 0.00010690957889034063, 0.000106903661463063, 0.0001068977417475235, 0.00010689183804981699, 0.00010688592414431736, 0.00010688004424095872, 0.00010687418060571171, 0.00010686831141070347, 0.00010686236046396507, 0.00010685646184333955, 0.00010685056796013115, 0.00010684465282111536, 0.00010683879474562957, 0.00010683287175859071, 0.00010682694803859297, 0.00010682104671853354, 0.00010681518406652404, 0.00010680929027270087, 0.00010680342753130613, 0.0001067975582647897, 0.00010679165792796779, 0.0001067857543196465, 0.00010677989322293998, 0.00010677400261123095, 0.00010676814151452443, 0.00010676227927368697, 0.00010675639643849284, 0.00010675048466036165, 0.00010674459960841384, 0.00010673876427253021, 0.00010673286507983923, 0.0001067269905753484, 0.0001067211536841618, 0.00010671524787696389, 0.00010670938039815205, 0.00010670349044789371, 0.00010669763875451323, 0.0001066917622120392, 0.00010668588313102466, 0.00010668000862653383, 0.0001066741257913397, 0.0001066682417226294, 0.00010666236877344156, 0.0001066565046555143, 0.00010665061969295172, 0.00010664474003987171, 0.00010663887306161715, 0.00010663304777263323, 0.00010662713869393596, 0.00010662127146540274, 0.00010661540277095177, 0.00010660954961165356, 0.00010660370388920636, 0.00010659788678790939, 0.00010659204473025658, 0.00010658615780121896, 0.00010658030734135465, 0.00010657444910497544, 0.00010656863077016231, 0.00010656278079297823, 0.00010655691864152601, 0.00010655106777048965], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0008143322475570033, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286645193829988, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0016286644951140066, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.0024429967426710096, 0.004071661237785016, 0.004071661237785016, 0.004071661237785016, 0.004071661237785016, 0.004885993485342019, 0.004885993485342019, 0.004885993485342019, 0.004885993485342019, 0.004885993485342019, 0.004885993509611011, 0.005700325732899023, 0.005700325757168015, 0.0065146580047250185, 0.006514657980456026, 0.006514657980456026, 0.006514657980456026]}
[2018-05-28 18:14:01,223 AE_BIGRAMA_2L_MINIDS_OVER_01.py:129]: evaluating model ... 
[2018-05-28 18:14:17,677 AE_BIGRAMA_2L_MINIDS_OVER_01.py:133]: evaluated! 
[2018-05-28 18:14:17,678 AE_BIGRAMA_2L_MINIDS_OVER_01.py:135]: generating reports ... 
[2018-05-28 18:14:22,544 AE_BIGRAMA_2L_MINIDS_OVER_01.py:138]: done!
[2018-05-28 18:14:22,544 AE_BIGRAMA_2L_MINIDS_OVER_01.py:154]: >> experiment AE_BIGRAMA_2L_MINIDS_OVER_01 finished!
