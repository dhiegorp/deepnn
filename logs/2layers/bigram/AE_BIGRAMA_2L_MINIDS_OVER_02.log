[2018-04-29 11:22:46,011 AE_BIGRAMA_2L_MINIDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_02
[2018-04-29 11:22:46,011 AE_BIGRAMA_2L_MINIDS_OVER_02.py:146]: >> Printing header log
[2018-04-29 11:22:46,011 AE_BIGRAMA_2L_MINIDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_02
	layers = 9216,10138,9125
	using GLOBAL obj = 
		{'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'epochs': 200, 'numpy_seed': 666, 'shuffle_batches': True, 'autoencoder_configs': {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7ff269649048>, 'loss_function': 'mse'}, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'data_dir': '/home/dhiego/malware_dataset/', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'batch': 32, 'store_history': True, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'mlp_configs': {'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x7ff269649668>, 'activation': 'sigmoid'}}
	=======================================
	
[2018-04-29 11:22:46,011 AE_BIGRAMA_2L_MINIDS_OVER_02.py:148]: >> Loading dataset... 
[2018-04-29 11:23:04,140 AE_BIGRAMA_2L_MINIDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-04-29 11:23:04,141 AE_BIGRAMA_2L_MINIDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-04-29 11:23:04,141 AE_BIGRAMA_2L_MINIDS_OVER_02.py:57]: =======================================
[2018-04-29 11:23:04,141 AE_BIGRAMA_2L_MINIDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7ff269649048>, 'loss_function': 'mse'}
[2018-04-29 11:23:04,215 AE_BIGRAMA_2L_MINIDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-05-28 01:22:50,993 AE_BIGRAMA_2L_MINIDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_02
[2018-05-28 01:22:50,993 AE_BIGRAMA_2L_MINIDS_OVER_02.py:146]: >> Printing header log
[2018-05-28 01:22:50,993 AE_BIGRAMA_2L_MINIDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_02
	layers = 9216,14746,13272
	using GLOBAL obj = 
		{'numpy_seed': 666, 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'batch': 32, 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'store_history': True, 'shuffle_batches': True, 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'data_dir': '/home/dhiego/malware_dataset/', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'autoencoder_configs': {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f6fd94db828>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}, 'epochs': 200, 'mlp_configs': {'classifier_dim': 9, 'optimizer': <keras.optimizers.SGD object at 0x7f6fd94db898>, 'activation': 'sigmoid', 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy'}, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/'}
	=======================================
	
[2018-05-28 01:22:50,993 AE_BIGRAMA_2L_MINIDS_OVER_02.py:148]: >> Loading dataset... 
[2018-05-28 01:23:07,460 AE_BIGRAMA_2L_MINIDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:23:07,460 AE_BIGRAMA_2L_MINIDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:23:07,461 AE_BIGRAMA_2L_MINIDS_OVER_02.py:57]: =======================================
[2018-05-28 01:23:07,461 AE_BIGRAMA_2L_MINIDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'output_layer_activation': 'relu', 'optimizer': <keras.optimizers.SGD object at 0x7f6fd94db828>, 'discard_decoder_function': True, 'hidden_layer_activation': 'relu', 'loss_function': 'mse'}
[2018-05-28 01:23:07,525 AE_BIGRAMA_2L_MINIDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_MINIDS_OVER_02.py:145]: >> Initializing execution of experiment AE_BIGRAMA_2L_MINIDS_OVER_02
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_MINIDS_OVER_02.py:146]: >> Printing header log
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_MINIDS_OVER_02.py:35]: 
	=======================================
	network_name = AE_BIGRAMA_2L_MINIDS_OVER_02
	layers = 9216,14746,13272
	using GLOBAL obj = 
		{'store_history': True, 'autoencoder_configs': {'optimizer': <keras.optimizers.SGD object at 0x7fc1e96e0828>, 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'hidden_layer_activation': 'relu'}, 'executed_path': '/home/dhiego/deepnn/executed/2layers/bigram/', 'numpy_seed': 666, 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'fullds_data_dir': '/home/dhiego/malware_dataset/', 'epochs': 200, 'fullds_reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/fullds/', 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'checkpoints_dir': '/home/dhiego/deepnn/checkpoints/2layers/bigram/', 'log_dir': '/home/dhiego/deepnn/logs/2layers/bigram/', 'mlp_configs': {'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x7fc1e96e0898>}, 'tensorflow_dir': '/home/dhiego/deepnn/tensorflow/2layers/bigram/', 'reports_dir': '/home/dhiego/deepnn/reports/2layers/bigram/', 'shuffle_batches': True, 'batch': 32, 'data_dir': '/home/dhiego/malware_dataset/'}
	=======================================
	
[2018-05-28 01:27:03,938 AE_BIGRAMA_2L_MINIDS_OVER_02.py:148]: >> Loading dataset... 
[2018-05-28 01:27:21,805 AE_BIGRAMA_2L_MINIDS_OVER_02.py:52]: 
	=======================================
	loading malware dataset on = /home/dhiego/malware_dataset/	
	trainx shape = (1228, 9216)
	trainy shape = (1228, 9)
	valx shape = (407, 9216)
	valy shape = (407, 9)
	=======================================
	
[2018-05-28 01:27:21,805 AE_BIGRAMA_2L_MINIDS_OVER_02.py:150]: >> Executing autoencoder part ... 
[2018-05-28 01:27:21,805 AE_BIGRAMA_2L_MINIDS_OVER_02.py:57]: =======================================
[2018-05-28 01:27:21,805 AE_BIGRAMA_2L_MINIDS_OVER_02.py:62]: setting configurations for autoencoder: 
	 {'optimizer': <keras.optimizers.SGD object at 0x7fc1e96e0828>, 'discard_decoder_function': True, 'output_layer_activation': 'relu', 'loss_function': 'mse', 'hidden_layer_activation': 'relu'}
[2018-05-28 01:27:21,875 AE_BIGRAMA_2L_MINIDS_OVER_02.py:73]: training and evaluate autoencoder
[2018-05-28 15:35:14,525 AE_BIGRAMA_2L_MINIDS_OVER_02.py:85]: trained and evaluated!
[2018-05-28 15:35:14,526 AE_BIGRAMA_2L_MINIDS_OVER_02.py:88]: Training history: 
{'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.00010729279179690653, 0.0001072893304433113, 0.00010728578401285542, 0.00010728220685175791, 0.00010727846835032266, 0.00010727461502462264, 0.00010727063925903638, 0.00010726661738854918, 0.00010726249637196632, 0.00010725830661814261, 0.00010725401396404367, 0.00010724963360515833, 0.00010724517650011565, 0.000107240639270154, 0.00010723597355786464, 0.00010723126780099284, 0.00010722640068590623, 0.00010722147870616626, 0.00010721647147079518, 0.00010721142631821009, 0.00010720625661624738, 0.00010720106671322298, 0.00010719584845720404, 0.00010719058375662028, 0.00010718521492224512, 0.00010717973737755483, 0.00010717423349997619, 0.00010716865573656752, 0.00010716306758659527, 0.00010715742457196968, 0.00010715177147469027, 0.00010714606351275752, 0.0001071402744962994, 0.00010713442223085347, 0.00010712852366385908, 0.0001071225991036402, 0.00010711667765402728, 0.00010711078023116381, 0.00010710485738714132, 0.00010709887862371977, 0.00010709292088370399, 0.00010708687787018007, 0.00010708087123644422, 0.00010707486329768402, 0.00010706886590638082, 0.00010706283524589549, 0.00010705675111516637, 0.00010705071047928954, 0.00010704467842439464, 0.00010703864318738561, 0.0001070325724644408, 0.00010702646341310993, 0.000107020396944902, 0.00010701436122521273, 0.000107008330403834, 0.00010700223819268021, 0.00010699614973570603, 0.00010699012005845821, 0.0001069839998876049, 0.00010697787587318675, 0.00010697177114810094, 0.00010696566177498325, 0.00010695956597054326, 0.00010695349272693501, 0.00010694737420076989, 0.00010694124553831985, 0.00010693510003569273, 0.00010692897897098712, 0.00010692288840452154, 0.00010691680184251421, 0.00010691067162476118, 0.00010690453797461538, 0.00010689838373011289, 0.00010689224493137792, 0.00010688611087006006, 0.00010687998580089621, 0.00010687383842117929, 0.0001068677145855316, 0.00010686160717888893, 0.00010685547908850435, 0.00010684935582492212, 0.00010684325365625386, 0.00010683715638589613, 0.00010683103982620605, 0.00010682493168660451, 0.00010681881430457033, 0.00010681270028342074, 0.00010680661740408483, 0.00010680049585669898, 0.0001067943792970089, 0.00010678828767579763, 0.0001067822073350022, 0.00010677609388591809, 0.0001067699932725528, 0.0001067639239618946, 0.00010675780600779495, 0.00010675171756869782, 0.00010674561940448779, 0.00010673953023243178, 0.00010673345192961958, 0.00010672732793307848], 'loss': [0.00010773578655571564, 0.00010773232670751908, 0.00010772874925899129, 0.00010772507843172408, 0.00010772135167201399, 0.00010771747029227954, 0.00010771349496500117, 0.00010770938549466062, 0.00010770522376540624, 0.00010770098093410966, 0.00010769665304283954, 0.000107692239854594, 0.00010768775921561437, 0.00010768321633994191, 0.00010767861980704458, 0.00010767395449620261, 0.00010766919113768428, 0.0001076642920007908, 0.00010765932823348554, 0.00010765427272275381, 0.0001076491724186674, 0.00010764396088960025, 0.00010763871328884748, 0.00010763340101028256, 0.00010762801054479852, 0.0001076225235721503, 0.00010761699675948659, 0.00010761143489424534, 0.00010760578311049206, 0.00010760010852715826, 0.00010759436281956126, 0.00010758862507522731, 0.0001075828376790002, 0.00010757700044127842, 0.00010757112770067552, 0.00010756519710791452, 0.00010755923366669341, 0.0001075532661964404, 0.00010754729744637725, 0.000107541289282902, 0.0001075352333872488, 0.0001075292043913086, 0.00010752308905558473, 0.00010751701081065454, 0.00010751091220726317, 0.00010750482405565454, 0.00010749871263046163, 0.00010749254470402132, 0.00010748640412759758, 0.00010748027966730145, 0.0001074741406550901, 0.00010746796623479835, 0.00010746177401566568, 0.0001074556189110269, 0.0001074495009445822, 0.0001074433821723311, 0.00010743719609154703, 0.0001074310091812564, 0.00010742488085782969, 0.0001074186580891551, 0.00010741242541380208, 0.00010740622274288664, 0.00010740000907508413, 0.00010739380825278334, 0.00010738763309778579, 0.00010738142855455552, 0.0001073752110710228, 0.00010736898150039437, 0.00010736277228822714, 0.0001073565911370821, 0.00010735041546068042, 0.00010734419100929252, 0.00010733797229335003, 0.00010733172748350092, 0.00010732550409862147, 0.00010731928182765084, 0.0001073130712645729, 0.00010730683441798685, 0.00010730062613012693, 0.00010729443398209483, 0.00010728821728066829, 0.00010728200323366278, 0.00010727581658407421, 0.00010726962965008338, 0.00010726342212062947, 0.00010725722388164913, 0.00010725101841411156, 0.00010724481778141227, 0.0001072386426501149, 0.00010723243002512065, 0.0001072262283496131, 0.0001072200526969116, 0.00010721388334846003, 0.00010720767908963201, 0.00010720149447825959, 0.00010719533517868759, 0.0001071891283839395, 0.00010718295602556408, 0.00010717677387901117, 0.00010717059230126277, 0.00010716442840385436], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-05-28 15:35:14,527 AE_BIGRAMA_2L_MINIDS_OVER_02.py:92]: done!
[2018-05-28 15:35:14,527 AE_BIGRAMA_2L_MINIDS_OVER_02.py:152]: >> Executing classifier part ... 
[2018-05-28 15:35:14,527 AE_BIGRAMA_2L_MINIDS_OVER_02.py:97]: =======================================
[2018-05-28 15:35:14,527 AE_BIGRAMA_2L_MINIDS_OVER_02.py:101]: setting configurations for classifier: 
	 {'classifier_dim': 9, 'use_last_dim_as_classifier': False, 'loss_function': 'categorical_crossentropy', 'activation': 'sigmoid', 'optimizer': <keras.optimizers.SGD object at 0x7fc1e96e0898>}
[2018-05-28 15:35:14,603 AE_BIGRAMA_2L_MINIDS_OVER_02.py:110]: training ... 
[2018-05-29 04:30:56,743 AE_BIGRAMA_2L_MINIDS_OVER_02.py:122]: trained!
[2018-05-29 04:30:56,744 AE_BIGRAMA_2L_MINIDS_OVER_02.py:125]: Training history: 
{'val_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'val_loss': [0.00010729279179690653, 0.0001072893304433113, 0.00010728578401285542, 0.00010728220685175791, 0.00010727846835032266, 0.00010727461502462264, 0.00010727063925903638, 0.00010726661738854918, 0.00010726249637196632, 0.00010725830661814261, 0.00010725401396404367, 0.00010724963360515833, 0.00010724517650011565, 0.000107240639270154, 0.00010723597355786464, 0.00010723126780099284, 0.00010722640068590623, 0.00010722147870616626, 0.00010721647147079518, 0.00010721142631821009, 0.00010720625661624738, 0.00010720106671322298, 0.00010719584845720404, 0.00010719058375662028, 0.00010718521492224512, 0.00010717973737755483, 0.00010717423349997619, 0.00010716865573656752, 0.00010716306758659527, 0.00010715742457196968, 0.00010715177147469027, 0.00010714606351275752, 0.0001071402744962994, 0.00010713442223085347, 0.00010712852366385908, 0.0001071225991036402, 0.00010711667765402728, 0.00010711078023116381, 0.00010710485738714132, 0.00010709887862371977, 0.00010709292088370399, 0.00010708687787018007, 0.00010708087123644422, 0.00010707486329768402, 0.00010706886590638082, 0.00010706283524589549, 0.00010705675111516637, 0.00010705071047928954, 0.00010704467842439464, 0.00010703864318738561, 0.0001070325724644408, 0.00010702646341310993, 0.000107020396944902, 0.00010701436122521273, 0.000107008330403834, 0.00010700223819268021, 0.00010699614973570603, 0.00010699012005845821, 0.0001069839998876049, 0.00010697787587318675, 0.00010697177114810094, 0.00010696566177498325, 0.00010695956597054326, 0.00010695349272693501, 0.00010694737420076989, 0.00010694124553831985, 0.00010693510003569273, 0.00010692897897098712, 0.00010692288840452154, 0.00010691680184251421, 0.00010691067162476118, 0.00010690453797461538, 0.00010689838373011289, 0.00010689224493137792, 0.00010688611087006006, 0.00010687998580089621, 0.00010687383842117929, 0.0001068677145855316, 0.00010686160717888893, 0.00010685547908850435, 0.00010684935582492212, 0.00010684325365625386, 0.00010683715638589613, 0.00010683103982620605, 0.00010682493168660451, 0.00010681881430457033, 0.00010681270028342074, 0.00010680661740408483, 0.00010680049585669898, 0.0001067943792970089, 0.00010678828767579763, 0.0001067822073350022, 0.00010677609388591809, 0.0001067699932725528, 0.0001067639239618946, 0.00010675780600779495, 0.00010675171756869782, 0.00010674561940448779, 0.00010673953023243178, 0.00010673345192961958, 0.00010672732793307848], 'loss': [0.00010773578655571564, 0.00010773232670751908, 0.00010772874925899129, 0.00010772507843172408, 0.00010772135167201399, 0.00010771747029227954, 0.00010771349496500117, 0.00010770938549466062, 0.00010770522376540624, 0.00010770098093410966, 0.00010769665304283954, 0.000107692239854594, 0.00010768775921561437, 0.00010768321633994191, 0.00010767861980704458, 0.00010767395449620261, 0.00010766919113768428, 0.0001076642920007908, 0.00010765932823348554, 0.00010765427272275381, 0.0001076491724186674, 0.00010764396088960025, 0.00010763871328884748, 0.00010763340101028256, 0.00010762801054479852, 0.0001076225235721503, 0.00010761699675948659, 0.00010761143489424534, 0.00010760578311049206, 0.00010760010852715826, 0.00010759436281956126, 0.00010758862507522731, 0.0001075828376790002, 0.00010757700044127842, 0.00010757112770067552, 0.00010756519710791452, 0.00010755923366669341, 0.0001075532661964404, 0.00010754729744637725, 0.000107541289282902, 0.0001075352333872488, 0.0001075292043913086, 0.00010752308905558473, 0.00010751701081065454, 0.00010751091220726317, 0.00010750482405565454, 0.00010749871263046163, 0.00010749254470402132, 0.00010748640412759758, 0.00010748027966730145, 0.0001074741406550901, 0.00010746796623479835, 0.00010746177401566568, 0.0001074556189110269, 0.0001074495009445822, 0.0001074433821723311, 0.00010743719609154703, 0.0001074310091812564, 0.00010742488085782969, 0.0001074186580891551, 0.00010741242541380208, 0.00010740622274288664, 0.00010740000907508413, 0.00010739380825278334, 0.00010738763309778579, 0.00010738142855455552, 0.0001073752110710228, 0.00010736898150039437, 0.00010736277228822714, 0.0001073565911370821, 0.00010735041546068042, 0.00010734419100929252, 0.00010733797229335003, 0.00010733172748350092, 0.00010732550409862147, 0.00010731928182765084, 0.0001073130712645729, 0.00010730683441798685, 0.00010730062613012693, 0.00010729443398209483, 0.00010728821728066829, 0.00010728200323366278, 0.00010727581658407421, 0.00010726962965008338, 0.00010726342212062947, 0.00010725722388164913, 0.00010725101841411156, 0.00010724481778141227, 0.0001072386426501149, 0.00010723243002512065, 0.0001072262283496131, 0.0001072200526969116, 0.00010721388334846003, 0.00010720767908963201, 0.00010720149447825959, 0.00010719533517868759, 0.0001071891283839395, 0.00010718295602556408, 0.00010717677387901117, 0.00010717059230126277, 0.00010716442840385436], 'acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}
[2018-05-29 04:30:56,744 AE_BIGRAMA_2L_MINIDS_OVER_02.py:129]: evaluating model ... 
[2018-05-29 04:31:16,737 AE_BIGRAMA_2L_MINIDS_OVER_02.py:133]: evaluated! 
[2018-05-29 04:31:16,737 AE_BIGRAMA_2L_MINIDS_OVER_02.py:135]: generating reports ... 
[2018-05-29 04:31:20,235 AE_BIGRAMA_2L_MINIDS_OVER_02.py:138]: done!
[2018-05-29 04:31:20,235 AE_BIGRAMA_2L_MINIDS_OVER_02.py:154]: >> experiment AE_BIGRAMA_2L_MINIDS_OVER_02 finished!
