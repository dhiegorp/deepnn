[2017-10-21 21:14:27,865 AE_UNIGRAMA_6L_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_UNDER_03
[2017-10-21 21:14:27,865 AE_UNIGRAMA_6L_UNDER_03.py:149]: >> Printing header log
[2017-10-21 21:14:27,866 AE_UNIGRAMA_6L_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_UNDER_03
	layers = 96,86,78,71,63,55,48,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd230682780>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd230682860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-21 21:14:27,866 AE_UNIGRAMA_6L_UNDER_03.py:151]: >> Loading dataset... 
[2017-10-21 21:14:28,437 AE_UNIGRAMA_6L_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-21 21:14:28,437 AE_UNIGRAMA_6L_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-10-21 21:14:28,437 AE_UNIGRAMA_6L_UNDER_03.py:60]: =======================================
[2017-10-21 21:14:28,437 AE_UNIGRAMA_6L_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd230682780>, 'discard_decoder_function': True}
[2017-10-21 21:14:28,572 AE_UNIGRAMA_6L_UNDER_03.py:76]: training and evaluate autoencoder
[2017-10-21 21:15:14,288 AE_UNIGRAMA_6L_UNDER_03.py:88]: trained and evaluated!
[2017-10-21 21:15:14,288 AE_UNIGRAMA_6L_UNDER_03.py:91]: Training history: 
{'val_loss': [0.010192672386211533, 0.0099809994803374581, 0.0097727391481067169, 0.0095756723957489409, 0.0093904202907834355, 0.009216467957237396, 0.0090533385994986081, 0.0089003634171691964, 0.0087568534115765612, 0.0086221732372300328, 0.0084946074568039865, 0.0083710386255084358, 0.0082553542430294485, 0.0081468467275200053, 0.0080444481514643559, 0.0079484069841086417, 0.0078583568175319852, 0.0077737513687253885, 0.0076941661830977658, 0.0076188777580331029, 0.0075479654481004381, 0.0074811692308066726, 0.007418108970743905, 0.0073586251468962006, 0.0073021730480777956, 0.0072485645419353671, 0.007197716687096207, 0.0071496299301796904, 0.0071041402078084789, 0.0070610381005034124, 0.0070202235776418648, 0.0069814657820146319, 0.0069447105670811743, 0.0069098196452878225, 0.0068766178241255783, 0.0068450179920431405, 0.0068149632154565765, 0.0067863070637984788, 0.0067590211421168205, 0.0067330874558053496, 0.0067083078703140241, 0.0066846436041936999, 0.0066620241937168688, 0.0066404250869354347, 0.0066197429918666752, 0.0065999613576274378, 0.0065809923006034691, 0.0065628396984203597, 0.006545433781514824, 0.0065287351781384648, 0.0065127273426013807, 0.0064973316058433411, 0.0064825416061348633, 0.0064683230732287171, 0.0064546825385005061, 0.00644154724453794, 0.0064289147487831162, 0.0064167648633478075, 0.0064050379351169202, 0.0063937596308559072, 0.0063829287630419304, 0.0063725101110632754, 0.0063624581872558286, 0.0063527649524708222, 0.0063433798833241253, 0.0063343243742687112, 0.0063255930329814943, 0.0063171523993620195, 0.0063089678188626647, 0.0063010436884338751, 0.0062934109009802341, 0.0062860371354538048, 0.0062789330535938746, 0.0062720559184269832, 0.0062653929043602766, 0.0062589626845844836, 0.0062527445588108554, 0.0062467296881303465, 0.0062409015389706347, 0.0062352612694261461, 0.0062297940614276662, 0.0062245104053372784, 0.0062193836372858085, 0.0062144195512075628, 0.0062095975489476797, 0.0062049350296199098, 0.0062004109086351098, 0.006196017072407951, 0.0061917692997586326, 0.0061876552151758435, 0.0061836560641079586, 0.0061797809987900205, 0.0061760131619372112, 0.0061723681834966052, 0.0061688330803468102, 0.0061654007308129706, 0.0061620701256737834, 0.0061588396619465273, 0.006155695740244313, 0.0061526459132816265, 0.0061496784927870486, 0.006146807704799459], 'loss': [0.010293524507971248, 0.010081769300930399, 0.0098700132598778766, 0.0096667027324163334, 0.0094748348159087014, 0.0092945878234243721, 0.009125424116808686, 0.0089668355940554362, 0.0088180320625912949, 0.008678350343466831, 0.0085469425582059624, 0.0084205638106681115, 0.0083003810400254317, 0.0081877891820315643, 0.0080817370562738036, 0.0079819710934380117, 0.0078883740539217768, 0.0078005063889597407, 0.0077178678151904696, 0.0076399473814017837, 0.0075662370808949192, 0.0074968197278234222, 0.0074313960542424957, 0.0073696044256501975, 0.0073110901835914321, 0.0072555550629961104, 0.0072027474894235857, 0.00715274290629899, 0.0071054279759008784, 0.007060615721055076, 0.007018131452092252, 0.0069778588043494906, 0.006939577249570829, 0.0069032444523621098, 0.0068687152033917879, 0.0068358250936011306, 0.0068044995522148306, 0.0067746806031146805, 0.0067462296045964019, 0.0067191133109627136, 0.006693307414236487, 0.0066686320332117657, 0.0066450383856471286, 0.0066224648920589048, 0.006600885401859412, 0.0065802147977750179, 0.0065604166079658299, 0.0065414201323407773, 0.0065232226298807148, 0.0065057594200324887, 0.00648898814622251, 0.0064728886204455148, 0.0064574030843879927, 0.0064425136417164235, 0.0064281838260288795, 0.0064144221503120409, 0.0064011683925693213, 0.0063883914565295435, 0.0063760912534680629, 0.0063642250352780108, 0.0063528202796960505, 0.0063418331415779983, 0.0063312521359477408, 0.0063210224839226189, 0.0063111601762597226, 0.0063015991689084347, 0.0062923620812155275, 0.0062834547272211912, 0.0062748240756320857, 0.0062664441052267868, 0.0062583433607273772, 0.0062505359018419551, 0.0062429872324281516, 0.0062357016201414388, 0.0062286384419733276, 0.0062217917485069881, 0.0062151774535094146, 0.0062087775653396453, 0.0062025693029430871, 0.0061965684006339795, 0.0061907455933033579, 0.006185097140205661, 0.0061796203398185234, 0.0061743142098742501, 0.0061691721524074717, 0.0061641691507887241, 0.0061593332537406963, 0.0061546269281622483, 0.0061500586638571697, 0.0061456341168785395, 0.0061413534798447017, 0.0061371776595317883, 0.0061331298726037854, 0.0061291982010510636, 0.006125379584731961, 0.0061216796178785145, 0.0061180810747438032, 0.0061145874419202082, 0.0061111901746519004, 0.0061078921579209187, 0.0061046806096540654, 0.006101559619485105]}
[2017-10-21 21:15:14,288 AE_UNIGRAMA_6L_UNDER_03.py:95]: done!
[2017-10-21 21:15:14,289 AE_UNIGRAMA_6L_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-10-21 21:15:14,289 AE_UNIGRAMA_6L_UNDER_03.py:100]: =======================================
[2017-10-21 21:15:14,289 AE_UNIGRAMA_6L_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd230682860>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-21 21:15:14,319 AE_UNIGRAMA_6L_UNDER_03.py:113]: training ... 
[2017-10-21 21:16:28,294 AE_UNIGRAMA_6L_UNDER_03.py:125]: trained!
[2017-10-21 21:16:28,294 AE_UNIGRAMA_6L_UNDER_03.py:128]: Training history: 
{'val_loss': [0.010192672386211533, 0.0099809994803374581, 0.0097727391481067169, 0.0095756723957489409, 0.0093904202907834355, 0.009216467957237396, 0.0090533385994986081, 0.0089003634171691964, 0.0087568534115765612, 0.0086221732372300328, 0.0084946074568039865, 0.0083710386255084358, 0.0082553542430294485, 0.0081468467275200053, 0.0080444481514643559, 0.0079484069841086417, 0.0078583568175319852, 0.0077737513687253885, 0.0076941661830977658, 0.0076188777580331029, 0.0075479654481004381, 0.0074811692308066726, 0.007418108970743905, 0.0073586251468962006, 0.0073021730480777956, 0.0072485645419353671, 0.007197716687096207, 0.0071496299301796904, 0.0071041402078084789, 0.0070610381005034124, 0.0070202235776418648, 0.0069814657820146319, 0.0069447105670811743, 0.0069098196452878225, 0.0068766178241255783, 0.0068450179920431405, 0.0068149632154565765, 0.0067863070637984788, 0.0067590211421168205, 0.0067330874558053496, 0.0067083078703140241, 0.0066846436041936999, 0.0066620241937168688, 0.0066404250869354347, 0.0066197429918666752, 0.0065999613576274378, 0.0065809923006034691, 0.0065628396984203597, 0.006545433781514824, 0.0065287351781384648, 0.0065127273426013807, 0.0064973316058433411, 0.0064825416061348633, 0.0064683230732287171, 0.0064546825385005061, 0.00644154724453794, 0.0064289147487831162, 0.0064167648633478075, 0.0064050379351169202, 0.0063937596308559072, 0.0063829287630419304, 0.0063725101110632754, 0.0063624581872558286, 0.0063527649524708222, 0.0063433798833241253, 0.0063343243742687112, 0.0063255930329814943, 0.0063171523993620195, 0.0063089678188626647, 0.0063010436884338751, 0.0062934109009802341, 0.0062860371354538048, 0.0062789330535938746, 0.0062720559184269832, 0.0062653929043602766, 0.0062589626845844836, 0.0062527445588108554, 0.0062467296881303465, 0.0062409015389706347, 0.0062352612694261461, 0.0062297940614276662, 0.0062245104053372784, 0.0062193836372858085, 0.0062144195512075628, 0.0062095975489476797, 0.0062049350296199098, 0.0062004109086351098, 0.006196017072407951, 0.0061917692997586326, 0.0061876552151758435, 0.0061836560641079586, 0.0061797809987900205, 0.0061760131619372112, 0.0061723681834966052, 0.0061688330803468102, 0.0061654007308129706, 0.0061620701256737834, 0.0061588396619465273, 0.006155695740244313, 0.0061526459132816265, 0.0061496784927870486, 0.006146807704799459], 'loss': [0.010293524507971248, 0.010081769300930399, 0.0098700132598778766, 0.0096667027324163334, 0.0094748348159087014, 0.0092945878234243721, 0.009125424116808686, 0.0089668355940554362, 0.0088180320625912949, 0.008678350343466831, 0.0085469425582059624, 0.0084205638106681115, 0.0083003810400254317, 0.0081877891820315643, 0.0080817370562738036, 0.0079819710934380117, 0.0078883740539217768, 0.0078005063889597407, 0.0077178678151904696, 0.0076399473814017837, 0.0075662370808949192, 0.0074968197278234222, 0.0074313960542424957, 0.0073696044256501975, 0.0073110901835914321, 0.0072555550629961104, 0.0072027474894235857, 0.00715274290629899, 0.0071054279759008784, 0.007060615721055076, 0.007018131452092252, 0.0069778588043494906, 0.006939577249570829, 0.0069032444523621098, 0.0068687152033917879, 0.0068358250936011306, 0.0068044995522148306, 0.0067746806031146805, 0.0067462296045964019, 0.0067191133109627136, 0.006693307414236487, 0.0066686320332117657, 0.0066450383856471286, 0.0066224648920589048, 0.006600885401859412, 0.0065802147977750179, 0.0065604166079658299, 0.0065414201323407773, 0.0065232226298807148, 0.0065057594200324887, 0.00648898814622251, 0.0064728886204455148, 0.0064574030843879927, 0.0064425136417164235, 0.0064281838260288795, 0.0064144221503120409, 0.0064011683925693213, 0.0063883914565295435, 0.0063760912534680629, 0.0063642250352780108, 0.0063528202796960505, 0.0063418331415779983, 0.0063312521359477408, 0.0063210224839226189, 0.0063111601762597226, 0.0063015991689084347, 0.0062923620812155275, 0.0062834547272211912, 0.0062748240756320857, 0.0062664441052267868, 0.0062583433607273772, 0.0062505359018419551, 0.0062429872324281516, 0.0062357016201414388, 0.0062286384419733276, 0.0062217917485069881, 0.0062151774535094146, 0.0062087775653396453, 0.0062025693029430871, 0.0061965684006339795, 0.0061907455933033579, 0.006185097140205661, 0.0061796203398185234, 0.0061743142098742501, 0.0061691721524074717, 0.0061641691507887241, 0.0061593332537406963, 0.0061546269281622483, 0.0061500586638571697, 0.0061456341168785395, 0.0061413534798447017, 0.0061371776595317883, 0.0061331298726037854, 0.0061291982010510636, 0.006125379584731961, 0.0061216796178785145, 0.0061180810747438032, 0.0061145874419202082, 0.0061111901746519004, 0.0061078921579209187, 0.0061046806096540654, 0.006101559619485105]}
[2017-10-21 21:16:28,294 AE_UNIGRAMA_6L_UNDER_03.py:132]: evaluating model ... 
[2017-10-21 21:16:28,373 AE_UNIGRAMA_6L_UNDER_03.py:136]: evaluated! 
[2017-10-21 21:16:28,373 AE_UNIGRAMA_6L_UNDER_03.py:138]: generating reports ... 
[2017-10-21 21:16:28,957 AE_UNIGRAMA_6L_UNDER_03.py:141]: done!
[2017-10-21 21:16:28,957 AE_UNIGRAMA_6L_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_6L_UNDER_03 finished!
