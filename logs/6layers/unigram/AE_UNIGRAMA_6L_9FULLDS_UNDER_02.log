[2017-11-18 19:48:39,973 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_9FULLDS_UNDER_02
[2017-11-18 19:48:39,973 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:149]: >> Printing header log
[2017-11-18 19:48:39,973 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_9FULLDS_UNDER_02
	layers = 96,76,69,63,56,49,43,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff6b7b08eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff6b7b0e400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:48:39,973 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-18 19:48:42,233 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:48:42,233 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:48:42,233 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:60]: =======================================
[2017-11-18 19:48:42,234 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ff6b7b08eb8>, 'discard_decoder_function': True}
[2017-11-18 19:48:42,379 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-18 19:50:23,844 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-18 19:50:23,845 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.0095048813109629426, 0.0088066025570347137, 0.0082566561011370929, 0.0078232055586426961, 0.0074801595338395369, 0.0072070059810793495, 0.0069885109643664425, 0.0068126241423227974, 0.0066703398190356604, 0.0065545951293829998, 0.0064598893351751584, 0.0063818837683723168, 0.0063174194279813078, 0.0062637315792309165, 0.0062187939855923484, 0.0061809517628349329, 0.0061491066714880862, 0.0061221325553362203, 0.0060992145256092449, 0.0060795987370940458, 0.0060628311847532026, 0.0060483662629597923, 0.0060359215993983197, 0.0060251434314797488, 0.0060157809041656799, 0.0060076549327845018, 0.0060005669003898102, 0.0059944030387927422, 0.0059890176629245782, 0.0059843063067839247, 0.0059801757561391338, 0.0059765386935090731, 0.0059733550457536453, 0.0059705569138610104, 0.0059680655846445496, 0.0059658903556710566, 0.0059639610944316477, 0.0059622598573933769, 0.0059607578647719647, 0.0059594367558046908, 0.005958255648647888, 0.0059572099240819175, 0.005956284651595747, 0.0059554566300136285, 0.0059547189403892122, 0.0059540603998350233, 0.0059534646540733713, 0.0059529350731160405, 0.0059524478666513111, 0.0059520032687933461, 0.0059516072292592776, 0.0059512419529767135, 0.0059508447084734703, 0.0059504836912546545, 0.0059501684284661181, 0.0059498859509874991, 0.0059496482368900918, 0.0059494278570811666, 0.0059492286337996143, 0.0059490402005626542, 0.0059488765731589436, 0.0059487175189392649, 0.0059485745006841589, 0.0059484385654093403, 0.0059483112440982238, 0.0059481932341303567, 0.0059480744934114066, 0.0059479678187276987, 0.0059478611366851385, 0.005947767227812123, 0.0059476703346680575, 0.0059475810911358553, 0.0059474880079088818, 0.005947395223656649, 0.0059472993395309412, 0.005947193409460338, 0.0059470963339707745, 0.0059470119900646859, 0.0059469375865980958, 0.0059468644699037284, 0.005946794372221037, 0.005946726808721492, 0.0059466594913156375, 0.0059465961096118979, 0.0059465275699521238, 0.0059464670227753601, 0.0059464036490294485, 0.0059463406636768822, 0.0059462799048047819, 0.0059462199974202714, 0.0059461618390465511, 0.0059461031352621265, 0.0059460503005041706, 0.0059459926502334857, 0.0059459356827102124, 0.0059458805109178789, 0.0059458271360544376, 0.0059457684633312134, 0.0059457088699814194, 0.0059456476996981701, 0.0059455909493465889], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099308632369762163, 0.0091458440240327604, 0.0085254222043960604, 0.0080373747056166987, 0.0076521697496565282, 0.0073467517949867556, 0.007103116298340169, 0.0069078534286081926, 0.0067504169247935659, 0.006622875729129697, 0.0065189224357025252, 0.0064337459949901591, 0.0063634848674137164, 0.0063053322115752307, 0.0062568436507183644, 0.0062161973045757758, 0.0061819855719566991, 0.0061531803781941499, 0.0061287898640602747, 0.0061080092803714675, 0.0060902544104314569, 0.0060750602933596371, 0.0060619784528107212, 0.0060507164023404138, 0.0060409606305572086, 0.0060325073123657699, 0.0060251784179168998, 0.0060187919447510585, 0.0060132412039058088, 0.0060083998781124207, 0.0060041678663125082, 0.0060004745875268618, 0.0059972264490952129, 0.0059943924905149042, 0.005991896484856523, 0.0059896842232475848, 0.0059877582846296976, 0.0059860601725256358, 0.0059845594211299863, 0.0059832474383146829, 0.0059820877981299134, 0.0059810590251138914, 0.0059801515181390798, 0.0059793518706529733, 0.0059786376504361721, 0.0059780048751615781, 0.0059774370036508951, 0.0059769296817681799, 0.0059764700752779126, 0.005976050052740621, 0.0059756775376000213, 0.005975338696623666, 0.005974993818854849, 0.005974646115510269, 0.0059743425671097633, 0.0059740808039649403, 0.0059738590561971023, 0.0059736582389524583, 0.0059734751439293361, 0.0059733081449427254, 0.0059731540096848489, 0.0059730136130639339, 0.0059728799908516468, 0.0059727633240944447, 0.0059726509061892681, 0.0059725432671566304, 0.0059724433279108261, 0.0059723455769930007, 0.0059722515269592666, 0.0059721685667173934, 0.0059720836674109351, 0.0059720027241391745, 0.0059719209139040639, 0.0059718439368981737, 0.0059717551256825265, 0.0059716677048204832, 0.0059715720487211405, 0.0059714958250497007, 0.0059714282139115161, 0.0059713620848073955, 0.0059713007795015255, 0.005971238873242816, 0.0059711813360952895, 0.0059711215699808761, 0.0059710622261452892, 0.0059710043888642874, 0.0059709516510516461, 0.0059708962393018074, 0.0059708401754432639, 0.0059707856319142372, 0.0059707297063765858, 0.005970677315223538, 0.005970622987120729, 0.0059705680680104678, 0.0059705144241959775, 0.0059704641319195872, 0.0059704097328272948, 0.0059703549762726623, 0.0059703013879580007, 0.0059702472625924674, 0.0059701886764924501], 'acc': [0.5879464833607948, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822262206665, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822267327968, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822262206665, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 19:50:23,845 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:95]: done!
[2017-11-18 19:50:23,845 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-18 19:50:23,845 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:100]: =======================================
[2017-11-18 19:50:23,845 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ff6b7b0e400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:50:23,908 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:113]: training ... 
[2017-11-18 19:53:51,211 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:125]: trained!
[2017-11-18 19:53:51,212 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.0095048813109629426, 0.0088066025570347137, 0.0082566561011370929, 0.0078232055586426961, 0.0074801595338395369, 0.0072070059810793495, 0.0069885109643664425, 0.0068126241423227974, 0.0066703398190356604, 0.0065545951293829998, 0.0064598893351751584, 0.0063818837683723168, 0.0063174194279813078, 0.0062637315792309165, 0.0062187939855923484, 0.0061809517628349329, 0.0061491066714880862, 0.0061221325553362203, 0.0060992145256092449, 0.0060795987370940458, 0.0060628311847532026, 0.0060483662629597923, 0.0060359215993983197, 0.0060251434314797488, 0.0060157809041656799, 0.0060076549327845018, 0.0060005669003898102, 0.0059944030387927422, 0.0059890176629245782, 0.0059843063067839247, 0.0059801757561391338, 0.0059765386935090731, 0.0059733550457536453, 0.0059705569138610104, 0.0059680655846445496, 0.0059658903556710566, 0.0059639610944316477, 0.0059622598573933769, 0.0059607578647719647, 0.0059594367558046908, 0.005958255648647888, 0.0059572099240819175, 0.005956284651595747, 0.0059554566300136285, 0.0059547189403892122, 0.0059540603998350233, 0.0059534646540733713, 0.0059529350731160405, 0.0059524478666513111, 0.0059520032687933461, 0.0059516072292592776, 0.0059512419529767135, 0.0059508447084734703, 0.0059504836912546545, 0.0059501684284661181, 0.0059498859509874991, 0.0059496482368900918, 0.0059494278570811666, 0.0059492286337996143, 0.0059490402005626542, 0.0059488765731589436, 0.0059487175189392649, 0.0059485745006841589, 0.0059484385654093403, 0.0059483112440982238, 0.0059481932341303567, 0.0059480744934114066, 0.0059479678187276987, 0.0059478611366851385, 0.005947767227812123, 0.0059476703346680575, 0.0059475810911358553, 0.0059474880079088818, 0.005947395223656649, 0.0059472993395309412, 0.005947193409460338, 0.0059470963339707745, 0.0059470119900646859, 0.0059469375865980958, 0.0059468644699037284, 0.005946794372221037, 0.005946726808721492, 0.0059466594913156375, 0.0059465961096118979, 0.0059465275699521238, 0.0059464670227753601, 0.0059464036490294485, 0.0059463406636768822, 0.0059462799048047819, 0.0059462199974202714, 0.0059461618390465511, 0.0059461031352621265, 0.0059460503005041706, 0.0059459926502334857, 0.0059459356827102124, 0.0059458805109178789, 0.0059458271360544376, 0.0059457684633312134, 0.0059457088699814194, 0.0059456476996981701, 0.0059455909493465889], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099308632369762163, 0.0091458440240327604, 0.0085254222043960604, 0.0080373747056166987, 0.0076521697496565282, 0.0073467517949867556, 0.007103116298340169, 0.0069078534286081926, 0.0067504169247935659, 0.006622875729129697, 0.0065189224357025252, 0.0064337459949901591, 0.0063634848674137164, 0.0063053322115752307, 0.0062568436507183644, 0.0062161973045757758, 0.0061819855719566991, 0.0061531803781941499, 0.0061287898640602747, 0.0061080092803714675, 0.0060902544104314569, 0.0060750602933596371, 0.0060619784528107212, 0.0060507164023404138, 0.0060409606305572086, 0.0060325073123657699, 0.0060251784179168998, 0.0060187919447510585, 0.0060132412039058088, 0.0060083998781124207, 0.0060041678663125082, 0.0060004745875268618, 0.0059972264490952129, 0.0059943924905149042, 0.005991896484856523, 0.0059896842232475848, 0.0059877582846296976, 0.0059860601725256358, 0.0059845594211299863, 0.0059832474383146829, 0.0059820877981299134, 0.0059810590251138914, 0.0059801515181390798, 0.0059793518706529733, 0.0059786376504361721, 0.0059780048751615781, 0.0059774370036508951, 0.0059769296817681799, 0.0059764700752779126, 0.005976050052740621, 0.0059756775376000213, 0.005975338696623666, 0.005974993818854849, 0.005974646115510269, 0.0059743425671097633, 0.0059740808039649403, 0.0059738590561971023, 0.0059736582389524583, 0.0059734751439293361, 0.0059733081449427254, 0.0059731540096848489, 0.0059730136130639339, 0.0059728799908516468, 0.0059727633240944447, 0.0059726509061892681, 0.0059725432671566304, 0.0059724433279108261, 0.0059723455769930007, 0.0059722515269592666, 0.0059721685667173934, 0.0059720836674109351, 0.0059720027241391745, 0.0059719209139040639, 0.0059718439368981737, 0.0059717551256825265, 0.0059716677048204832, 0.0059715720487211405, 0.0059714958250497007, 0.0059714282139115161, 0.0059713620848073955, 0.0059713007795015255, 0.005971238873242816, 0.0059711813360952895, 0.0059711215699808761, 0.0059710622261452892, 0.0059710043888642874, 0.0059709516510516461, 0.0059708962393018074, 0.0059708401754432639, 0.0059707856319142372, 0.0059707297063765858, 0.005970677315223538, 0.005970622987120729, 0.0059705680680104678, 0.0059705144241959775, 0.0059704641319195872, 0.0059704097328272948, 0.0059703549762726623, 0.0059703013879580007, 0.0059702472625924674, 0.0059701886764924501], 'acc': [0.5879464833607948, 0.59383822268791198, 0.59383822272449271, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822262206665, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.59383822267327968, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822262206665, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.59383822270254427, 0.59383822267327968, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182]}
[2017-11-18 19:53:51,212 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-18 19:53:51,333 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:136]: evaluated! 
[2017-11-18 19:53:51,333 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:138]: generating reports ... 
[2017-11-18 19:53:52,168 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:141]: done!
[2017-11-18 19:53:52,168 AE_UNIGRAMA_6L_9FULLDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_6L_9FULLDS_UNDER_02 finished!
