[2017-10-20 01:43:07,286 AE_UNIGRAMA_6L_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_UNDER_02
[2017-10-20 01:43:07,286 AE_UNIGRAMA_6L_UNDER_02.py:149]: >> Printing header log
[2017-10-20 01:43:07,286 AE_UNIGRAMA_6L_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_UNDER_02
	layers = 96,76,69,63,56,49,43,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2357d377b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2357d37898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:43:07,286 AE_UNIGRAMA_6L_UNDER_02.py:151]: >> Loading dataset... 
[2017-10-20 01:43:07,859 AE_UNIGRAMA_6L_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:43:07,859 AE_UNIGRAMA_6L_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:43:07,859 AE_UNIGRAMA_6L_UNDER_02.py:60]: =======================================
[2017-10-20 01:43:07,859 AE_UNIGRAMA_6L_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f2357d377b8>, 'discard_decoder_function': True}
[2017-10-20 01:43:08,013 AE_UNIGRAMA_6L_UNDER_02.py:76]: training and evaluate autoencoder
[2017-10-20 01:43:46,020 AE_UNIGRAMA_6L_UNDER_02.py:88]: trained and evaluated!
[2017-10-20 01:43:46,020 AE_UNIGRAMA_6L_UNDER_02.py:91]: Training history: 
{'val_loss': [0.010081703314162985, 0.0098022378247134296, 0.0095461436779304062, 0.0093120300283717847, 0.0090977178685727172, 0.0089007939894070864, 0.0087206717303583616, 0.008556038954859551, 0.0084054503091316683, 0.0082674644399281984, 0.0081408078259473399, 0.0080242870309732879, 0.0079168927159894362, 0.007817703150351251, 0.0077258427558141345, 0.0076405715654330629, 0.0075612695399519458, 0.0074874286342509174, 0.0074184480119759708, 0.0073539836117547681, 0.0072935611601628115, 0.007236738003734984, 0.0071833023877613603, 0.0071328582075947276, 0.0070852219580662297, 0.0070401742451973118, 0.0069974778067722196, 0.0069569592177175458, 0.0069184165039414807, 0.0068816932499907273, 0.0068465698281905468, 0.0068129864400148831, 0.0067808695802236574, 0.0067500868469449003, 0.0067205241635497175, 0.0066922353372864118, 0.0066651373315727179, 0.0066391769831231533, 0.0066142608827070015, 0.0065903005114026011, 0.0065672579688819807, 0.0065450726932115497, 0.0065236854017279404, 0.0065030493776982159, 0.0064831852573610594, 0.0064640347586189945, 0.0064456005179112062, 0.0064277910111562031, 0.0064106439950020787, 0.0063940970829539142, 0.0063781094266496408, 0.006362666479800049, 0.0063477416962495967, 0.0063333224425556273, 0.0063194010725251808, 0.0063059570226250529, 0.0062929028229697925, 0.0062802947683737627, 0.0062680952527930742, 0.0062562616084975821, 0.0062448248461055046, 0.0062337294238235209, 0.0062230305822365342, 0.0062126635996188591, 0.0062026326617288328, 0.006192896560139151, 0.0061834983226451952, 0.0061743855355203591, 0.0061655594312956339, 0.0061570005318267642, 0.006148699447720357, 0.0061406567277296764, 0.0061328566016899391, 0.0061252693521018147, 0.0061179295313790382, 0.0061108247138088965, 0.0061039087729577021, 0.0060972151966232346, 0.0060907163861515798, 0.0060844041483275949, 0.0060782898130885511, 0.0060722455088063022, 0.0060660194529421271, 0.0060598282558933514, 0.0060537953282876087, 0.0060479545110635816, 0.0060422968285566815, 0.0060368076721587149, 0.0060314868289464913, 0.0060263399093595359, 0.0060213582614457523, 0.0060165194624889513, 0.006011829434523574, 0.0060072875024273047, 0.0060028840379173203, 0.0059986103042184644, 0.0059944643452071126, 0.0059904435833008978, 0.0059865392609516708, 0.0059827512864120387, 0.0059790753112018771, 0.0059755128015483621], 'loss': [0.010227520610122829, 0.0099365946521367769, 0.0096682850769466248, 0.0094227169387926333, 0.009198194931787293, 0.0089920769893800691, 0.0088030209057330718, 0.0086301705921921681, 0.0084720695913341713, 0.0083272828964932096, 0.0081944493983300386, 0.0080723148543380783, 0.0079597710848161429, 0.0078559078982520045, 0.0077598036731093591, 0.0076706786079019694, 0.0075877925679293705, 0.0075106250480522609, 0.0074386277966448592, 0.007371296639913108, 0.0073082365322292547, 0.0072490335931542395, 0.0071932708137035003, 0.0071407529550072749, 0.007091093704232645, 0.0070441276199666907, 0.0069996352698459318, 0.0069574231145068883, 0.0069172999829617138, 0.006879062988276158, 0.0068425370761512174, 0.0068075552822583537, 0.0067740927144688155, 0.0067420740604409793, 0.0067113039559457445, 0.0066818001361812233, 0.0066535448207283542, 0.0066264721550065714, 0.0066004645585391007, 0.0065754803049835461, 0.0065514269309517939, 0.0065282880862088345, 0.0065059854721131868, 0.00648444792892287, 0.0064636680051986615, 0.0064436398602829769, 0.0064243526271239295, 0.0064057370489800933, 0.0063877537449880213, 0.0063704375887991428, 0.0063536913559463538, 0.0063375182482445433, 0.0063218588070152867, 0.006306727052183699, 0.0062921054695046566, 0.0062779776114322465, 0.0062643024720109601, 0.0062510331740033868, 0.0062382038308910854, 0.0062257774968728303, 0.0062137216057104056, 0.0062020581101709044, 0.0061907440806912477, 0.0061798277588649333, 0.0061692375052644745, 0.0061589738608240057, 0.0061490172883764726, 0.0061393890191572499, 0.0061300605985999436, 0.006121008578497864, 0.0061122196149504581, 0.0061036998084926615, 0.0060954416069398465, 0.0060874096340583963, 0.0060796107997809845, 0.0060720564917728223, 0.0060647288932663647, 0.0060576088171275981, 0.0060506986102665137, 0.0060439887768563199, 0.0060374627809126682, 0.006031130980608668, 0.0060247229913063007, 0.0060182392311562364, 0.0060118645261893, 0.0060056709900805205, 0.0059996694870196971, 0.0059938494934051881, 0.0059881899271162654, 0.0059827279838142065, 0.0059774240659757043, 0.0059722798127170417, 0.0059672847147470027, 0.0059624433431021079, 0.0059577434546398324, 0.0059531898831361339, 0.0059487770126071277, 0.0059444837294491473, 0.0059403115099258197, 0.005936265975458991, 0.0059323382876428745, 0.0059285166054579399]}
[2017-10-20 01:43:46,020 AE_UNIGRAMA_6L_UNDER_02.py:95]: done!
[2017-10-20 01:43:46,020 AE_UNIGRAMA_6L_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-10-20 01:43:46,021 AE_UNIGRAMA_6L_UNDER_02.py:100]: =======================================
[2017-10-20 01:43:46,021 AE_UNIGRAMA_6L_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f2357d37898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:43:46,060 AE_UNIGRAMA_6L_UNDER_02.py:113]: training ... 
[2017-10-20 01:44:50,750 AE_UNIGRAMA_6L_UNDER_02.py:125]: trained!
[2017-10-20 01:44:50,751 AE_UNIGRAMA_6L_UNDER_02.py:128]: Training history: 
{'val_loss': [0.010081703314162985, 0.0098022378247134296, 0.0095461436779304062, 0.0093120300283717847, 0.0090977178685727172, 0.0089007939894070864, 0.0087206717303583616, 0.008556038954859551, 0.0084054503091316683, 0.0082674644399281984, 0.0081408078259473399, 0.0080242870309732879, 0.0079168927159894362, 0.007817703150351251, 0.0077258427558141345, 0.0076405715654330629, 0.0075612695399519458, 0.0074874286342509174, 0.0074184480119759708, 0.0073539836117547681, 0.0072935611601628115, 0.007236738003734984, 0.0071833023877613603, 0.0071328582075947276, 0.0070852219580662297, 0.0070401742451973118, 0.0069974778067722196, 0.0069569592177175458, 0.0069184165039414807, 0.0068816932499907273, 0.0068465698281905468, 0.0068129864400148831, 0.0067808695802236574, 0.0067500868469449003, 0.0067205241635497175, 0.0066922353372864118, 0.0066651373315727179, 0.0066391769831231533, 0.0066142608827070015, 0.0065903005114026011, 0.0065672579688819807, 0.0065450726932115497, 0.0065236854017279404, 0.0065030493776982159, 0.0064831852573610594, 0.0064640347586189945, 0.0064456005179112062, 0.0064277910111562031, 0.0064106439950020787, 0.0063940970829539142, 0.0063781094266496408, 0.006362666479800049, 0.0063477416962495967, 0.0063333224425556273, 0.0063194010725251808, 0.0063059570226250529, 0.0062929028229697925, 0.0062802947683737627, 0.0062680952527930742, 0.0062562616084975821, 0.0062448248461055046, 0.0062337294238235209, 0.0062230305822365342, 0.0062126635996188591, 0.0062026326617288328, 0.006192896560139151, 0.0061834983226451952, 0.0061743855355203591, 0.0061655594312956339, 0.0061570005318267642, 0.006148699447720357, 0.0061406567277296764, 0.0061328566016899391, 0.0061252693521018147, 0.0061179295313790382, 0.0061108247138088965, 0.0061039087729577021, 0.0060972151966232346, 0.0060907163861515798, 0.0060844041483275949, 0.0060782898130885511, 0.0060722455088063022, 0.0060660194529421271, 0.0060598282558933514, 0.0060537953282876087, 0.0060479545110635816, 0.0060422968285566815, 0.0060368076721587149, 0.0060314868289464913, 0.0060263399093595359, 0.0060213582614457523, 0.0060165194624889513, 0.006011829434523574, 0.0060072875024273047, 0.0060028840379173203, 0.0059986103042184644, 0.0059944643452071126, 0.0059904435833008978, 0.0059865392609516708, 0.0059827512864120387, 0.0059790753112018771, 0.0059755128015483621], 'loss': [0.010227520610122829, 0.0099365946521367769, 0.0096682850769466248, 0.0094227169387926333, 0.009198194931787293, 0.0089920769893800691, 0.0088030209057330718, 0.0086301705921921681, 0.0084720695913341713, 0.0083272828964932096, 0.0081944493983300386, 0.0080723148543380783, 0.0079597710848161429, 0.0078559078982520045, 0.0077598036731093591, 0.0076706786079019694, 0.0075877925679293705, 0.0075106250480522609, 0.0074386277966448592, 0.007371296639913108, 0.0073082365322292547, 0.0072490335931542395, 0.0071932708137035003, 0.0071407529550072749, 0.007091093704232645, 0.0070441276199666907, 0.0069996352698459318, 0.0069574231145068883, 0.0069172999829617138, 0.006879062988276158, 0.0068425370761512174, 0.0068075552822583537, 0.0067740927144688155, 0.0067420740604409793, 0.0067113039559457445, 0.0066818001361812233, 0.0066535448207283542, 0.0066264721550065714, 0.0066004645585391007, 0.0065754803049835461, 0.0065514269309517939, 0.0065282880862088345, 0.0065059854721131868, 0.00648444792892287, 0.0064636680051986615, 0.0064436398602829769, 0.0064243526271239295, 0.0064057370489800933, 0.0063877537449880213, 0.0063704375887991428, 0.0063536913559463538, 0.0063375182482445433, 0.0063218588070152867, 0.006306727052183699, 0.0062921054695046566, 0.0062779776114322465, 0.0062643024720109601, 0.0062510331740033868, 0.0062382038308910854, 0.0062257774968728303, 0.0062137216057104056, 0.0062020581101709044, 0.0061907440806912477, 0.0061798277588649333, 0.0061692375052644745, 0.0061589738608240057, 0.0061490172883764726, 0.0061393890191572499, 0.0061300605985999436, 0.006121008578497864, 0.0061122196149504581, 0.0061036998084926615, 0.0060954416069398465, 0.0060874096340583963, 0.0060796107997809845, 0.0060720564917728223, 0.0060647288932663647, 0.0060576088171275981, 0.0060506986102665137, 0.0060439887768563199, 0.0060374627809126682, 0.006031130980608668, 0.0060247229913063007, 0.0060182392311562364, 0.0060118645261893, 0.0060056709900805205, 0.0059996694870196971, 0.0059938494934051881, 0.0059881899271162654, 0.0059827279838142065, 0.0059774240659757043, 0.0059722798127170417, 0.0059672847147470027, 0.0059624433431021079, 0.0059577434546398324, 0.0059531898831361339, 0.0059487770126071277, 0.0059444837294491473, 0.0059403115099258197, 0.005936265975458991, 0.0059323382876428745, 0.0059285166054579399]}
[2017-10-20 01:44:50,751 AE_UNIGRAMA_6L_UNDER_02.py:132]: evaluating model ... 
[2017-10-20 01:44:50,807 AE_UNIGRAMA_6L_UNDER_02.py:136]: evaluated! 
[2017-10-20 01:44:50,807 AE_UNIGRAMA_6L_UNDER_02.py:138]: generating reports ... 
[2017-10-20 01:44:51,448 AE_UNIGRAMA_6L_UNDER_02.py:141]: done!
[2017-10-20 01:44:51,448 AE_UNIGRAMA_6L_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_6L_UNDER_02 finished!
