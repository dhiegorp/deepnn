[2017-11-18 16:22:23,674 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_9FULLDS_OVER_04
[2017-11-18 16:22:23,674 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 16:22:23,675 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_9FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f935079fe48>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f93507a3390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:22:23,675 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 16:22:25,829 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:22:25,830 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:22:25,830 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 16:22:25,830 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f935079fe48>, 'discard_decoder_function': True}
[2017-11-18 16:22:25,975 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 16:24:55,880 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 16:24:55,881 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.009362794386646691, 0.0085630160857379459, 0.0079512506528651074, 0.007483940071144642, 0.0071324190163888374, 0.0068671723257151982, 0.0066665843043932247, 0.0065144366165092544, 0.006398292221587585, 0.0063093229934904497, 0.0062407049783757065, 0.0061872255184421731, 0.0061453317528373562, 0.006112229386026239, 0.0060855193719581363, 0.0060643863554315581, 0.0060471781292120433, 0.0060330668074283882, 0.0060214296490561873, 0.006011804983616067, 0.0060038426460562021, 0.005997165375006156, 0.005991578014404573, 0.0059868524821207495, 0.0059828728685399893, 0.005979418816272195, 0.005976520260783629, 0.0059740289101751576, 0.005971872145501717, 0.0059700049593420382, 0.0059683999166991976, 0.0059670053178753233, 0.0059656625556581896, 0.0059645159303688827, 0.0059608310464980439, 0.0059576375915325608, 0.0059551174684986611, 0.0059530573590901277, 0.0059513487610610002, 0.0059499257644285881, 0.0059487366538360656, 0.0059477247360057361, 0.0059468585189886439, 0.0059461129677147546, 0.0059454669171854586, 0.0059448990142380205, 0.0059443933019727377, 0.0059439049930493483, 0.0059434231685577881, 0.0059430363398245189, 0.0059426849502084373, 0.0059423628757758777, 0.0059420606322505764, 0.0059417844935669775, 0.0059415293130640296, 0.0059412849840435288, 0.0059410569962943761, 0.0059408409854185655, 0.005940632051533278, 0.0059404094253921007, 0.005940166216885116, 0.0059399471793820735, 0.0059397489181420232, 0.0059395658490800796, 0.0059393877434780092, 0.005939216997754411, 0.0059390508833155444, 0.0059388804059333274, 0.0059387124927686398, 0.0059385427003586034, 0.005938376106738699, 0.0059382063674664164, 0.0059380371220073072, 0.0059378719769687949, 0.0059377083457145229, 0.0059375425678147679, 0.0059373745409301518, 0.0059372128711521173, 0.0059370409162665108, 0.0059368700283288257, 0.0059366965702694159, 0.0059365258007579016, 0.0059363278777683232, 0.0059361294378622005, 0.0059359375129356979, 0.0059357449694378154, 0.0059355523917982841, 0.0059353579845428687, 0.0059351616509796803, 0.0059349669419257785, 0.0059347695294351419, 0.0059345747247161679, 0.0059343791553611676, 0.0059341799401230111, 0.0059339819580914834, 0.0059337878553727312, 0.0059335862910351042, 0.0059333879058925286, 0.0059331941959310909, 0.0059329951561074221, 0.0059328003792836308], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098585625391394514, 0.0089497556545254618, 0.0082487759850365956, 0.0077127565119822026, 0.007307183380934089, 0.0070018332395110454, 0.006771370483560293, 0.0065969980171614916, 0.0064645887179796543, 0.0063633871977165479, 0.0062857492088634129, 0.006225688696491513, 0.0061788786304637936, 0.0061420501051240861, 0.0061127108618241194, 0.0060893526540620347, 0.0060706519978117497, 0.0060554276241305757, 0.0060429087422428735, 0.0060325787416750177, 0.0060240679381206507, 0.0060170296059695724, 0.0060111202299137616, 0.0060061700727845006, 0.0060019994190467331, 0.0059984463755266794, 0.005995419561212266, 0.0059928720066150347, 0.0059906728474812647, 0.005988784760204275, 0.0059871483457915927, 0.0059857499080170429, 0.0059844683628857169, 0.0059833165139967686, 0.0059809488913324859, 0.005977429143709044, 0.0059745737764839418, 0.0059722805776047687, 0.0059704033713808367, 0.0059688444473045988, 0.0059675443413956253, 0.0059664504450741424, 0.0059655193687907365, 0.0059647254423596486, 0.0059640336123515641, 0.005963432726958851, 0.0059629045215934765, 0.0059624232462779595, 0.0059619115817479357, 0.0059615049725077196, 0.0059611339731240462, 0.0059608042920201495, 0.0059604989562507815, 0.0059602192640318286, 0.0059599586902752133, 0.0059597130777522128, 0.0059594822665935973, 0.0059592612807909751, 0.0059590552143255994, 0.0059588496461012242, 0.005958620323492615, 0.0059583843080389786, 0.0059581843807921132, 0.0059579975503046764, 0.0059578261530566128, 0.0059576544759659495, 0.0059574868641377619, 0.0059573188331744067, 0.0059571507208189215, 0.0059569845429554309, 0.0059568209466627879, 0.0059566517921565421, 0.0059564881052694297, 0.0059563219902790719, 0.0059561577085549622, 0.0059559904680783629, 0.0059558318391061855, 0.0059556682025175807, 0.0059555030660618045, 0.0059553303281299113, 0.005955162040358385, 0.0059549920581559203, 0.005954812127823378, 0.0059546120035549764, 0.0059544217318494887, 0.0059542294729528905, 0.0059540400663817151, 0.0059538482460537992, 0.0059536574086615848, 0.0059534635231798744, 0.0059532708508066891, 0.005953070519056948, 0.0059528785364591913, 0.0059526835920796026, 0.0059524875515926737, 0.0059522935835185286, 0.0059520933590532154, 0.0059519020062727811, 0.0059517125978154123, 0.0059515174881937978, 0.0059513253551006237], 'acc': [0.5846323800464488, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822264767316, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822267327968, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822266596353, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822267327968, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822270254427, 0.59383822263669894, 0.59383822265133124, 0.59383822263669894, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822267327968, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822263669894, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427]}
[2017-11-18 16:24:55,881 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 16:24:55,882 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 16:24:55,882 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 16:24:55,882 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f93507a3390>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:24:55,948 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 16:27:18,977 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_9FULLDS_OVER_04
[2017-11-18 16:27:18,977 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 16:27:18,977 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_9FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe17bcf0eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe17bcf5400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:27:18,977 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 16:27:21,168 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:27:21,169 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:27:21,169 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 16:27:21,169 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fe17bcf0eb8>, 'discard_decoder_function': True}
[2017-11-18 16:27:21,314 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 16:29:47,486 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 16:29:47,487 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0093348114735877109, 0.0084862670659586296, 0.0078686738009566288, 0.0074144708302771502, 0.0070733616716587471, 0.0068123062457499132, 0.0066089735442388482, 0.0064476222952965408, 0.0063177859550975169, 0.006211917642202777, 0.0061247454900041258, 0.0060521925572622178, 0.0059911746214096357, 0.0059395730281532775, 0.0058956423696323555, 0.0058580309216608043, 0.0058225846985606247, 0.0057917115454298798, 0.0057653373789975952, 0.0057427076440926088, 0.0057231947769900704, 0.0057063323165981788, 0.0056917760288428404, 0.0056790991217200533, 0.005668043503530929, 0.0056583851021199385, 0.0056499198430964986, 0.0056424853317501161, 0.0056359029838110933, 0.0056300859879332673, 0.0056249353768887903, 0.0056203266243610873, 0.0056162014283076917, 0.0056124854233397942, 0.0056091344949386491, 0.0056061474330009993, 0.005603452793516572, 0.0056009948147013808, 0.0055987610163708594, 0.0055967213647410644, 0.0055948347201518157, 0.005593075507427595, 0.0055914690174013156, 0.0055899249287257131, 0.0055884481221163632, 0.0055871129200069213, 0.005585843777025268, 0.0055846523076640859, 0.0055835156771499844, 0.0055824250362927104, 0.0055813477848660241, 0.0055802667838477146, 0.0055791896505904947, 0.0055781191017941455, 0.005577056017782688, 0.0055760181413464401, 0.0055749775219410217, 0.0055739658110142195, 0.0055729191475101187, 0.0055718853675583374, 0.0055708607784700015, 0.0055698163551372538, 0.0055687397668628966, 0.0055676503771815407, 0.0055665538263962753, 0.0055654627218457795, 0.0055643623094603235, 0.0055632445634709307, 0.0055621073818986344, 0.0055608560855013346, 0.0055595118267847054, 0.0055580943926740317, 0.0055565332041663832, 0.0055547794011393779, 0.0055529397927041174, 0.0055510400234318061, 0.0055491216296760671, 0.0055471987445393457, 0.0055453030380376916, 0.0055433846277673209, 0.0055410989687854385, 0.005538482981563184, 0.0055357836014380659, 0.0055330076005216718, 0.0055298034545138222, 0.0055253224927235157, 0.0055209532602067566, 0.0055169569502472714, 0.0055132448900517012, 0.0055093615826182357, 0.005506090011388797, 0.0055029086979295691, 0.0054997286339348965, 0.0054966200675160923, 0.0054936210465032533, 0.0054907253637905785, 0.0054875773760890232, 0.0054842228640126899, 0.0054804742166335062, 0.0054764832027368758, 0.0054716999508722525], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098636535309438948, 0.0088901896602656492, 0.0081615020720235808, 0.0076307580303672821, 0.0072366950870117186, 0.0069385162743072068, 0.0067085459588544349, 0.0065280479056973525, 0.0063840512198749142, 0.006267577778809554, 0.0061723454385548661, 0.0060936348501108633, 0.0060279164382118135, 0.0059725853353414134, 0.0059257272605323435, 0.0058857941154330674, 0.0058503047040945671, 0.0058175849996811701, 0.0057896662142703443, 0.0057658214465344266, 0.005745343332228846, 0.0057277022391682064, 0.005712481232800575, 0.0056993469475421334, 0.0056879016098855453, 0.0056779327040109052, 0.0056692356952138326, 0.0056616235185472626, 0.0056549283118907789, 0.0056490240909746305, 0.0056438054745975479, 0.0056391815032260807, 0.0056350415875343939, 0.0056313347032885142, 0.0056280142126843378, 0.0056250277920716985, 0.0056223609197573405, 0.0056199433738248024, 0.0056177488050013283, 0.0056157545447216945, 0.0056139216992084533, 0.0056122265183070185, 0.0056106521567617605, 0.0056091866949126191, 0.0056077561352543262, 0.0056064388271417995, 0.0056052277979445671, 0.0056040869423657986, 0.0056029887864467, 0.0056019382883053959, 0.00560092602485963, 0.0055999174856753292, 0.0055988932953105136, 0.0055978661691704797, 0.0055968526233985839, 0.005595840297365472, 0.0055948440586809471, 0.0055938536559378017, 0.0055928713583988845, 0.0055918768225474355, 0.0055908702413468171, 0.0055898653690951159, 0.0055888626802558586, 0.0055878132881672822, 0.0055867554007181068, 0.0055856932308655169, 0.0055846302490921472, 0.0055835439884269018, 0.0055824393136498828, 0.0055812880871477953, 0.0055800113094575284, 0.0055786552035919767, 0.0055772024321703514, 0.0055755825143531963, 0.0055738241576701788, 0.005572003035024092, 0.0055701497436251995, 0.0055682601647688611, 0.0055663907294355606, 0.0055645401509552082, 0.0055625277437746151, 0.0055601188330096606, 0.005557560738246068, 0.0055549369091073162, 0.0055520841324267741, 0.0055484629211126771, 0.005544073327578356, 0.0055400459858886896, 0.0055363297398904358, 0.005532655353681107, 0.0055292497859538202, 0.0055261489176626358, 0.0055230661731236648, 0.0055199998068644167, 0.005517039259860702, 0.0055141938683155407, 0.0055113087977074994, 0.0055081062885377402, 0.0055046431167887749, 0.0055008435986407499, 0.005496576845376579], 'acc': [0.55161409105452142, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822264767316, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822267327968, 0.59383822270254427, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822264767316, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822264767316, 0.5938382226842539, 0.59383822262938279, 0.59383822272449271, 0.59383822267327968, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822266596353, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.5938382226001182, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.5938382226842539, 0.59383822267327968, 0.59383822265133124, 0.5938382226001182, 0.59383822266596353, 0.59383822272449271, 0.59383822265133124, 0.59383822270254427]}
[2017-11-18 16:29:47,487 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 16:29:47,487 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 16:29:47,487 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 16:29:47,487 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fe17bcf5400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:29:47,520 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 16:37:57,138 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_9FULLDS_OVER_04
[2017-11-18 16:37:57,139 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:149]: >> Printing header log
[2017-11-18 16:37:57,139 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_9FULLDS_OVER_04
	layers = 96,134,122,109,97,84,72,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8cb644bb70>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8cb644b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 16:37:57,139 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:151]: >> Loading dataset... 
[2017-11-18 16:37:59,285 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 16:37:59,285 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-11-18 16:37:59,285 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:60]: =======================================
[2017-11-18 16:37:59,286 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f8cb644bb70>, 'discard_decoder_function': True}
[2017-11-18 16:37:59,431 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:76]: training and evaluate autoencoder
[2017-11-18 16:40:18,743 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:88]: trained and evaluated!
[2017-11-18 16:40:18,744 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:91]: Training history: 
{'val_loss': [0.0096487263717285766, 0.0089550249094402946, 0.008397175651830879, 0.0079475296902559618, 0.0075828329068209832, 0.0072832896664412816, 0.00703701648679081, 0.0068345060173281083, 0.0066671712068688211, 0.0065264608748654192, 0.0064080001424227252, 0.0063093427039179039, 0.0062269606344807086, 0.0061579031164003878, 0.0060998853391877692, 0.006051041533090982, 0.0060099030209781216, 0.0059750639028828051, 0.0059454914428689375, 0.0059202604313428591, 0.0058987697397996372, 0.0058803695634976772, 0.0058645948183061181, 0.0058510455612479292, 0.0058394240602017136, 0.0058293580466067469, 0.0058190977191110993, 0.0058090938223530671, 0.0058006430338268626, 0.0057934552941263234, 0.0057873180686629343, 0.0057820438759730707, 0.0057753460039033835, 0.0057674447771569786, 0.0057608893541437776, 0.0057554040431876379, 0.0057507586179082774, 0.0057468069343355674, 0.0057434172441245754, 0.0057405060045427969, 0.0057379942272167868, 0.0057358338092157709, 0.0057339513774835281, 0.0057322949894800784, 0.0057308255517338454, 0.0057295368555988005, 0.0057284132891855877, 0.0057274079274075382, 0.0057265189106143859, 0.0057257211903019101, 0.005725007713609777, 0.005724361128451351, 0.0057237854687608603, 0.0057232609752514967, 0.0057227851952864582, 0.0057223563462267162, 0.0057219675403582569, 0.0057216171043980094, 0.0057212914363643681, 0.0057209920817017498, 0.0057207136710154876, 0.0057204600983360582, 0.0057202205609548007, 0.005720002592025473, 0.0057198018717310173, 0.0057196118223704386, 0.0057194330321384598, 0.0057192667450232841, 0.0057191084800832298, 0.0057189608316557759, 0.0057188192696831864, 0.0057186790879231219, 0.005718548318134324, 0.0057184231035939826, 0.005718302304364634, 0.0057181861484851123, 0.0057180720464097461, 0.0057179597794266195, 0.0057178490074883317, 0.0057177391554920692, 0.0057176329646100735, 0.0057175285701435612, 0.0057174159943453699, 0.0057172736460880374, 0.0057170992786970392, 0.0057169139822133815, 0.0057167450387238944, 0.0057166128607418218, 0.0057164929359322996, 0.0057163760357819438, 0.0057162432577111885, 0.005716102098421807, 0.0057159687199200976, 0.005715845741786115, 0.0057157248948097985, 0.0057156061259389622, 0.0057154910892894366, 0.0057153748275622458, 0.0057152596906269735, 0.0057151431354013973, 0.0057150284725130812], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010055232793092728, 0.0092934325230639957, 0.0086728511203267439, 0.0081732242632343161, 0.00776995738644285, 0.0074407348448848002, 0.0071707151538579353, 0.0069487159114915839, 0.0067660004522171772, 0.0066143403516683835, 0.0064858755273295206, 0.0063788100625079107, 0.0062896233836557689, 0.0062150909031310469, 0.0061526196995985325, 0.0061001389950323618, 0.0060560071176256128, 0.0060188281826530441, 0.0059873144529513879, 0.0059605763025505935, 0.0059377678656385652, 0.0059183539456433062, 0.0059017411770846189, 0.0058875152852298903, 0.0058753072805208849, 0.0058648233562346667, 0.0058553482420016381, 0.0058451169863186856, 0.0058361893565256461, 0.0058286413357184902, 0.0058222275313730256, 0.0058167592585301733, 0.0058115350125499034, 0.0058038615996235934, 0.0057968719062998176, 0.0057910599114678087, 0.0057861853598527736, 0.0057820511715605764, 0.0057785282575318316, 0.0057755138826668193, 0.0057729222624625211, 0.00577068864067826, 0.0057687645561319122, 0.0057670921805161885, 0.0057656076007762819, 0.005764304743824787, 0.0057631664621577766, 0.0057621654455152311, 0.0057612779196221445, 0.0057604912127414681, 0.0057597833831785532, 0.005759148990178241, 0.0057585782243314513, 0.0057580669765931423, 0.0057576018690466664, 0.0057571834548041214, 0.0057568050978920888, 0.0057564580879810104, 0.0057561469190709758, 0.0057558599369408594, 0.005755591294389276, 0.0057553452367244927, 0.0057551183198705884, 0.0057549081447031162, 0.005754711357797781, 0.0057545318854674357, 0.0057543627944630542, 0.005754205132022407, 0.0057540523165859111, 0.005753910965722306, 0.0057537692855177984, 0.0057536446109525668, 0.005753515548128427, 0.0057533965933607503, 0.0057532849893197043, 0.0057531696284374781, 0.0057530628283039087, 0.005752955568567736, 0.005752848338553408, 0.0057527474735292964, 0.0057526449432245162, 0.0057525418281995973, 0.0057524427066474688, 0.0057523206005640429, 0.0057521624275935533, 0.0057519868936362706, 0.0057518077305274262, 0.0057516663211918074, 0.0057515435577983522, 0.0057514300239522196, 0.0057513159966663058, 0.0057511805040354642, 0.0057510519537988308, 0.0057509263263055303, 0.0057508071076993244, 0.0057506902780435493, 0.0057505739552023861, 0.0057504629473129568, 0.0057503477282382252, 0.0057502353655470911, 0.005750121812724703], 'acc': [0.43918006627475087, 0.59383822270254427, 0.59383822262938279, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822268059583, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822262938279, 0.5938382226842539, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198]}
[2017-11-18 16:40:18,744 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:95]: done!
[2017-11-18 16:40:18,744 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:155]: >> Executing classifier part ... 
[2017-11-18 16:40:18,744 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:100]: =======================================
[2017-11-18 16:40:18,744 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f8cb644b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 16:40:18,775 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:113]: training ... 
[2017-11-18 16:46:45,274 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:125]: trained!
[2017-11-18 16:46:45,275 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:128]: Training history: 
{'val_loss': [0.0096487263717285766, 0.0089550249094402946, 0.008397175651830879, 0.0079475296902559618, 0.0075828329068209832, 0.0072832896664412816, 0.00703701648679081, 0.0068345060173281083, 0.0066671712068688211, 0.0065264608748654192, 0.0064080001424227252, 0.0063093427039179039, 0.0062269606344807086, 0.0061579031164003878, 0.0060998853391877692, 0.006051041533090982, 0.0060099030209781216, 0.0059750639028828051, 0.0059454914428689375, 0.0059202604313428591, 0.0058987697397996372, 0.0058803695634976772, 0.0058645948183061181, 0.0058510455612479292, 0.0058394240602017136, 0.0058293580466067469, 0.0058190977191110993, 0.0058090938223530671, 0.0058006430338268626, 0.0057934552941263234, 0.0057873180686629343, 0.0057820438759730707, 0.0057753460039033835, 0.0057674447771569786, 0.0057608893541437776, 0.0057554040431876379, 0.0057507586179082774, 0.0057468069343355674, 0.0057434172441245754, 0.0057405060045427969, 0.0057379942272167868, 0.0057358338092157709, 0.0057339513774835281, 0.0057322949894800784, 0.0057308255517338454, 0.0057295368555988005, 0.0057284132891855877, 0.0057274079274075382, 0.0057265189106143859, 0.0057257211903019101, 0.005725007713609777, 0.005724361128451351, 0.0057237854687608603, 0.0057232609752514967, 0.0057227851952864582, 0.0057223563462267162, 0.0057219675403582569, 0.0057216171043980094, 0.0057212914363643681, 0.0057209920817017498, 0.0057207136710154876, 0.0057204600983360582, 0.0057202205609548007, 0.005720002592025473, 0.0057198018717310173, 0.0057196118223704386, 0.0057194330321384598, 0.0057192667450232841, 0.0057191084800832298, 0.0057189608316557759, 0.0057188192696831864, 0.0057186790879231219, 0.005718548318134324, 0.0057184231035939826, 0.005718302304364634, 0.0057181861484851123, 0.0057180720464097461, 0.0057179597794266195, 0.0057178490074883317, 0.0057177391554920692, 0.0057176329646100735, 0.0057175285701435612, 0.0057174159943453699, 0.0057172736460880374, 0.0057170992786970392, 0.0057169139822133815, 0.0057167450387238944, 0.0057166128607418218, 0.0057164929359322996, 0.0057163760357819438, 0.0057162432577111885, 0.005716102098421807, 0.0057159687199200976, 0.005715845741786115, 0.0057157248948097985, 0.0057156061259389622, 0.0057154910892894366, 0.0057153748275622458, 0.0057152596906269735, 0.0057151431354013973, 0.0057150284725130812], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010055232793092728, 0.0092934325230639957, 0.0086728511203267439, 0.0081732242632343161, 0.00776995738644285, 0.0074407348448848002, 0.0071707151538579353, 0.0069487159114915839, 0.0067660004522171772, 0.0066143403516683835, 0.0064858755273295206, 0.0063788100625079107, 0.0062896233836557689, 0.0062150909031310469, 0.0061526196995985325, 0.0061001389950323618, 0.0060560071176256128, 0.0060188281826530441, 0.0059873144529513879, 0.0059605763025505935, 0.0059377678656385652, 0.0059183539456433062, 0.0059017411770846189, 0.0058875152852298903, 0.0058753072805208849, 0.0058648233562346667, 0.0058553482420016381, 0.0058451169863186856, 0.0058361893565256461, 0.0058286413357184902, 0.0058222275313730256, 0.0058167592585301733, 0.0058115350125499034, 0.0058038615996235934, 0.0057968719062998176, 0.0057910599114678087, 0.0057861853598527736, 0.0057820511715605764, 0.0057785282575318316, 0.0057755138826668193, 0.0057729222624625211, 0.00577068864067826, 0.0057687645561319122, 0.0057670921805161885, 0.0057656076007762819, 0.005764304743824787, 0.0057631664621577766, 0.0057621654455152311, 0.0057612779196221445, 0.0057604912127414681, 0.0057597833831785532, 0.005759148990178241, 0.0057585782243314513, 0.0057580669765931423, 0.0057576018690466664, 0.0057571834548041214, 0.0057568050978920888, 0.0057564580879810104, 0.0057561469190709758, 0.0057558599369408594, 0.005755591294389276, 0.0057553452367244927, 0.0057551183198705884, 0.0057549081447031162, 0.005754711357797781, 0.0057545318854674357, 0.0057543627944630542, 0.005754205132022407, 0.0057540523165859111, 0.005753910965722306, 0.0057537692855177984, 0.0057536446109525668, 0.005753515548128427, 0.0057533965933607503, 0.0057532849893197043, 0.0057531696284374781, 0.0057530628283039087, 0.005752955568567736, 0.005752848338553408, 0.0057527474735292964, 0.0057526449432245162, 0.0057525418281995973, 0.0057524427066474688, 0.0057523206005640429, 0.0057521624275935533, 0.0057519868936362706, 0.0057518077305274262, 0.0057516663211918074, 0.0057515435577983522, 0.0057514300239522196, 0.0057513159966663058, 0.0057511805040354642, 0.0057510519537988308, 0.0057509263263055303, 0.0057508071076993244, 0.0057506902780435493, 0.0057505739552023861, 0.0057504629473129568, 0.0057503477282382252, 0.0057502353655470911, 0.005750121812724703], 'acc': [0.43918006627475087, 0.59383822270254427, 0.59383822262938279, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.5938382226001182, 0.59383822268059583, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822272449271, 0.59383822263669894, 0.59383822268791198, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822262938279, 0.5938382226842539, 0.59383822264767316, 0.5938382226842539, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198]}
[2017-11-18 16:46:45,275 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:132]: evaluating model ... 
[2017-11-18 16:46:45,424 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:136]: evaluated! 
[2017-11-18 16:46:45,424 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:138]: generating reports ... 
[2017-11-18 16:46:46,233 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:141]: done!
[2017-11-18 16:46:46,234 AE_UNIGRAMA_6L_9FULLDS_OVER_04.py:157]: >> experiment AE_UNIGRAMA_6L_9FULLDS_OVER_04 finished!
