[2017-11-18 18:21:38,279 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_9FULLDS_OVER_05
[2017-11-18 18:21:38,279 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 18:21:38,279 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_9FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5f4f9caeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5f4f9cf400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:21:38,279 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 18:21:40,615 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:21:40,616 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:21:40,616 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 18:21:40,616 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f5f4f9caeb8>, 'discard_decoder_function': True}
[2017-11-18 18:21:40,777 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 18:24:53,911 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 18:24:53,913 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0094820063021095607, 0.0087297662496375102, 0.0081367374874257142, 0.0076610508001108612, 0.007285944281816099, 0.0069888893799642041, 0.0067527676523156197, 0.0065640259983523923, 0.0064124357268811145, 0.0062898682435178358, 0.0061904419651984052, 0.0061089092622915314, 0.0060425074745376227, 0.0059880441087559935, 0.0059432928408990667, 0.0059063170223816195, 0.005875659932237624, 0.0058500137682716636, 0.0058285189438775564, 0.0058102505634963593, 0.0057947831823073328, 0.0057816557653449568, 0.0057704959340080025, 0.0057609960312233911, 0.0057528740479119702, 0.0057459512214802369, 0.0057400023847584258, 0.0057348857454247761, 0.0057304653713704853, 0.0057266203104561139, 0.0057233002482448289, 0.0057204274187026734, 0.005717917397404031, 0.00571572821519212, 0.0057138238429580981, 0.0057121362205655021, 0.005710645132393154, 0.0057093202628815485, 0.0057081258764202294, 0.0057070414810032419, 0.0057060094238784286, 0.0057050810562250245, 0.0057042524309603663, 0.0057035313072234112, 0.0057028982921297098, 0.0057023273609292466, 0.0057018051333472168, 0.0057013204230734228, 0.0057008505633045423, 0.0057004078729293809, 0.0056999920799271318, 0.0056995912254793118, 0.005699212874057581, 0.0056988466928074005, 0.0056985023756467353, 0.0056981705953166829, 0.005697852382997721, 0.0056975485660472544, 0.0056972551555398449, 0.0056969738979192391, 0.0056966915872983031, 0.0056964144515758743, 0.0056961269889886671, 0.0056958162779921512, 0.0056955125375395144, 0.0056952340981023895, 0.0056949810093102409, 0.0056947418199342122, 0.0056945077619025564, 0.0056942693443502715, 0.0056940401697723698, 0.0056937975219071993, 0.0056935541995947183, 0.005693273583221024, 0.0056930256031832846, 0.0056928029046515441, 0.0056925786931056755, 0.0056923523138645857, 0.0056921226899688928, 0.0056918948802012689, 0.0056916649559617472, 0.0056914399607837455, 0.005691215155395662, 0.0056909838887646887, 0.005690755841888019, 0.0056905212848235394, 0.0056902829637920068, 0.0056900422279447457, 0.0056897923894546915, 0.0056895340452445082, 0.0056892723884386957, 0.0056890017131034755, 0.0056887269198917772, 0.0056884536975382038, 0.0056881781571463588, 0.0056879022242539027, 0.0056876326527464304, 0.0056873615129478753, 0.0056870870797209325, 0.0056868037668415146, 0.0056865042559316502], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099438224155860497, 0.0090941521660914612, 0.0084267604598375172, 0.0078949937942719393, 0.0074726887900879325, 0.0071390324032268625, 0.0068744606723910836, 0.0066637000146984862, 0.0064949294112895267, 0.0063590952087771244, 0.0062489646182403409, 0.0061593301600773301, 0.0060860962739343024, 0.0060263100530363722, 0.0059772451406835637, 0.0059368476772099473, 0.0059034202890993039, 0.0058756567875813404, 0.005852413927326652, 0.0058328320807374389, 0.0058161792519903699, 0.005802128830934004, 0.0057901840677458119, 0.0057800507496567326, 0.0057714038468601042, 0.0057640197901534197, 0.0057577226726845598, 0.0057523062897244124, 0.0057476621066411358, 0.0057436313176175762, 0.0057401323435631244, 0.0057371129297022734, 0.0057345029255653048, 0.0057322224037959753, 0.0057302347924073332, 0.0057284969712899179, 0.0057269673456936416, 0.00572561218812641, 0.0057243997329093606, 0.0057233017981322184, 0.0057222856991395411, 0.0057213362148030448, 0.0057204861476367183, 0.0057197441452684558, 0.0057190932204636627, 0.0057185250309292413, 0.0057180012239967919, 0.005717520889091875, 0.0057170630762006253, 0.005716625187062235, 0.0057162153107053896, 0.0057158156352286162, 0.0057154432583517521, 0.005715091767872574, 0.0057147496650952262, 0.0057144218027967569, 0.0057141134232818547, 0.0057138148068213877, 0.0057135295805664085, 0.0057132596085910032, 0.0057129859854012808, 0.0057127184853688426, 0.0057124455554983071, 0.0057121593945484682, 0.0057118613293139064, 0.0057115859479055942, 0.0057113328180993178, 0.0057111038701002682, 0.0057108695540502644, 0.0057106380831810086, 0.0057104139547505608, 0.0057101827561219726, 0.0057099413273487267, 0.0057096882060589027, 0.0057094249405891407, 0.0057091968422919069, 0.0057089866963318629, 0.0057087649806864798, 0.0057085416389132436, 0.0057083143216717959, 0.005708095067966836, 0.0057078750715587011, 0.0057076490435594282, 0.0057074298691889309, 0.0057072033619820686, 0.0057069760157618223, 0.0057067484230217359, 0.0057065061106523389, 0.0057062681880279435, 0.0057060105520470557, 0.005705757350851195, 0.005705498165962092, 0.0057052320581694512, 0.0057049573025774432, 0.0057046840702871379, 0.0057044100326491534, 0.0057041439095954884, 0.0057038719291664219, 0.0057036040770444378, 0.00570333103954653, 0.0057030436729186259], 'acc': [0.51749110096025075, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822262206665, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822267327968, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124]}
[2017-11-18 18:24:53,913 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:95]: done!
[2017-11-18 18:24:53,913 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 18:24:53,914 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 18:24:53,914 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f5f4f9cf400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:24:53,984 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 18:31:50,375 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:125]: trained!
[2017-11-18 18:31:50,378 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0094820063021095607, 0.0087297662496375102, 0.0081367374874257142, 0.0076610508001108612, 0.007285944281816099, 0.0069888893799642041, 0.0067527676523156197, 0.0065640259983523923, 0.0064124357268811145, 0.0062898682435178358, 0.0061904419651984052, 0.0061089092622915314, 0.0060425074745376227, 0.0059880441087559935, 0.0059432928408990667, 0.0059063170223816195, 0.005875659932237624, 0.0058500137682716636, 0.0058285189438775564, 0.0058102505634963593, 0.0057947831823073328, 0.0057816557653449568, 0.0057704959340080025, 0.0057609960312233911, 0.0057528740479119702, 0.0057459512214802369, 0.0057400023847584258, 0.0057348857454247761, 0.0057304653713704853, 0.0057266203104561139, 0.0057233002482448289, 0.0057204274187026734, 0.005717917397404031, 0.00571572821519212, 0.0057138238429580981, 0.0057121362205655021, 0.005710645132393154, 0.0057093202628815485, 0.0057081258764202294, 0.0057070414810032419, 0.0057060094238784286, 0.0057050810562250245, 0.0057042524309603663, 0.0057035313072234112, 0.0057028982921297098, 0.0057023273609292466, 0.0057018051333472168, 0.0057013204230734228, 0.0057008505633045423, 0.0057004078729293809, 0.0056999920799271318, 0.0056995912254793118, 0.005699212874057581, 0.0056988466928074005, 0.0056985023756467353, 0.0056981705953166829, 0.005697852382997721, 0.0056975485660472544, 0.0056972551555398449, 0.0056969738979192391, 0.0056966915872983031, 0.0056964144515758743, 0.0056961269889886671, 0.0056958162779921512, 0.0056955125375395144, 0.0056952340981023895, 0.0056949810093102409, 0.0056947418199342122, 0.0056945077619025564, 0.0056942693443502715, 0.0056940401697723698, 0.0056937975219071993, 0.0056935541995947183, 0.005693273583221024, 0.0056930256031832846, 0.0056928029046515441, 0.0056925786931056755, 0.0056923523138645857, 0.0056921226899688928, 0.0056918948802012689, 0.0056916649559617472, 0.0056914399607837455, 0.005691215155395662, 0.0056909838887646887, 0.005690755841888019, 0.0056905212848235394, 0.0056902829637920068, 0.0056900422279447457, 0.0056897923894546915, 0.0056895340452445082, 0.0056892723884386957, 0.0056890017131034755, 0.0056887269198917772, 0.0056884536975382038, 0.0056881781571463588, 0.0056879022242539027, 0.0056876326527464304, 0.0056873615129478753, 0.0056870870797209325, 0.0056868037668415146, 0.0056865042559316502], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099438224155860497, 0.0090941521660914612, 0.0084267604598375172, 0.0078949937942719393, 0.0074726887900879325, 0.0071390324032268625, 0.0068744606723910836, 0.0066637000146984862, 0.0064949294112895267, 0.0063590952087771244, 0.0062489646182403409, 0.0061593301600773301, 0.0060860962739343024, 0.0060263100530363722, 0.0059772451406835637, 0.0059368476772099473, 0.0059034202890993039, 0.0058756567875813404, 0.005852413927326652, 0.0058328320807374389, 0.0058161792519903699, 0.005802128830934004, 0.0057901840677458119, 0.0057800507496567326, 0.0057714038468601042, 0.0057640197901534197, 0.0057577226726845598, 0.0057523062897244124, 0.0057476621066411358, 0.0057436313176175762, 0.0057401323435631244, 0.0057371129297022734, 0.0057345029255653048, 0.0057322224037959753, 0.0057302347924073332, 0.0057284969712899179, 0.0057269673456936416, 0.00572561218812641, 0.0057243997329093606, 0.0057233017981322184, 0.0057222856991395411, 0.0057213362148030448, 0.0057204861476367183, 0.0057197441452684558, 0.0057190932204636627, 0.0057185250309292413, 0.0057180012239967919, 0.005717520889091875, 0.0057170630762006253, 0.005716625187062235, 0.0057162153107053896, 0.0057158156352286162, 0.0057154432583517521, 0.005715091767872574, 0.0057147496650952262, 0.0057144218027967569, 0.0057141134232818547, 0.0057138148068213877, 0.0057135295805664085, 0.0057132596085910032, 0.0057129859854012808, 0.0057127184853688426, 0.0057124455554983071, 0.0057121593945484682, 0.0057118613293139064, 0.0057115859479055942, 0.0057113328180993178, 0.0057111038701002682, 0.0057108695540502644, 0.0057106380831810086, 0.0057104139547505608, 0.0057101827561219726, 0.0057099413273487267, 0.0057096882060589027, 0.0057094249405891407, 0.0057091968422919069, 0.0057089866963318629, 0.0057087649806864798, 0.0057085416389132436, 0.0057083143216717959, 0.005708095067966836, 0.0057078750715587011, 0.0057076490435594282, 0.0057074298691889309, 0.0057072033619820686, 0.0057069760157618223, 0.0057067484230217359, 0.0057065061106523389, 0.0057062681880279435, 0.0057060105520470557, 0.005705757350851195, 0.005705498165962092, 0.0057052320581694512, 0.0057049573025774432, 0.0057046840702871379, 0.0057044100326491534, 0.0057041439095954884, 0.0057038719291664219, 0.0057036040770444378, 0.00570333103954653, 0.0057030436729186259], 'acc': [0.51749110096025075, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822263669894, 0.59383822263669894, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822270254427, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822264767316, 0.59383822270254427, 0.5938382226842539, 0.59383822265133124, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822267327968, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822263669894, 0.59383822267327968, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822263669894, 0.59383822263669894, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822268791198, 0.59383822262206665, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822267327968, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124]}
[2017-11-18 18:31:50,378 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 18:31:50,605 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 18:31:50,605 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 18:31:51,455 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:141]: done!
[2017-11-18 18:31:51,455 AE_UNIGRAMA_6L_9FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_6L_9FULLDS_OVER_05 finished!
