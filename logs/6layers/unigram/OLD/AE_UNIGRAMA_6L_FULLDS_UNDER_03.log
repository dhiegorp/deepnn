[2017-11-13 16:54:49,553 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_FULLDS_UNDER_03
[2017-11-13 16:54:49,553 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-13 16:54:49,553 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fee07efaeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fee07eff400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 16:54:49,553 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-13 16:54:52,000 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 16:54:52,001 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-13 16:54:52,001 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:60]: =======================================
[2017-11-13 16:54:52,001 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fee07efaeb8>, 'discard_decoder_function': True}
[2017-11-13 16:54:52,145 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-13 16:58:57,294 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-13 16:58:57,295 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0099221373990709318, 0.0095834928044131341, 0.0093391440142711404, 0.0091603428419050996, 0.0090273820881713665, 0.0089268072668116615, 0.008849083901872775, 0.0087869917982090536, 0.0087334903881901207, 0.0086902599252598866, 0.0086548147662838821, 0.0086253571078641275, 0.0086007094526172612, 0.008579790201661058, 0.0085619334915282529, 0.0085465786348821616, 0.0085332481627301542, 0.0085214864108704644, 0.0085110826183689599, 0.0085019438432715078, 0.0084938862997982392, 0.0084862786902060675, 0.0084774169474648494, 0.0084698629873239655, 0.0084633004195503528, 0.0084382504411657823, 0.0084117335133536558, 0.0083901702129623983, 0.0083722720872124786, 0.0083570727107800669, 0.0083441332623346107, 0.0083332951825819922, 0.0083240222066739422, 0.0083160007920818537, 0.0083090340813094087, 0.0083029442814201698, 0.0082975890222513823, 0.0082928645433101612, 0.0082886681783477505, 0.0082849306021897471, 0.0082815795529665257, 0.0082785616776344974, 0.0082758379359454057, 0.0082733602978724494, 0.00827110117080237, 0.0082690250614534094, 0.0082671038627772381, 0.0082653065669688833, 0.0082635157127227687, 0.0082618760394096071, 0.0082602766262027151, 0.0082586481780476412, 0.0082569807967754986, 0.008255082002551031, 0.0082519383846382712, 0.0082491847379451422, 0.0082467590742434753, 0.0082446000597294917, 0.0082426465502181984, 0.0082408562025348964, 0.0082391917117512307, 0.0082376310105535828, 0.0082361571602345349, 0.0082347618507680673, 0.0082334361772591329, 0.0082321576798079377, 0.0082309223962718399, 0.0082297150428293601, 0.0082285261234814125, 0.0082273522189290193, 0.0082261873469391938, 0.0082250322779665892, 0.0082238902666772699, 0.0082227502634987723, 0.0082216191333840099, 0.0082204951516235188, 0.0082193687862796364, 0.0082182252802877505, 0.0082170715283784567, 0.0082158970642110651, 0.0082147160910538176, 0.0082134905328391586, 0.0082122133414985633, 0.0082108964907393559, 0.0082095534739572967, 0.0082081816601062112, 0.0082068001606372606, 0.0082054152144875568, 0.0082039817002592004, 0.0082025217585120509, 0.0082010736528788149, 0.0081996413595352875, 0.0081982111092143446, 0.0081967749023308251, 0.0081951760104044483, 0.0081933002353525037, 0.0081915771160842917, 0.0081900657780635492, 0.0081885952149264203, 0.0081871237827602535, 0.0081856571574644415], 'val_acc': [0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.0040426313855200296, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010135305461264453, 0.0097438810851387895, 0.0094542411972549228, 0.0092448352066619617, 0.009090338958690462, 0.0089746727382372573, 0.0088863794185331853, 0.0088175163249143047, 0.0087597271442601717, 0.0087117606231434525, 0.0086727871607458189, 0.0086406540118520933, 0.008613869808138705, 0.0085913390335007889, 0.0085721642832471013, 0.0085557708326954411, 0.0085416360533845069, 0.0085292916951399938, 0.0085183751864359464, 0.0085087665913980235, 0.0085003492691613225, 0.0084927494887903198, 0.0084845586199182171, 0.008476507507275589, 0.0084696169646542117, 0.0084552047130603408, 0.0084272447686102384, 0.0084030579539397469, 0.0083831776028614, 0.0083664967938553436, 0.0083522517780511667, 0.0083402588439260988, 0.0083300962446757488, 0.0083213627851225561, 0.0083137942147462358, 0.0083071954036914551, 0.0083014122991784591, 0.0082963198419727553, 0.0082918134180396137, 0.0082878028839960104, 0.008284231020489528, 0.008281020851485953, 0.0082781288056753589, 0.008275508058463282, 0.0082731221638948204, 0.0082709394725492512, 0.008268930142779898, 0.0082670675517015624, 0.0082652672562381017, 0.0082635659499502457, 0.008261943196326154, 0.0082603332236668905, 0.0082587028171250288, 0.0082569670100626994, 0.0082544356730185984, 0.0082515211231989176, 0.0082489887897299712, 0.0082467442020139215, 0.0082447364717370773, 0.0082429025534367113, 0.0082412093274896164, 0.0082396287680252048, 0.0082381375412233435, 0.0082367323054913198, 0.0082353920771495621, 0.00823411216603381, 0.0082328748104267806, 0.0082316728409622519, 0.0082304990240290987, 0.0082293419511258285, 0.0082281965918302152, 0.0082270603630853183, 0.0082259366153432465, 0.0082248149025187078, 0.0082237010056248287, 0.0082225917025278445, 0.008221491938656943, 0.0082203830470360395, 0.0082192558038907057, 0.0082181142176689734, 0.0082169628378707549, 0.0082157885211533496, 0.0082145601860118943, 0.0082132874960469601, 0.0082119773075165631, 0.0082106473280099315, 0.0082092976147987752, 0.0082079486083387922, 0.0082065739435817891, 0.0082051459133096437, 0.0082037223262246637, 0.008202304616520174, 0.0082008972049776412, 0.0081994958517759061, 0.008198027135270446, 0.0081963073525120975, 0.0081944881544126179, 0.0081929077107490856, 0.008191453699926533, 0.0081900124142831911, 0.0081885766681058288], 'acc': [0.041733153308880638, 0.052534675340616177, 0.052534675341530696, 0.052534675341530696, 0.052534675341530696, 0.052534675325983882, 0.044433533816128634, 0.0038050816251380877, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-13 16:58:57,295 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:95]: done!
[2017-11-13 16:58:57,296 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-13 16:58:57,296 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:100]: =======================================
[2017-11-13 16:58:57,296 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fee07eff400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 16:58:57,333 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:113]: training ... 
[2017-11-13 17:03:53,191 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:125]: trained!
[2017-11-13 17:03:53,192 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0099221373990709318, 0.0095834928044131341, 0.0093391440142711404, 0.0091603428419050996, 0.0090273820881713665, 0.0089268072668116615, 0.008849083901872775, 0.0087869917982090536, 0.0087334903881901207, 0.0086902599252598866, 0.0086548147662838821, 0.0086253571078641275, 0.0086007094526172612, 0.008579790201661058, 0.0085619334915282529, 0.0085465786348821616, 0.0085332481627301542, 0.0085214864108704644, 0.0085110826183689599, 0.0085019438432715078, 0.0084938862997982392, 0.0084862786902060675, 0.0084774169474648494, 0.0084698629873239655, 0.0084633004195503528, 0.0084382504411657823, 0.0084117335133536558, 0.0083901702129623983, 0.0083722720872124786, 0.0083570727107800669, 0.0083441332623346107, 0.0083332951825819922, 0.0083240222066739422, 0.0083160007920818537, 0.0083090340813094087, 0.0083029442814201698, 0.0082975890222513823, 0.0082928645433101612, 0.0082886681783477505, 0.0082849306021897471, 0.0082815795529665257, 0.0082785616776344974, 0.0082758379359454057, 0.0082733602978724494, 0.00827110117080237, 0.0082690250614534094, 0.0082671038627772381, 0.0082653065669688833, 0.0082635157127227687, 0.0082618760394096071, 0.0082602766262027151, 0.0082586481780476412, 0.0082569807967754986, 0.008255082002551031, 0.0082519383846382712, 0.0082491847379451422, 0.0082467590742434753, 0.0082446000597294917, 0.0082426465502181984, 0.0082408562025348964, 0.0082391917117512307, 0.0082376310105535828, 0.0082361571602345349, 0.0082347618507680673, 0.0082334361772591329, 0.0082321576798079377, 0.0082309223962718399, 0.0082297150428293601, 0.0082285261234814125, 0.0082273522189290193, 0.0082261873469391938, 0.0082250322779665892, 0.0082238902666772699, 0.0082227502634987723, 0.0082216191333840099, 0.0082204951516235188, 0.0082193687862796364, 0.0082182252802877505, 0.0082170715283784567, 0.0082158970642110651, 0.0082147160910538176, 0.0082134905328391586, 0.0082122133414985633, 0.0082108964907393559, 0.0082095534739572967, 0.0082081816601062112, 0.0082068001606372606, 0.0082054152144875568, 0.0082039817002592004, 0.0082025217585120509, 0.0082010736528788149, 0.0081996413595352875, 0.0081982111092143446, 0.0081967749023308251, 0.0081951760104044483, 0.0081933002353525037, 0.0081915771160842917, 0.0081900657780635492, 0.0081885952149264203, 0.0081871237827602535, 0.0081856571574644415], 'val_acc': [0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.046306504961411248, 0.0040426313855200296, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010135305461264453, 0.0097438810851387895, 0.0094542411972549228, 0.0092448352066619617, 0.009090338958690462, 0.0089746727382372573, 0.0088863794185331853, 0.0088175163249143047, 0.0087597271442601717, 0.0087117606231434525, 0.0086727871607458189, 0.0086406540118520933, 0.008613869808138705, 0.0085913390335007889, 0.0085721642832471013, 0.0085557708326954411, 0.0085416360533845069, 0.0085292916951399938, 0.0085183751864359464, 0.0085087665913980235, 0.0085003492691613225, 0.0084927494887903198, 0.0084845586199182171, 0.008476507507275589, 0.0084696169646542117, 0.0084552047130603408, 0.0084272447686102384, 0.0084030579539397469, 0.0083831776028614, 0.0083664967938553436, 0.0083522517780511667, 0.0083402588439260988, 0.0083300962446757488, 0.0083213627851225561, 0.0083137942147462358, 0.0083071954036914551, 0.0083014122991784591, 0.0082963198419727553, 0.0082918134180396137, 0.0082878028839960104, 0.008284231020489528, 0.008281020851485953, 0.0082781288056753589, 0.008275508058463282, 0.0082731221638948204, 0.0082709394725492512, 0.008268930142779898, 0.0082670675517015624, 0.0082652672562381017, 0.0082635659499502457, 0.008261943196326154, 0.0082603332236668905, 0.0082587028171250288, 0.0082569670100626994, 0.0082544356730185984, 0.0082515211231989176, 0.0082489887897299712, 0.0082467442020139215, 0.0082447364717370773, 0.0082429025534367113, 0.0082412093274896164, 0.0082396287680252048, 0.0082381375412233435, 0.0082367323054913198, 0.0082353920771495621, 0.00823411216603381, 0.0082328748104267806, 0.0082316728409622519, 0.0082304990240290987, 0.0082293419511258285, 0.0082281965918302152, 0.0082270603630853183, 0.0082259366153432465, 0.0082248149025187078, 0.0082237010056248287, 0.0082225917025278445, 0.008221491938656943, 0.0082203830470360395, 0.0082192558038907057, 0.0082181142176689734, 0.0082169628378707549, 0.0082157885211533496, 0.0082145601860118943, 0.0082132874960469601, 0.0082119773075165631, 0.0082106473280099315, 0.0082092976147987752, 0.0082079486083387922, 0.0082065739435817891, 0.0082051459133096437, 0.0082037223262246637, 0.008202304616520174, 0.0082008972049776412, 0.0081994958517759061, 0.008198027135270446, 0.0081963073525120975, 0.0081944881544126179, 0.0081929077107490856, 0.008191453699926533, 0.0081900124142831911, 0.0081885766681058288], 'acc': [0.041733153308880638, 0.052534675340616177, 0.052534675341530696, 0.052534675341530696, 0.052534675341530696, 0.052534675325983882, 0.044433533816128634, 0.0038050816251380877, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-13 17:03:53,193 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-13 17:03:53,303 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-13 17:03:53,304 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-13 17:03:54,205 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:141]: done!
[2017-11-13 17:03:54,205 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_6L_FULLDS_UNDER_03 finished!
[2017-11-14 07:04:35,379 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:146]: The experiment AE_UNIGRAMA_6L_FULLDS_UNDER_03 was already executed!
[2017-11-18 14:56:23,524 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:146]: The experiment AE_UNIGRAMA_6L_FULLDS_UNDER_03 was already executed!
[2017-11-18 16:22:52,914 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:146]: The experiment AE_UNIGRAMA_6L_FULLDS_UNDER_03 was already executed!
[2017-11-18 18:03:10,654 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_FULLDS_UNDER_03
[2017-11-18 18:03:10,654 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 18:03:10,654 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f7d6dd12eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f7d6dd17400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:03:10,654 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 18:03:12,827 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:03:12,827 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:03:12,827 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 18:03:12,828 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f7d6dd12eb8>, 'discard_decoder_function': True}
[2017-11-18 18:03:12,957 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 18:04:53,533 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 18:04:53,534 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0093620201512535934, 0.0086136984196311852, 0.0080420005093138694, 0.0076014574470654956, 0.0072594697928437413, 0.0069901787437011177, 0.0067741099475666974, 0.0065985854743517459, 0.0064548379544802602, 0.0063356660443020301, 0.0062356011039115013, 0.0061521180227702811, 0.0060818145626273523, 0.006022367893572033, 0.0059718314833112143, 0.0059287897210180737, 0.0058919894086311335, 0.0058594739012548872, 0.0058082931596123146, 0.0057664516937940523, 0.0057317761435470883, 0.0057027545034199489, 0.0056783162260709416, 0.0056576424182311538, 0.0056400050147128854, 0.0056248898685522016, 0.0056102728560664108, 0.0055956098279966752, 0.0055814982590069451, 0.0055680808029180337, 0.0055567497442805371, 0.0055471323300474752, 0.0055389147003183673, 0.0055318487067431352, 0.0055257388609997139, 0.0055204204846521273, 0.0055157494299471086, 0.0055116423343584487, 0.005508010274036153, 0.0055048043707174137, 0.0055019388657141285, 0.0054993826194465415, 0.0054970675403747168, 0.0054949611187178346, 0.0054930280670708468, 0.005491258511052784, 0.005489613582578292, 0.005488041163093928, 0.005486467395656191, 0.0054849219224896613, 0.0054834586321227379, 0.0054821105881326122, 0.0054808275181819294, 0.0054795982396399186, 0.0054784209622519937, 0.0054772781819626771, 0.0054761735690420149, 0.0054750870248403442, 0.0054740071961897861, 0.0054729337805217403, 0.0054718671160011124, 0.0054707993615147592, 0.005469748100696439, 0.0054687037348654152, 0.005467687488233384, 0.0054666722200719178, 0.0054656700286754116, 0.005464674569173514, 0.0054636788933556044, 0.0054626911653541865, 0.0054617056791499141, 0.0054607204216690197, 0.0054597291220575082, 0.0054587108403607214, 0.005457677864063995, 0.0054566482173053713, 0.0054555952255311187, 0.0054545409932769545, 0.0054534731059034313, 0.0054523885083747276, 0.0054512569481094163, 0.0054500983361064435, 0.005448915726374814, 0.0054476826308135634, 0.0054464066785837916, 0.0054449392011158447, 0.0054429123486682785, 0.0054414381085012278, 0.0054400510195566042, 0.0054386487661579191, 0.0054372419315318072, 0.005435736319810037, 0.0054341785003729258, 0.0054326092558052118, 0.0054310559867910332, 0.0054295141129586432, 0.0054279704848958134, 0.0054264141949018942, 0.0054248489168407903, 0.0054232679199302776, 0.0054216715544003558], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098322045083847152, 0.0089761278826052445, 0.0083242330145846671, 0.0078232039913408921, 0.0074364677358730097, 0.0071344448351708788, 0.0068946009880425417, 0.0067009586374806611, 0.0065429422598457, 0.006412952734591611, 0.006304322320675724, 0.0062135609255595395, 0.0061374657704047122, 0.0060732677263760221, 0.0060188365311762979, 0.0059725626734636033, 0.0059330933042006859, 0.0058992437742137463, 0.005856627746271062, 0.0058099908949822143, 0.005771688580475505, 0.00573980575273088, 0.005712983049168804, 0.0056903572041233606, 0.0056711572417432656, 0.0056547341774886182, 0.0056401580842825715, 0.0056250482393862848, 0.0056105396287142867, 0.0055965018667631849, 0.005584035066006827, 0.0055735048311997427, 0.00556452981312602, 0.0055568435553900739, 0.0055502102467044779, 0.0055444649296875698, 0.0055394493571214072, 0.0055350362728699099, 0.005531149356894271, 0.0055277086753223051, 0.0055246584468816229, 0.0055219328812399762, 0.005519486416352571, 0.0055172676253115943, 0.0055152505227654162, 0.0055133909754897714, 0.0055116836263507706, 0.0055100799590665625, 0.0055085084392726092, 0.0055069420362657074, 0.0055054403434877811, 0.0055040345297230342, 0.0055027240290561087, 0.0055014727874031985, 0.0055002782269658428, 0.0054991249882377071, 0.0054980095414067795, 0.0054969136828719673, 0.0054958312894188288, 0.0054947607622979041, 0.0054936878167333317, 0.0054926281768956208, 0.0054915874240328028, 0.0054905492012991787, 0.0054895337394399706, 0.0054885293554267269, 0.0054875345716836619, 0.005486551586884241, 0.0054855709839477353, 0.0054845959159617735, 0.0054836241612756147, 0.0054826537848256937, 0.0054816771030578746, 0.0054807002238684184, 0.0054796724674538028, 0.0054786436436248583, 0.0054776213664323274, 0.0054765873321925215, 0.0054755455626711398, 0.0054744886730185892, 0.0054733965746972431, 0.0054722691012647701, 0.0054711135936167301, 0.0054699242052947822, 0.0054686825991781618, 0.0054673858512660741, 0.0054654816266277769, 0.0054637422399121888, 0.0054623360375343211, 0.0054609629349460466, 0.0054595854678191813, 0.0054581789000340952, 0.0054566534781926605, 0.0054551111810879644, 0.0054535748337250197, 0.0054520558370605371, 0.0054505321866982082, 0.0054490154244877216, 0.0054474878901090117, 0.0054459574178974185, 0.0054444063881146252], 'acc': [0.54621333008940942, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822264767316, 0.59383822268059583, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822267327968, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182]}
[2017-11-18 18:04:53,534 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:95]: done!
[2017-11-18 18:04:53,534 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 18:04:53,535 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 18:04:53,535 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f7d6dd17400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:04:53,567 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 18:09:14,369 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 18:09:14,371 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0093620201512535934, 0.0086136984196311852, 0.0080420005093138694, 0.0076014574470654956, 0.0072594697928437413, 0.0069901787437011177, 0.0067741099475666974, 0.0065985854743517459, 0.0064548379544802602, 0.0063356660443020301, 0.0062356011039115013, 0.0061521180227702811, 0.0060818145626273523, 0.006022367893572033, 0.0059718314833112143, 0.0059287897210180737, 0.0058919894086311335, 0.0058594739012548872, 0.0058082931596123146, 0.0057664516937940523, 0.0057317761435470883, 0.0057027545034199489, 0.0056783162260709416, 0.0056576424182311538, 0.0056400050147128854, 0.0056248898685522016, 0.0056102728560664108, 0.0055956098279966752, 0.0055814982590069451, 0.0055680808029180337, 0.0055567497442805371, 0.0055471323300474752, 0.0055389147003183673, 0.0055318487067431352, 0.0055257388609997139, 0.0055204204846521273, 0.0055157494299471086, 0.0055116423343584487, 0.005508010274036153, 0.0055048043707174137, 0.0055019388657141285, 0.0054993826194465415, 0.0054970675403747168, 0.0054949611187178346, 0.0054930280670708468, 0.005491258511052784, 0.005489613582578292, 0.005488041163093928, 0.005486467395656191, 0.0054849219224896613, 0.0054834586321227379, 0.0054821105881326122, 0.0054808275181819294, 0.0054795982396399186, 0.0054784209622519937, 0.0054772781819626771, 0.0054761735690420149, 0.0054750870248403442, 0.0054740071961897861, 0.0054729337805217403, 0.0054718671160011124, 0.0054707993615147592, 0.005469748100696439, 0.0054687037348654152, 0.005467687488233384, 0.0054666722200719178, 0.0054656700286754116, 0.005464674569173514, 0.0054636788933556044, 0.0054626911653541865, 0.0054617056791499141, 0.0054607204216690197, 0.0054597291220575082, 0.0054587108403607214, 0.005457677864063995, 0.0054566482173053713, 0.0054555952255311187, 0.0054545409932769545, 0.0054534731059034313, 0.0054523885083747276, 0.0054512569481094163, 0.0054500983361064435, 0.005448915726374814, 0.0054476826308135634, 0.0054464066785837916, 0.0054449392011158447, 0.0054429123486682785, 0.0054414381085012278, 0.0054400510195566042, 0.0054386487661579191, 0.0054372419315318072, 0.005435736319810037, 0.0054341785003729258, 0.0054326092558052118, 0.0054310559867910332, 0.0054295141129586432, 0.0054279704848958134, 0.0054264141949018942, 0.0054248489168407903, 0.0054232679199302776, 0.0054216715544003558], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0098322045083847152, 0.0089761278826052445, 0.0083242330145846671, 0.0078232039913408921, 0.0074364677358730097, 0.0071344448351708788, 0.0068946009880425417, 0.0067009586374806611, 0.0065429422598457, 0.006412952734591611, 0.006304322320675724, 0.0062135609255595395, 0.0061374657704047122, 0.0060732677263760221, 0.0060188365311762979, 0.0059725626734636033, 0.0059330933042006859, 0.0058992437742137463, 0.005856627746271062, 0.0058099908949822143, 0.005771688580475505, 0.00573980575273088, 0.005712983049168804, 0.0056903572041233606, 0.0056711572417432656, 0.0056547341774886182, 0.0056401580842825715, 0.0056250482393862848, 0.0056105396287142867, 0.0055965018667631849, 0.005584035066006827, 0.0055735048311997427, 0.00556452981312602, 0.0055568435553900739, 0.0055502102467044779, 0.0055444649296875698, 0.0055394493571214072, 0.0055350362728699099, 0.005531149356894271, 0.0055277086753223051, 0.0055246584468816229, 0.0055219328812399762, 0.005519486416352571, 0.0055172676253115943, 0.0055152505227654162, 0.0055133909754897714, 0.0055116836263507706, 0.0055100799590665625, 0.0055085084392726092, 0.0055069420362657074, 0.0055054403434877811, 0.0055040345297230342, 0.0055027240290561087, 0.0055014727874031985, 0.0055002782269658428, 0.0054991249882377071, 0.0054980095414067795, 0.0054969136828719673, 0.0054958312894188288, 0.0054947607622979041, 0.0054936878167333317, 0.0054926281768956208, 0.0054915874240328028, 0.0054905492012991787, 0.0054895337394399706, 0.0054885293554267269, 0.0054875345716836619, 0.005486551586884241, 0.0054855709839477353, 0.0054845959159617735, 0.0054836241612756147, 0.0054826537848256937, 0.0054816771030578746, 0.0054807002238684184, 0.0054796724674538028, 0.0054786436436248583, 0.0054776213664323274, 0.0054765873321925215, 0.0054755455626711398, 0.0054744886730185892, 0.0054733965746972431, 0.0054722691012647701, 0.0054711135936167301, 0.0054699242052947822, 0.0054686825991781618, 0.0054673858512660741, 0.0054654816266277769, 0.0054637422399121888, 0.0054623360375343211, 0.0054609629349460466, 0.0054595854678191813, 0.0054581789000340952, 0.0054566534781926605, 0.0054551111810879644, 0.0054535748337250197, 0.0054520558370605371, 0.0054505321866982082, 0.0054490154244877216, 0.0054474878901090117, 0.0054459574178974185, 0.0054444063881146252], 'acc': [0.54621333008940942, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822264767316, 0.59383822268059583, 0.59383822265133124, 0.59383822267327968, 0.59383822265133124, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.5938382226001182, 0.59383822265133124, 0.59383822268791198, 0.5938382226001182, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.59383822263669894, 0.59383822266596353, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822272449271, 0.5938382226001182, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822272449271, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822268791198, 0.59383822267327968, 0.59383822268791198, 0.59383822265133124, 0.59383822268791198, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.5938382226001182, 0.5938382226001182, 0.59383822264767316, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822264767316, 0.5938382226001182, 0.59383822270254427, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182]}
[2017-11-18 18:09:14,371 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 18:09:14,513 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 18:09:14,513 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 18:09:15,376 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:141]: done!
[2017-11-18 18:09:15,377 AE_UNIGRAMA_6L_FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_6L_FULLDS_UNDER_03 finished!
