[2017-10-20 01:36:32,158 AE_UNIGRAMA_6L_OVER_04.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_OVER_04
[2017-10-20 01:36:32,158 AE_UNIGRAMA_6L_OVER_04.py:149]: >> Printing header log
[2017-10-20 01:36:32,158 AE_UNIGRAMA_6L_OVER_04.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_OVER_04
	layers = 96,134,122,109,97,84,72,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f770e8c7b70>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f770e8c7cf8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:36:32,158 AE_UNIGRAMA_6L_OVER_04.py:151]: >> Loading dataset... 
[2017-10-20 01:36:32,790 AE_UNIGRAMA_6L_OVER_04.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:36:32,791 AE_UNIGRAMA_6L_OVER_04.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:36:32,791 AE_UNIGRAMA_6L_OVER_04.py:60]: =======================================
[2017-10-20 01:36:32,791 AE_UNIGRAMA_6L_OVER_04.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f770e8c7b70>, 'discard_decoder_function': True}
[2017-10-20 01:36:32,943 AE_UNIGRAMA_6L_OVER_04.py:76]: training and evaluate autoencoder
[2017-10-20 01:37:22,636 AE_UNIGRAMA_6L_OVER_04.py:88]: trained and evaluated!
[2017-10-20 01:37:22,636 AE_UNIGRAMA_6L_OVER_04.py:91]: Training history: 
{'val_loss': [0.010238364273093669, 0.010067566540299959, 0.009898896183693941, 0.0097380076157670033, 0.0095849779112520718, 0.0094397308782684757, 0.00930172455285894, 0.0091705427203867523, 0.0090458019390757642, 0.0089268391141771822, 0.0088134794270959046, 0.0087056877264635266, 0.0086030645372145234, 0.0085053058119566906, 0.008412241856100169, 0.0083235516645651323, 0.0082389389486727214, 0.0081582393715345057, 0.0080812145959322772, 0.0080076738825019412, 0.0079374690141985858, 0.0078703693813578571, 0.0078062622472089907, 0.0077449940318123998, 0.0076864457768855482, 0.0076304256888348821, 0.0075767940831228701, 0.0075254802882920632, 0.0074763350642275857, 0.0074292951623552575, 0.0073842479497692841, 0.0073411139559180763, 0.007299729899873742, 0.0072600833732343962, 0.0072220179432359102, 0.0071855034544149963, 0.0071504752646757768, 0.007116881721968101, 0.0070845941306683872, 0.0070536249528420905, 0.0070238812604995248, 0.0069953125267943929, 0.006967832538607395, 0.0069414332498654334, 0.0069160393965482488, 0.0068911622939665969, 0.0068669826308175308, 0.0068437273382143463, 0.0068213255750534706, 0.0067997963157340495, 0.0067790782141419594, 0.0067590869509625388, 0.0067392854992868066, 0.0067197282808974775, 0.0067009516493123037, 0.0066829006391885557, 0.0066655278500155667, 0.0066488359892069183, 0.0066327557182389568, 0.0066172489896416664, 0.006602333829180791, 0.0065879536339092208, 0.0065740607003767918, 0.0065606778130960063, 0.0065477851148154657, 0.0065353465782388431, 0.0065233659909754212, 0.0065118175408487872, 0.0065006825044668076, 0.0064899316109495314, 0.0064795440526810725, 0.0064695316841168029, 0.0064598715355183552, 0.0064505534367739715, 0.0064415502358491092, 0.0064328536806718128, 0.0064244706159436787, 0.006416375485688559, 0.0064085387212802483, 0.006400984805423531, 0.0063936832468250429, 0.0063866255908761327, 0.006379791686041315, 0.0063732046717050791, 0.0063668351540805907, 0.0063606705481955112, 0.0063547098067447154, 0.0063489490797999405, 0.0063433835480265236, 0.0063379974845367516, 0.0063327832691039074, 0.0063277352012721579, 0.0063228466077171076, 0.0063181184284167441, 0.0063135351667173729, 0.0063090889738893425, 0.0063047962709845886, 0.00630063764217784, 0.0062966206211416695, 0.0062927326229037404, 0.006288969096447234, 0.0062853252155131564], 'loss': [0.010317938906594552, 0.010147368001906727, 0.0099761723669517157, 0.0098099757527409341, 0.0096517792824465723, 0.0095014500557075773, 0.0093587222403188966, 0.0092229901325843709, 0.0090939525060341926, 0.0089710570182639834, 0.0088538422421555098, 0.0087422632504101164, 0.0086360884470877732, 0.0085349509065493386, 0.0084385319613492701, 0.0083467102224338112, 0.0082591517760287267, 0.0081755514648761858, 0.0080957969498363248, 0.0080196175463245773, 0.0079468331072472618, 0.0078773163891550247, 0.0078108398986209849, 0.0077472949614055733, 0.0076865237999018269, 0.007628402334695754, 0.0075727589917841433, 0.0075194575954354572, 0.0074684441784544451, 0.0074195386670168071, 0.00737270359900112, 0.0073278198372423832, 0.0072848096958715892, 0.0072435257457237924, 0.0072039369283073435, 0.0071658962640909051, 0.0071293940649155502, 0.0070943482985494502, 0.007060705215315842, 0.0070283641551003619, 0.0069973171123640628, 0.0069674699685748692, 0.0069387921749785334, 0.0069111835992292309, 0.0068846387329574883, 0.0068589362488131111, 0.0068337550170985226, 0.0068094573408988036, 0.0067860615653224567, 0.0067635046300428478, 0.0067418182544071361, 0.0067209250235857956, 0.0067006125356418155, 0.0066803266278845294, 0.0066607289222889356, 0.0066418644989890488, 0.006623711804764891, 0.0066062406214330745, 0.0065894171031170195, 0.0065732029608388436, 0.0065575619823497978, 0.0065424953073322696, 0.0065279552168095488, 0.0065139009936105345, 0.0065003471868599234, 0.0064872889922612384, 0.0064746777114321578, 0.0064625328915570331, 0.0064508069058183005, 0.0064394869257769815, 0.0064285475527152153, 0.0064179757489755832, 0.006407780263094391, 0.0063979402147279277, 0.0063884282557919994, 0.0063792292309722328, 0.0063703482244770512, 0.006361771371220161, 0.006353482568536936, 0.0063454598181531263, 0.0063377075291112224, 0.0063302104058546678, 0.0063229632476881634, 0.0063159343438508068, 0.0063091655460443315, 0.006302600951158953, 0.0062962465993396033, 0.0062900983311176377, 0.0062841475178781253, 0.0062784009648014158, 0.0062728165345496576, 0.0062674169025664942, 0.0062621903337295535, 0.0062571245462581578, 0.0062522183168970263, 0.0062474525890232379, 0.0062428400350921197, 0.0062383718287186453, 0.0062340439755764927, 0.0062298565140176052, 0.0062257990861550828, 0.0062218726610910255]}
[2017-10-20 01:37:22,636 AE_UNIGRAMA_6L_OVER_04.py:95]: done!
[2017-10-20 01:37:22,636 AE_UNIGRAMA_6L_OVER_04.py:155]: >> Executing classifier part ... 
[2017-10-20 01:37:22,637 AE_UNIGRAMA_6L_OVER_04.py:100]: =======================================
[2017-10-20 01:37:22,637 AE_UNIGRAMA_6L_OVER_04.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f770e8c7cf8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:37:22,671 AE_UNIGRAMA_6L_OVER_04.py:113]: training ... 
[2017-10-20 01:38:40,238 AE_UNIGRAMA_6L_OVER_04.py:125]: trained!
[2017-10-20 01:38:40,238 AE_UNIGRAMA_6L_OVER_04.py:128]: Training history: 
{'val_loss': [0.010238364273093669, 0.010067566540299959, 0.009898896183693941, 0.0097380076157670033, 0.0095849779112520718, 0.0094397308782684757, 0.00930172455285894, 0.0091705427203867523, 0.0090458019390757642, 0.0089268391141771822, 0.0088134794270959046, 0.0087056877264635266, 0.0086030645372145234, 0.0085053058119566906, 0.008412241856100169, 0.0083235516645651323, 0.0082389389486727214, 0.0081582393715345057, 0.0080812145959322772, 0.0080076738825019412, 0.0079374690141985858, 0.0078703693813578571, 0.0078062622472089907, 0.0077449940318123998, 0.0076864457768855482, 0.0076304256888348821, 0.0075767940831228701, 0.0075254802882920632, 0.0074763350642275857, 0.0074292951623552575, 0.0073842479497692841, 0.0073411139559180763, 0.007299729899873742, 0.0072600833732343962, 0.0072220179432359102, 0.0071855034544149963, 0.0071504752646757768, 0.007116881721968101, 0.0070845941306683872, 0.0070536249528420905, 0.0070238812604995248, 0.0069953125267943929, 0.006967832538607395, 0.0069414332498654334, 0.0069160393965482488, 0.0068911622939665969, 0.0068669826308175308, 0.0068437273382143463, 0.0068213255750534706, 0.0067997963157340495, 0.0067790782141419594, 0.0067590869509625388, 0.0067392854992868066, 0.0067197282808974775, 0.0067009516493123037, 0.0066829006391885557, 0.0066655278500155667, 0.0066488359892069183, 0.0066327557182389568, 0.0066172489896416664, 0.006602333829180791, 0.0065879536339092208, 0.0065740607003767918, 0.0065606778130960063, 0.0065477851148154657, 0.0065353465782388431, 0.0065233659909754212, 0.0065118175408487872, 0.0065006825044668076, 0.0064899316109495314, 0.0064795440526810725, 0.0064695316841168029, 0.0064598715355183552, 0.0064505534367739715, 0.0064415502358491092, 0.0064328536806718128, 0.0064244706159436787, 0.006416375485688559, 0.0064085387212802483, 0.006400984805423531, 0.0063936832468250429, 0.0063866255908761327, 0.006379791686041315, 0.0063732046717050791, 0.0063668351540805907, 0.0063606705481955112, 0.0063547098067447154, 0.0063489490797999405, 0.0063433835480265236, 0.0063379974845367516, 0.0063327832691039074, 0.0063277352012721579, 0.0063228466077171076, 0.0063181184284167441, 0.0063135351667173729, 0.0063090889738893425, 0.0063047962709845886, 0.00630063764217784, 0.0062966206211416695, 0.0062927326229037404, 0.006288969096447234, 0.0062853252155131564], 'loss': [0.010317938906594552, 0.010147368001906727, 0.0099761723669517157, 0.0098099757527409341, 0.0096517792824465723, 0.0095014500557075773, 0.0093587222403188966, 0.0092229901325843709, 0.0090939525060341926, 0.0089710570182639834, 0.0088538422421555098, 0.0087422632504101164, 0.0086360884470877732, 0.0085349509065493386, 0.0084385319613492701, 0.0083467102224338112, 0.0082591517760287267, 0.0081755514648761858, 0.0080957969498363248, 0.0080196175463245773, 0.0079468331072472618, 0.0078773163891550247, 0.0078108398986209849, 0.0077472949614055733, 0.0076865237999018269, 0.007628402334695754, 0.0075727589917841433, 0.0075194575954354572, 0.0074684441784544451, 0.0074195386670168071, 0.00737270359900112, 0.0073278198372423832, 0.0072848096958715892, 0.0072435257457237924, 0.0072039369283073435, 0.0071658962640909051, 0.0071293940649155502, 0.0070943482985494502, 0.007060705215315842, 0.0070283641551003619, 0.0069973171123640628, 0.0069674699685748692, 0.0069387921749785334, 0.0069111835992292309, 0.0068846387329574883, 0.0068589362488131111, 0.0068337550170985226, 0.0068094573408988036, 0.0067860615653224567, 0.0067635046300428478, 0.0067418182544071361, 0.0067209250235857956, 0.0067006125356418155, 0.0066803266278845294, 0.0066607289222889356, 0.0066418644989890488, 0.006623711804764891, 0.0066062406214330745, 0.0065894171031170195, 0.0065732029608388436, 0.0065575619823497978, 0.0065424953073322696, 0.0065279552168095488, 0.0065139009936105345, 0.0065003471868599234, 0.0064872889922612384, 0.0064746777114321578, 0.0064625328915570331, 0.0064508069058183005, 0.0064394869257769815, 0.0064285475527152153, 0.0064179757489755832, 0.006407780263094391, 0.0063979402147279277, 0.0063884282557919994, 0.0063792292309722328, 0.0063703482244770512, 0.006361771371220161, 0.006353482568536936, 0.0063454598181531263, 0.0063377075291112224, 0.0063302104058546678, 0.0063229632476881634, 0.0063159343438508068, 0.0063091655460443315, 0.006302600951158953, 0.0062962465993396033, 0.0062900983311176377, 0.0062841475178781253, 0.0062784009648014158, 0.0062728165345496576, 0.0062674169025664942, 0.0062621903337295535, 0.0062571245462581578, 0.0062522183168970263, 0.0062474525890232379, 0.0062428400350921197, 0.0062383718287186453, 0.0062340439755764927, 0.0062298565140176052, 0.0062257990861550828, 0.0062218726610910255]}
[2017-10-20 01:38:40,239 AE_UNIGRAMA_6L_OVER_04.py:132]: evaluating model ... 
[2017-10-20 01:38:40,299 AE_UNIGRAMA_6L_OVER_04.py:136]: evaluated! 
[2017-10-20 01:38:40,300 AE_UNIGRAMA_6L_OVER_04.py:138]: generating reports ... 
[2017-10-20 01:38:40,920 AE_UNIGRAMA_6L_OVER_04.py:141]: done!
[2017-10-20 01:38:40,921 AE_UNIGRAMA_6L_OVER_04.py:157]: >> experiment AE_UNIGRAMA_6L_OVER_04 finished!
