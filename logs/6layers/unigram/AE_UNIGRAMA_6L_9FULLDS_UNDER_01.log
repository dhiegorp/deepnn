[2017-11-18 19:05:19,820 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_9FULLDS_UNDER_01
[2017-11-18 19:05:19,821 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:149]: >> Printing header log
[2017-11-18 19:05:19,821 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_9FULLDS_UNDER_01
	layers = 96,28,26,24,22,20,19,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fec2c40fe80>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fec2c4143c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 19:05:19,821 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:151]: >> Loading dataset... 
[2017-11-18 19:05:22,242 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 19:05:22,242 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-11-18 19:05:22,242 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:60]: =======================================
[2017-11-18 19:05:22,242 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fec2c40fe80>, 'discard_decoder_function': True}
[2017-11-18 19:05:22,410 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:76]: training and evaluate autoencoder
[2017-11-18 19:06:44,398 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:88]: trained and evaluated!
[2017-11-18 19:06:44,400 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:91]: Training history: 
{'val_loss': [0.0096348037122475309, 0.0090381366962985227, 0.0085705549047848436, 0.0081955595734333753, 0.0078854426727566884, 0.0076238575691986348, 0.0074023222764669884, 0.0072113889062798385, 0.0070476332993939031, 0.0069076258700117828, 0.0067870902922312504, 0.0066828900999165398, 0.0065924587029072453, 0.006513791822289958, 0.0064451179962751728, 0.0063850198287444268, 0.0063323765694999227, 0.0062861485367052827, 0.0062454652747304306, 0.0062096465617905681, 0.0061780673370260891, 0.0061502173665852087, 0.0061255885691658208, 0.0061038986183169002, 0.0060846834629705642, 0.0060677096580190448, 0.0060526774151408846, 0.0060393307730247491, 0.0060274775639875969, 0.0060169666140274898, 0.0060076347942601303, 0.0059993082852722668, 0.0059919294575006814, 0.0059853466101009939, 0.0059794915766612335, 0.005974258454407003, 0.0059695917676938492, 0.0059654316133300979, 0.0059616905518145857, 0.0059583727236137548, 0.005955383978723844, 0.0059527078166313795, 0.0059502977221206144, 0.0059481324397475189, 0.0059461646056325011, 0.0059443762028252361, 0.0059427534181621909, 0.0059412717869699013, 0.0059399145064229957, 0.0059386705428646665, 0.0059375219922088354, 0.0059364628853999938, 0.0059354771499360139, 0.0059345461906833066, 0.005933656971350597, 0.005932795754330933, 0.0059319675431300321, 0.0059311639692789051, 0.005930382773182254, 0.005929623400188027, 0.0059288924722358969, 0.0059281761509197596, 0.0059274660632355177, 0.0059267727642579194, 0.0059260836697516582, 0.0059254096491684677, 0.0059247422575415308, 0.0059240525835684852, 0.0059233445215365142, 0.0059226313249085838, 0.0059219214884521157, 0.0059212459883119023, 0.0059206114098900647, 0.0059199970682247112, 0.0059194051887694913, 0.0059188346956774059, 0.0059182745312470275, 0.0059177267160821119, 0.0059171891565037941, 0.0059166604907822462, 0.0059161392561317815, 0.0059156176102413043, 0.0059151024760788623, 0.005914605348341876, 0.0059141109778639237, 0.0059136372489648646, 0.0059131655910691378, 0.0059126982807145151, 0.0059122287242843446, 0.0059117410376973286, 0.0059112185308212075, 0.0059106593835381504, 0.0059100568369996158, 0.005909435619770911, 0.0059088158375182791, 0.005908192265884884, 0.0059075552378211257, 0.0059069134230810691, 0.0059062835325900077, 0.0059056549423909203, 0.0059050228471536764], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010007267998929505, 0.0093294911347654268, 0.0088036486673681771, 0.0083869812235956801, 0.0080484724184629649, 0.0077650188166605624, 0.0075253967426779471, 0.0073214309619049423, 0.007145330613773722, 0.0069949306166744883, 0.0068659774053828572, 0.0067547504051996693, 0.0066584416294642587, 0.006574750489303692, 0.0065019063193616699, 0.0064382427265154037, 0.006382506706206487, 0.0063336637545328093, 0.0062907494306683222, 0.0062529923047605646, 0.0062197434875510089, 0.0061904165473229003, 0.0061645711471153006, 0.0061417469076128208, 0.0061216329519797087, 0.0061038181114161294, 0.0060880766750320316, 0.0060741428574596331, 0.0060617791185146597, 0.0060507941062740381, 0.0060410720246019895, 0.0060324324240053637, 0.0060247319003554978, 0.006017921047315607, 0.0060118418857359225, 0.006006430505248038, 0.0060016085904485298, 0.0059973096797487167, 0.0059934758540182093, 0.0059900354818392164, 0.0059869806502849815, 0.005984232773083192, 0.0059817711447964703, 0.0059795587532116183, 0.0059775610052449722, 0.0059757508915130337, 0.005974105479554891, 0.0059726129570520699, 0.0059712488137138022, 0.0059700011769205615, 0.0059688528288076685, 0.0059677959899108839, 0.0059668199319017033, 0.0059659053003149115, 0.0059650385026650014, 0.005964207483828891, 0.0059634006138201889, 0.00596262867423809, 0.0059618756318049002, 0.0059611454641608115, 0.0059604300473539706, 0.0059597354425258899, 0.0059590497619674892, 0.0059583774992787572, 0.0059577155869938387, 0.0059570657648694864, 0.0059564232243113175, 0.0059557712193460963, 0.0059551018323030034, 0.0059544273080676703, 0.0059537418841459685, 0.0059530750851325091, 0.0059524499852956986, 0.0059518484262459422, 0.0059512693530292225, 0.0059507021671786359, 0.005950156271942824, 0.0059496224752697158, 0.0059490950712510031, 0.0059485755858176273, 0.005948062892683144, 0.0059475578058831554, 0.0059470572902457367, 0.0059465613356540284, 0.0059460768120838219, 0.0059456093984079778, 0.0059451440431413562, 0.0059446876738744013, 0.0059442322972599049, 0.0059437626394704653, 0.0059432717184446423, 0.0059427385304406206, 0.0059421681189125147, 0.0059415681659855243, 0.0059409580505882303, 0.0059403618988565568, 0.0059397628966284975, 0.0059391527708285577, 0.0059385488405471615, 0.0059379381411156177, 0.0059373315408980431], 'acc': [0.55996072176366962, 0.59383822262938279, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822262206665, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822262206665, 0.59383822267327968, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.59383822266596353]}
[2017-11-18 19:06:44,400 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:95]: done!
[2017-11-18 19:06:44,400 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-11-18 19:06:44,400 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:100]: =======================================
[2017-11-18 19:06:44,400 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fec2c4143c8>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 19:06:44,462 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:113]: training ... 
[2017-11-18 19:10:30,675 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:125]: trained!
[2017-11-18 19:10:30,676 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:128]: Training history: 
{'val_loss': [0.0096348037122475309, 0.0090381366962985227, 0.0085705549047848436, 0.0081955595734333753, 0.0078854426727566884, 0.0076238575691986348, 0.0074023222764669884, 0.0072113889062798385, 0.0070476332993939031, 0.0069076258700117828, 0.0067870902922312504, 0.0066828900999165398, 0.0065924587029072453, 0.006513791822289958, 0.0064451179962751728, 0.0063850198287444268, 0.0063323765694999227, 0.0062861485367052827, 0.0062454652747304306, 0.0062096465617905681, 0.0061780673370260891, 0.0061502173665852087, 0.0061255885691658208, 0.0061038986183169002, 0.0060846834629705642, 0.0060677096580190448, 0.0060526774151408846, 0.0060393307730247491, 0.0060274775639875969, 0.0060169666140274898, 0.0060076347942601303, 0.0059993082852722668, 0.0059919294575006814, 0.0059853466101009939, 0.0059794915766612335, 0.005974258454407003, 0.0059695917676938492, 0.0059654316133300979, 0.0059616905518145857, 0.0059583727236137548, 0.005955383978723844, 0.0059527078166313795, 0.0059502977221206144, 0.0059481324397475189, 0.0059461646056325011, 0.0059443762028252361, 0.0059427534181621909, 0.0059412717869699013, 0.0059399145064229957, 0.0059386705428646665, 0.0059375219922088354, 0.0059364628853999938, 0.0059354771499360139, 0.0059345461906833066, 0.005933656971350597, 0.005932795754330933, 0.0059319675431300321, 0.0059311639692789051, 0.005930382773182254, 0.005929623400188027, 0.0059288924722358969, 0.0059281761509197596, 0.0059274660632355177, 0.0059267727642579194, 0.0059260836697516582, 0.0059254096491684677, 0.0059247422575415308, 0.0059240525835684852, 0.0059233445215365142, 0.0059226313249085838, 0.0059219214884521157, 0.0059212459883119023, 0.0059206114098900647, 0.0059199970682247112, 0.0059194051887694913, 0.0059188346956774059, 0.0059182745312470275, 0.0059177267160821119, 0.0059171891565037941, 0.0059166604907822462, 0.0059161392561317815, 0.0059156176102413043, 0.0059151024760788623, 0.005914605348341876, 0.0059141109778639237, 0.0059136372489648646, 0.0059131655910691378, 0.0059126982807145151, 0.0059122287242843446, 0.0059117410376973286, 0.0059112185308212075, 0.0059106593835381504, 0.0059100568369996158, 0.005909435619770911, 0.0059088158375182791, 0.005908192265884884, 0.0059075552378211257, 0.0059069134230810691, 0.0059062835325900077, 0.0059056549423909203, 0.0059050228471536764], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.010007267998929505, 0.0093294911347654268, 0.0088036486673681771, 0.0083869812235956801, 0.0080484724184629649, 0.0077650188166605624, 0.0075253967426779471, 0.0073214309619049423, 0.007145330613773722, 0.0069949306166744883, 0.0068659774053828572, 0.0067547504051996693, 0.0066584416294642587, 0.006574750489303692, 0.0065019063193616699, 0.0064382427265154037, 0.006382506706206487, 0.0063336637545328093, 0.0062907494306683222, 0.0062529923047605646, 0.0062197434875510089, 0.0061904165473229003, 0.0061645711471153006, 0.0061417469076128208, 0.0061216329519797087, 0.0061038181114161294, 0.0060880766750320316, 0.0060741428574596331, 0.0060617791185146597, 0.0060507941062740381, 0.0060410720246019895, 0.0060324324240053637, 0.0060247319003554978, 0.006017921047315607, 0.0060118418857359225, 0.006006430505248038, 0.0060016085904485298, 0.0059973096797487167, 0.0059934758540182093, 0.0059900354818392164, 0.0059869806502849815, 0.005984232773083192, 0.0059817711447964703, 0.0059795587532116183, 0.0059775610052449722, 0.0059757508915130337, 0.005974105479554891, 0.0059726129570520699, 0.0059712488137138022, 0.0059700011769205615, 0.0059688528288076685, 0.0059677959899108839, 0.0059668199319017033, 0.0059659053003149115, 0.0059650385026650014, 0.005964207483828891, 0.0059634006138201889, 0.00596262867423809, 0.0059618756318049002, 0.0059611454641608115, 0.0059604300473539706, 0.0059597354425258899, 0.0059590497619674892, 0.0059583774992787572, 0.0059577155869938387, 0.0059570657648694864, 0.0059564232243113175, 0.0059557712193460963, 0.0059551018323030034, 0.0059544273080676703, 0.0059537418841459685, 0.0059530750851325091, 0.0059524499852956986, 0.0059518484262459422, 0.0059512693530292225, 0.0059507021671786359, 0.005950156271942824, 0.0059496224752697158, 0.0059490950712510031, 0.0059485755858176273, 0.005948062892683144, 0.0059475578058831554, 0.0059470572902457367, 0.0059465613356540284, 0.0059460768120838219, 0.0059456093984079778, 0.0059451440431413562, 0.0059446876738744013, 0.0059442322972599049, 0.0059437626394704653, 0.0059432717184446423, 0.0059427385304406206, 0.0059421681189125147, 0.0059415681659855243, 0.0059409580505882303, 0.0059403618988565568, 0.0059397628966284975, 0.0059391527708285577, 0.0059385488405471615, 0.0059379381411156177, 0.0059373315408980431], 'acc': [0.55996072176366962, 0.59383822262938279, 0.5938382226001182, 0.59383822268791198, 0.59383822265133124, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822266596353, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.59383822272449271, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822262206665, 0.5938382226842539, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822263669894, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822262206665, 0.59383822267327968, 0.5938382226001182, 0.59383822272449271, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226001182, 0.59383822266596353, 0.59383822270254427, 0.59383822272449271, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822268791198, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822272449271, 0.59383822264767316, 0.59383822270254427, 0.59383822268791198, 0.5938382226001182, 0.5938382226842539, 0.59383822265133124, 0.5938382226001182, 0.59383822268791198, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822272449271, 0.59383822263669894, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.59383822266596353]}
[2017-11-18 19:10:30,676 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:132]: evaluating model ... 
[2017-11-18 19:10:30,773 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:136]: evaluated! 
[2017-11-18 19:10:30,773 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:138]: generating reports ... 
[2017-11-18 19:10:31,617 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:141]: done!
[2017-11-18 19:10:31,617 AE_UNIGRAMA_6L_9FULLDS_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_6L_9FULLDS_UNDER_01 finished!
