[2017-11-13 02:28:16,100 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_MINIDS_UNDER_02
[2017-11-13 02:28:16,101 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:149]: >> Printing header log
[2017-11-13 02:28:16,101 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_MINIDS_UNDER_02
	layers = 96,76,69,63,56,49,43
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ffaa52a7eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ffaa52ac400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 02:28:16,101 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:151]: >> Loading dataset... 
[2017-11-13 02:28:16,809 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-11-13 02:28:16,810 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:153]: >> Executing autoencoder part ... 
[2017-11-13 02:28:16,810 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:60]: =======================================
[2017-11-13 02:28:16,810 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7ffaa52a7eb8>, 'discard_decoder_function': True}
[2017-11-13 02:28:16,951 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:76]: training and evaluate autoencoder
[2017-11-13 02:29:26,277 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:88]: trained and evaluated!
[2017-11-13 02:29:26,278 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:91]: Training history: 
{'val_loss': [0.010297297150395174, 0.010234649016151419, 0.010175595887448487, 0.010120587537695262, 0.010068973765248039, 0.010020132366997159, 0.0099739230456017645, 0.0099299429642334298, 0.0098880223486724848, 0.0098484760067221403, 0.0098108858714870354, 0.0097748139270730176, 0.0097401241761490322, 0.0097073595278435922, 0.009676494569860427, 0.009647347368853908, 0.0096198185260466477, 0.0095938640996315223, 0.0095692931961780595, 0.009545843303896016, 0.0095234272662259381, 0.0095022074968232097, 0.0094820414687122549, 0.0094623920407326256, 0.0094434601085115095, 0.0094255414760245713, 0.0094085693373223665, 0.0093924836342164138, 0.0093771867994149813, 0.0093626002382944072, 0.0093486764949493699, 0.0093353748231516896, 0.0093225977594746084, 0.0093103105541609485, 0.009298608198651151, 0.0092874817224738761, 0.0092768682492377595, 0.0092667303563936931, 0.0092570730467711245, 0.0092478665595936514, 0.0092390715785075298, 0.0092306681233544768, 0.0092226239163636283, 0.0092149396222707958, 0.009207561684834692, 0.0092004855616939114, 0.0091937114051837462, 0.0091872138757134007, 0.0091809652517220782, 0.009174982760946325, 0.0091692323425999357, 0.0091637116008642435, 0.0091583959647492403, 0.0091532744488031451, 0.0091483713955130275, 0.0091436384695834823, 0.0091390866010716415, 0.0091346904434623771, 0.0091304441699308087, 0.0091263486287075351, 0.009122399800218171, 0.0091185794076899616, 0.0091148774073801959, 0.0091112834370269211, 0.0091078002109680478, 0.0091044458259437171, 0.0091012055850605098, 0.0090980814686772108, 0.0090950550061397843, 0.009092150027534775, 0.0090893361315851316, 0.0090866156483283712, 0.0090839750683939149, 0.0090814134500726892, 0.0090789457637692021, 0.0090765450669099412, 0.0090742194263409952, 0.0090719626551722509, 0.0090697838658238428, 0.0090676670111577307, 0.0090656159168670172, 0.0090636236205364692, 0.0090616999685653524, 0.0090598338750990798, 0.0090580225911780811, 0.0090562624676797029, 0.0090545590163717479, 0.0090529035714534585, 0.0090512949315533324, 0.0090497364134261155, 0.0090482157402322193, 0.0090467425852626231, 0.0090453108066353653, 0.0090439159658540144, 0.0090425580767672306, 0.0090412356644924245, 0.0090399507059262148, 0.0090387025190219565, 0.0090374858724472686, 0.009036298775456874, 0.0090351302010529995], 'val_acc': [0.0018587360594795538, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.013011152416356878, 0.042750929368029739, 0.046468401486988845, 0.049256505590056843, 0.050185873619796616, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396], 'loss': [0.010323067606136559, 0.010260314611945881, 0.010199486719331055, 0.01014247822925018, 0.010089274899966525, 0.010039116753369442, 0.0099915933372257092, 0.0099465775406005277, 0.0099036658712798424, 0.0098629680141055585, 0.0098244952290938835, 0.0097877701541801577, 0.0097524270423319931, 0.0097188041954728889, 0.0096870987717870491, 0.0096572108856404059, 0.0096289899415429852, 0.009602328727494629, 0.0095771844152500816, 0.0095533147361530207, 0.0095304407662475631, 0.0095087267480190724, 0.0094881405957734644, 0.0094683597433325266, 0.0094490920954235658, 0.0094307378620211522, 0.0094133556494746893, 0.0093968863351145768, 0.0093812503128987406, 0.0093663759871896023, 0.0093521639943974621, 0.0093385977189720006, 0.0093256361346369006, 0.009313136004896052, 0.0093011853136877824, 0.009289807373269723, 0.009278974073384353, 0.0092686514536716776, 0.009258772985530031, 0.0092493753591764167, 0.009240400331173855, 0.0092318237352184383, 0.0092236254519949528, 0.0092157787788194525, 0.0092082760716343699, 0.0092010655192533517, 0.0091941561790317133, 0.0091875401212757682, 0.0091811769837130044, 0.0091750659369110848, 0.0091692104079310124, 0.0091635846202596603, 0.0091581750161987031, 0.0091529703219939244, 0.009147957368618188, 0.009143151772181609, 0.0091385104874928593, 0.0091340455089792497, 0.0091297296370988108, 0.0091255586937793436, 0.0091215405858178483, 0.0091176590239417359, 0.0091138986564975755, 0.0091102528777923693, 0.0091067220501661224, 0.0091032995358704787, 0.0091000074800046665, 0.0090968238055870888, 0.0090937565001255535, 0.0090907880253334235, 0.0090879388016172919, 0.0090851746081673963, 0.0090824987346646464, 0.0090799133505697401, 0.0090773898424705481, 0.0090749657540579263, 0.009072604084864818, 0.0090703181321397843, 0.0090681019873938163, 0.0090659622712027602, 0.0090638793605370034, 0.0090618626396020054, 0.0090599054317250533, 0.0090580129430394042, 0.0090561732632630648, 0.0090543854450457796, 0.0090526561255634894, 0.0090509775794754017, 0.0090493448336220039, 0.009047762924701103, 0.0090462218565933901, 0.0090447313981685956, 0.0090432783220130465, 0.0090418700540934004, 0.0090404965164347078, 0.0090391550684770193, 0.0090378539770676735, 0.009036588266757491, 0.0090353558253274784, 0.0090341541776462215, 0.0090329858509350866], 'acc': [0.0024585125998770742, 0.0012292562999385371, 0.0012292562999385371, 0.0012292562999385371, 0.0012292562999385371, 0.0024585125998770742, 0.0043023970543642166, 0.04425322680694601, 0.058389674251659855, 0.06084818685153693, 0.059618930551598392, 0.060233558706146995, 0.060233558715305668, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558715305668, 0.060233558710726331, 0.060233558701567658, 0.060233558701567658, 0.060233558696988321, 0.060233558715305668, 0.060233558696988321, 0.060233558701567658, 0.060233558701567658, 0.060233558696988321, 0.060233558696988321, 0.060233558701567658, 0.060233558706146995, 0.060233558715305668, 0.060233558701567658, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558715305668, 0.060233558706146995, 0.060233558701567658, 0.060233558701567658, 0.060233558706146995, 0.060233558706146995, 0.060233558701567658, 0.060233558706146995, 0.060233558701567658, 0.060233558701567658, 0.060233558710726331, 0.060233558701567658, 0.060233558706146995, 0.060233558706146995, 0.060233558701567658, 0.060233558715305668, 0.060233558706146995, 0.060233558696988321, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558706146995, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558715305668, 0.060233558701567658, 0.060233558710726331, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558696988321, 0.060233558710726331, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558710726331, 0.060233558596242916, 0.060233558701567658, 0.060233558710726331, 0.060233558701567658, 0.060233558715305668, 0.060233558706146995, 0.060233558701567658, 0.060233558710726331, 0.060233558701567658, 0.060233558710726331, 0.060233558706146995, 0.060233558710726331, 0.060233558696988321, 0.060233558715305668, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558710726331, 0.060233558696988321, 0.060233558701567658, 0.060233558696988321, 0.060233558706146995, 0.060233558696988321, 0.060233558701567658, 0.060233558706146995]}
[2017-11-13 02:29:26,278 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:95]: done!
[2017-11-13 02:29:26,278 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:155]: >> Executing classifier part ... 
[2017-11-13 02:29:26,278 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:100]: =======================================
[2017-11-13 02:29:26,278 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7ffaa52ac400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 02:29:26,312 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:113]: training ... 
[2017-11-13 02:31:08,784 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:125]: trained!
[2017-11-13 02:31:08,787 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:128]: Training history: 
{'val_loss': [0.010297297150395174, 0.010234649016151419, 0.010175595887448487, 0.010120587537695262, 0.010068973765248039, 0.010020132366997159, 0.0099739230456017645, 0.0099299429642334298, 0.0098880223486724848, 0.0098484760067221403, 0.0098108858714870354, 0.0097748139270730176, 0.0097401241761490322, 0.0097073595278435922, 0.009676494569860427, 0.009647347368853908, 0.0096198185260466477, 0.0095938640996315223, 0.0095692931961780595, 0.009545843303896016, 0.0095234272662259381, 0.0095022074968232097, 0.0094820414687122549, 0.0094623920407326256, 0.0094434601085115095, 0.0094255414760245713, 0.0094085693373223665, 0.0093924836342164138, 0.0093771867994149813, 0.0093626002382944072, 0.0093486764949493699, 0.0093353748231516896, 0.0093225977594746084, 0.0093103105541609485, 0.009298608198651151, 0.0092874817224738761, 0.0092768682492377595, 0.0092667303563936931, 0.0092570730467711245, 0.0092478665595936514, 0.0092390715785075298, 0.0092306681233544768, 0.0092226239163636283, 0.0092149396222707958, 0.009207561684834692, 0.0092004855616939114, 0.0091937114051837462, 0.0091872138757134007, 0.0091809652517220782, 0.009174982760946325, 0.0091692323425999357, 0.0091637116008642435, 0.0091583959647492403, 0.0091532744488031451, 0.0091483713955130275, 0.0091436384695834823, 0.0091390866010716415, 0.0091346904434623771, 0.0091304441699308087, 0.0091263486287075351, 0.009122399800218171, 0.0091185794076899616, 0.0091148774073801959, 0.0091112834370269211, 0.0091078002109680478, 0.0091044458259437171, 0.0091012055850605098, 0.0090980814686772108, 0.0090950550061397843, 0.009092150027534775, 0.0090893361315851316, 0.0090866156483283712, 0.0090839750683939149, 0.0090814134500726892, 0.0090789457637692021, 0.0090765450669099412, 0.0090742194263409952, 0.0090719626551722509, 0.0090697838658238428, 0.0090676670111577307, 0.0090656159168670172, 0.0090636236205364692, 0.0090616999685653524, 0.0090598338750990798, 0.0090580225911780811, 0.0090562624676797029, 0.0090545590163717479, 0.0090529035714534585, 0.0090512949315533324, 0.0090497364134261155, 0.0090482157402322193, 0.0090467425852626231, 0.0090453108066353653, 0.0090439159658540144, 0.0090425580767672306, 0.0090412356644924245, 0.0090399507059262148, 0.0090387025190219565, 0.0090374858724472686, 0.009036298775456874, 0.0090351302010529995], 'val_acc': [0.0018587360594795538, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.00092936802973977691, 0.013011152416356878, 0.042750929368029739, 0.046468401486988845, 0.049256505590056843, 0.050185873619796616, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396, 0.051115241649536396], 'loss': [0.010323067606136559, 0.010260314611945881, 0.010199486719331055, 0.01014247822925018, 0.010089274899966525, 0.010039116753369442, 0.0099915933372257092, 0.0099465775406005277, 0.0099036658712798424, 0.0098629680141055585, 0.0098244952290938835, 0.0097877701541801577, 0.0097524270423319931, 0.0097188041954728889, 0.0096870987717870491, 0.0096572108856404059, 0.0096289899415429852, 0.009602328727494629, 0.0095771844152500816, 0.0095533147361530207, 0.0095304407662475631, 0.0095087267480190724, 0.0094881405957734644, 0.0094683597433325266, 0.0094490920954235658, 0.0094307378620211522, 0.0094133556494746893, 0.0093968863351145768, 0.0093812503128987406, 0.0093663759871896023, 0.0093521639943974621, 0.0093385977189720006, 0.0093256361346369006, 0.009313136004896052, 0.0093011853136877824, 0.009289807373269723, 0.009278974073384353, 0.0092686514536716776, 0.009258772985530031, 0.0092493753591764167, 0.009240400331173855, 0.0092318237352184383, 0.0092236254519949528, 0.0092157787788194525, 0.0092082760716343699, 0.0092010655192533517, 0.0091941561790317133, 0.0091875401212757682, 0.0091811769837130044, 0.0091750659369110848, 0.0091692104079310124, 0.0091635846202596603, 0.0091581750161987031, 0.0091529703219939244, 0.009147957368618188, 0.009143151772181609, 0.0091385104874928593, 0.0091340455089792497, 0.0091297296370988108, 0.0091255586937793436, 0.0091215405858178483, 0.0091176590239417359, 0.0091138986564975755, 0.0091102528777923693, 0.0091067220501661224, 0.0091032995358704787, 0.0091000074800046665, 0.0090968238055870888, 0.0090937565001255535, 0.0090907880253334235, 0.0090879388016172919, 0.0090851746081673963, 0.0090824987346646464, 0.0090799133505697401, 0.0090773898424705481, 0.0090749657540579263, 0.009072604084864818, 0.0090703181321397843, 0.0090681019873938163, 0.0090659622712027602, 0.0090638793605370034, 0.0090618626396020054, 0.0090599054317250533, 0.0090580129430394042, 0.0090561732632630648, 0.0090543854450457796, 0.0090526561255634894, 0.0090509775794754017, 0.0090493448336220039, 0.009047762924701103, 0.0090462218565933901, 0.0090447313981685956, 0.0090432783220130465, 0.0090418700540934004, 0.0090404965164347078, 0.0090391550684770193, 0.0090378539770676735, 0.009036588266757491, 0.0090353558253274784, 0.0090341541776462215, 0.0090329858509350866], 'acc': [0.0024585125998770742, 0.0012292562999385371, 0.0012292562999385371, 0.0012292562999385371, 0.0012292562999385371, 0.0024585125998770742, 0.0043023970543642166, 0.04425322680694601, 0.058389674251659855, 0.06084818685153693, 0.059618930551598392, 0.060233558706146995, 0.060233558715305668, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558715305668, 0.060233558710726331, 0.060233558701567658, 0.060233558701567658, 0.060233558696988321, 0.060233558715305668, 0.060233558696988321, 0.060233558701567658, 0.060233558701567658, 0.060233558696988321, 0.060233558696988321, 0.060233558701567658, 0.060233558706146995, 0.060233558715305668, 0.060233558701567658, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558715305668, 0.060233558706146995, 0.060233558701567658, 0.060233558701567658, 0.060233558706146995, 0.060233558706146995, 0.060233558701567658, 0.060233558706146995, 0.060233558701567658, 0.060233558701567658, 0.060233558710726331, 0.060233558701567658, 0.060233558706146995, 0.060233558706146995, 0.060233558701567658, 0.060233558715305668, 0.060233558706146995, 0.060233558696988321, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558706146995, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558715305668, 0.060233558701567658, 0.060233558710726331, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558696988321, 0.060233558710726331, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558706146995, 0.060233558710726331, 0.060233558596242916, 0.060233558701567658, 0.060233558710726331, 0.060233558701567658, 0.060233558715305668, 0.060233558706146995, 0.060233558701567658, 0.060233558710726331, 0.060233558701567658, 0.060233558710726331, 0.060233558706146995, 0.060233558710726331, 0.060233558696988321, 0.060233558715305668, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558701567658, 0.060233558710726331, 0.060233558696988321, 0.060233558701567658, 0.060233558696988321, 0.060233558706146995, 0.060233558696988321, 0.060233558701567658, 0.060233558706146995]}
[2017-11-13 02:31:08,788 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:132]: evaluating model ... 
[2017-11-13 02:31:08,981 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:136]: evaluated! 
[2017-11-13 02:31:08,982 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:138]: generating reports ... 
[2017-11-13 02:31:10,017 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:141]: done!
[2017-11-13 02:31:10,017 AE_UNIGRAMA_6L_MINIDS_UNDER_02.py:157]: >> experiment AE_UNIGRAMA_6L_MINIDS_UNDER_02 finished!
