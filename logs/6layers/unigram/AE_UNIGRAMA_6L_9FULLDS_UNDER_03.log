[2017-11-18 18:44:45,024 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_9FULLDS_UNDER_03
[2017-11-18 18:44:45,024 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:149]: >> Printing header log
[2017-11-18 18:44:45,024 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_9FULLDS_UNDER_03
	layers = 96,86,78,71,63,55,48,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f98a423aeb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f98a423f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:44:45,024 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:151]: >> Loading dataset... 
[2017-11-18 18:44:47,225 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:44:47,226 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:44:47,226 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:60]: =======================================
[2017-11-18 18:44:47,226 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f98a423aeb8>, 'discard_decoder_function': True}
[2017-11-18 18:44:47,378 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:76]: training and evaluate autoencoder
[2017-11-18 18:46:30,008 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:88]: trained and evaluated!
[2017-11-18 18:46:30,010 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:91]: Training history: 
{'val_loss': [0.0094347366226651529, 0.00866773058597008, 0.0080716481583945256, 0.0076123997399659441, 0.0072601944697936616, 0.0069875660736095991, 0.0067726753760596076, 0.0066028416055113962, 0.006468049928070878, 0.0063603836803456434, 0.0062733759341343214, 0.0062024479730890562, 0.0061446861760983112, 0.0060970252046059683, 0.0060574165531713069, 0.0060242171938716272, 0.0059962799265715115, 0.0059726907674343662, 0.0059526772339284443, 0.005935590710793511, 0.0059209842788817439, 0.0059084201975869687, 0.0058975429064500083, 0.0058880020786098693, 0.0058798506900973454, 0.0058728170632331668, 0.0058666899123799654, 0.0058593293847033576, 0.0058514577012648752, 0.0058448823159974713, 0.0058393433628633248, 0.0058346261868978287, 0.0058306097399541965, 0.0058271733805049832, 0.0058242152272170843, 0.0058216679158789274, 0.0058194574196088764, 0.0058175375149782113, 0.0058158603317156644, 0.0058143817689933789, 0.0058130844233838927, 0.0058119302390992793, 0.0058109224990430574, 0.0058099765003511994, 0.0058091304607063706, 0.0058083613919116791, 0.0058076658306861735, 0.0058070405977492341, 0.0058064607381225122, 0.0058059422323224917, 0.0058054586557396929, 0.0058050145830128045, 0.0058045952747042334, 0.0058042081343321538, 0.0058038505731210065, 0.0058035129936735768, 0.0058031886543405001, 0.0058028793080686942, 0.0058025936887882591, 0.0058023116361549708, 0.0058020353484118424, 0.0058017714825814443, 0.0058015159193326431, 0.0058012667232874519, 0.0058010260988497825, 0.0058007838874671964, 0.0058005276964912351, 0.0058002462620014867, 0.0057999587014388706, 0.0057996516524978703, 0.0057993403375621111, 0.005798991157997431, 0.0057985380919837078, 0.0057980425648825251, 0.0057976420763236544, 0.005797342209108461, 0.0057970528768595255, 0.0057967799969492577, 0.0057964922503617178, 0.0057962038418198003, 0.0057959102381853192, 0.0057955991196282173, 0.0057952955497982571, 0.0057949704099761424, 0.005794651095797498, 0.005794333263229509, 0.0057940296756869639, 0.0057937189448386628, 0.0057934155511077338, 0.005793100981163638, 0.0057927944237254735, 0.0057924885438150704, 0.0057921831459950184, 0.0057918723903319846, 0.0057915524624593392, 0.0057912167447158099, 0.0057908778593289151, 0.0057905252820284036, 0.0057901739666853837, 0.0057898337877663906, 0.0057894842307610753], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099061219208239713, 0.0090393143451901921, 0.0083620540203959409, 0.0078385581779798416, 0.0074368634648032134, 0.0071278831221797036, 0.0068865891805962795, 0.0066964175176948615, 0.0065460577458545622, 0.0064264329171924593, 0.0063305820145921916, 0.0062527592846973075, 0.0061896098424419092, 0.0061378432329178469, 0.0060950512151305069, 0.006059432859855246, 0.0060295563822078775, 0.0060043821827046335, 0.0059831378522154244, 0.0059651043393518953, 0.0059497120764005458, 0.0059365477555603924, 0.00592522086477088, 0.005915314799106763, 0.0059068027725556419, 0.0058994926605407914, 0.0058931854181540361, 0.0058871116793820892, 0.005879219511620553, 0.0058722096481383925, 0.0058663409904955105, 0.0058613864348190095, 0.0058571760940163272, 0.0058535865497274337, 0.005850519294556396, 0.0058478792109979954, 0.0058456018988449574, 0.0058436279066343228, 0.0058419122908214558, 0.0058404150882140722, 0.0058390951064501359, 0.0058379332701068241, 0.0058368997218191795, 0.0058359776143882226, 0.0058351311253319049, 0.005834370213925996, 0.0058336806478651226, 0.0058330614272378385, 0.005832498158955023, 0.005831983099561594, 0.0058315141543533828, 0.0058310836382901628, 0.0058306812102847765, 0.0058303075076993208, 0.0058299573444148267, 0.0058296288313222722, 0.0058293187462307378, 0.0058290283044207325, 0.0058287386113725853, 0.0058284732919518783, 0.0058282119673185809, 0.0058279585223464355, 0.005827714752692126, 0.0058274712298434436, 0.0058272385855328932, 0.0058270055402060679, 0.0058267687324937961, 0.0058265073058345511, 0.0058262298057159649, 0.0058259366574462054, 0.0058256328909902415, 0.0058253141809051405, 0.0058249411986171611, 0.0058244693764486904, 0.0058240336205957087, 0.0058237061396513717, 0.0058234164787256803, 0.0058231329118070005, 0.0058228564737299489, 0.005822572911326704, 0.0058222803157689422, 0.0058219816408364615, 0.0058216791548775914, 0.0058213671893078012, 0.0058210482670544546, 0.0058207356662945478, 0.0058204277215759392, 0.0058201213629178522, 0.0058198117642357401, 0.0058195092192904396, 0.0058192030347337734, 0.0058189026335336846, 0.0058185924551041272, 0.0058182858312357325, 0.0058179767061026276, 0.0058176520930305238, 0.0058173074723556649, 0.0058169665975477654, 0.0058166208692769289, 0.0058162828093563596, 0.0058159366305709451], 'acc': [0.5859825702639494, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822267327968, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822262938279, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822267327968, 0.59383822265133124, 0.59383822263669894]}
[2017-11-18 18:46:30,010 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:95]: done!
[2017-11-18 18:46:30,010 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:155]: >> Executing classifier part ... 
[2017-11-18 18:46:30,011 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:100]: =======================================
[2017-11-18 18:46:30,011 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f98a423f400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:46:30,079 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:113]: training ... 
[2017-11-18 18:50:17,266 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:125]: trained!
[2017-11-18 18:50:17,268 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:128]: Training history: 
{'val_loss': [0.0094347366226651529, 0.00866773058597008, 0.0080716481583945256, 0.0076123997399659441, 0.0072601944697936616, 0.0069875660736095991, 0.0067726753760596076, 0.0066028416055113962, 0.006468049928070878, 0.0063603836803456434, 0.0062733759341343214, 0.0062024479730890562, 0.0061446861760983112, 0.0060970252046059683, 0.0060574165531713069, 0.0060242171938716272, 0.0059962799265715115, 0.0059726907674343662, 0.0059526772339284443, 0.005935590710793511, 0.0059209842788817439, 0.0059084201975869687, 0.0058975429064500083, 0.0058880020786098693, 0.0058798506900973454, 0.0058728170632331668, 0.0058666899123799654, 0.0058593293847033576, 0.0058514577012648752, 0.0058448823159974713, 0.0058393433628633248, 0.0058346261868978287, 0.0058306097399541965, 0.0058271733805049832, 0.0058242152272170843, 0.0058216679158789274, 0.0058194574196088764, 0.0058175375149782113, 0.0058158603317156644, 0.0058143817689933789, 0.0058130844233838927, 0.0058119302390992793, 0.0058109224990430574, 0.0058099765003511994, 0.0058091304607063706, 0.0058083613919116791, 0.0058076658306861735, 0.0058070405977492341, 0.0058064607381225122, 0.0058059422323224917, 0.0058054586557396929, 0.0058050145830128045, 0.0058045952747042334, 0.0058042081343321538, 0.0058038505731210065, 0.0058035129936735768, 0.0058031886543405001, 0.0058028793080686942, 0.0058025936887882591, 0.0058023116361549708, 0.0058020353484118424, 0.0058017714825814443, 0.0058015159193326431, 0.0058012667232874519, 0.0058010260988497825, 0.0058007838874671964, 0.0058005276964912351, 0.0058002462620014867, 0.0057999587014388706, 0.0057996516524978703, 0.0057993403375621111, 0.005798991157997431, 0.0057985380919837078, 0.0057980425648825251, 0.0057976420763236544, 0.005797342209108461, 0.0057970528768595255, 0.0057967799969492577, 0.0057964922503617178, 0.0057962038418198003, 0.0057959102381853192, 0.0057955991196282173, 0.0057952955497982571, 0.0057949704099761424, 0.005794651095797498, 0.005794333263229509, 0.0057940296756869639, 0.0057937189448386628, 0.0057934155511077338, 0.005793100981163638, 0.0057927944237254735, 0.0057924885438150704, 0.0057921831459950184, 0.0057918723903319846, 0.0057915524624593392, 0.0057912167447158099, 0.0057908778593289151, 0.0057905252820284036, 0.0057901739666853837, 0.0057898337877663906, 0.0057894842307610753], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0099061219208239713, 0.0090393143451901921, 0.0083620540203959409, 0.0078385581779798416, 0.0074368634648032134, 0.0071278831221797036, 0.0068865891805962795, 0.0066964175176948615, 0.0065460577458545622, 0.0064264329171924593, 0.0063305820145921916, 0.0062527592846973075, 0.0061896098424419092, 0.0061378432329178469, 0.0060950512151305069, 0.006059432859855246, 0.0060295563822078775, 0.0060043821827046335, 0.0059831378522154244, 0.0059651043393518953, 0.0059497120764005458, 0.0059365477555603924, 0.00592522086477088, 0.005915314799106763, 0.0059068027725556419, 0.0058994926605407914, 0.0058931854181540361, 0.0058871116793820892, 0.005879219511620553, 0.0058722096481383925, 0.0058663409904955105, 0.0058613864348190095, 0.0058571760940163272, 0.0058535865497274337, 0.005850519294556396, 0.0058478792109979954, 0.0058456018988449574, 0.0058436279066343228, 0.0058419122908214558, 0.0058404150882140722, 0.0058390951064501359, 0.0058379332701068241, 0.0058368997218191795, 0.0058359776143882226, 0.0058351311253319049, 0.005834370213925996, 0.0058336806478651226, 0.0058330614272378385, 0.005832498158955023, 0.005831983099561594, 0.0058315141543533828, 0.0058310836382901628, 0.0058306812102847765, 0.0058303075076993208, 0.0058299573444148267, 0.0058296288313222722, 0.0058293187462307378, 0.0058290283044207325, 0.0058287386113725853, 0.0058284732919518783, 0.0058282119673185809, 0.0058279585223464355, 0.005827714752692126, 0.0058274712298434436, 0.0058272385855328932, 0.0058270055402060679, 0.0058267687324937961, 0.0058265073058345511, 0.0058262298057159649, 0.0058259366574462054, 0.0058256328909902415, 0.0058253141809051405, 0.0058249411986171611, 0.0058244693764486904, 0.0058240336205957087, 0.0058237061396513717, 0.0058234164787256803, 0.0058231329118070005, 0.0058228564737299489, 0.005822572911326704, 0.0058222803157689422, 0.0058219816408364615, 0.0058216791548775914, 0.0058213671893078012, 0.0058210482670544546, 0.0058207356662945478, 0.0058204277215759392, 0.0058201213629178522, 0.0058198117642357401, 0.0058195092192904396, 0.0058192030347337734, 0.0058189026335336846, 0.0058185924551041272, 0.0058182858312357325, 0.0058179767061026276, 0.0058176520930305238, 0.0058173074723556649, 0.0058169665975477654, 0.0058166208692769289, 0.0058162828093563596, 0.0058159366305709451], 'acc': [0.5859825702639494, 0.5938382226001182, 0.5938382226001182, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.59383822266596353, 0.59383822266596353, 0.5938382226001182, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822266596353, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.59383822268791198, 0.59383822266596353, 0.59383822263669894, 0.59383822270254427, 0.5938382226001182, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822270254427, 0.5938382226842539, 0.59383822263669894, 0.59383822270254427, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.59383822272449271, 0.59383822272449271, 0.5938382226001182, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822270254427, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822265133124, 0.59383822270254427, 0.59383822272449271, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.59383822270254427, 0.59383822268791198, 0.59383822266596353, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226842539, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.59383822267327968, 0.5938382226001182, 0.59383822270254427, 0.59383822265133124, 0.5938382226842539, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.59383822268791198, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.59383822270254427, 0.59383822268791198, 0.59383822270254427, 0.5938382226001182, 0.59383822262938279, 0.59383822268791198, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.59383822270254427, 0.59383822266596353, 0.5938382226001182, 0.59383822267327968, 0.59383822265133124, 0.59383822263669894]}
[2017-11-18 18:50:17,269 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:132]: evaluating model ... 
[2017-11-18 18:50:17,419 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:136]: evaluated! 
[2017-11-18 18:50:17,420 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:138]: generating reports ... 
[2017-11-18 18:50:18,267 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:141]: done!
[2017-11-18 18:50:18,267 AE_UNIGRAMA_6L_9FULLDS_UNDER_03.py:157]: >> experiment AE_UNIGRAMA_6L_9FULLDS_UNDER_03 finished!
