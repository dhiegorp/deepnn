[2017-11-13 17:21:17,587 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_FULLDS_OVER_05
[2017-11-13 17:21:17,587 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-13 17:21:17,587 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f571db86eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f571db8b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-13 17:21:17,587 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-13 17:21:19,916 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-13 17:21:19,916 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-13 17:21:19,916 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-13 17:21:19,916 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f571db86eb8>, 'discard_decoder_function': True}
[2017-11-13 17:21:20,045 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-13 17:26:41,660 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-13 17:26:41,661 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0099762262562916194, 0.0096615140625124721, 0.0094122646622242009, 0.0092149698293573796, 0.0090573479529937068, 0.0089331938396045411, 0.0088372679289672705, 0.0087602471464540491, 0.008697346611669269, 0.008645822909804049, 0.0086048806989096581, 0.0085718766705724127, 0.0085453119218617795, 0.0085238170358586818, 0.0085062268434810493, 0.0084916572783036905, 0.0084795049028536136, 0.0084691667129743933, 0.0084601868486845807, 0.0084524451060517015, 0.0084458522365806026, 0.0084400200358606004, 0.0084350519864595762, 0.0084308350146588967, 0.0084271347222083723, 0.0084235153860251332, 0.0084190399751193114, 0.0084133556421376546, 0.0084086360494739342, 0.008404603037327386, 0.00840110652277418, 0.0083980464045531993, 0.0083953213392976272, 0.0083928623485547658, 0.0083906346537071484, 0.0083886183393062884, 0.0083867694586323756, 0.0083850507382460925, 0.0083834343647686323, 0.0083819018171683302, 0.0083804506721582225, 0.0083790667446104975, 0.0083776912999362334, 0.0083762566894101161, 0.0083747823890031638, 0.0083732640881396658, 0.0083712494977637268, 0.0083679398213736007, 0.0083651476156668871, 0.0083627424855572431, 0.0083606078579353746, 0.0083586707364155799, 0.0083568829982153016, 0.0083551927103781825, 0.0083535683253360381, 0.008352010538928192, 0.0083505217847097708, 0.0083490655152007355, 0.0083476210609270077, 0.008346184677088777, 0.008344738052809492, 0.0083432777657097244, 0.0083417907026580966, 0.0083402969896004767, 0.0083387473465320987, 0.0083371987710106205, 0.0083356638028615326, 0.0083341462587618025, 0.0083326566824056311, 0.0083311620955271604, 0.008329662047353947, 0.0083281488470303266, 0.0083265570288428882, 0.0083247395643046441, 0.0083227508870124256, 0.0083207365454683532, 0.0083187416751034898, 0.0083166851806880486, 0.0083142524661796793, 0.0083105357388463669, 0.0083066168648848991, 0.0083031473203518738, 0.0082999446046994208, 0.0082954469597934354, 0.0082895183023263853, 0.0082831885881286607, 0.0082776947124960105, 0.0082728468451220422, 0.0082684388303446744, 0.0082642907966085765, 0.0082604120810985428, 0.0082567832489162194, 0.0082533795000469794, 0.0082501489491103013, 0.0082469863347498333, 0.0082438426240813156, 0.0082400726022329538, 0.0082363355572813574, 0.0082329259096935413, 0.0082297842468394156, 0.0082268773522316992], 'val_acc': [0.0011025358324145535, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010162116546786035, 0.0098117786817772997, 0.0095310842318155585, 0.0093089765983967385, 0.0091321672406310499, 0.0089915497006732535, 0.0088819670755559271, 0.008796434571830037, 0.0087269373290442872, 0.0086696879303569119, 0.0086239697923786631, 0.0085873704029143603, 0.0085579352114979242, 0.0085342056733537005, 0.008514927963428889, 0.0084991110951747276, 0.0084859914210037076, 0.0084749663523470929, 0.0084654958916404385, 0.0084572910706485083, 0.0084503117805419786, 0.008444284356977803, 0.0084390322112733122, 0.0084345912505034964, 0.0084307596091571079, 0.0084272895334808612, 0.0084234988926191398, 0.0084182469107277388, 0.0084131645152810096, 0.0084088872531727296, 0.0084051864189226694, 0.0084019775920890147, 0.008399135489265977, 0.0083965954101128098, 0.0083942998298279815, 0.0083922212929716938, 0.0083903286494502148, 0.0083885861561159587, 0.0083869534949435401, 0.0083854156020446661, 0.0083839615932226226, 0.0083825756283917065, 0.0083812387862254312, 0.0083798675058148701, 0.008378431864692797, 0.008376961146135304, 0.0083752702060838607, 0.0083724868924982179, 0.0083694303697710148, 0.0083668400396662533, 0.0083645821290761254, 0.0083625612712320153, 0.0083607165707608837, 0.0083589989000825531, 0.0083573573127542593, 0.0083557787675164041, 0.008354280070128858, 0.0083528327644401736, 0.0083514057467684172, 0.0083499942554454282, 0.0083485809202249166, 0.0083471534551250812, 0.0083456991794351662, 0.008344235941465902, 0.0083427409284439601, 0.0083412109460712317, 0.0083396869791712552, 0.008338175067508679, 0.0083366813691639532, 0.0083352080868115616, 0.0083337263953490778, 0.0083322378687768154, 0.0083307271104932877, 0.008329080541440867, 0.008327205179343088, 0.0083252540459746414, 0.0083233062432818469, 0.0083213483432781794, 0.0083192009482236894, 0.0083163253128724305, 0.0083124057552237101, 0.0083088002119515586, 0.008305547363407717, 0.0083020553777020181, 0.0082965809657549704, 0.008290445775925798, 0.0082846119692607419, 0.0082795021539261125, 0.0082749402247907933, 0.0082706941845087766, 0.0082666985546557079, 0.0082629903837968949, 0.0082595279418335339, 0.0082562786990067229, 0.0082531487233699005, 0.0082500673109983085, 0.0082467281993725914, 0.0082429204422148801, 0.008239398649728516, 0.0082361694123324804, 0.0082331952488371545], 'acc': [0.00085921197986989076, 0.0084693752310605851, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-13 17:26:41,661 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:95]: done!
[2017-11-13 17:26:41,661 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-13 17:26:41,661 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-13 17:26:41,662 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f571db8b400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-13 17:26:41,699 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-13 17:34:08,612 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:125]: trained!
[2017-11-13 17:34:08,613 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0099762262562916194, 0.0096615140625124721, 0.0094122646622242009, 0.0092149698293573796, 0.0090573479529937068, 0.0089331938396045411, 0.0088372679289672705, 0.0087602471464540491, 0.008697346611669269, 0.008645822909804049, 0.0086048806989096581, 0.0085718766705724127, 0.0085453119218617795, 0.0085238170358586818, 0.0085062268434810493, 0.0084916572783036905, 0.0084795049028536136, 0.0084691667129743933, 0.0084601868486845807, 0.0084524451060517015, 0.0084458522365806026, 0.0084400200358606004, 0.0084350519864595762, 0.0084308350146588967, 0.0084271347222083723, 0.0084235153860251332, 0.0084190399751193114, 0.0084133556421376546, 0.0084086360494739342, 0.008404603037327386, 0.00840110652277418, 0.0083980464045531993, 0.0083953213392976272, 0.0083928623485547658, 0.0083906346537071484, 0.0083886183393062884, 0.0083867694586323756, 0.0083850507382460925, 0.0083834343647686323, 0.0083819018171683302, 0.0083804506721582225, 0.0083790667446104975, 0.0083776912999362334, 0.0083762566894101161, 0.0083747823890031638, 0.0083732640881396658, 0.0083712494977637268, 0.0083679398213736007, 0.0083651476156668871, 0.0083627424855572431, 0.0083606078579353746, 0.0083586707364155799, 0.0083568829982153016, 0.0083551927103781825, 0.0083535683253360381, 0.008352010538928192, 0.0083505217847097708, 0.0083490655152007355, 0.0083476210609270077, 0.008346184677088777, 0.008344738052809492, 0.0083432777657097244, 0.0083417907026580966, 0.0083402969896004767, 0.0083387473465320987, 0.0083371987710106205, 0.0083356638028615326, 0.0083341462587618025, 0.0083326566824056311, 0.0083311620955271604, 0.008329662047353947, 0.0083281488470303266, 0.0083265570288428882, 0.0083247395643046441, 0.0083227508870124256, 0.0083207365454683532, 0.0083187416751034898, 0.0083166851806880486, 0.0083142524661796793, 0.0083105357388463669, 0.0083066168648848991, 0.0083031473203518738, 0.0082999446046994208, 0.0082954469597934354, 0.0082895183023263853, 0.0082831885881286607, 0.0082776947124960105, 0.0082728468451220422, 0.0082684388303446744, 0.0082642907966085765, 0.0082604120810985428, 0.0082567832489162194, 0.0082533795000469794, 0.0082501489491103013, 0.0082469863347498333, 0.0082438426240813156, 0.0082400726022329538, 0.0082363355572813574, 0.0082329259096935413, 0.0082297842468394156, 0.0082268773522316992], 'val_acc': [0.0011025358324145535, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642, 0.013230429988974642], 'loss': [0.010162116546786035, 0.0098117786817772997, 0.0095310842318155585, 0.0093089765983967385, 0.0091321672406310499, 0.0089915497006732535, 0.0088819670755559271, 0.008796434571830037, 0.0087269373290442872, 0.0086696879303569119, 0.0086239697923786631, 0.0085873704029143603, 0.0085579352114979242, 0.0085342056733537005, 0.008514927963428889, 0.0084991110951747276, 0.0084859914210037076, 0.0084749663523470929, 0.0084654958916404385, 0.0084572910706485083, 0.0084503117805419786, 0.008444284356977803, 0.0084390322112733122, 0.0084345912505034964, 0.0084307596091571079, 0.0084272895334808612, 0.0084234988926191398, 0.0084182469107277388, 0.0084131645152810096, 0.0084088872531727296, 0.0084051864189226694, 0.0084019775920890147, 0.008399135489265977, 0.0083965954101128098, 0.0083942998298279815, 0.0083922212929716938, 0.0083903286494502148, 0.0083885861561159587, 0.0083869534949435401, 0.0083854156020446661, 0.0083839615932226226, 0.0083825756283917065, 0.0083812387862254312, 0.0083798675058148701, 0.008378431864692797, 0.008376961146135304, 0.0083752702060838607, 0.0083724868924982179, 0.0083694303697710148, 0.0083668400396662533, 0.0083645821290761254, 0.0083625612712320153, 0.0083607165707608837, 0.0083589989000825531, 0.0083573573127542593, 0.0083557787675164041, 0.008354280070128858, 0.0083528327644401736, 0.0083514057467684172, 0.0083499942554454282, 0.0083485809202249166, 0.0083471534551250812, 0.0083456991794351662, 0.008344235941465902, 0.0083427409284439601, 0.0083412109460712317, 0.0083396869791712552, 0.008338175067508679, 0.0083366813691639532, 0.0083352080868115616, 0.0083337263953490778, 0.0083322378687768154, 0.0083307271104932877, 0.008329080541440867, 0.008327205179343088, 0.0083252540459746414, 0.0083233062432818469, 0.0083213483432781794, 0.0083192009482236894, 0.0083163253128724305, 0.0083124057552237101, 0.0083088002119515586, 0.008305547363407717, 0.0083020553777020181, 0.0082965809657549704, 0.008290445775925798, 0.0082846119692607419, 0.0082795021539261125, 0.0082749402247907933, 0.0082706941845087766, 0.0082666985546557079, 0.0082629903837968949, 0.0082595279418335339, 0.0082562786990067229, 0.0082531487233699005, 0.0082500673109983085, 0.0082467281993725914, 0.0082429204422148801, 0.008239398649728516, 0.0082361694123324804, 0.0082331952488371545], 'acc': [0.00085921197986989076, 0.0084693752310605851, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032897373408, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.01055603289645889, 0.010556032895544373, 0.010556032895544373, 0.010556032895544373]}
[2017-11-13 17:34:08,613 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-13 17:34:08,828 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-13 17:34:08,828 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-13 17:34:09,861 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:141]: done!
[2017-11-13 17:34:09,861 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_6L_FULLDS_OVER_05 finished!
[2017-11-14 07:04:50,236 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_6L_FULLDS_OVER_05 was already executed!
[2017-11-18 14:56:37,871 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_6L_FULLDS_OVER_05 was already executed!
[2017-11-18 16:23:08,267 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:146]: The experiment AE_UNIGRAMA_6L_FULLDS_OVER_05 was already executed!
[2017-11-18 18:23:30,201 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_FULLDS_OVER_05
[2017-11-18 18:23:30,201 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:149]: >> Printing header log
[2017-11-18 18:23:30,201 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_FULLDS_OVER_05
	layers = 96,172,156,139,123,107,91
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_dataset/', 'fullds_data_dir': '/home/dhiegorp/malware_dataset/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 1000, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd66a593eb8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd66a598400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-11-18 18:23:30,201 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:151]: >> Loading dataset... 
[2017-11-18 18:23:32,362 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_dataset/	
	trainx shape = (8147, 96)
	trainy shape = (8147, 9)
	valx shape = (2721, 96)
	valy shape = (2721, 9)
	=======================================
	
[2017-11-18 18:23:32,363 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-11-18 18:23:32,363 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:60]: =======================================
[2017-11-18 18:23:32,363 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fd66a593eb8>, 'discard_decoder_function': True}
[2017-11-18 18:23:32,491 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:76]: training and evaluate autoencoder
[2017-11-18 18:26:56,219 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:88]: trained and evaluated!
[2017-11-18 18:26:56,221 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:91]: Training history: 
{'val_loss': [0.0091012296431486721, 0.0082370409369263327, 0.0075927711097411987, 0.007126280372549575, 0.0067888015757278236, 0.0065439284201718262, 0.0063642445157286506, 0.0062303099312704191, 0.0061289666729504484, 0.006050890294314033, 0.005989877852614324, 0.0059418775584823896, 0.0059033839465199378, 0.0058722189582750143, 0.0058466177211252265, 0.0058254015116682989, 0.0058076104733823242, 0.0057926484330077079, 0.0057800419820121423, 0.0057693686817513589, 0.0057601849002594544, 0.0057522909331913438, 0.0057454286327155001, 0.0057394783405668535, 0.005734286487437251, 0.0057297125253354042, 0.0057256736316694543, 0.0057220686321550326, 0.0057188295808034435, 0.0057159217118324269, 0.0057132880202399065, 0.0057108927653669126, 0.0057086915411643799, 0.0057066474750792715, 0.0057047443102958969, 0.0057029521211883196, 0.0057012224310645553, 0.0056995271985925315, 0.0056978866187715272, 0.0056963295575528407, 0.005694841632659888, 0.0056934209920579577, 0.0056920499211941863, 0.0056907439694076894, 0.005689483604594813, 0.0056882511943480143, 0.0056870473693893349, 0.0056858634411397387, 0.0056846919330059437, 0.0056835495542018827, 0.0056824341158970273, 0.0056813524970774519, 0.0056802978531554343, 0.0056792511554241169, 0.0056782175972647023, 0.0056771814476771201, 0.0056761542778566224, 0.0056751266085754608, 0.0056740876930864723, 0.0056730506885030096, 0.0056720115371884962, 0.0056709636126681534, 0.0056698993210349121, 0.0056688090279261635, 0.0056676743005308946, 0.0056665171871666184, 0.0056651935209983944, 0.0056637672873269332, 0.0056623163147364328, 0.0056608775761512404, 0.0056595365451467426, 0.0056582741703405477, 0.0056570414237257739, 0.0056558126294988832, 0.0056545835616253932, 0.0056533602452078797, 0.0056521365254226137, 0.0056509096990895648, 0.0056496809289072946, 0.0056484301744124076, 0.0056471793342639104, 0.0056459135856809358, 0.0056446382622051408, 0.0056427549172907475, 0.0056380322031048362, 0.0056195270971082581, 0.0055927819264686447, 0.0055715651654401153, 0.0055548635747650612, 0.0055415339429767986, 0.0055306244504462433, 0.0055215844359298161, 0.0055139033789227921, 0.0055073143237327577, 0.0055015761178816526, 0.0054965557743415633, 0.0054920867569943103, 0.0054880356383932641, 0.0054843700188836747, 0.0054809809769361733, 0.0054777864447546022], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096792633841514975, 0.0086555654744087107, 0.0079116247242495621, 0.0073640601782303571, 0.0069679768101694149, 0.0066821039875513636, 0.0064740407957253141, 0.0063204529334664004, 0.0062054853555538894, 0.0061178725905902979, 0.0060500979328184414, 0.005997046670972811, 0.0059550477925592463, 0.0059212393687409944, 0.00589372736987262, 0.0058710626462535965, 0.005852211810951604, 0.0058363643512600758, 0.0058230637027767151, 0.0058118211654977076, 0.0058022647131496415, 0.0057940499899821795, 0.0057869613855597987, 0.0057808022418670878, 0.0057754531466485907, 0.0057707678935200986, 0.0057666325162397955, 0.0057629715065753385, 0.0057597025418755828, 0.0057567651045207007, 0.0057541253490457399, 0.0057517304277243907, 0.005749540814504117, 0.0057475156315028612, 0.0057456283765518401, 0.0057438596956430948, 0.005742171401007308, 0.0057405217160195624, 0.0057389096267648496, 0.0057373680364684859, 0.0057359001343987304, 0.0057344889362931717, 0.0057331422447647962, 0.0057318369334748119, 0.0057305903764990548, 0.0057293772553412099, 0.0057282020937232088, 0.005727044482625919, 0.0057258951855859753, 0.0057247681414055304, 0.0057236706426821455, 0.005722602100866136, 0.0057215589195571273, 0.0057205365746902425, 0.0057195249364320501, 0.0057185083481720821, 0.0057174997945841181, 0.0057164919012212103, 0.0057154823150277704, 0.0057144643134369255, 0.0057134397639522043, 0.0057124189421583925, 0.0057113832771038264, 0.005710339394016337, 0.0057092540790773293, 0.0057081419001060773, 0.00570694283698071, 0.0057055767952167644, 0.0057041649948437476, 0.0057027394301701001, 0.0057013532590581492, 0.005700082157440031, 0.0056988636700031113, 0.0056976594082413052, 0.005696454782386901, 0.0056952525648592848, 0.0056940543177700286, 0.0056928522154717186, 0.005691640560458182, 0.0056904253952947768, 0.0056891995377548708, 0.0056879628178523748, 0.0056867168439391916, 0.0056854013694358583, 0.0056818206979178335, 0.0056721496480816938, 0.005645189580898647, 0.0056199090317764124, 0.0056000382040343917, 0.0055841884279823218, 0.0055713561014629504, 0.005560749043517681, 0.005551844702161802, 0.0055442090276905378, 0.0055376258087726851, 0.0055318570908328658, 0.0055267608053392392, 0.0055221911161160361, 0.0055180409517035399, 0.005514256057103247, 0.005510739301269268], 'acc': [0.5864735485235284, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822266596353, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822267327968, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822267327968, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822266596353]}
[2017-11-18 18:26:56,221 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:95]: done!
[2017-11-18 18:26:56,221 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:155]: >> Executing classifier part ... 
[2017-11-18 18:26:56,221 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:100]: =======================================
[2017-11-18 18:26:56,221 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fd66a598400>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-11-18 18:26:56,284 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:113]: training ... 
[2017-11-18 18:34:32,897 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:125]: trained!
[2017-11-18 18:34:32,899 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:128]: Training history: 
{'val_loss': [0.0091012296431486721, 0.0082370409369263327, 0.0075927711097411987, 0.007126280372549575, 0.0067888015757278236, 0.0065439284201718262, 0.0063642445157286506, 0.0062303099312704191, 0.0061289666729504484, 0.006050890294314033, 0.005989877852614324, 0.0059418775584823896, 0.0059033839465199378, 0.0058722189582750143, 0.0058466177211252265, 0.0058254015116682989, 0.0058076104733823242, 0.0057926484330077079, 0.0057800419820121423, 0.0057693686817513589, 0.0057601849002594544, 0.0057522909331913438, 0.0057454286327155001, 0.0057394783405668535, 0.005734286487437251, 0.0057297125253354042, 0.0057256736316694543, 0.0057220686321550326, 0.0057188295808034435, 0.0057159217118324269, 0.0057132880202399065, 0.0057108927653669126, 0.0057086915411643799, 0.0057066474750792715, 0.0057047443102958969, 0.0057029521211883196, 0.0057012224310645553, 0.0056995271985925315, 0.0056978866187715272, 0.0056963295575528407, 0.005694841632659888, 0.0056934209920579577, 0.0056920499211941863, 0.0056907439694076894, 0.005689483604594813, 0.0056882511943480143, 0.0056870473693893349, 0.0056858634411397387, 0.0056846919330059437, 0.0056835495542018827, 0.0056824341158970273, 0.0056813524970774519, 0.0056802978531554343, 0.0056792511554241169, 0.0056782175972647023, 0.0056771814476771201, 0.0056761542778566224, 0.0056751266085754608, 0.0056740876930864723, 0.0056730506885030096, 0.0056720115371884962, 0.0056709636126681534, 0.0056698993210349121, 0.0056688090279261635, 0.0056676743005308946, 0.0056665171871666184, 0.0056651935209983944, 0.0056637672873269332, 0.0056623163147364328, 0.0056608775761512404, 0.0056595365451467426, 0.0056582741703405477, 0.0056570414237257739, 0.0056558126294988832, 0.0056545835616253932, 0.0056533602452078797, 0.0056521365254226137, 0.0056509096990895648, 0.0056496809289072946, 0.0056484301744124076, 0.0056471793342639104, 0.0056459135856809358, 0.0056446382622051408, 0.0056427549172907475, 0.0056380322031048362, 0.0056195270971082581, 0.0055927819264686447, 0.0055715651654401153, 0.0055548635747650612, 0.0055415339429767986, 0.0055306244504462433, 0.0055215844359298161, 0.0055139033789227921, 0.0055073143237327577, 0.0055015761178816526, 0.0054965557743415633, 0.0054920867569943103, 0.0054880356383932641, 0.0054843700188836747, 0.0054809809769361733, 0.0054777864447546022], 'val_acc': [0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074, 0.60308710033076074], 'loss': [0.0096792633841514975, 0.0086555654744087107, 0.0079116247242495621, 0.0073640601782303571, 0.0069679768101694149, 0.0066821039875513636, 0.0064740407957253141, 0.0063204529334664004, 0.0062054853555538894, 0.0061178725905902979, 0.0060500979328184414, 0.005997046670972811, 0.0059550477925592463, 0.0059212393687409944, 0.00589372736987262, 0.0058710626462535965, 0.005852211810951604, 0.0058363643512600758, 0.0058230637027767151, 0.0058118211654977076, 0.0058022647131496415, 0.0057940499899821795, 0.0057869613855597987, 0.0057808022418670878, 0.0057754531466485907, 0.0057707678935200986, 0.0057666325162397955, 0.0057629715065753385, 0.0057597025418755828, 0.0057567651045207007, 0.0057541253490457399, 0.0057517304277243907, 0.005749540814504117, 0.0057475156315028612, 0.0057456283765518401, 0.0057438596956430948, 0.005742171401007308, 0.0057405217160195624, 0.0057389096267648496, 0.0057373680364684859, 0.0057359001343987304, 0.0057344889362931717, 0.0057331422447647962, 0.0057318369334748119, 0.0057305903764990548, 0.0057293772553412099, 0.0057282020937232088, 0.005727044482625919, 0.0057258951855859753, 0.0057247681414055304, 0.0057236706426821455, 0.005722602100866136, 0.0057215589195571273, 0.0057205365746902425, 0.0057195249364320501, 0.0057185083481720821, 0.0057174997945841181, 0.0057164919012212103, 0.0057154823150277704, 0.0057144643134369255, 0.0057134397639522043, 0.0057124189421583925, 0.0057113832771038264, 0.005710339394016337, 0.0057092540790773293, 0.0057081419001060773, 0.00570694283698071, 0.0057055767952167644, 0.0057041649948437476, 0.0057027394301701001, 0.0057013532590581492, 0.005700082157440031, 0.0056988636700031113, 0.0056976594082413052, 0.005696454782386901, 0.0056952525648592848, 0.0056940543177700286, 0.0056928522154717186, 0.005691640560458182, 0.0056904253952947768, 0.0056891995377548708, 0.0056879628178523748, 0.0056867168439391916, 0.0056854013694358583, 0.0056818206979178335, 0.0056721496480816938, 0.005645189580898647, 0.0056199090317764124, 0.0056000382040343917, 0.0055841884279823218, 0.0055713561014629504, 0.005560749043517681, 0.005551844702161802, 0.0055442090276905378, 0.0055376258087726851, 0.0055318570908328658, 0.0055267608053392392, 0.0055221911161160361, 0.0055180409517035399, 0.005514256057103247, 0.005510739301269268], 'acc': [0.5864735485235284, 0.5938382226842539, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.5938382226842539, 0.59383822268791198, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822272449271, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.5938382226842539, 0.5938382226001182, 0.59383822263669894, 0.5938382226001182, 0.59383822272449271, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822263669894, 0.5938382226842539, 0.59383822266596353, 0.59383822265133124, 0.59383822265133124, 0.59383822266596353, 0.5938382226001182, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.5938382226842539, 0.59383822266596353, 0.59383822268791198, 0.59383822264767316, 0.59383822266596353, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.5938382226842539, 0.59383822270254427, 0.59383822272449271, 0.5938382226842539, 0.5938382226842539, 0.59383822267327968, 0.59383822266596353, 0.59383822268791198, 0.5938382226842539, 0.5938382226001182, 0.59383822268791198, 0.59383822270254427, 0.59383822265133124, 0.59383822268791198, 0.5938382226842539, 0.59383822263669894, 0.59383822267327968, 0.5938382226842539, 0.59383822268791198, 0.59383822263669894, 0.59383822263669894, 0.5938382226001182, 0.59383822270254427, 0.59383822263669894, 0.5938382226001182, 0.59383822264767316, 0.59383822263669894, 0.59383822265133124, 0.5938382226001182, 0.59383822265133124, 0.5938382226842539, 0.59383822268791198, 0.59383822265133124, 0.5938382226842539, 0.5938382226842539, 0.5938382226842539, 0.59383822265133124, 0.59383822265133124, 0.59383822265133124, 0.5938382226001182, 0.59383822270254427, 0.5938382226001182, 0.59383822265133124, 0.59383822264767316, 0.5938382226001182, 0.59383822265133124, 0.59383822263669894, 0.5938382226001182, 0.59383822265133124, 0.59383822265133124, 0.5938382226842539, 0.59383822263669894, 0.59383822268791198, 0.59383822272449271, 0.5938382226001182, 0.5938382226842539, 0.59383822263669894, 0.59383822266596353]}
[2017-11-18 18:34:32,899 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:132]: evaluating model ... 
[2017-11-18 18:34:33,105 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:136]: evaluated! 
[2017-11-18 18:34:33,106 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:138]: generating reports ... 
[2017-11-18 18:34:33,948 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:141]: done!
[2017-11-18 18:34:33,948 AE_UNIGRAMA_6L_FULLDS_OVER_05.py:157]: >> experiment AE_UNIGRAMA_6L_FULLDS_OVER_05 finished!
