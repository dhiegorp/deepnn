[2017-10-20 01:40:14,010 AE_UNIGRAMA_6L_OVER_05.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_OVER_05
[2017-10-20 01:40:14,010 AE_UNIGRAMA_6L_OVER_05.py:149]: >> Printing header log
[2017-10-20 01:40:14,010 AE_UNIGRAMA_6L_OVER_05.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_OVER_05
	layers = 96,172,156,139,123,107,91,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f69316727f0>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f69316728d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:40:14,010 AE_UNIGRAMA_6L_OVER_05.py:151]: >> Loading dataset... 
[2017-10-20 01:40:14,616 AE_UNIGRAMA_6L_OVER_05.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:40:14,617 AE_UNIGRAMA_6L_OVER_05.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:40:14,617 AE_UNIGRAMA_6L_OVER_05.py:60]: =======================================
[2017-10-20 01:40:14,617 AE_UNIGRAMA_6L_OVER_05.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7f69316727f0>, 'discard_decoder_function': True}
[2017-10-20 01:40:14,769 AE_UNIGRAMA_6L_OVER_05.py:76]: training and evaluate autoencoder
[2017-10-20 01:41:18,828 AE_UNIGRAMA_6L_OVER_05.py:88]: trained and evaluated!
[2017-10-20 01:41:18,828 AE_UNIGRAMA_6L_OVER_05.py:91]: Training history: 
{'val_loss': [0.010171696491761056, 0.0099242989001553303, 0.0096873329003725802, 0.0094623016228130765, 0.0092512211696587528, 0.0090530071525270171, 0.0088672700258435808, 0.0086932282507087219, 0.0085283734949935762, 0.0083729626063852956, 0.0082268441514870266, 0.008089340063414387, 0.0079599740762665155, 0.0078374940701189093, 0.0077221513410760121, 0.0076135729758075848, 0.0075113097011876816, 0.0074149571812701272, 0.0073241704320154222, 0.0072385311424455236, 0.0071577132129037688, 0.0070814050051996478, 0.0070093161976968934, 0.0069412277495578545, 0.0068769642155354352, 0.006816206891158921, 0.0067587133573167382, 0.0067043029962862294, 0.0066527348482586634, 0.0066039374125879046, 0.0065576681507176623, 0.0065138056548831634, 0.0064721884531380959, 0.0064326763745106508, 0.0063952424885448909, 0.0063596736296983678, 0.0063258318064325801, 0.0062936693845406788, 0.0062631030660468849, 0.0062339744707188638, 0.006206261054664629, 0.0061798488330026763, 0.0061546878172534774, 0.0061306475633997682, 0.0061070605780112258, 0.0060842008326465755, 0.0060623885464740285, 0.0060415709595504083, 0.0060217124998541791, 0.0060027150478781819, 0.0059845627572899856, 0.0059672135420032815, 0.0059505834185334828, 0.0059344532819928736, 0.005918624473313306, 0.0059033184983944137, 0.0058886983161826785, 0.0058747344549925353, 0.005861414193096103, 0.0058486587835344236, 0.0058364744564746839, 0.0058247734771757539, 0.0058135570695132125, 0.0058028349015847901, 0.0057925661856163164, 0.0057826712727546692, 0.0057732021041408347, 0.0057640978183638872, 0.0057553704204834086, 0.0057469821625067176, 0.005738926646351593, 0.0057311952027551084, 0.0057237640691429484, 0.005716617350712363, 0.0057097447925285334, 0.0057031368632492743, 0.0056967241568386994, 0.0056903872510840683, 0.005684098871043956, 0.0056776128238461721, 0.0056709812133534914, 0.005664620686973338, 0.0056585201882795328, 0.0056526545854112247, 0.005647025202646796, 0.005641616441198663, 0.005636431190244106, 0.0056314435597079838, 0.0056266576262904147, 0.0056220442818332335, 0.0056176235965110337, 0.0056133700853220597, 0.0056092645332466492, 0.005605302089790651, 0.0056015016514544816, 0.0055978287610339633, 0.005594284966117166, 0.0055908674935093603, 0.005587556773318899, 0.0055843612774652621, 0.0055812254278023894, 0.0055782135202095857], 'loss': [0.010289820564822617, 0.010044295669343842, 0.0098018275291075641, 0.009570131625593184, 0.0093516927297194463, 0.0091466838453874016, 0.0089542927625735035, 0.0087740461639121189, 0.0086043023726987047, 0.0084437254413312103, 0.0082925537156917674, 0.0081503122802262813, 0.0080164463540336513, 0.0078900693993060669, 0.0077707078877422035, 0.0076582365744869143, 0.0075523462593005929, 0.0074525410913333949, 0.0073584480518526689, 0.0072697255023158099, 0.0071859692504426861, 0.0071068791502007104, 0.0070321281556756715, 0.006961503511749222, 0.0068947405310504518, 0.0068316998981401899, 0.00677202432802761, 0.0067155127076989644, 0.006661976981260107, 0.0066112132972540229, 0.0065631241129497191, 0.0065174852681049149, 0.0064741902553648693, 0.0064330738494041036, 0.0063939993739123534, 0.0063569275593612926, 0.0063216857999659386, 0.0062881189194687066, 0.0062562029773842245, 0.0062258124200383355, 0.006196831997836578, 0.0061692430883343776, 0.0061428991201337713, 0.0061177791167249798, 0.0060935326435184768, 0.0060697250768253792, 0.0060469183647809364, 0.0060251326318521148, 0.0060043162654812854, 0.0059844312534542195, 0.0059654011282916442, 0.0059472012523041958, 0.0059297808686977673, 0.0059129950408975483, 0.0058965806845866359, 0.0058805350000731369, 0.0058651745709182483, 0.0058504649304590784, 0.0058364113274739608, 0.0058229809063678516, 0.0058101069708208801, 0.0057977823793576699, 0.0057859394024455373, 0.0057745805338194527, 0.0057637083270319711, 0.0057532785731678592, 0.0057432248867297182, 0.0057335891420297559, 0.0057243163315046945, 0.0057154235609800774, 0.0057068603716048825, 0.0056986335739974197, 0.0056907243894432575, 0.0056831138205646406, 0.0056757893231276658, 0.0056687345978424421, 0.0056619387221326289, 0.0056552604060063679, 0.0056486619663892457, 0.0056420207437478144, 0.0056350936359864986, 0.0056282654699434985, 0.0056217197499386215, 0.0056154422860388827, 0.0056094016720092616, 0.005603585772607853, 0.005598013162482404, 0.0055926457203732327, 0.0055874689229144115, 0.0055825065889526853, 0.0055777269765304215, 0.0055731447732972452, 0.0055687062012417486, 0.0055644372941785307, 0.005560306466133611, 0.0055563387280122851, 0.0055524925260559028, 0.0055487905073734649, 0.0055452057240003077, 0.0055417389904859242, 0.0055383618768778545, 0.005535092433776017]}
[2017-10-20 01:41:18,829 AE_UNIGRAMA_6L_OVER_05.py:95]: done!
[2017-10-20 01:41:18,829 AE_UNIGRAMA_6L_OVER_05.py:155]: >> Executing classifier part ... 
[2017-10-20 01:41:18,829 AE_UNIGRAMA_6L_OVER_05.py:100]: =======================================
[2017-10-20 01:41:18,829 AE_UNIGRAMA_6L_OVER_05.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7f69316728d0>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:41:18,866 AE_UNIGRAMA_6L_OVER_05.py:113]: training ... 
[2017-10-20 01:42:50,595 AE_UNIGRAMA_6L_OVER_05.py:125]: trained!
[2017-10-20 01:42:50,596 AE_UNIGRAMA_6L_OVER_05.py:128]: Training history: 
{'val_loss': [0.010171696491761056, 0.0099242989001553303, 0.0096873329003725802, 0.0094623016228130765, 0.0092512211696587528, 0.0090530071525270171, 0.0088672700258435808, 0.0086932282507087219, 0.0085283734949935762, 0.0083729626063852956, 0.0082268441514870266, 0.008089340063414387, 0.0079599740762665155, 0.0078374940701189093, 0.0077221513410760121, 0.0076135729758075848, 0.0075113097011876816, 0.0074149571812701272, 0.0073241704320154222, 0.0072385311424455236, 0.0071577132129037688, 0.0070814050051996478, 0.0070093161976968934, 0.0069412277495578545, 0.0068769642155354352, 0.006816206891158921, 0.0067587133573167382, 0.0067043029962862294, 0.0066527348482586634, 0.0066039374125879046, 0.0065576681507176623, 0.0065138056548831634, 0.0064721884531380959, 0.0064326763745106508, 0.0063952424885448909, 0.0063596736296983678, 0.0063258318064325801, 0.0062936693845406788, 0.0062631030660468849, 0.0062339744707188638, 0.006206261054664629, 0.0061798488330026763, 0.0061546878172534774, 0.0061306475633997682, 0.0061070605780112258, 0.0060842008326465755, 0.0060623885464740285, 0.0060415709595504083, 0.0060217124998541791, 0.0060027150478781819, 0.0059845627572899856, 0.0059672135420032815, 0.0059505834185334828, 0.0059344532819928736, 0.005918624473313306, 0.0059033184983944137, 0.0058886983161826785, 0.0058747344549925353, 0.005861414193096103, 0.0058486587835344236, 0.0058364744564746839, 0.0058247734771757539, 0.0058135570695132125, 0.0058028349015847901, 0.0057925661856163164, 0.0057826712727546692, 0.0057732021041408347, 0.0057640978183638872, 0.0057553704204834086, 0.0057469821625067176, 0.005738926646351593, 0.0057311952027551084, 0.0057237640691429484, 0.005716617350712363, 0.0057097447925285334, 0.0057031368632492743, 0.0056967241568386994, 0.0056903872510840683, 0.005684098871043956, 0.0056776128238461721, 0.0056709812133534914, 0.005664620686973338, 0.0056585201882795328, 0.0056526545854112247, 0.005647025202646796, 0.005641616441198663, 0.005636431190244106, 0.0056314435597079838, 0.0056266576262904147, 0.0056220442818332335, 0.0056176235965110337, 0.0056133700853220597, 0.0056092645332466492, 0.005605302089790651, 0.0056015016514544816, 0.0055978287610339633, 0.005594284966117166, 0.0055908674935093603, 0.005587556773318899, 0.0055843612774652621, 0.0055812254278023894, 0.0055782135202095857], 'loss': [0.010289820564822617, 0.010044295669343842, 0.0098018275291075641, 0.009570131625593184, 0.0093516927297194463, 0.0091466838453874016, 0.0089542927625735035, 0.0087740461639121189, 0.0086043023726987047, 0.0084437254413312103, 0.0082925537156917674, 0.0081503122802262813, 0.0080164463540336513, 0.0078900693993060669, 0.0077707078877422035, 0.0076582365744869143, 0.0075523462593005929, 0.0074525410913333949, 0.0073584480518526689, 0.0072697255023158099, 0.0071859692504426861, 0.0071068791502007104, 0.0070321281556756715, 0.006961503511749222, 0.0068947405310504518, 0.0068316998981401899, 0.00677202432802761, 0.0067155127076989644, 0.006661976981260107, 0.0066112132972540229, 0.0065631241129497191, 0.0065174852681049149, 0.0064741902553648693, 0.0064330738494041036, 0.0063939993739123534, 0.0063569275593612926, 0.0063216857999659386, 0.0062881189194687066, 0.0062562029773842245, 0.0062258124200383355, 0.006196831997836578, 0.0061692430883343776, 0.0061428991201337713, 0.0061177791167249798, 0.0060935326435184768, 0.0060697250768253792, 0.0060469183647809364, 0.0060251326318521148, 0.0060043162654812854, 0.0059844312534542195, 0.0059654011282916442, 0.0059472012523041958, 0.0059297808686977673, 0.0059129950408975483, 0.0058965806845866359, 0.0058805350000731369, 0.0058651745709182483, 0.0058504649304590784, 0.0058364113274739608, 0.0058229809063678516, 0.0058101069708208801, 0.0057977823793576699, 0.0057859394024455373, 0.0057745805338194527, 0.0057637083270319711, 0.0057532785731678592, 0.0057432248867297182, 0.0057335891420297559, 0.0057243163315046945, 0.0057154235609800774, 0.0057068603716048825, 0.0056986335739974197, 0.0056907243894432575, 0.0056831138205646406, 0.0056757893231276658, 0.0056687345978424421, 0.0056619387221326289, 0.0056552604060063679, 0.0056486619663892457, 0.0056420207437478144, 0.0056350936359864986, 0.0056282654699434985, 0.0056217197499386215, 0.0056154422860388827, 0.0056094016720092616, 0.005603585772607853, 0.005598013162482404, 0.0055926457203732327, 0.0055874689229144115, 0.0055825065889526853, 0.0055777269765304215, 0.0055731447732972452, 0.0055687062012417486, 0.0055644372941785307, 0.005560306466133611, 0.0055563387280122851, 0.0055524925260559028, 0.0055487905073734649, 0.0055452057240003077, 0.0055417389904859242, 0.0055383618768778545, 0.005535092433776017]}
[2017-10-20 01:42:50,596 AE_UNIGRAMA_6L_OVER_05.py:132]: evaluating model ... 
[2017-10-20 01:42:50,669 AE_UNIGRAMA_6L_OVER_05.py:136]: evaluated! 
[2017-10-20 01:42:50,670 AE_UNIGRAMA_6L_OVER_05.py:138]: generating reports ... 
[2017-10-20 01:42:51,273 AE_UNIGRAMA_6L_OVER_05.py:141]: done!
[2017-10-20 01:42:51,274 AE_UNIGRAMA_6L_OVER_05.py:157]: >> experiment AE_UNIGRAMA_6L_OVER_05 finished!
