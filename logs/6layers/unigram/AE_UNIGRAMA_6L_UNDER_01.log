[2017-10-20 01:38:57,110 AE_UNIGRAMA_6L_UNDER_01.py:148]: >> Initializing execution of experiment AE_UNIGRAMA_6L_UNDER_01
[2017-10-20 01:38:57,110 AE_UNIGRAMA_6L_UNDER_01.py:149]: >> Printing header log
[2017-10-20 01:38:57,110 AE_UNIGRAMA_6L_UNDER_01.py:38]: 
	=======================================
	network_name = AE_UNIGRAMA_6L_UNDER_01
	layers = 96,28,26,24,22,20,19,9
	using GLOBAL obj = 
		{'numpy_seed': 666, 'log_format': '[%(asctime)s %(filename)s:%(lineno)s]: %(message)s', 'log_dir': '/home/dhiegorp/deepnn/logs/6layers/unigram/', 'reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/', 'fullds_reports_dir': '/home/dhiegorp/deepnn/reports/6layers/unigram/fullds/', 'tensorflow_dir': '/home/dhiegorp/deepnn/tensorflow/6layers/unigram/', 'checkpoints_dir': '/home/dhiegorp/deepnn/checkpoints/6layers/unigram/', 'executed_path': '/home/dhiegorp/deepnn/executed/6layers/unigram/', 'data_dir': '/home/dhiegorp/malware_deepnn/', 'fullds_data_dir': '/home/dhiegorp/malware_deepnn/', 'data_target_list': [1, 2, 3, 4, 5, 6, 7, 8, 9], 'epochs': 200, 'batch': 32, 'store_history': True, 'shuffle_batches': True, 'autoencoder_configs': {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa55106e7b8>, 'discard_decoder_function': True}, 'mlp_configs': {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa55106e898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}}
	=======================================
	
[2017-10-20 01:38:57,110 AE_UNIGRAMA_6L_UNDER_01.py:151]: >> Loading dataset... 
[2017-10-20 01:38:57,712 AE_UNIGRAMA_6L_UNDER_01.py:55]: 
	=======================================
	loading malware dataset on = /home/dhiegorp/malware_deepnn/	
	trainx shape = (1627, 96)
	trainy shape = (1627, 9)
	valx shape = (1076, 96)
	valy shape = (1076, 9)
	=======================================
	
[2017-10-20 01:38:57,712 AE_UNIGRAMA_6L_UNDER_01.py:153]: >> Executing autoencoder part ... 
[2017-10-20 01:38:57,712 AE_UNIGRAMA_6L_UNDER_01.py:60]: =======================================
[2017-10-20 01:38:57,712 AE_UNIGRAMA_6L_UNDER_01.py:65]: setting configurations for autoencoder: 
	 {'hidden_layer_activation': 'relu', 'output_layer_activation': 'relu', 'loss_function': 'mse', 'optimizer': <keras.optimizers.SGD object at 0x7fa55106e7b8>, 'discard_decoder_function': True}
[2017-10-20 01:38:57,865 AE_UNIGRAMA_6L_UNDER_01.py:76]: training and evaluate autoencoder
[2017-10-20 01:39:29,317 AE_UNIGRAMA_6L_UNDER_01.py:88]: trained and evaluated!
[2017-10-20 01:39:29,318 AE_UNIGRAMA_6L_UNDER_01.py:91]: Training history: 
{'val_loss': [0.010281584692987367, 0.010167080265050928, 0.010061202086092813, 0.0099633013151004413, 0.009872820273346395, 0.0097893855662594051, 0.0097123711892718716, 0.0096413274659155473, 0.0095756587063457448, 0.0095148911824290642, 0.0094585824709344079, 0.0094063540186636058, 0.0093578322267776088, 0.0093127720224148273, 0.0092707504501019274, 0.0092315939653207814, 0.0091950037450872386, 0.0091607491710815284, 0.0091287904283980457, 0.0090988220570809783, 0.0090707501943559001, 0.0090443717703555596, 0.0090195908242331115, 0.0089962803395153418, 0.0089742843906453987, 0.0089535198821842008, 0.008933907333193658, 0.0089153135056887853, 0.0088977220270879658, 0.008881023351006127, 0.0088651329555919176, 0.0088500512736160511, 0.0088356900302395507, 0.0088219849399696054, 0.0088088952738888653, 0.0087963979670494016, 0.0087844506252321604, 0.0087729973725448312, 0.0087620241976028041, 0.0087514824569779257, 0.0087413535449916997, 0.0087316139604633174, 0.0087222593202910016, 0.0087132366879611213, 0.008704584746251097, 0.0086962638187419519, 0.0086877625349036595, 0.0086795350062387356, 0.0086715736194447959, 0.0086638892976546381, 0.0086564732538917024, 0.008649290274468608, 0.0086423490494212697, 0.0086356179743700533, 0.0086291097416144324, 0.0086228027783998989, 0.0086166813838049819, 0.0086107611202645255, 0.0086050143545029559, 0.0085994396964607402, 0.0085940166864696497, 0.0085887422276224572, 0.0085836500327577149, 0.0085787034288851965, 0.0085739024211981488, 0.0085692205137424312, 0.0085646631559668646, 0.0085602356847998828, 0.0085559248314914203, 0.0085517200849064001, 0.0085476345528041793, 0.0085436547535115009, 0.0085397766085971681, 0.0085359952623737783, 0.0085323126155703033, 0.008528724366445856, 0.0085252244631347819, 0.0085218118185170517, 0.0085184846703503219, 0.0085152446216173114, 0.0085120778461592796, 0.0085089914067942637, 0.0085059775915481573, 0.0085030378233710638, 0.008500173094173457, 0.0084973749303047762, 0.0084946467177630797, 0.0084919816464684265, 0.0084893731123397344, 0.0084865116358468079, 0.0084833330197820658, 0.0084802529127181239, 0.0084772665212865649, 0.0084743731963313196, 0.0084715654959272059, 0.0084688392014253093, 0.0084661948165707431, 0.0084636251521764197, 0.0084611252954292036, 0.0084586972439987061, 0.0084563341843428216, 0.0084540296491360141], 'loss': [0.010337726566791718, 0.010219112560656735, 0.010109351338279452, 0.010007931668821954, 0.0099141484134462471, 0.0098275751964210286, 0.0097477948693781812, 0.0096741811404967501, 0.0096062452354329312, 0.0095434242753013182, 0.0094852716969377662, 0.0094313672792393152, 0.0093813593096953272, 0.0093348825032139888, 0.0092917065466419282, 0.009251425450309405, 0.009213875677521308, 0.0091787722160937817, 0.009145941461660265, 0.0091152896780632865, 0.0090865469065431297, 0.0090596157932664335, 0.0090343042396434838, 0.0090105052477581112, 0.008988115672061028, 0.0089669834396538008, 0.0089470285867336852, 0.0089281620898529583, 0.0089102833707528969, 0.0088933573156531123, 0.0088772812592622392, 0.0088619861795298516, 0.0088474562250824163, 0.0088336195987915433, 0.0088204137297471976, 0.0088077935589947944, 0.0087957416673104458, 0.0087842158057349698, 0.0087731629129231305, 0.0087625691936235161, 0.0087523899111523543, 0.0087426051488300738, 0.0087332019419824342, 0.0087241778967612413, 0.008715468395865433, 0.0087071237455968783, 0.0086988542222068144, 0.0086905951282557851, 0.008682629475329981, 0.0086749216167287153, 0.0086674915498423672, 0.0086603156435769903, 0.0086533564624285582, 0.0086466388613187107, 0.0086401214064101752, 0.0086338279125427794, 0.0086277146510592099, 0.0086217893141000718, 0.0086160488243511874, 0.0086104920959373735, 0.0086050873654353599, 0.0085998265131089907, 0.0085947338809942136, 0.0085898054409920994, 0.0085850170313780776, 0.0085803605072296459, 0.0085758291506600592, 0.0085714181390554901, 0.008567126856495173, 0.0085629566750628269, 0.0085588815577955571, 0.0085549231729691727, 0.0085510740076096131, 0.0085473183110887536, 0.0085436537141723359, 0.0085400934471361236, 0.0085366187158104241, 0.008533226912835477, 0.0085299289582117469, 0.0085267073485700354, 0.0085235782174854901, 0.0085205065313161115, 0.0085175218565484538, 0.0085146005288883816, 0.0085117593281699173, 0.0085089856394656473, 0.0085062803448702779, 0.0085036381987537712, 0.0085010566607291674, 0.0084984546834082058, 0.0084953940780884887, 0.0084922853553897771, 0.0084892739098205404, 0.0084863554785908485, 0.0084835354183796507, 0.0084807876664652875, 0.008478125620269306, 0.0084755385950546578, 0.0084730247608039676, 0.0084705863591024826, 0.0084682120280437628, 0.0084659115485182998]}
[2017-10-20 01:39:29,318 AE_UNIGRAMA_6L_UNDER_01.py:95]: done!
[2017-10-20 01:39:29,318 AE_UNIGRAMA_6L_UNDER_01.py:155]: >> Executing classifier part ... 
[2017-10-20 01:39:29,318 AE_UNIGRAMA_6L_UNDER_01.py:100]: =======================================
[2017-10-20 01:39:29,318 AE_UNIGRAMA_6L_UNDER_01.py:104]: setting configurations for classifier: 
	 {'activation': 'sigmoid', 'loss_function': 'categorical_crossentropy', 'optimizer': <keras.optimizers.SGD object at 0x7fa55106e898>, 'use_last_dim_as_classifier': False, 'classifier_dim': 9}
[2017-10-20 01:39:29,353 AE_UNIGRAMA_6L_UNDER_01.py:113]: training ... 
[2017-10-20 01:39:56,952 AE_UNIGRAMA_6L_UNDER_01.py:125]: trained!
[2017-10-20 01:39:56,952 AE_UNIGRAMA_6L_UNDER_01.py:128]: Training history: 
{'val_loss': [0.010281584692987367, 0.010167080265050928, 0.010061202086092813, 0.0099633013151004413, 0.009872820273346395, 0.0097893855662594051, 0.0097123711892718716, 0.0096413274659155473, 0.0095756587063457448, 0.0095148911824290642, 0.0094585824709344079, 0.0094063540186636058, 0.0093578322267776088, 0.0093127720224148273, 0.0092707504501019274, 0.0092315939653207814, 0.0091950037450872386, 0.0091607491710815284, 0.0091287904283980457, 0.0090988220570809783, 0.0090707501943559001, 0.0090443717703555596, 0.0090195908242331115, 0.0089962803395153418, 0.0089742843906453987, 0.0089535198821842008, 0.008933907333193658, 0.0089153135056887853, 0.0088977220270879658, 0.008881023351006127, 0.0088651329555919176, 0.0088500512736160511, 0.0088356900302395507, 0.0088219849399696054, 0.0088088952738888653, 0.0087963979670494016, 0.0087844506252321604, 0.0087729973725448312, 0.0087620241976028041, 0.0087514824569779257, 0.0087413535449916997, 0.0087316139604633174, 0.0087222593202910016, 0.0087132366879611213, 0.008704584746251097, 0.0086962638187419519, 0.0086877625349036595, 0.0086795350062387356, 0.0086715736194447959, 0.0086638892976546381, 0.0086564732538917024, 0.008649290274468608, 0.0086423490494212697, 0.0086356179743700533, 0.0086291097416144324, 0.0086228027783998989, 0.0086166813838049819, 0.0086107611202645255, 0.0086050143545029559, 0.0085994396964607402, 0.0085940166864696497, 0.0085887422276224572, 0.0085836500327577149, 0.0085787034288851965, 0.0085739024211981488, 0.0085692205137424312, 0.0085646631559668646, 0.0085602356847998828, 0.0085559248314914203, 0.0085517200849064001, 0.0085476345528041793, 0.0085436547535115009, 0.0085397766085971681, 0.0085359952623737783, 0.0085323126155703033, 0.008528724366445856, 0.0085252244631347819, 0.0085218118185170517, 0.0085184846703503219, 0.0085152446216173114, 0.0085120778461592796, 0.0085089914067942637, 0.0085059775915481573, 0.0085030378233710638, 0.008500173094173457, 0.0084973749303047762, 0.0084946467177630797, 0.0084919816464684265, 0.0084893731123397344, 0.0084865116358468079, 0.0084833330197820658, 0.0084802529127181239, 0.0084772665212865649, 0.0084743731963313196, 0.0084715654959272059, 0.0084688392014253093, 0.0084661948165707431, 0.0084636251521764197, 0.0084611252954292036, 0.0084586972439987061, 0.0084563341843428216, 0.0084540296491360141], 'loss': [0.010337726566791718, 0.010219112560656735, 0.010109351338279452, 0.010007931668821954, 0.0099141484134462471, 0.0098275751964210286, 0.0097477948693781812, 0.0096741811404967501, 0.0096062452354329312, 0.0095434242753013182, 0.0094852716969377662, 0.0094313672792393152, 0.0093813593096953272, 0.0093348825032139888, 0.0092917065466419282, 0.009251425450309405, 0.009213875677521308, 0.0091787722160937817, 0.009145941461660265, 0.0091152896780632865, 0.0090865469065431297, 0.0090596157932664335, 0.0090343042396434838, 0.0090105052477581112, 0.008988115672061028, 0.0089669834396538008, 0.0089470285867336852, 0.0089281620898529583, 0.0089102833707528969, 0.0088933573156531123, 0.0088772812592622392, 0.0088619861795298516, 0.0088474562250824163, 0.0088336195987915433, 0.0088204137297471976, 0.0088077935589947944, 0.0087957416673104458, 0.0087842158057349698, 0.0087731629129231305, 0.0087625691936235161, 0.0087523899111523543, 0.0087426051488300738, 0.0087332019419824342, 0.0087241778967612413, 0.008715468395865433, 0.0087071237455968783, 0.0086988542222068144, 0.0086905951282557851, 0.008682629475329981, 0.0086749216167287153, 0.0086674915498423672, 0.0086603156435769903, 0.0086533564624285582, 0.0086466388613187107, 0.0086401214064101752, 0.0086338279125427794, 0.0086277146510592099, 0.0086217893141000718, 0.0086160488243511874, 0.0086104920959373735, 0.0086050873654353599, 0.0085998265131089907, 0.0085947338809942136, 0.0085898054409920994, 0.0085850170313780776, 0.0085803605072296459, 0.0085758291506600592, 0.0085714181390554901, 0.008567126856495173, 0.0085629566750628269, 0.0085588815577955571, 0.0085549231729691727, 0.0085510740076096131, 0.0085473183110887536, 0.0085436537141723359, 0.0085400934471361236, 0.0085366187158104241, 0.008533226912835477, 0.0085299289582117469, 0.0085267073485700354, 0.0085235782174854901, 0.0085205065313161115, 0.0085175218565484538, 0.0085146005288883816, 0.0085117593281699173, 0.0085089856394656473, 0.0085062803448702779, 0.0085036381987537712, 0.0085010566607291674, 0.0084984546834082058, 0.0084953940780884887, 0.0084922853553897771, 0.0084892739098205404, 0.0084863554785908485, 0.0084835354183796507, 0.0084807876664652875, 0.008478125620269306, 0.0084755385950546578, 0.0084730247608039676, 0.0084705863591024826, 0.0084682120280437628, 0.0084659115485182998]}
[2017-10-20 01:39:56,952 AE_UNIGRAMA_6L_UNDER_01.py:132]: evaluating model ... 
[2017-10-20 01:39:57,003 AE_UNIGRAMA_6L_UNDER_01.py:136]: evaluated! 
[2017-10-20 01:39:57,003 AE_UNIGRAMA_6L_UNDER_01.py:138]: generating reports ... 
[2017-10-20 01:39:57,636 AE_UNIGRAMA_6L_UNDER_01.py:141]: done!
[2017-10-20 01:39:57,636 AE_UNIGRAMA_6L_UNDER_01.py:157]: >> experiment AE_UNIGRAMA_6L_UNDER_01 finished!
